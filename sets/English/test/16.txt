Additionally, problems here may or may not contain randomness, and each of these variants have very slightly different corresponding theories, but the underlying ideas are essentially the same.  Do you want to find the shortest path through a maze?  Or how to steer a fighter jet to perform a barrel roll?  Or how to move a robot arm around an obstacle?  These are MDP/optimal-control problems.

2.) State estimation problems ("filtering," "smoothing," and trajectory estimation).  Whereas in my last bullet point the goal was to get a system to a particular state, here the goal is to figure out what state a system is in.
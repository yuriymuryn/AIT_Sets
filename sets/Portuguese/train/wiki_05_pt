O distrito de Leiria é um distrito português, dividido entre as províncias tradicionais da Beira Litoral e da Estremadura. Limita a norte com o distrito de Coimbra, a leste com o distrito de Castelo Branco e com o distrito de Santarém, a sul com o distrito de Lisboa e a oeste com o oceano Atlântico. Tem uma área de (13.º maior distrito português) e uma população residente de (2011). A sede do distrito é a cidade com o mesmo nome e inclui a sede administrativa da Diocese de Leiria-Fátima.
Tem 110 freguesias distribuídas pelos seus 16 concelhos .
O distrito de Leiria subdivide-se nos seguintes dezasseis municípios:
Na atual divisão principal do país, o distrito encontra-se totalmente integrado na Região Centro, distribuindo-se os seus municípios pelas subregiões do Oeste (o qual foi transferido para a Região Centro em 2002, com a redução da área da Região de Lisboa e Vale do Tejo), Pinhal Litoral e Pinhal Interior Norte. Em resumo:
O concelho mais populoso é o de Leiria, que é o único com mais de cem mil habitantes. Fora Leiria, apenas Alcobaça, Caldas da Rainha e Pombal têm mais de 50 mil habitantes.
Os concelhos situados no nordeste têm vindo a perder população nos últimos anos.
Leiria é o concelho com menor percentagem de população com mais de 65 anos.
Leiria, Caldas da Rainha e Marinha Grande são os concelhos cuja população mais tem crescido.
Atualmente, a dinâmica económica do distrito é, predominantemente, do tipo urbano-industrial, havendo apenas alguns concelhos nos quais as condições necessárias para o arranque industrial não têm sido reunidas, continuando maioritariamente agrícolas e rurais.
De acordo com um relatório da NERLEI, Associação Empresarial de Leiria, o setor primário produz no distrito, relativamente aos totais nacionais:
- 80% de peras
- 35% de maçãs
- 20% de pêssegos
- 15% de vinhos de qualidade
- 50% de efectivos suinícolas
- de pinhal em regime contínuo
- de floresta comunitária
- 17% de pesca
- e uma boa parte do queijo denominado Rabaçal
Relativamente ao setor secundário, Leiria é o distrito líder no fabrico de moldes metálicos, tendo, igualmente, uma grande importância as industrias extractiva, transformadora e a construção civil.
Mesmo assim, a imagem de marca ligada ao vidro, aos plásticos, à madeira, aos têxteis e aos agroindustriais, sendo um dos distritos com maiores índices de PME/Excelência.
A indústria encontra-se principalmente nos concelhos de Leiria, Alcobaça, Marinha Grande, Pombal e Caldas da Rainha, que garantem 70% das unidades industriais do distrito e 75% do emprego neste setor.
Por sua vez, o setor terciário assume mais de 50% de todo o tecido empresarial do distrito, tendo vindo a população ativa deste sector a crescer progressivamente nos últimos anos. Este crescimento tem ocorrido sensivelmente na mesma proporção de crescimento da malha dos principais centros urbanos, situando-se já acima dos 40%.
Mais de 70% das empresas deste setor estão ligadas ao comércio, tendo os serviços uma preponderante cobertura com os principais balcões bancários, e as mais importantes seguradoras, tal como uma boa presença de empresas de transportes, de serviços de saúde privados e públicos e uma notável rede escolar da pré-primária ao superior, com vários pólos de universidades privadas e seis escolas superiores do Instituto Politécnico de Leiria, nesta cidade, nas Caldas da Rainha e em Peniche.
Também a imprensa, falada e escrita, tem no distrito delegações dos principais órgãos nacionais.
Relativamente ao transporte ferroviário, verifica-se uma debilidade, devido à visível decadência da linha do Oeste. Contudo, esta situação poderá vir a ser alterada com a definição da futura linha de alta velocidade.
O concelho de Pombal é servido pela Linha do Norte, a principal linha ferroviária portuguesa.
Quanto à rede viária, o distrito é cruzado pela A1, e pela A8, até à cidade de Leiria, sendo as acessibilidades aos restantes concelhos facilitadas por IP e IC.
Existem ainda importantes portos de pesca em Peniche e na Nazaré, a cobertura em quase todos os concelhos por parques industriais e pela rede de gás natural, estando a caminho da totalidade o abastecimento de água e o saneamento básico.

O distrito de Lisboa é um distrito português, que limita a norte com o distrito de Leiria, a leste com o distrito de Santarém, a sul com o distrito de Setúbal e a oeste com o oceano Atlântico. O distrito tem uma área de e é assim o 16.º maior distrito português. A população residente, em 2009, era de . A capital deste distrito é a cidade de Lisboa.
A divisão do distrito de Lisboa é a seguinte:
Segundo as estatísticas do Instituto Nacional de Estatística em 2009, residiam no distrito de Lisboa , distribuídos pelos dezasseis concelhos, sendo os municípios da Área Metropolitana de Lisboa os mais populosos. A Grande Lisboa concentra uma média de 2 milhões de habitantes.
A estrutura da população mostra que 56% tem entre 15 e 64 anos, sendo o peso idêntico entre a população entre os 0 e os 14 e a com mais de 65 anos (15% e 17 % respectivamente).
Em termos evolutivos, a população entre os anos de 1980 e 1999 manteve-se estável com mais ou menos 2 milhões de habitantes. Desde o ano de 1999 até o ano de 2005 a população do distrito cresceu em cerca de 200 mi habitantes. Em 2005, o distrito de Lisboa registou uma taxa de natalidade de 11,6 por mil e uma taxa de mortalidade de 2,6 por mil. A população encontra-se em renovação.
O distrito de Lisboa subdivide-se nos seguintes dezasseis municípios:
A estrutura empresarial que domina o distrito é o setor terciário (79%). O setor primário representa 1% da economia, enquanto o secundário representa 19%.

O Distrito de Portalegre é um distrito português, pertencente integralmente à sub-região e Comunidade Intermunicipal do Alto Alentejo. Limita a norte com o distrito de Castelo Branco, a leste com a Espanha, a sul com o distrito de Évora e a oeste com o distrito de Santarém. Tem uma área de (6.º maior distrito português) e uma população residente de 118 506 habitantes (AERA-INE 2012).
A sede do distrito é a cidade homónima. O distrito engloba 69 freguesias subdivididas por 15 municípios:
À data da criação dos distritos (1835), o município de Olivença já se achava administrado por Espanha (apesar de constituir território português, segundo o Congresso de Viena), não tendo sido adstrito a nenhum dos distritos portugueses. No entanto, é provável que integrasse, pela proximidade geográfica e cultural, o distrito de Portalegre e não o de Évora.
Na actual divisão principal do país, o distrito integra-se na Região do Alentejo e todos os municípios, pertencem à sub-região do Alto Alentejo. Formam a CIMAA - Comunidade Intermunicipal do Alto Alentejo.
Os principais núcleos urbanos são as cidades de Elvas (16.640 habitantes), Portalegre (15.300 habitantes), Ponte de Sôr (7.700 habitantes) e a vila de Campo Maior (7.300 habitantes).
O Distrito de Portalegre é o distrito português com menos população, segundo os dados do Anuário Estatístico da Região Alentejo do INE de 2012 com 111.009 habitantes. Embora o distrito tenha 15 municípios, existem apenas 3 cidades nele, sendo então os restantes 12 concelhos sediados por vilas. Apesar da capital de distrito ser a cidade de Portalegre, é Elvas a maior cidade do distrito, e também o concelho do distrito com mais população.
"Lista ordenada dos concelhos pertencentes ao distrito de Portalegre e respetiva população da sede de concelho e do concelho tendo em conta os censos do INE:"
Os estabelecimentos marcados com (*) incluem ensino secundário.
O Pólo de Formação Superior de Elvas é uma parceria entre a Universidade de Évora, a Universidade Técnica de Lisboa, a Universidade da Estremadura, o Instituto Politécnico de Portalegre e os Municípios de Elvas, Badajoz, Olivença, Campo Maior, Alandroal, Arronches, Borba, Vila Viçosa, Estremoz e Sousel. Este pólo iniciou funções no ano letivo 2013/2014 com pós-graduações nas áreas da Regeneração Urbana e Económica. No futuro pretende-se que este pólo venha a ter mais oferta superior.
O Distrito de Portalegre integra juntamente com os distritos de Évora, Faro, Castelo Branco, Beja e Setúbal a Área Judicial de Évora que é comandada pelo Tribunal da Relação de Évora e é neste distrito composto por uma comarca, dois tribunais de primeira instância, quatro tribunais de instância local e um tribunal de secção de proximidade. Os tribunais são os seguintes e caracterizam-se da seguinte forma:

O distrito do Porto é um distrito de Portugal que correspondente ao núcleo da província tradicional do Douro Litoral. Limita a norte com o distrito de Braga, a leste com o distrito de Vila Real, a sul com o distrito de Viseu e com o distrito de Aveiro e a oeste com o Oceano Atlântico. Tem uma área de (17.º maior distrito português) e uma população residente de (2009). A sede do distrito é a cidade com o mesmo nome.
O distrito do Porto subdivide-se nos seguintes dezoito municípios:
Na actual divisão principal do país, o distrito integra-se na Região Norte, espalhando-se os seus municípios pelas sub-regiões do Grande Porto e Tâmega. Em resumo:
Há que salientar que o Porto é a sede e a capital de uma grande área metropolitana portuguesa: a Área Metropolitana do Porto, que agrupa 17 municípios com 2 294 741 habitantes em 2 089 km² de área, presidida, na atualidade, por Hermínio Loureiro. Tem uma densidade populacional próxima de 1098 hab/km². O Porto e a Área Metropolitana do Porto (NUTS III) constituem o núcleo estrutural da Região Norte (NUTS II), que tem uma área de 21 278 km² (24% do Continente) e uma população de 3 689 609 habitantes (Censos de 2011), correspondendo a 37% de Portugal Continental e a 35% do Estado-nação português, sendo, portanto, a região mais populosa e de maior dimensão do país e a região onde se situam a maioria das pequenas e médias empresas, sendo também a que mais contribui para as exportações nacionais, sendo a única região que exporta mais do que importa. A Região Norte produz 40% do valor acrescentado do país e tem 50% do emprego industrial, tendo uma taxa de cobertura das importações pelas exportações de 129%, contra a média nacional de 74%. Esta região é servida por duas importantes infra-estruturas: o Porto de Leixões, que representa 25% do comércio internacional português e movimenta cerca de 14 milhões de toneladas de mercadorias por ano, e o Aeroporto Francisco Sá Carneiro, que é o melhor aeroporto de Portugal em termos de espaço na aerogare. Em termos de movimentos aéreos de carga e de passageiros, é o segundo maior de Portugal, tendo sido galardoado como o melhor do mundo na categoria de aeroportos até 5 milhões de passageiros.
Dando continuidade à reorganização administrativa, na actualidade, verifica-se o forte aumento de importância das Áreas Metropolitanas e Comunidades Intermunicipais em detrimento dos distritos. De acordo com a lei nº 45/2008 de 27 de Agosto, das áreas metropolitanas, criadas em 2003, só subsistiram as chamadas clássicas: a Área Metropolitana do Porto e a Área Metropolitana de Lisboa, sendo as restantes reorganizadas em Comunidades Intermunicipais. A razão óbvia para esta situação, para além de razões de associação económica e administrativa, tem a ver com o facto das populações não se identificarem com o distrito a que foram sujeitos, como acontece, a título de exemplo paradigmático, com os municípios de Espinho, Santa Maria da Feira, Arouca, São João da Madeira, Oliveira de Azeméis e Vale de Cambra, municípios da Área Metropolitana do Porto, que, apesar de pertencerem ao Distrito de Aveiro, sempre tiveram uma forte ligação socio-económica ao espaço urbano do Porto, para além da proximidade territorial à cidade do Porto e do seu enquadramento identitário nos municípios do Distrito do Porto, factos que se acentuaram na contemporaneidade. Com a lei 75/2013 de 12 de Setembro, dando continuidade à reorganização administrativa e à restruturação de competências na organização do território, os distritos foram relegados para um plano secundário, com o protagonismo administrativo das Áreas Metropolitanas e das Comunidades Intermunicipais.

Santarém é um distrito de Portugal, pertencente às Unidades Territoriais (sub-regiiões) da Lezíria do Tejo e do Médio Tejo. Limita a norte com o Distrito de Leiria e com o Distrito de Castelo Branco, a leste com o Distrito de Portalegre, a sul com o Distrito de Évora e com o Distrito de Setúbal e a oeste com o Distrito de Lisboa e com o Distrito de Leiria. Tem uma área de 6 747 km² (3.º maior distrito português) e uma população residente de 465 701 habitantes (2009). A sede do distrito é a cidade com o mesmo nome.
O distrito de Santarém subdivide-se nos seguintes 21 municípios:
Até 2002, o distrito integrava-se quase totalmente na Região de Lisboa e Vale do Tejo, com excepção de Mação, o único concelho que pertencia à Região Centro e à sub-região do Pinhal Interior Sul. Os restantes municípios constituíam duas sub-regiões de Lisboa e Vale do Tejo: Médio Tejo e Lezíria do Tejo.
Na actual divisão do país, após a reformulação dos contornos e renomeação da região de Lisboa e Vale do Tejo, o distrito passou a repartir-se entre as regiões Centro e do Alentejo; da Região Centro fazem parte agora as sub-regiões do Médio Tejo e Pinhal Interior Sul, e ao Alentejo pertence a sub-região da Lezíria do Tejo.
Assim, em resumo:
 Evolução da População desde 1864 até 2011 
 Evolução dos Grupos Etários (de 1981 a 2011)
Segundo o INE, o distrito de Santarém tinha em 2010 cerca de 46,500 empresas registadas. A média regional do segmento de PME anda em torno de 5.20% e 0.04% para o segmento de Grandes empresas, o que indica que no distrito existem em torno de 2,418 PME e cerca de 19 Grandes. Os restantes 97.76% respetivos a Micro empresas totalizam cerca de 44,063.
Outras estatísticas, da D&B, indicam que existiam 18,952 empresas registadas em 2011 no distrito. Contudo, esta amostra contabiliza apenas empresas com obrigatoriedade legal de prestar contas.

Distrito de Setúbal é um distrito de Portugal. Está dividido entre as províncias tradicionais da Estremadura e do Baixo Alentejo. Limita a norte com o Distrito de Lisboa e com o Distrito de Santarém, a leste com o Distrito de Évora e com o Distrito de Beja, a sul com o Distrito de Beja e a oeste com o Oceano Atlântico. Tem uma área de 5 064 km² (8.º maior distrito português) e uma população residente de 866 794 habitantes (2009). A sede do distrito é a cidade com o mesmo nome. Actualmente, é o distrito com maior propensão ao desenvolvimento nas áreas da saúde, trabalho, economia, turismo, demografia e educação, devido à proximidade ao mar, à eficiente rede de escolas existentes e à fácil captação de investimentos no distrito. 
O distrito de Setúbal integra 13 municípios:
 Evolução da População Entre 1864 e 2011 
 Evolução dos Grupos Etários (de 1981 a 2011)
O relevo do distrito de Setúbal é maioritariamente constituído por planícies. As principais serras do distrito de Setúbal são a Serra da Arrábida e a Serra de Grândola. Na Costa da Caparica (no concelho de Almada) há uma arriba (Arriba Fóssil). O distrito de Setúbal é atravessado pelo Rio Sado e os seus afluentes.
O distrito de Setúbal é o mais recente do país.
Foi o único não criado pela reforma de Mouzinho da Silveira (1835), incluindo-se então o seu território no distrito de Lisboa.
Só seria autonomizado face a este, em virtude do seu grande crescimento económico, pelo governo da Ditadura Militar, em 22 de Dezembro de 1926.
No entanto, pode ter havido uma motivação adicional para a criação deste distrito: uma das primeiras decisões do novo regime foi a de restaurar o concelho de Palmela, que era então uma simples freguesia do município setubalense. Nesta cidade, quando se toma conhecimento da intenção do Governo, começam a agitar-se as forças políticas, alarmadas com a possibilidade de perderem uma importante parcela do território concelhio; é-lhes então dada a notícia de que, em compensação dessa perda, seria criado um novo distrito, de que Setúbal seria a capital – veja-se, a este propósito, o que foi publicado pelo jornal O Setubalense.

O Distrito de Viana do Castelo é um distrito português que pertence à província tradicional do Minho. Está limitado a norte e leste por Espanha, a sul pelo Distrito de Braga e a oeste pelo Oceano Atlântico. Tem uma área de 2 255 km² (o menor – décimo oitavo – distrito português) e uma população residente de 250 390 habitantes (2009). A sede do distrito é a cidade com o mesmo nome.
Povoações do distrito:
 Evolução da População desde 1864 até 2011
 Evolução dos Grupos Etários (entre 1981 e 2011) 
Mais dados sobre a evolução da população em:
• A Evolução da População do Distrito de Braga de 1864 a 2011
• A Evolução da População Portuguesa de 1864 a 2011
O distrito de Viana do Castelo subdivide-se nos seguintes dez municípios:
Na atual divisão principal do país, o distrito faz parte da Região Norte, onde constitui a sub-região do Minho-Lima. Em resumo:

O distrito de Vila Real é um distrito de Portugal pertencente à província tradicional de Trás-os-Montes e Alto Douro. Limita a norte com a Espanha, a leste com o Distrito de Bragança, a sul com o Distrito de Viseu e a oeste com o Distrito do Porto e com o Distrito de Braga. A sua área soma 4 328 km² (sendo o 11.º maior distrito português) e a sua população residente é de 213 775 habitantes (2009). A sede do distrito é a cidade com o mesmo nome.
O distrito de Vila Real subdivide-se nos seguintes catorze municípios:
Na divisão do país em unidades territoriais para fins estatísticos (NUTS), o distrito faz parte da Região Norte, onde se divide pelas sub-regiões do Douro, de Alto Trás-os-Montes e do Tâmega. Em resumo:

O Douro é uma sub-região estatística portuguesa, parte da Região Norte, integrando partes do Distrito de Bragança, Distrito de Vila Real, Distrito de Viseu e Distrito da Guarda e abrangida pela Comissão de Coordenação e Desenvolvimento Regional do Norte. Limita a norte com o Alto Trás-os-Montes, a leste com a Espanha, a sul com a Beira Interior Norte e o Dão-Lafões e a oeste com o Tâmega. Tem uma área de 4112 km² e uma população de habitantes (censos de 2011).
Compreende 19 concelhos:
Note-se que em 2008, Vila Flor passou a integrar a sub-região do Alto Trás-os-Montes.

Uma democracia direta é qualquer forma de organização na qual todos os cidadãos podem participar diretamente no processo de tomada de decisões. As primeiras democracias da antiguidade foram democracias diretas. O exemplo mais marcante das primeiras democracias diretas é a de Atenas (e de outras cidades gregas), nas quais o povo se reunia nas praças e ali tomava decisões políticas. Na Grécia antiga o "povo" era composto por pessoas com título de cidadão ateniense. Porém, mulheres, escravos e mestiços não tinham direito a esse título, exclusivo para homens que fossem filhos e netos de atenienses. No mundo atual o sistema que mais se aproxima dos ideais da democracia direta é a democracia semidireta da Suíça.
Num sistema de democracia indireta (ou democracia representativa), os cidadãos elegem representantes, os quais serão responsáveis pela tomada de decisões em seu nome. Este é o processo mais comum de tomada de decisão nos governos democráticos, e por isto é também chamado de mandato político.
Já em regime de democracia direta, os cidadãos não delegam o seu poder de decisão. As decisões são tomadas através de assembleias gerais. Se por acaso precisam de um representante, este só recebe os poderes que a assembleia quiser dar-lhe, os quais podem ser revogados a qualquer momento. Assim, na democracia direta, o poder do representante se assemelha ao que é conferido por um mandato comercial.
Democracia direta pura, como tal, não existe em nenhum país moderno a nível nacional. Existe hoje em dia apenas para decisões de caráter estritamente local ou paroquial em alguns cantões da Suíça ("Glarus" e "Appenzell Innerrhoden"), e na cidade sueca de Vallentuna.
Por definição, a própria forma de democracia direta a ser implementada em um país deve ser escolhida com ampla participação popular, seja através de plebiscitos e/ou referendos, assembléias populares e congresso geral do povo, governo2.0 (platafomas digitais colaborativas que podem ser utilizadas para elaboração de leis), etc.
Entretanto, o termo "democracia direta" também é usado para descrever sistemas mistos, onde democracia "direta" e "indireta" coexistem; seu nome mais correto seria "democracia semidireta". Nesses sistemas de democracia semidireta, além da existência de representantes eleitos que tomam a maior parte das decisões em nome dos cidadãos, estes também têm a oportunidade de influenciá-las através de iniciativas populares, plebiscitos e referendos (ratificação de decisões de representantes). A Suíça, por exemplo, se considera oficialmente uma "democracia semidireta", com o sistema representativo e de referendos e plebiscitos coexistindo; somente no cantão de "Glarus" e no semicantão "Appenzell Innerrhoden" a democracia é praticamente direta, com o Povo se reunindo ao ar livre no vilarejo para tomar decisões.
Mais da metade dos referendos realizados a nível nacional entre 1900 e 1993 - 52 porcento - tiveram lugar na Suíça.
Outra forma de análise conceitua todas as democracias como diretas pois todo o poder emana do povo que o exerce diretamente com uma delegação condicionada a representantes (na suposição que os representantes cumprirão os seus programas pré-eleitorais pactuados com o cidadão, podendo o não cumprimento resultar em cassação de mandato através de ação na justiça) ou diretamente sem delegação condicionada.
Pelo aspecto político, em termos gerais, podemos definir a democracia direta como uma entre seis formas de "governo", a saber:
Na Suíça, maioria simples é suficiente nas cidades e estados (chamados cantões ou semicantões (veja Cantões da Suíça). Já em nível nacional, podem ser necessárias "maiorias duplas", cuja intenção seria de confirmação de qualquer lei criada por um cidadão
Maiorias duplas são, primeiramente, a aprovação pela maioria dos votantes e, depois, a maioria dos estados em que a votação teria sido aprovada. Uma lei criada por um cidadão não pode ser aprovada se a maioria das pessoas a aprova, mas não a maioria dos estados. A maioria dupla foi instituída em 1890, copiando-se o modelo vigente no congresso americano, onde os deputados votam representando as pessoas e os senadores, os estados. Aparentemente este método tem sido muito bem sucedido desde 1890.
Contrastando com o conceito de plebiscitos promovidos por governos para obter suporte a uma política de governo já estabelecida, como no caso das constituições da França e da Áustria (ou mesmo do Brasil), na democracia semidireta da Suíça não compete ao Governo nem ao Parlamento a decisão de submeter qualquer matéria à decisão popular. Em consequência os instrumentos de "democracia direta" da Suíça são os meios de que o Povo dispõe para se opor, e para controlar, políticas criadas pelo governo e pelos partidos políticos.
Na Suíça o Povo tem a última palavra sobre questões essenciais, num sistema chamado de "democracia semidireta". Além do Parlamento, os cidadãos comuns podem participar da elaboração da Constituição e das leis. E os suíços não se abstêm de o fazer. Na Suíça, ao contrário da maioria dos países onde há plebiscitos, não compete ao Governo nem ao Parlamento a decisão de submeter qualquer matéria à decisão popular, mas sim a seu Povo.
Pelo menos quatro vezes por ano os cidadãos suíços recebem um envelope da Confederação Suíça, de seu Cantão ou de sua Comuna e são convocados a opinar sobre assuntos específicos.
Ao contrário das "democracias representativas" puras, os eleitores suíços podem se manifestar amiúde, se constituindo assim na instância política suprema, e não apenas episódica.
A grande maioria das votações se faz de forma secreta utilizando urnas, ou enviando envelopes fechados pelo correio. Em dois cantões ainda se utiliza o sistema de "assembleia popular" ("Landsgemeinde"), onde os cidadãos votam em praça pública, erguendo suas mãos.
Mediante um abaixo-assinado de cem mil pessoas (cerca de 1,34% da população), o povo suíço pode obrigar o governo a submeter à votação um novo artigo, uma emenda ou uma revisão constitucional
Outro instrumento muito importante da democracia semidireta suíça é o referendo, que permite aos cidadãos aceitar ou rejeitar decisões tomadas pelo Parlamento. Algumas leis requerem obrigatoriamente a consulta popular antes de entrarem em vigor; é o que se chama de "referendo obrigatório". Em outros casos, os cidadãos que queiram se opor a uma determinada lei aprovada pelo Parlamento na Suíça deverão tentar reunir 50.000 assinaturas (cerca de 0,67% da população), e assim ter direito a convocar um "referendo facultativo", que poderá revogar essa lei.
Uma das mais importantes consequências benéficas desse sistema de controle popular do parlamento é que esse, sabendo que uma lei depois de aprovada por ele poderá ser revogada pelo Povo, procura consultar todos os grupos da sociedade que a ela possam se opor, tentando obter um consenso o mais amplo possível antes de aprová-la.
A "Landsgemeinde" ("Assembleia provincial", em alemão) é uma das mais antigas e mais puras formas de "democracia direta", pela qual os eleitores se reúnem ao ar livre, e votam erguendo suas mãos. Introduzida no cantão suíço de Uri em 1231, só permanece em vigor, em nível cantonal, no semicantão "Appenzell Innerrhoden" e no cantão de "Glarus". Nas outras localidades os eleitores suíços exprimem sua vontade através das urnas. A "Landsgemeinde" normalmente ocorre uma vez por ano, na primavera. É nessa ocasião que se elegem os governantes, os juízes e os representantes na câmara alta do parlamento federal. A "Landsgemeinde" é também o local das votações sobre assuntos cantonais. A contagem de votos é aproximada; ela se baseia mais numa estimativa que na contagem efetiva das mãos erguidas.
O Canadá tem feito algumas experiências no uso da democracia direta. Uma das mais importantes foi a criação do "The Citizens' Assembly on Electoral Reform", um grupo criado pelo governo da Colúmbia Britânica para investigar e propor alterações no sistema de eleições provinciais; em 25 de outubro de 2004 esse grupo propôs a substituição do sistema eleitoral existente ' pelo sistema ', cuja aprovação foi submetida ao eleitorado em geral, num referendo realizado em 17 de maio de 2005, conjuntamente com as eleições.
Na Colúmbia Britânica, para ser considerada aprovada e tornada lei pelo referendo, a proposta teria que passar pela regra da "maioria dupla", ou seja obter a aprovação de 60% do total votos válidos na província e simultaneamente obter mais de 50% dos votos em pelo menos 48 dos 79 distritos eleitorais; ou seja, vencer por maioria simples em 60% dos distritos.
A proposta obteve maioria simples em 77 dos 79 distritos eleitorais. Porém o total de votos "sim" válidos, (57.69%) não atingiu o requisito mínimo de 60% para que a proposta se tornasse lei.
Processo idêntico foi iniciado pela província de Ontário, em março de 2006, e foi concluído em maio de 2007, com a seguinte recomendação: ""Nós, a Assembleia dos Cidadãos Sobre a Reforma Eleitoral, recomendamos uma nova maneira de votar que acreditamos ser apoiada pelas tradições da província e refletir os valores que são importantes para os ontarianos. A Assembleia recomenda que Ontário adote o sistema ", especificamente concebido para atender as necessidades de Ontário.”" A proposta foi submetida a referendo obrigatório, realizado em 10 de outubro de 2007, tendo sido derrotada por larga margem; a manutenção do atual sistema de votação "" recebeu 63.1% do total de votos válidos em Ontário, obtendo maioria simples em 102 dos 107 distritos eleitorais..
Na Itália, o projeto "Listapartecipata" cujo slogan é "O controle do governo nas mãos do Povo (e não só no dia das eleições)" é uma experiência de democracia direta que vem sendo posta em prática, e é similar ao projeto sueco, chamado "Demoex - democracia experimental". O Projeto Lista Partecipata permite que um grupo de pessoas se reúna e participe de discussões utilizando internet, telefone ou os correios para eleger um membro como candidato às eleições regionais. Em caso de vitória, o membro da lista eleito é obrigado a seguir as decisões tomadas por todos os membros dentro desse sistema de decisão multi-canal, e arriscando-se a ser automaticamente demitido do cargo se não o fizer (. Esse sistema de decisões, chamado Deciadiamo foi criado pela Fundação Telemática Livre, com sede em Roma.
O "Movimento per la Democrazia Diretta", cujo lema é "Ogni cittadino um membro del Parlamento" ("Cada cidadão um membro do Parlamento") promove a democracia direta na Itália, e coordena várias iniciativas similares.
As duas maneiras de democracia, representativa e direta, coexistem na França. Além do sistema representativo tradicional, contam os eleitores franceses com o procedimento referendário previsto no artigo 11 da constituição francesa, à qual foi incluído em 28 de março de 2003, e pelo qual os projetos de deliberação ou de ato relevante da competência de uma coletividade podem, por sua iniciativa, ser submetidos, pela via do referendo, à decisão dos eleitores dessa coletividade..
Enquanto alguns países, como a Suíça e, num menor grau, a Itália, recorrem frequentemente aos referendos, por tradição histórica o uso do referendo é mais raro na França.
Em Portugal há que se considerar dois aspectos: o aspecto nacional e o aspecto local (municipal), uma vez que a organização política portuguesa, ao contrário do que ocorre em outros países, como no Brasil, não reproduz nos diversos níveis de governo o mesmo sistema político.
No plano nacional, Portugal, que é uma república parlamentarista, consagra o referendo de uma forma muito tímida, por razões históricas, escaldados que foram com o referendo perverso de 1933 - no qual as abstenções foram contadas como votos "sim" - e que culminou na instituição da ditadura de Salazar. Múltiplas salvaguardas constitucionais foram incorporadas na atual constituição portuguesa para assegurar que o referendo em Portugal não possa jamais vir a ser usado de maneira delegatória, e foram tantas que acabaram por restringir bastante a operacionalidade de seus referendos; apesar disso já três foram realizados em Portugal com sucesso.
Em Portugal o referendo é um instrumento de democracia semidireta, pelo qual os eleitores são chamados a pronunciarem-se, por sufrágio direto e secreto, em questões que o poder político pretenda resolver mediante ato normativo. É regulado pelo artigo n.° 115 da Constituição da República Portuguesa. A sua convocação é feita pelo Presidente da República sob proposta da Assembleia da República ou do Governo. Está previsto no mesmo artigo que o referendo pode partir de uma iniciativa popular, que apresenta a sua proposta à Assembleia da República, e dependo da sua aceitação é enviada para o Presidente da República que decidirá favoravelmente ou contra a convocação do referendo.
O primeiro refendo português, depois da queda do Estado Novo, realizou-se em 28 de Junho de 1998, com a pergunta: "“Concorda com a despenalização da interrupção voluntária da gravidez, se realizada, por opção da mulher, nas 10 primeiras semanas, em estabelecimento de saúde legalmente autorizado?”", tendo vencido o "não" (1 356 754 votos, ou 50,07%).
Na esfera exclusivamente local (municipal) Portugal adota certos princípios de democracia direta, muito semelhantes aos adotados na Suíça.
Na Suécia um partido político local desenvolveu um projeto, denominado "Demoex - democracia experimental", que criou a tecnologia de computação e o software para votações através da internet, estando em operação experimental na cidade de Vallentuna, um subúrbio de Estocolmo. 
No plano nacional dois partidos promovem a plataforma da democracia direta na Suécia: o Direktdemokraterna eo Aktivdemokrati.
Na década de 90 consultas populares, referendos, iniciativas da sociedade civil e revogação de leis se tornaram instrumentos ao alcance do público da maioria dos países latino-americanos, com a incorporação em suas constituições de mecanismos de participação direta. Esses mecanismos de participação que já existiam na Colômbia, no Chile e Uruguai se generalizaram nos últimos 15 anos, mas emergem em contextos políticos muito diferentes entre si, e ainda são muitas vezes aplicados de maneira descaracterizada, esporádica e, às vezes, perversa, dizem os especialistas. As experiências – ou a falta delas – na região mostraram uma realidade que é muito diferente da existente na Suíça, onde o emprego mecanismos de democracia direta têm tradição de mais de um século de prática eficiente e exitosa.
Em países em que as instituições democráticas não são sólidas, ou são instáveis, como é o caso da maioria dos países da América Latina, se o chefe do Poder Executivo tem o poder de convocar consultas populares, existe um risco de que faça uso "político" dessa convocação, isto é, que se utilize da convocação para fins partidários, ideológicos, autoritários ou auto-legitimadores. Nos países de "baixa qualidade democrática", se o alcance desses instrumentos não forem muito bem definidos e delimitados nas suas constituições, existe o risco de que referendos e plebiscitos possam vir a influir negativamente na democracia; um chefe do poder executivo pode tentar convocar um referendo que mire além do tema da consulta, buscando sua auto-legitimação política, levando a plebiscito na realidade sua pessoa mais que nada, e pervertendo assim a função dos mecanismos de democracia direta. Há várias maneiras constitucionais de prevenir esses riscos; uma delas é proibir a realização de plebiscitos e referendos em anos eleitorais.
A democracia representativa precisa cuidar de ter sempre a seu alcance meios e modos constitucionais que impeçam seus instrumentos de vir a ser usados, perversamente, para fomentar a democracia delegativa - que é seu exato oposto - o que poderia conduzir, como no passado já conduziu, à criação regimes totalitários.
Em março de 2007 realizou-se, em Buenos Aires, a "Conferência Internacional sobre Democracia Direta na América Latina", com a participação de acadêmicos da região e também do Canadá, da Espanha, Itália e Suíça, e da Universidade de Genebra, que foi promovida pela organização intergovernamental "IDEA" (sigla em inglês do "Instituto Internacional para a Democracia e a Assistência Eleitoral") com sede na Suécia. Em maio de 2008, na cidade suíça de Lucerna, se realizará a primeira "Conferência Mundial sobre Democracia Direta".
Em 1996 a Argentina regulamentou a "iniciativa cidadã", pela qual o Povo pode apresentar projetos de lei de seu interesse ao Congresso, que deverá submetê-los à votação em no máximo doze meses (curiosamente o dispositivo não prevê sanções ao Congresso, caso não o faça). A lei 24 747 fixou em 1,5% dos eleitores, distribuídos pelo menos por seis distritos eleitorais, o número necessário de assinaturas para essa convocação. Não podem ser propostas emendas constitucionais.
A constituição argentina não contempla a iniciativa popular, nem o veto popular (quer dizer os cidadãos não podem convocar um plebiscito ou referendo para propor uma reforma, ou para derrubar uma lei). Não há o direito "revogatório de mandato"" ("recall) a nível nacional.
Desde 2004, na Bolívia, os cidadãos têm o "direito de iniciativa" para convocar um referendo de carater nacional e vinculante, mediante um abaixo-assinado por 6% dos eleitores. Para referendos regionais esse número sobe para 8% dos eleitores, e para referendos municipais, 10%. São excluídos assuntos fiscais, de segurança interna e externa, e da divisão política da república. As resoluções do referendos se aprovam por maioria simples do eleitorado, e exigem um quórum de no mínimo 50% de participação. Não podem ser realizados no período entre os 120 dias anteriores e os 120 dias posteriores à realização de eleições ("quarentena").
A constituição brasileira (1988) prevê, em seu artigo 14, que "a soberania popular será exercida pelo sufrágio universal e pelo voto direto e secreto, com valor igual para todos, e, nos termos da lei, mediante": I - "plebiscito;" II - "referendo;" III - "iniciativa popular". A constituição, e a lei que a regulamentou, estabelecem que a iniciativa popular consiste na apresentação de um projeto de lei, subscrita por no mínimo 1% do eleitorado nacional, distribuídos por pelo menos cinco estados, com não menos do que 0,3% dos eleitores de cada um deles. Cabe à Câmara dos Deputados aceitá-lo ou rejeitá-lo, e o projeto deve versar sobre um único tema.
Todos os estados brasileiros incorporam o "direito de iniciativa" legislativa. O Amapá, Espírito Santo, Maranhão, Pará, Paraná, Paraíba, Piauí, Rio de Janeiro, Rio Grande do Norte, Santa Catarina, Tocantins e Sergipe o incluem (ou deverão fazê-lo) nas Leis Orgânicas dos Municípios. No Acre, Alagoas, Amapá, Amazonas, Bahia; Ceará, Espírito Santo, Goiás, Minas Gerais, Paraíba, Pará, Pernambuco, Piauí, Río Grande do Sul; Roraima, São Paulo, Sergipe e Santa Catarina a "iniciativa legislativa" incluí o direito a propor emendas constitucionais. As constituições do Amapá, Ceará, Mato Grosso, Pará, Paraná, Sergipe, Rio de Janeiro, Rio Grande do Norte, Rio Grande do Sul e Santa Catarina contém artigos específicos que estabelecem os mecanismos de Iniciativa, Referendo, e Plebiscito como formas de expressão popular; embora apenas as constituições do Mato Grosso, Pará, Rio de Janeiro, Rio Grande do Sul e Sergipe especifiquem seus alcances e limites, detalhadamente, em artigos específicos. A maioria desses mecanismos foi aprovada entre 1989 e 1990.
Várias cidades brasileiras tem desenvolvido formas de participação popular ativa na vida do município, especialmente com a prática de Orçamento Participativo, como é o caso de Porto Alegre, Recife, Belo Horizonte, Suzano, Contagem, Ribeirão Preto, entre outras.
O Chile não possui nenhum tipo de iniciativa popular a nível nacional. Várias organizações e políticos advogam a incorporação de mecanismos de democracia direta à constituição chilena.
A constituição de 1967 do Equador já previa a realização de plebiscitos em várias circunstâncias, tais como reformas constitucionais proposta pelo Poder Executivo que fosse derrotada no Poder Legislativo, reformas aprovadas pelo Poder Legislativo com as quais o Poder Executivo estevisse em desacordo, total ou parcial, projetos de lei de importância fundamental para o progresso do país, decisões de transcendetal importância para os interesses da nação, e outros. As constituições subsequentes ampliaram as possibilidades de consulta popular e a atual constituição (1998) prevê a figura "revogatória de mandato" ("recall").
No Peru os referendos tornaram-se obrigatórios, desde 1993, para alterações na constituição, exceto se uma reforma constitucional for aprovada no Congresso por duas legislaturas consecutivas, e obtenha, em cada caso, uma votação favorável superior a dois terços do número legal de congressistas (maioria qualificada). Os mecanismos de democracia direta incluídos na constituição do Peru são bem mais limitados que os da constituição venezuelana, e não podem ser vistos como instrumentos que promovam a participação dos cidadãos nas decisões políticas, mas apenas como instrumentos criados para conter o poder dos partidos políticos e, em especial, do parlamento.
O Uruguai é o país latino-americano que tem a maior e mais antiga experiência com instrumentos da democracia direta, tendo incorporado seus mecanismos pela primeira vez em 1934, e posteriormente os ampliou e melhorou. O plebiscito uruguaio de 1989, que deteve os julgamentos contra militares acusados de violar direitos humanos, foi considerado muito importante, e a partir dessa experiência, iniciou-se uma etapa "contestatória" de referendos sendo convocados para impedir privatizações, ou para frear uma redução nas aposentadorias.
Até os anos 90, os plebiscitos no Uruguai eram utilizados pelos partidos políticos para dirimir suas diferenças, inclusive diferenças intrapartidárias. Isso mudou, e agora os políticos uruguaios só costumam aderir a essas consultas depois do tema ter sido lançado pelos movimentos sociais.
Os cidadãos uruguaios têm o "poder de iniciativa" para convocar reformas constitucionais, sendo para isso requeridos 10% de assinaturas dos eleitores. Em 2000 foi aprovada a lei n° 17.244, que incorporou à constituição uruguaia um interessante processo em duas etapas, pelo qual os cidadãos uruguaios, reunindo 2% de assinaturas dentre os eleitores, podem, durante os 150 dias contados da publicação de uma nova lei, interpor recurso de veto a essa lei. Se votarem a favor dessa interposição pelo menos 25% dos eleitores, uma consulta popular será convocada, para aprovar ou derrubar a referida lei.
A constituição venezuelana é a única na América Latina que prevê a possibilidade da revogação do mandato presidencial, o chamado "recall", e é uma das poucas que inclui a obrigatoriedade de submeter a referendo cada emenda ou reforma constitucional, sendo a menos restritiva para fixar o número de votos necessários para introduzir mudanças.
Os venezuelanos podem convocar um referendo consultivo em matérias de "especial transcendência nacional", mediante abaixo-assinado por 10% dos eleitores. O referendo contra leis e decretos propostas pelo presidente pode também ser solicitado por 10% dos eleitores. Para que os resultados de um referendo sejam válidos devem nele votar pelos menos 40% dos eleitores inscritos (quorum). Não podem ser submetidas a referendo matérias relativas ao orçamento, aos impostos, ao crédito público e à anistia; bem como as leis que protejam, garantam, ou ampliem os "direitos humanos". A constituição venezuelana permite a revogação de mandato em todos os cargos e magistraturas eleitas, inclusive do presidente da república, pela solicitação de um número não inferior a 20% dos eleitores inscritos na circunscrição correspondente. A revogação de mandato se dará se o número dos que votarem pela revogação for superior aos votos obtidos pelo eleito na sua eleição original, sendo necessário um quorum mínimo de 25% de participação.
Os cidadãos venezuelanos têm "direito de iniciativa" legislativa e popular (0,1%). Também podem promover uma reforma constitucional mediante abaixo-assinado por 15% dos eleitores inscritos.
Além do crescente desencanto com os políticos profissionais, na democracia representativa a opinião do Povo só é consultada uma vez a cada quatro anos. E após serem eleitos, os políticos tradicionais podem agir praticamente como bem entenderem, até a próxima eleição
Essa separação em castas de governantes e governados faz com que os políticos estejam mais atentos às suas próprias vontades e vontades de outros poderes que não aquele que emana da eleição popular, como por exemplo o econômico. O político ocupa uma posição que foi criada pela delegação de um poder que não lhe pertence de fato, mas apenas de direito. Entretanto, ele age como se o poder delegado fosse dele, e não do eleitor. Isso torna sua vontade suscetível a todo tipo de fisiologismo e negociata das quais ele possa extrair mais poder, seja em forma de aliados políticos ou em forma de capital.
O fim da casta de políticos tornaria o jogo político-social mais intenso, com discussões verdadeiramente produtivas mobilizando a sociedade, pois atribuiria ao voto um valor inestimável, uma vez que pela vontade do povo questões de interesse próprio seriam decididas (imaginem o fervor que surgiria nas semanas que antecederiam uma votação a favor ou contra o aumento do salário mínimo, ou para cortes na previdência pública).
Os instrumentos de democracia semidireta, como são entendidos atualmente, resultam não só de construções políticos-processuais. Ultrapassam as limitações formais ou os institutos como o "plebiscito" e "referendo", ou os aspectos materiais que se prendem às formas de sua execução - na realidade decisões democráticas podem ser obtidas seja pelo medieval sistema de levantar mãos suíço ("Landsgemeinde"), ou pela mais atualizada técnica eletrônica digital - mas exigem, como pressuposto para poder se realizar, uma formação social consistente, em toda sua complexidade, que aja como um mecanismo indutor e controlador, criando meios de freios e contrapesos, de "accountabillity", nessa forma democrática de exercício da cidadania, fora do tripé dos três Poderes constituídos.
O então deputado federal Aécio Neves, que criou uma comissão parlamentar para estudar esse assunto, declarou:
A tecnologia digital possibilitou a construção de incontáveis redes digitais computadorizadas que viabilizam o voto direto e diário.
Por exemplo, através da rede TCP/IP, qualquer cidadão com acesso à internet poderia votar. Entretanto, mesmo que seja relativamente fácil colocar os mais longínqüos pontos da Terra em conexão permanente com a internet, é necessário um grande investimento de capital para que isso ocorra. O acesso à internet está disseminado em locais como instituições de ensino, repartições públicas, companhias privadas, agências de notícias e bibliotecas, porém são relativamente poucos os cidadãos com acesso caseiro (14,1 milhões no Brasil em março de 2006, contra os quase 126 milhões de eleitores que votaram nas últimas eleições).
Uma forma simples de resolver este problema seria a utilização de redes digitais já existentes e mais abrangentes, como por exemplo as lotéricas (atualmente, no Brasil, é possível enviar diversos tipos de informação ao aparato governamental via lotéricas, como a declaração de isenção do imposto de renda). Outra alternativa viável seria o voto pelo telefone.
Estas formas de votação têm em comum um ponto fraco: a autenticação. Seria necessário a criação de meios de autenticação suficientemente seguros para viabilizar esta televotação, ou votação descentralizada. Atualmente, no Brasil, a autenticação do voto é feita por meio da assinatura, um método falho e bem pouco sofisticado - mas já estão sendo feitas experiências com leitores biométricos instalados junto às urnas eletrônicas.
Na Suécia um projeto denominado "Democracy Experiment", ou DEMOEX, já desenvolveu a tecnologia de computação, e o software para votações através da internet, que está em operação experimental na cidade de Vallentuna, um subúrbio de Estocolmo. Também é usada pelo "The World Parliament Experiment."
Os primeiros anos das atividades do DEMOEX foram avaliados pela Universidade Mitthögskolan, na Suécia, num ensaio (em suéco) sob o título "Flexible representation by use of delegated voting - a case study of practical use", elaborado por Karin Ottesen, 2003.
Na Itália já opera o projeto "Listapartecipata", que tem como seu lema "O controle do governo nas mãos do Povo (e não somente no dia das eleições)", e cujos princípios são muito similares ao Demoex.
A Câmara dos Deputados do Congresso Brasileiro conta com uma comissão permanente denominada CLP - Comissão de Legislação Participativa, cuja função precípua é incrementar a participação popular na vida do legislativo brasileiro. A CLP desenvolve seu trabalho elaborando projetos de lei que podem nascer de propostas enviadas por qualquer cidadão brasileiro, sendo reunidas estas propostas no Banco de Ideias da CLP. Os membros da CLP e do próprio Congresso estão ainda constantemente sendo bombardeados com ideias de democracia direta divulgadas em páginas da internet, tais como democraciadireta.org e MDD-BrasiL.

Divisa Alegre é um município brasileira do estado de Minas Gerais, emancipado em 1995. Está localizado no norte de Minas Gerais, na microrregião de Salinas e compõe com outros municípios o Alto Rio Pardo, próximo à divisa de Minas Gerais e Bahia.
O município foi criado em 1995 e instalado em 1 de janeiro de 1997.
"Coordenadas:"
Latitude: -15.7261, -
Longitude: -41.3385
15° 43′ 34″ Sul, 41° 20′ 19″ Oeste.
Superfície
11.780 hectares
117,80 km² (45,48 sq mi)
Altitude:960 m
Clima: tropical com estação seca.
Número de habitantes:6.553
Densidade demográfica:49,9(hab./km²)
O município é localizado as margens da rodovia BR-116 trecho esse conhecido como Rio-Bahia pois no início de sua pavimentação em meados dos anos 60 ia do Rio de Janeiro à Bahia, hoje vai de Jaguarão, no estado do Rio Grande do Sul, na fronteira com o Uruguai até a cidade de Fortaleza, no estado do Ceará, ela liga Divisa Alegre ao norte com o estado da Bahia, e ao sul a primeira cidade onde passa a mesma rodovia é Medina no mesmo estado de Minas Gerais, a cidade vizinha mais próxima é Águas Vermelhas.

O ácido desoxirribonucleico (ADN, em português: ácido desoxirribonucleico"; ou DNA, em inglês: deoxyribonucleic acid") é um composto orgânico cujas moléculas contêm as instruções genéticas que coordenam o desenvolvimento e funcionamento de todos os seres vivos e alguns vírus, e que transmitem as características hereditárias de cada ser vivo. A sua principal função é armazenar as informações necessárias para a construção das proteínas de ARNs. Os segmentos de ADN que contêm a informação genética são denominados genes. O restante da sequência de ADN tem importância estrutural ou está envolvido na regulação do uso da informação genética.
A estrutura da molécula de ADN foi descoberta conjuntamente pelo norte-americano James Watson e pelo britânico Francis Crick em 7 de Março de 1953, o que lhes valeu o Prêmio Nobel de Fisiologia ou Medicina em 1962, juntamente com Maurice Wilkins.
Do ponto de vista químico, o ADN é um longo polímero de unidades simples (monômeros) de nucleotídeos, cuja cadeia principal é formada por moléculas de açúcares e fosfato intercalados unidos por ligações fosfodiéster. Ligada à molécula de açúcar está uma de quatro bases nitrogenadas. A sequência de bases ao longo da molécula de ADN constitui a informação genética. A leitura destas sequências é feita por intermédio do código genético, que especifica a sequência linear dos aminoácidos das proteínas. A tradução é feita por um RNA mensageiro que copia parte da cadeia de ADN por um processo chamado transcrição e posteriormente a informação contida neste é "traduzida" em proteínas pela tradução. Embora a maioria do ARN produzido seja usado na síntese de proteínas, algum ARN tem função estrutural, como por exemplo o ARN ribossômico, que faz parte da constituição dos ribossomos.
Dentro da célula, o ADN pode ser observado numa estrutura chamada cromossoma durante a metáfase. O conjunto de cromossomas de uma célula forma o cariótipo. Antes da divisão celular os cromossomas são duplicados por meio de um processo chamado replicação. Eucariontes como animais, plantas, fungos e protozoários têm o seu ADN dentro do núcleo enquanto que procariontes como as bactérias o têm disperso no citoplasma. Dentro dos cromossomas, proteínas da cromatina como as histonas compactam e organizam o ADN. Estas estruturas compactas guiam as interacções entre o ADN e outras proteínas, ajudando a controlar que partes do ADN são transcritas.
O ADN é um longo polímero formado por unidades repetidas chamadas nucleotídeos.
A cadeia de ADN tem 2,2 a 2,4 nanómetros de largura, e um nucleotídeo possui aproximadamente 0,33 nanómetros de comprimento. Embora os monômeros (nucleotídeos) que constituem o ADN sejam muito pequenos, os polímeros de ADN podem ser moléculas enormes, com milhões de nucleotídeos. Por exemplo, o maior cromossomo humano (cromossomo 1), possui 220 milhões de pares de bases de comprimento. Uma molécula de ADN do ser humano possui aproximadamente dois metros de comprimento, encapsulada em um núcleo celular de 6 µm, o equivalente a acomodar uma linha de 40 km de comprimento em uma bola de tênis.
Em organismos vivos, o ADN não existe como uma molécula única (cadeia simples), mas sim como um par de moléculas firmemente associadas.
As duas longas cadeias de ADN enrolam-se como uma trepadeira formando uma dupla hélice. Os nucleotídeos estão presentes em ambas as cadeias da dupla hélice, unidos com nucleótidos da mesma cadeia por ligações fosfodiéster e à cadeia complementar por meio de pontes de hidrogénio formadas pelas suas bases. Em geral, uma base ligada a um açúcar é chamada nucleosídeo e uma base ligada a um açúcar e um ou mais fosfatos é chamada nucleotídeo. Portanto, o ADN pode ser referido como um polinucleotídeo.
A cadeia principal do ADN é formada por fosfato e resíduos de açúcar, dispostos alternadamente. O açúcar no ADN é 2-desoxirribose, uma pentose (açúcar com cinco carbonos). Os açúcares são unidos por grupos fosfato que formam ligações fosfodiester entre o terceiro e quinto átomos de carbono dos anéis de açúcar adjacentes. Estas ligações assimétricas significam que uma cadeia de ADN tem uma direção. Numa dupla hélice, a direção dos nucleotídeos de uma cadeia é oposta à direção dos nucleotídeos da outra cadeia. O formato das cadeia do ADN é designado antiparalelo. As terminações assimétricas das cadeias de ADN são designadas terminais 5' (cinco linha) e 3' (três linha). Uma das diferenças principais entre o ADN e o ARN encontra-se no açúcar, com a substituição da 2-desoxirribose no ADN pela ribose no ARN.
A dupla hélice do ADN é estabilizada por pontes de hidrogênio entre as bases presas às duas cadeias. As quatro bases encontradas no ADN são a adenina (A), citosina (C), guanina (G) e timina (T). Estas quatro bases ligam-se ao açúcar/fosfato para formar o nucleotídeo completo.
Estas bases são classificadas em dois tipos; a adenina e guanina são compostos heterocíclicos chamados purinas, enquanto que a citosina e timina são pirimidinas. Uma quinta base (uma pirimidina) chamada uracila (U) aparece no ARN e substitui a timina, a uracila difere da timina pela falta de um grupo de metila no seu anel. A uracila normalmente não está presente no ADN, só ocorrendo como um produto da decomposição da citosina. Exceções para esta regra são os fagos AR9, 3NT, I10, bem como o PBS1 (muito utilizado em pesquisas), que contém uracila no seu ADN, em vez de timina.
Cada tipo de base numa cadeia forma uma ligação com apenas um tipo de base na outra cadeia. Este comportamento é designado de complementariedade de bases. Assim, as purinas formam pontes de hidrogênio com pirimidinas, i.e. A liga-se com T e C com G. Este arranjo de dois nucleotídeos complementares na dupla hélice é chamado "par de bases". Além das pontes de hidrogênio entre as bases, as duas cadeias são mantidas juntas devido a forças geradas por "interações hidrofóbicas" entre as bases "empilhadas", a qual não é influenciada pela sequência do ADN.
Como as pontes de hidrogênio não são ligações covalentes, podem ser quebradas e reunidas com relativa facilidade. Desta forma, as duas fitas da dupla hélice de ADN podem ser separadas como um zíper (fecho de correr) por força mecânica ou altas temperaturas.
Como resultado desta complementariedade, toda a informação contida numa das cadeias de ADN está também contida na outra, o que é fundamental para a replicação do ADN.
Os dois tipos de pares de base formam diferentes números de pontes de hidrogênio: AT forma duas pontes de hidrogênio enquanto que GC formam três pontes de hidrogênio. Desta forma a interação entre GC é mais forte que AT. Como resultado, a percentagem de GC numa dupla fita de ADN determina a força de interação entre as duas cadeias.
Uma parte da dupla cadeia de ADN que precisa de ser separada facilmente, tal como a TATAAT Caixa de Pribnow nos promotores bacterianos, tende a ter sequências com maior predomínio de AT, para facilitar a abertura da dupla cadeia aquando da transcrição. No laboratório, a força desta interacção pode ser medida encontrando a temperatura necessária para quebrar as pontes de hidrogénio, a temperatura de desnaturação (também chamado "T"). Quando todos os pares de base numa dupla hélice de ADN quebram as suas ligações, as duas cadeias separam-se e existem em solução como duas moléculas completamente independentes. Estas moléculas de ADN de cadeia simples não têm uma única forma comum, mas algumas conformações são mais estáveis do que outras.
O ADN normalmente encontra-se em forma de uma espiral dextrógira (gira para a direita, ou no sentido horário). Portanto, as duas cadeias de nucleotídeos giram uma sobre a outra e acabam por formar sulcos entre as cadeias de fosfato, deixando expostas as faces das bases nitrogenadas que não estão unidas por pontes de hidrogênio com a base complementar.
Há dois tipos de sulcos na superfície da dupla hélice: um com 22 Å denominado sulco maior e um com 12 Å designado de sulco menor.
A principal função dos sulcos do ADN é fornecer a informação acerca das bases que se encontram ligadas numa determinada região da dupla cadeia sem necessidade de abertura. O sulco maior oferece maior acessibilidade para ligação com proteínas do que o sulco menor. Um exemplo disto é a TBP ("TATA-binding protein") uma importante proteína para a transcrição em eucariotas.
Uma sequência de ADN é chamada de "senso" se possui a mesma sequência do ARNm. A cadeia oposta (complementar) à cadeia "senso" é denominada sequência "antissenso". Como a ARN polimerase sintetiza um ARN que é complementar à fita molde, então podemos dizer que ela utiliza a cadeia anti-senso como molde para produzir um ARN. As sequências senso e anti-senso podem existir em diferentes partes da mesma cadeia de ADN, que pode ser de um lado ou do outro, dependendo de onde se encontra a sequência codificadora.
Às vezes não é possível dizer qual é a cadeia senso ou antissenso. Isto acontece devido à existência de genes que se sobrepõem. Neste caso ambas as cadeias dão origem a um ARN.
Nas bactérias, a sobreposição pode estar envolvida da regulação da transcrição.
Nos vírus, a sobreposição aumenta a capacidade do armazenamento de informações em pequenos genomas virais.
O ADN pode ser torcido num processo denominado superenrolamento. No estado "relaxado" do ADN, uma fita normalmente dá uma volta completa ao eixo da dupla hélice a cada 10,4 pares de base, mas se o ADN está torcido, as cadeias ficam mais ou menos enroladas.
Se o ADN está torcido na direção da hélice, é denominado um "superenrolamento positivo" e as bases estão unidas mais firmemente. Já o "superenrolamento negativo" refere-se a uma torção na direção oposta, resultando num "afrouxamento" das bases. Na natureza, o ADN apresenta um ligeiro superenrolamento negativo que é causado pela ação da enzima topoisomerase.
Estas enzimas também são necessárias para aliviar o estresse de torção causado no ADN durante os processos de transcrição e replicação.
O ADN pode existir em muitas formações diferentes. As formações mais comuns são: ADN-A, ADN-B, ADN-C, ADN-D, ADN-E, ADN-H, ADN-L, ADN-P, e ADN-Z.
Porém, só as formações de ADN A, B e Z foram encontradas em sistemas biológicos naturais. A formação que o ADN adopta depende de vários fatores da própria sequência de ADN: a intensidade e direção do superenrolamento, modificações químicas das bases e a solução na qual o ADN está presente (ex.: concentração de metais, iões e poliaminas).
Das três formações referidas, a forma “B” é a mais comum nas condições encontradas nas células.
A forma “A” corresponde à espiral dextra mais larga, com um sulco menor largo e superficial e um sulco maior estreito e profundo. A forma “A” ocorre sob condições não fisiológicas em amostras de ADN desidratadas, enquanto na célula pode ser produzida por pareamento híbrido de ADN e ARN ou pelo complexo enzima-ADN.
Em segmentos de ADN onde as bases foram quimicamente modificadas por metilação, o ADN pode sofrer uma grande modificação na sua formação e adoptar a forma ADN-Z. A cadeia gira sobre o eixo da dupla hélice para a esquerda, o oposto da forma mais comum – ADN-B.
Esta estrutura é rara e pode ser reconhecida por proteínas especificas de ligação com o ADN-Z. Pode estar envolvida na regulação da transcrição.
Nas extremidades do cromossomas lineares estão zonas especializadas do ADN chamadas telómeros. A função principal destas regiões é permitir que a célula replique as extremidades do cromossoma usando a enzima telomerase, porque enzimas que permitem replicar ADN normalmente não conseguem copiar as extremidades 3' dos cromossomas. Estas tampas de cromossoma especializadas também ajudam a proteger as extremidades do ADN, e evitam que o sistema de reparação de ADN elimine estas regiões como erros que precisassem de ser corrigidos. Em células humanas, os telómeros têm normalmente vários milhares de repetições de uma sequência simples (TTAGGG).
Estas sequências ricas em guanina podem estabilizar as extremidades dos cromossomas formando estruturas de unidades de quatro bases empilhadas, ao invés dos pares de base usuais encontrados em outras moléculas de ADN. Quatro bases de guanina formam uma placa chata e depois estas unidades chatas de quatro bases empilham-se no topo umas das outras, para formarem estruturas quadrúplex-G estáveis. Estas estruturas são estabilizadas por pontes de hidrogénio entre as margens das bases e por quelação de um ião metálico no centro de cada unidade de quatro bases. Outras estruturas podem também ser formadas, com o conjunto central de quatro bases provenientes de uma cadeia simples enrolada à volta das bases ou de diversas cadeias paralelas, cada uma contribuindo com uma base para a estrutura central.
Além destas estruturas empilhadas, os telómeros também formam grandes estruturas em forma de laço chamados "telomere loops" ou "T-loops". O ADN de cadeia simples enrola-se à volta de um círculo grande estabilizado por proteínas que se ligam a telómeros. Mesmo no fim dos "T-loops", o ADN de cadeia simples do telómero é mantido sobre uma região de ADN de cadeia dupla pela cadeia do telómero que desestabiliza o ADN de dupla hélice e o emparelhamento de bases de uma das duas cadeias. Esta estrutura de cadeia tripla é chamada de laço de deslocamento ou D-loop.
A expressão de genes é influenciado pela maneira como o ADN está disposto nos cromossomas, numa estrutura chamada cromatina. As modificações de bases podem estar envolvidas na disposição, com as regiões quem tem expressão génica baixa ou inexistente contendo usualmente níveis elevados de metilação de citosina. Por exemplo, a metilação de citosina produz 5-metilcitosina, que é importante na inactivação do cromossoma X. O nível médio de metilação varia entre organismos - o verme "Caenorhabditis elegans" tem pouca metilação da citosina, enquanto que vertebrados têm níveis mais elevados, com até 1% do seu ADN contendo 5-metilcitosina Apesar da importância da 5-metilcitosina, esta pode desaminar transformando-se em timina. Citosinas metiladas são por isso especialmente susceptíveis de sofrer mutações. Outras modificações de bases incluem metilação de adeninas em bactérias e glicosilação do uracilo para produzir a "base-J" em organismos da classe Kinetoplastida.
O ADN pode ser danificado por muitos tipos diferentes de mutagénios, que alteram a sequência de ADN. Estes incluem agentes oxidantes, agentes alquilantes e também por radiação electromagnética de grande energia tal como luz ultravioleta e raios-X. O tipo de dano ao ADN produzido depende do tipo de mutagénio. A luz ultravioleta, por exemplo, pode danificar o ADN produzindo dímeros de timina, que são ligações cruzadas entre pirimidinas. Por outro lado, oxidantes como radicais livres ou peróxido de hidrogénio produzem múltiplos tipos de danos, incluindo modificações de bases, em particular guanosina, e quebras das cadeias duplas. Em cada célula humana, cerca de 500 bases podem sofrer danos por oxidação por dia. As quebras da cadeia dupla são lesões oxidativas de difícil reparação, que podem produzir mutações pontuais, inserções e delecções, assim como translocações cromossómicas.
Muitos mutagénios encaixam entre o espaço entre dois pares de bases adjacentes, na chamada "intercalação". A maioria dos intercaladores são aromáticos e moléculas planas e incluem brometo de etídio, daunomicina, doxorrubicina e talidomida. Para que um intercalador encaixe entre pares de bases, as bases têm de se separar, abrindo a cadeia dupla. Isto inibe a transcrição e a replicação do ADN, causando toxicidade e mutações. Como resultado, os intercaladores de ADN são muitas vezes carcinogénicos. Benzopireno, acridinas, aflatoxina e brometo de etídio são exemplos bem conhecidos. No entanto, devido à sua capacidade de inibir a transcrição e replicação, estas toxinas também são usadas em quimioterapia para inibir o crescimento rápido de células tumorais.
O ADN ocorre normalmente como cromossomas lineares em eucariotas e como cromossomas circulares em procariotas. O conjunto dos cromossomas numa célula perfazem o seu genoma; o genoma humano tem aproximadamente 3 mil milhões de pares de base dispostos em 46 cromossomas. A informação transportada pelo ADN está contida nas sequências de ADN chamados genes. A transmissão da informação dos genes é conseguida pela complementaridade do emparelhamento das bases. Por exemplo, na transcrição, quando uma célula usa a informação num gene, a sequência de ADN é copiado para uma sequência de ARN complementar por meio da atracção entre o ADN e os nucleotídeos de ARN correctos. Esta cópia de ARN pode ser depois usada para compor uma sequência proteica correspondente no processo de tradução, que depende da mesma interacção entre nucleotídeos de ARN. Alternativamente, uma célula pode simplesmente copiar a sua informação genética num processo chamado replicação do ADN.
O ADN genómico está localizado no núcleo celular dos eucariontes, assim como em pequenas quantidades em mitocôndrias e em cloroplastos. Em procariontes, o ADN está dentro de um corpo de forma irregular no citoplasma chamado nucleóide. A informação genética num genoma está nos genes, e o conjunto completo desta informação num organismo é chamado o seu genótipo. Um gene é a unidade básica da hereditariedade e é uma região do ADN que influencia uma característica particular num organismo. Genes contêm uma fase aberta de leitura que pode ser transcrita, assim como sequências reguladoras tais como promotores ou acentuassomos, que controlam a transcrição da fase aberta de leitura.
Em muitas espécies, apenas uma pequena fracção da sequência total do genoma codifica uma proteína. Por exemplo, apenas 1,5% do genoma humano consiste de exões (que codificam proteínas), com mais de 50% do ADN humano consistindo de sequências repetitivas. As razões para a presença de tanto ADN não-codificante em genomas eucarióticos e as extraordinárias diferenças no tamanho do genoma, ou valor C, entre espécies representam um enigma conhecido por enigma do valor C. Contudo, sequências de ADN que não codificam proteínas podem ainda codificar moléculas de ARN não-codificante funcional, que estão envolvidas na regulação da expressão génica.
Algumas sequências de ADN não-codificante têm um papel estrutural nos cromossomas. Os telómeros e centrómeros contêm tipicamente poucos genes, mas são importantes para a função e estabilidade dos cromossomas. Uma forma abundante de ADN não codificante em humanos são os pseudogenes, que são cópias de genes que foram desabilitados por mutação. Estas sequências são usualmente apenas fósseis moleculares, apesar de poderem servir ocasionalmente como material genético em bruto para a criação de novos genes por meio do processo de duplicação de genes e divergência.
Um gene é uma sequência de ADN que contêm informação genética e pode influenciar o fenótipo de um organismo. Dentro de um gene, a sequência de bases ao longo de uma cadeia de ADN definem uma cadeia de ARN mensageiro, que por sua vez define uma ou mais sequências proteicas. A relação entre a sequência de nucleótidos de um gene e a sequência de aminoácidos de uma proteína é determinada pelas regras de tradução, conhecidas colectivamente como o código genético. O código genético consiste de 'palavras' de três letras chamadas codões formadas por uma sequência de três nucleótidos (p.e. ACU, CAG, UUU).
Na transcrição, os codões de um gene são copiados para um ARN mensageiro pela ARN polimerase. Esta cópia de ARN é depois descodificada por um ribossoma que lê a sequência de ARN emparelhando o ARN mensageiro com o ARN de transferência, que carrega aminoácidos. Uma vez que há quatro bases em combinações de 3 letras, há 64 codões possíveis (formula_1 combinações). Estas codificam os vinte aminoácidos, dando à maioria dos aminoácidos mais do que um codão possível. Há também três codões 'stop' ou 'nonsense' significando o fim da região codificante; estes são os codões UAA, UGA e UAG.
A divisão celular é essencial para que um organismo cresça, mas quando uma célula se divide tem de replicar o ADN do seu genoma para que as duas células-filha tenham a mesma informação genética que a célula parental. A estrutura em dupla-hélice do ADN fornece um mecanismo simples para a sua replicação. As duas cadeias são separadas e sequências de ADN complementares a cada uma das cadeias são recriadas por uma enzima chamada ADN polimerase. Esta enzima constrói a cadeia complementar encontrando a base correcta por intermédio do emparelhamento com a base complementar, e ligando-a à cadeia original. Como as polimerases de ADN só conseguem fazer a extensão de uma cadeia de ADN na direcção 5' para 3', outros mecanismos são usados para copiar a cadeia antiparalela da dupla hélice. Desta forma, a base presente na cadeia antiga determina que base vai aparecer na nova cadeia e a célula acaba com uma cópia perfeita do seu ADN.
Todas as funções do ADN dependem de interacções com proteínas. Estas interacções com proteínas podem ser não-específicas, ou a proteína pode ligar-se especificamente a uma única sequência de ADN. Algumas enzimas também se podem ligar ao ADN. Destas, as polimerases que copiam as sequências de ADN na transcrição e replicação são particularmente importantes.
Proteínas estruturais que se ligam ao ADN são exemplos bem estudados de interacções não-específicas ADN-proteínas. Nos cromossomas, o ADN está ligado a proteínas estruturais formando complexos. Estas proteínas organizam o ADN numa estrutura compacta, a cromatina. Em eucariontes esta estrutura envolve a ligação do ADN a um complexo de pequenas proteínas básicas chamadas histonas, enquanto que em procariontes estão envolvidas vários tipos de proteínas. As histonas formam um complexo em forma de disco, o nucleossoma, que contém duas voltas completas de ADN de cadeia dupla à sua volta. Estas interacções não-específicas formam-se quando os resíduos básicos das histonas fazem ligações iónicas ao esqueleto açúcar-fosfato acídico do ADN, e por isso são largamente independentes da sequência de bases. Modificações químicas nestes resíduos de amino-ácidos incluem metilação, fosforilação e acetilação. Estas mudanças químicas alteram a força da interacção entre o ADN e as histonas, tornando o ADN mais ou menos acessível a factores de transcrição e mudando a taxa de transcrição. Outras proteínas com ligação a ADN não-específicas incluem o grupo de proteínas de alta mobilidade, que se ligam a ADN dobrado ou distorcido. Estas proteínas são importantes pois dobram conjuntos de nucleossomas e organizam-nos em estruturas maiores que constituem os cromossomas.
Um grupo distinto destas proteínas são as que se ligam especificamente a ADN de cadeia simples. Nos humanos, a proteína de replicação A é o membro desta família mais bem compreendido e é usado em processos onde a dupla hélice é separada, incluindo durante a replicação do ADN, recombinação e reparo. Estas proteínas parecem estabilizar ADN de cadeia dupla e protegem-no da formação de "hairpin loops" e da degradação por nucleases.
Em contraste, outras proteínas evoluíram de modo a ligar-se a sequências de ADN específicas. Os factores de transcrição são dos mais intensivamente estudados (proteínas que regulam a transcrição). Cada factor de transcrição liga-se a um conjunto particular de sequências de ADN e activa ou inibe a transcrição de genes que tenham estas sequências perto dos seus promotores. Os factores de transcrição fazem isto de duas maneiras. Primeiro, podem ligar-se à polimerase do ARN responsável pela transcrição, quer directamente quer por meio de proteínas mediadoras; isto posiciona a polimerase no promotor e permite que comece a transcrição. Em alternativa, os factores de transcrição podem ligar-se a enzimas que modificam as histonas no promotor; isto muda a acessibilidade do molde de ADN à polimerase.
Como estes locais de ligação podem ocorrer pelo genoma inteiro de um organismo, mudanças na actividade de um tipo de factor de transcrição pode afectar milhares de genes. Por consequência, estas proteínas são muitas vezes alvo de processos de transdução de sinal que controlam respostas a mudanças ambientais ou diferenciação e desenvolvimento celular. A especificidade da interacção destes factores de transcrição com o ADN provém das proteínas que fazem contactos múltiplos com a extremidade das bases de ADN, permitindo a leitura da sequência de ADN. A maior parte destas interacções com bases faz-se no sulco maior, onde as bases estão mais acessíveis.
As nucleases são enzimas que cortam as cadeias de ADN mediante a catálise da hidrólise das ligações fosfodiéster. As nucleases que hidrolisam nucleótidos a partir dos extremos das cadeias de ADN denominam-se "exonucleases", enquanto que as "endonucleases" cortam no interior das cadeias. As nucleases que se utilizam com maior frequência em biologia molecular são as enzimas de restrição, endonucleases que cortam o ADN em sequências específicas. Por exemplo, a enzima EcoRV, mostrada à esquerda, reconhece a sequência de 6 bases 5′-GAT|ATC-3′ e faz um corte em ambas as cadeias na linha vertical indicada, gerando duas moléculas de ADN. Outras enzimas de restrição geram, no entanto, extremidades coesivas, já que cortam de forma diferente as duas cadeias de ADN. Na natureza, estas enzimas protegem as bactérias contra as infecções de fagos, ao digerir o ADN do fago quando entra através da parede bacteriana, actuando como um mecanismo de defesa. Em biotecnologia, estas nucleases específicas utilizam-se na clonagem molecular e na técnica de impressão de ADN (" fingerprinting", em inglês).
As enzimas denominadas ADN ligases podem reunir pedaços de ADN cortados ou quebrados. As ligases são particularmente importantes na replicação do ADN da cadeia atrasada de ADN, já que unem os fragmentos curtos de ADN gerados no garfo de replicação para formar uma cópia completa do molde de ADN. Também se utilizam no reparo de ADN e na recombinação genética.
As topoisomerases são enzimas que possuem actividade de nuclease e ligase. Estas proteínas mudam a quantidade de ADN superenrolado. Algumas destas enzimas funcionam cortando a hélice de ADN e permitindo a uma secção que faça rotação, de maneira a reduzir o grau de superenrolamento; uma vez feito isto, a enzima volta a unir os fragmentos de ADN. Outros tipos de enzimas são capazes de cortar uma hélice de ADN e depois passar a segunda cadeia de ADN através desta quebra, antes de reunir as hélices. As topoisomerases são necessárias para muitos processos em que intervém o ADN, como a replicação e a transcrição.
As helicases são proteínas que pertencem ao grupo dos motores moleculares. Utilizam energia química armazenada nos trifosfatos de nucleósidos, fundamentalmente ATP, para romper pontes de hidrogénio entre bases e separar a dupla hélice de ADN em cadeias simples. Estas enzimas são essenciais para a maioria dos processos em que as enzimas necessitam de aceder às bases do ADN.
As polimerases são enzimas que sintetizam cadeias de nucleótidos a partir de trifosfatos de nucleósidos. A sequência de seus produtos são cópias de cadeias de polinucleótidos existentes, que se denominam "moldes". Estas enzimas funcionam adicionando nucleótidos ao grupo hidróxilo em 3' do nucleótido anterior numa cadeia de ADN. Por consequência, todas as polimerases funcionam na direcção 5′ → 3′. Nos sítios activos destas enzimas, o trifosfato de nucleósido que se incorpora emparelha a sua base com a correspondente no molde: isto permite que a polimerase sintetize de forma precisa a cadeia complementar ao molde.
As polimerases classificam-se de acordo com o tipo de molde que utilizam:
Uma hélice de ADN normalmente não interage com outros segmentos de ADN. Nas células humanas os diferentes cromossomas ocupam áreas separadas no núcleo celular denominadas “territórios cromossómicos”. A separação física dos diferentes cromossomas é importante para que o ADN mantenha a sua capacidade de funcionar como um armazém estável de informação. Um dos poucos momentos em que os cromossomas interagem é durante o sobrecruzamento cromossómico ("chromosomal crossover", em inglês), durante o qual se recombinam. O sobrecruzamento cromossómico ocorre quando duas hélices de ADN se rompem, sofrem intercâmbio e se unem novamente.
A recombinação permite aos cromossomas trocar informação genética e produzir novas combinações de genes, o que aumenta a eficiência da selecção natural e pode ser importante na evolução rápida de novas proteínas. Durante a profase I da meiose, uma vez que os cromossomas homólogos estão perfeitamente emparelhados formando estruturas que se denominam bivalentes, produz-se o fenómeno de sobrecruzamento ou entrecruzamento "(crossing-over)", no qual os cromatídeos homólogos não irmãos (procedentes do pai e da mãe) trocam material genético. A recombinação genética resultante faz aumentar em grande medida a variação genética entre a descendência de progenitores que se reproduzem por via sexual. A recombinação genética também pode estar implicada na reparação do ADN, em particular na resposta celular às roturas da dupla cadeia ("double-strand breaks").
A forma mais frequente de sobrecruzamento cromossómico é a recombinação homóloga, na qual os dois cromossomas implicados compartilham sequências muito similares. A recombinação não-homóloga pode ser danosa para as células, já que pode produzir translocações cromossómicas e anormalidades genéticas. A reacção de recombinação é catalisada por enzimas conhecidas como "recombinases", tais como a RAD51. O primeiro passo no processo de recombinação é uma rotura da dupla cadeia, causada por uma endonuclease ou por dano no ADN. Posteriormente, uma série de passos catalisados em parte pela recombinase conduz à união das duas hélices formando pelo menos uma junção de Holliday, na qual um segmento de uma cadeia simples é anelada com a cadeia complementar na outra hélice. A junção de Holliday é uma estrutura de união tetraédrica que pode mover-se ao longo do par de cromossomas, intercambiando uma cadeia por outra. A reacção de recombinação detém-se pelo corte da união e a reunião dos segmentos de ADN libertados.
O ADN contém a informação genética que permite à maioria dos organismos vivos funcionar, crescer e reproduzir-se. No entanto, desconhece-se o intervalo de tempo durante o qual ele exerceu esta função nos ~3000 milhões de anos desde a história da vida, já que se propôs que as formas de vida mais precoces poderiam ter utilizado ARN como material genético. O ARN poderia ter funcionado como parte central de um metabolismo primordial, já que pode transmitir informação genética e simultaneamente actuar como catalisador, formando parte das ribozimas. Este antigo "mundo de ARN" onde os ácidos nucleicos funcionariam como catalisadores e como armazéns de informação genética, poderia ter influenciado na evolução do código genético actual, baseado em quatro nucleótidos. Isto se deveria a que o número de bases únicas num organismo é determinado entre um número pequeno de bases (o que aumentaria a precisão da replicação) e um número grande de bases (que por sua vez aumentaria a eficiência catalítica das ribozimas).
Infelizmente, não dispomos de evidência directa dos sistemas genéticos ancestrais, porque a recuperação do ADN a partir da maior parte dos fósseis é impossível. O ADN é capaz de sobreviver no meio ambiente durante menos de um milhão de anos, e logo começa a degradar-se lentamente em fragmentos de menor tamanho em solução. Algumas investigações pretendem a obtenção de ADN mais antigo, como no caso do isolamento de uma bactéria viável a partir de um cristal salino de 250 milhões de anos de antiguidade, mas estes dados são controversos.
No entanto, podem utilizar-se ferramentas de evolução molecular para inferir os genomas de organismos ancestrais a partir de organismos contemporâneos. Em muitos casos, estas inferências são suficientemente fiáveis, de maneira que uma biomolécula codificada num genoma ancestral pode ser ressuscitada no laboratório para ser estudada hoje. Uma vez recomposta a biomolécula ancestral, suas propriedades poderiam oferecer informações sobre os ambientes primordial, remetendo ao campo emergente da "paleogenética experimental". Apesar de tudo, o processo de trabalho "retrospectivo" tem limitações inerentes, razão pela qual outros investigadores tentam elucidar o mecanismo evolutivo trabalhando desde a origem da Terra até adiante no tempo. Dada suficiente informação sobre como as substâncias cósmicas poderiam haver-se depositado na Terra e sobre as transformações que poderiam ter tido lugar na superfície terrestre, talvez poderíamos ser capazes de desenvolver modelos prospectivos de evolução da informação genética.
A história do ADN começa no final da década de 1860, com a chegada do médico suíço Friedrich Miescher (1844-1895) à Universidade de Tübingen, uma pacata cidade no sul da Alemanha. O jovem pesquisador estava disposto à dedicar-se ao estudo da química da célula e escolheu essa universidade porque nela o químico Felix Hoppe-Seyler (1825-1895) havia inaugurado um importante laboratório de química fisiológica. Na época floresciam ideias a respeito das origens e funções das células, após a queda da teoria da geração espontânea. A teoria celular estabelecia-se como um dos pilares da Biologia. Por tudo isso, as células atraíam a atenção de estudantes entusiasmados, como Miescher.
Felix Hoppe-Seyler foi quem primeiro descreveu as interações entre a hemoglobina, a proteína responsável pela cor do sangue, e o gás oxigênio. Seu trabalho levou-o a interessar-se pela composição bioquímica dos linfócitos. Mas Miescher enfrentou dificuldades para obter amostras com linfócitos em quantidade e grau de pureza adequados. Por sugestão de Hoppe-Seyler, Miescher começou a estudar a química das células do pus; o material para a pesquisa era abundante, pois dezenas de bandagens com material purulento eram diariamente descartadas por um hospital próximo à universidade. Miescher desenvolveu técnicas adequadas para o isolamento das células presentes em pus das bandagens e para a sua análise química. O objetivo inicial era investigar as proteínas celulares, um grupo de substâncias descoberto cerca de trinta anos antes.
Em um dos seus muitos experimentos com células do pus, Miescher obteve um precipitado que diferia quimicamente de todas as substâncias protéicas conhecidas. Ele descobriu que a nova substância concentrava-se no núcleo celular, na época considerado uma estrutura de pouca importância para o funcionamento celular. Aprimorando os métodos de extração e purificação da nova substância, Miescher pôde realizar uma análise química mais precisa, que mostrou que as quantidades relativas de hidrogênio, carbono, oxigênio e nitrogênio presentes diferiam das encontradas em proteínas, além de uma quantidade incomum de fósforo. À substância descoberta Miescher denominou "nucleína", pelo fato de ela estar concentrada no núcleo das células.
O trabalho sobre nucleína só foi publicado em 1871, após certa resistência do editor da revista científica, o próprio Hoppe-Seyler, que, no início, não acreditou nos resultados apresentados por Miescher. Mesmo depois da publicação do trabalho, muitos pesquisadores continuaram duvidando da existência da nucleína; na opinião deles, o achado de Miescher devia ser uma mistura de fosfato inorgânico e proteínas.
As desconfianças quanto à real existência da nova substância descrita por Miescher só foram superadas por volta de 1889, quando Richard Altmann (1852-1900) obteve preparações altamente purificadas de nucleína, sem nenhuma contaminação por proteínas. Pelo fato de a substância ter caráter ácido, o que já havia sido detectado por Miescher, Altmann sugeriu que ela fosse chamada de ácido nucléico em vez de nucleína.
Outro pesquisador pioneiro na descoberta foi Albrecht Kossel (1853-1927). Em 1877, ele juntou-se ao grupo de pesquisa de Hoppe-Seyler, então trabalhando na Universidade de Estrasburgo (França), e começou a estudar a composição química das nucleínas. Kossel detectou dois tipos de bases nitrogenadas já conhecidas, a adenina e a guanina. Em 1893, identificou uma nova base nitrogenada, que era liberada pela degradação de nucleína da células do timo; por isso denominou-a timina. Logo em seguida, descobriu que a nucleína continha um quarto tipo de base nitrogenada, a qual denominou citosina. Em 1894, o grupo liderado por Kossel descobriu que os ácidos nucleicos continham também pentose, um açúcar com cinco átomos de carbono. Em reconhecimento às suas contribuições na área, foi agraciado em 1910 com o Nobel de Fisiologia ou Medicina.
Em 1909, Phoebus Levene e Walter Abraham Jacobs (1883-1967) conseguiram determinar a organização das moléculas de fosfato, de pentose e base nitrogenada no ácido nucleico. Esses três componentes estão unidos entre si formando uma unidade fundamental, o nucleotídeo. Em 1929, Levene e colaboradores identificaram pentoses componente do ácido nucleico das células do timo, que denominaram 2-deoxi-D-ribose, pelo fato de ela possuir, no carbono 2 de sua cadeia, um átomo de oxigênio a menos que a ribose, uma pentose já conhecida, encontrada pelos pesquisadores em dois tipos de ácidos nucléicos: o ácido ribonucleico, ou ribose, e o ácido desoxirribonucléico, ou ADN, cujo açúcar é a desoxirribose.
Frederick Griffith fez uma importante observação no curso dos experimentos com a bactéria "Streptococcus pneumoniae" em 1928. Esta bactéria, que causa pneumonia em humanos, normalmente é letal em camundongos. Entretanto algumas linhagens desta espécie de bactérias eram menos virulentas (menos capazes de causar doenças ou morte). Nos experimentos de Griffith, ele usou duas linhagens distinguíveis pelas suas colônias quando cultivadas em laboratório. Uma linhagem era um tipo normalmente virulento e mortal para a maioria dos animais de laboratório. As células desta linhagem estão envoltas em uma cápsula de polissacarídeo, dando às colônias em aspecto liso, sendo esta linhagem identificada com "S" ("smooth", em inglês). A outra linhagem de Griffith era um tipo mutante não virulento que crescia em camundongos. Nesta linhagem, a capa de polissacarídeo está ausente, dando às colônias um aspecto rugoso. Esta linhagem é chamada "R" ("rough", em inglês).
Griffith inativou algumas células virulentas a alta temperatura. Injetou então as células mortas por aquecimento nos camundongos. Os camundongos sobreviveram, mostrando que os restos das células não causam morte. Entretanto os camundongos injetados com uma mistura de células virulentas mortas por aquecimento e células não virulentas vivas morreram. Além disso, as células vivas podiam ser recuperadas de camundongos mortos. Estas células deram colônias lisas e foram virulentas em uma injeção subsequente. De algum modo, os restos das células "S" aquecidas haviam convertido células "R" vivas em células "S" vivas.
A etapa seguinte era determinar que componente químico das células doadoras mortas havia causado esta conversão. Esta substância tinha mudado o genótipo da linhagem receptora e portanto podia ser uma candidata a material genético. Este problema foi resolvido pelos experimentos feitos em 1944 por Oswald Avery e dois colegas, C M. Macleod e M. McCarty. Seu enfoque ao problema foi destruir quimicamente todas as principais categorias de substâncias no extrato de células mortas, uma de cada vez, e descobrir se o extrato havia perdido a habilidade de conversão. As células virulentas possuíam uma capa lisa de polissacarídeo, enquanto as células não virulentas, não. Assim os polissacarídeos eram um candidato óbvio a ser o agente responsável. Entretanto, quando os polissacarídeos foram destruídos, a mistura ainda era capaz de conversão. As proteínas, gorduras e ácido ribonucleico (ARN) foram todos excluídos. A mistura só perdia a sua capacidade de conversão quando a mistura doadora era tratada com enzima desoxirribonuclease (DNase), que quebra o ADN. Estes resultados indicavam fortemente que o ADN era o material genético. Hoje sabemos que os fragmentos do ADN transformante que conferem virulência entram no cromossomo bacteriano e substituem suas contrapartes que conferem não-virulência.
Os experimentos feitos por Avery e seus colegas foram definitivos, mas muitos cientistas mostraram-se muito relutantes em aceitar o ADN (e não as proteínas) como material genético. Evidências adicionais foram publicadas em 1952 por Alfred Day Hershey e Martha Chase, cujo experimento com o fago T2, um vírus que transfecta na bactéria a informação específica para a reprodução viral. Se eles pudessem descobrir que material o fago transmitia à bactéria hospedeira, determinariam o material genético do fago.
O fago tem uma constituição molecular relativamente simples. A maior parte de sua estrutura é de proteína, com o ADN contido dentro da capa de proteína de sua "cabeça". Hershey e Chase decidiram marcar o ADN e a proteína usando radioisótopos, de modo que pudessem rastrear os dois materiais durante a infecção. O fósforo não é encontrado nas proteínas mas é uma parte integrante do ADN. Contrariamente, o enxofre está presente nas proteínas mas nunca no ADN. Hershey e Chase incorporaram o radioisótopo de fósforo (P) no ADN do fago e o enxofre (S) nas proteínas de uma cultura separada de fagos. Eles então infectaram duas culturas de "E. coli" com muitas partículas de vírus por células: uma cultura de E. "coli" recebeu fagos marcados com P e a outra recebeu fagos marcados com S. Decorrido tempo suficiente para que ocorresse a infecção, os cientistas removeram as embalagens de fago (chamadas "ghosts") das células bacterianas por agitação em um liquidificador. Eles separaram as células bacterianas dos envoltórios dos fagos em uma centrífuga e então mediram a radioatividade nas duas frações. Quando o fago marcado com P foi usado para infectar E. "coli", a mais alta radioatividade foi encontrada dentro das bactérias, indicando que o ADN do fago havia entrado nas células. Quando era usado o fago marcado com S, maior parte do material radioativo estava nos invólucros dos fagos, indicando que a proteína do fago nunca entrava nas bactérias. A conclusão era inevitável: o ADN era o material hereditário. As proteínas do fago eram apenas embalagens estruturais abandonadas após o ADN viral entrar na bactéria.
A investigação sobre o ADN tem um impacto significativo, especialmente no âmbito da medicina, mas também na agricultura e pecuária, com objectivos de domesticação, selecção e de cruzamentos dirigidos. A moderna biologia e bioquímica fazem uso intensivo da tecnologia do ADN recombinante, introduzindo genes de interesse em organismos, com o objectivo de expressar uma proteína recombinante concreta, que pode ser:
A Medicina Forense pode utilizar o ADN presente no sangue, no sémen, na pele, na saliva ou em pelos existentes na cena de um crime para identificar o responsável. Esta técnica denomina-se impressão genética ou "perfil de ADN". Ao realizar a impressão genética, compara-se o comprimento de secções altamente variáveis do ADN repetitivo, como os microssatélites, entre pessoas diferentes. Este método é muito fiável para identificar um criminoso. No entanto, a identificação pode complicar-se se a cena do crime estiver contaminada com ADN de pessoas diferentes. A técnica da impressão genética foi desenvolvida em 1984 pelo geneticista britânico Sir Alec Jeffreys, e utilizada pela primeira vez para condenar Colin Pitchfork por causa dos assassinatos de Narborough (Reino Unido) em 1983 e 1986. Pode-se requerer às pessoas acusadas de certos tipos de crimes que cedam uma amostra de ADN para ser introduzida numa base de dados. Isto tem facilitado o trabalho dos investigadores na resolução de casos antigos, onde só se obteve uma amostra de ADN da cena do crime, em alguns casos permitindo exonerar um convicto. A impressão genética também pode ser utilizado para identificar vítimas de acidentes em massa, ou para realizar provas de consanguinidade.
A Bioinformática implica a manipulação, busca e extracção de informação dos dados da sequência do ADN. O desenvolvimento das técnicas para armazenar e procurar sequências de ADN gerou avanços no desenvolvimento de software para computadores, com muitas aplicações, especialmente algoritmos de busca de frases, aprendizagem automática e teorias de bases de dados. A busca de frases ou algoritmos de coincidências, que procuram a ocorrência de uma sequência de letras dentro de uma sequência de letras maior, desenvolveu-se para buscar sequências específicas de nucleótidos. Em outras aplicações como editores de textos, inclusive algoritmos simples podem funcionar, mas as sequências de ADN podem gerar que estes algoritmos apresentem um comportamento de "quase o pior caso", devido ao baixo número de carácteres. O problema relacionado do alinhamento de sequências procura identificar sequências homólogas e localizar mutações específicas que as diferenciam. Estas técnicas, fundamentalmente o alinhamento múltiplo de sequências, utilizam-se ao estudar as relações filogenéticas e a função das proteínas. As colecções de dados que representam sequências do ADN do tamanho de um genoma, tais como as produzidas pelo Projecto Genoma Humano, são difíceis de utilizar sem notações que marcam a localização dos genes e dos elementos reguladores em cada cromossoma. As regiões de ADN que têm padrões associados com genes codificantes de proteínas ou ARN podem identificar-se por algoritmos de localização de genes, o que permite aos investigadores predizer a presença de produtos génicos específicos num organismo mesmo antes que se tenha isolado experimentalmente.
A nanotecnologia de ADN utiliza as propriedades únicas de reconhecimento molecular de ADN e outros ácidos nucleicos para criar complexos ramificados auto-ensamblados com propriedades úteis. Neste caso, o ADN utiliza-se como um material estrutural, mais que como um portador de informação biológica. Isto conduziu à criação de lâminas periódicas de duas dimensões (ambas baseadas em azulejos, assim como usando o método de "ADN origami"), para além de estruturas em três dimensões em forma de poliedros.
O ADN armazena mutações conservadas com o tempo e portanto contém informação histórica. Comparando sequências de ADN, os geneticistas podem inferir a história evolutiva dos organismos, a sua filogenia. O campo da filogenia é uma ferramenta potente na biologia evolutiva. Se se compararem as sequências de ADN dentro de uma espécie, os geneticistas de populações podem conhecer a história de populações particulares. Isto pode-se utilizar numa ampla variedade de estudos, desde ecologia até antropologia; por exemplo, evidência baseada na análise de ADN está a ser utilizada para identificar as Dez Tribos Perdidas de Israel.

Domicile conjugal (no Brasil e em Portugal, Domicílio Conjugal) é um filme franco-italiano de 1970, dirigido por François Truffaut.
Antoine Doinel casou-se com Christine Darbon, que dá aulas de violino. Antoine tinge flores no pátio do prédio onde vivem. Entre os seus vizinhos contam-se um cantor de ópera e a sua esposa, um recluso voluntário, um criada apaixonada por ele e um homem misterioso apelidado "o estrangulador". Antoine muda de profissão e é contratado por uma empresa norte-americana. Christine espera uma criança que se chamará Alphonse. Antoine conhece Kyoko, uma bela japonesa, com quem tem uma aventura. Sentindo-se apaixonada, a jovem lhe envia umas flores acompanhadas de uma declaração de amor. As tais flores são recebidas por Christine que, assim, descobre estar sendo traída pelo marido. Como conseqüência, Antoine se vê obrigado a sair de casa e passa a viver num quarto de hotel. Com o passar do tempo, a relação com Kyoko vai-se desgastando. Por várias vezes, ele tenta voltar para sua esposa, mas esta não concorda, muito embora no fundo ela continue a amá-lo. As constantes visitas ao seu filho Alphonse, no entanto, vão amolecendo o coração de Christine, de modo que os dois terminam se acertando.

Um sistema digital é um conjunto de dispositivos de transmissão, processamento ou armazenamento de sinais digitais que usam valores discretos (descontínuos). Em contraste, os sistemas não-digitais (ou analógicos) usam um intervalo contínuo de valores para representarem informação. Embora as representações digitais sejam discretas, a informação representada pode ser discreta, como números, letras, ou ícones,ou contínua, como sons, imagens, outras medidas de sistemas contínuos.
A palavra digital tem origem no latim "digitus" (palavra latina para "dedo"), uma vez que os dedos eram usados para contagem discreta. O seu uso é mais comum em computação e electrónica, sobretudo onde a informação real é convertida na forma numérica binária como no som digital ou na fotografia digital.
Pode ser dita como: uma representação da informação de forma abstracta (intocável), a qual pode ser manipulada por meio de dispositivos digitais, ou a forma de representação por valores lógicos e exactos, de qualquer tipo de dado.

Dora Incontri (São Paulo, 1962) é uma educadora, jornalista, poetisa e escritora brasileira; autora de mais de 40 obras publicadas, dentre elas livros didáticos de filosofia e ensino inter-religioso. É mestre, doutora e pós-doutora em História e Filosofia da Educação pela Universidade de São Paulo. Também é um importante nome da pedagogia espírita e coordena um curso de Pós-Graduação Latu-Senso nessa área, pela Universidade Livre Pampédia, de que é idealizadora e coordenadora. A Universidade Livre Pampédia é um projeto alternativo de educação superior, com sede em Bragança Paulista. É também coordenadora da Associação Brasileira de Pedagogia Espírita. 
É uma das divulgadoras do pensamento de Jan Amos Comenius, educador checo, no Brasil. Em 1998, fundou a Editora Comenius e já publicou duas obras clássicas desse autor no Brasil: "Pampédia (ou da Educação Universal)" e "O Labirinto do Mundo e o Paraíso do Coração". Em 2014, foi agraciada com a medalha Comenius, do Museu Comenius, da República Checa. 
É uma das poucas estudiosas do educador Johann Heinrich Pestalozzi no Brasil e também é uma notória estudiosa de seu discípulo Allan Kardec, o fundador do Espiritismo.

Delfinópolis é um município brasileiro do sudoeste do estado de Minas Gerais. Dista 401 quilômetros de Belo Horizonte, e se estende numa área total de 1.171 km² elevada a 689 metros de altitude na sede municipal. Sua população em julho de 2017 foi estimada em habitantes.
No século XIX, Violanta Luzia de São José, doou 288 hectares de terra para a construção da capela do Divino Espírito Santo. A partir daí, começou a se formar um núcleo chamado Povoado Espírito Santo da Forquilha. Em 1919, em homenagem ao governador do Estado, Delfim Moreira da Costa Ribeiro, a cidade recebeu o nome de Delfinópolis.
Com a implementação do turismo, a chegada do asfalto e as facilidades de deslocamento para cidades como Passos, Franca e Ribeirão Preto, a cidade passou por significativas modificações nos aspectos cultural, social e político, atraindo muitos turistas para o Porto da Praia Vermelha.
A cidade possui 1.375 km² de área, 6.501 habitantes, altitude variando entre 671m e 1.400m.
Nas atividades agrícolas, destacam-se: milho, café, cana-de-açúcar, banana, arroz, feijão, soja. Na pecuária: leite e seus derivados, gado de corte e suinocultura.
Merece destaque o desenvolvimento do setor turístico.
O município faz parte do circuito turístico Nascentes das Gerais e tem como principal atração turística o Complexo do Claro, um conjunto de cachoeiras localizadas próximas ao centro da cidade. Encontra-se também uma grande parte em seu território o Parque Nacional da Serra da Canastra e anexo a esse o Vão da Babilônia, região com muitas pousadas e atrativos turísticos, rota de trilheiros e admiradores da natureza.

Os descobrimentos portugueses foram o conjunto de conquistas realizadas pelos portugueses em viagens e explorações marítimas entre 1415 e 1543 que começaram com a conquista de Ceuta em África. Os descobrimentos resultaram na expansão portuguesa e deram um contributo essencial para delinear o mapa do mundo, impulsionados pela Reconquista e pela procura de alternativas às rotas do comércio no Mediterrâneo. Com estas descobertas os portugueses iniciaram a Era dos Descobrimentos europeus que durou do século XV até ao XVII e foram responsáveis por importantes avanços da tecnologia e ciência náutica, cartografia e astronomia, desenvolvendo os primeiros navios capazes de navegar em segurança em mar aberto no Atlântico. Deve-se, todavia, referir que a construção naval chinesa produzia no século XV navios com 120 m de comprimento, tais como os da frota do almirante Zheng He e das suas 7 expedições no Oceano Indico no intervalo de 1402 a 1435.
Embora com antecedentes no reinado de D. Dinis (1279) e nas expedições às Ilhas Canárias do tempo de D. Afonso IV, é a partir da conquista de Ceuta em 1415, que Portugal inicia o projecto nacional de navegações oceânicas sistemáticas que ficou conhecido como "descobrimentos portugueses".
Terminada a Reconquista, o espírito de conquista e Cristianização dos povos muçulmanos subsistia. Os portugueses dirigiram-se então para o Norte de África, de onde tinham vindo os "mouros" que se haviam estabelecido na Península Ibérica. Avançando progressivamente pelo Atlântico ao longo das costas do continente africano, passaram o Cabo da Boa Esperança e entraram no Oceano Índico movidos pela procura de rotas alternativas ao comércio Mediterrânico. Chegaram à Índia em 1498, simultaneamente exploraram o Atlântico Sul e aportaram nas costas do Brasil em 1500, navegando no extremo da Ásia chegaram à China em 1513 e ao Japão em 1543.
As expedições prolongaram-se por vários reinados, desde o tempo das explorações na costa africana e americana impulsionadas pelo regente D. Pedro, duque de Coimbra e o Infante D. Henrique, filhos de D. João I, e mais o seu sobrinho D. Infante D. Fernando, duque de Viseu, até à ao projeto da descoberta de um caminho marítimo para a Índia no reinado de D. João
II, culminando com o do D. Manuel I a altura em que império ultramarino português fica consolidado.
Com a Reconquista concluída, Dinis I de Portugal interessou-se pelo comércio externo, organizando a exportação para países europeus. Em 1293 instituiu a chamada Bolsa dos Mercadores, um fundo de seguro marítimo para os comerciantes portugueses que viviam no Condado da Flandres, que pagavam determinadas quantias em função da tonelagem, que revertiam em seu benefício se necessário. Vinho e frutos secos do Algarve eram vendidos na Flandres e na Inglaterra, sal das regiões de Lisboa, Setúbal e Aveiro eram exportações rentáveis para o Norte da Europa, além de couro e Kermes, um corante escarlate. Os portugueses importavam armaduras e armas, roupas finas e diversos produtos fabricados da Flandres e da Itália.
Em 1317 D. Dinis fez um acordo com o navegador e mercador genovês Manuel Pessanha (Emanuele Pessagno), nomeando-o primeiro almirante da frota real com privilégios comerciais com seu país, em troca de vinte navios e suas tripulações, com o objetivo de defender as costas do país contra ataques de pirataria (muçulmana), lançando as bases da Marinha Portuguesa e para o estabelecimento de uma comunidade mercante genovesa em Portugal. Obrigados a reduzir suas atividades no Mar Negro, os mercadores da República de Génova tinham-se voltado para o comércio norte Africano de trigo, azeite (também fonte de energia) e ouro - navegando até aos portos de Bruges (Flandres) e Inglaterra. Genoveses e florentinos estabeleceram-se então em Portugal, que lucrou com a iniciativa e experiência financeira destes rivais da República de Veneza.
Na segunda metade do século XIV, surtos de peste bubónica levaram a um grave despovoamento: a economia era extremamente localizada em poucas cidades e a migração do campo levou ao abandono da agricultura e ao aumento do desemprego nas povoações. Só o mar oferecia alternativas, com a maioria da população fixada nas zonas costeiras de pesca e comércio.
Entre 1325 e 1357 D. Afonso IV de Portugal concedeu o financiamento público para levantar uma frota comercial e ordenou as primeiras explorações marítimas, com apoio de genoveses, sob o comando de Manuel Pessanha. Em 1341 as ilhas Canárias, já conhecidas dos genoveses, foram oficialmente descobertas sob o patrocínio do rei Português. A sua exploração foi concedida em 1338 a mercadores estrangeiros, mas em 1344 Castela disputou-as, concedendo-as ao castelhano D. Luís de la Cerda. No ano seguinte, Afonso IV enviou uma carta ao Papa Clemente VI referindo-se às viagens dos portugueses às Canárias e protestando contra essa concessão. Nas reivindicações de posse, sucessivamente renovadas pelos dois povos, prevaleceu, no final, a vontade do rei de Castela sobre estas ilhas.
Em 1353 foi assinado um tratado comercial com a Inglaterra para que os pescadores portugueses pudessem pescar nas costas inglesas, abrindo assim caminho para o futuro Tratado de Windsor em 1386. Em 1380 foi criada a Companhia das Naus, uma bolsa de seguros marítimos e, em 1387 há notícia do estabelecimento de mercadores do Algarve em Bruges. Em 1395, D. João I emitiu uma lei para regular o comércio dos mercadores estrangeiros.
Há unanimidade dos historiadores em considerar a conquista de Ceuta como o início da expansão portuguesa, tipicamente referida como os "Descobrimentos". Foi uma praça conquistada com relativa facilidade, por uma expedição organizada por D. João I, em 1415. A aventura ultramarina ganharia grande impulso através da acção do Infante D. Henrique, reconhecido internacionalmente como o seu grande impulsionador, e continuada pelo seu sobrinho e protegido Infante D. Fernando, duque de Beja e Viseu.
Até ao século XIX, considerava-se como única a que a motivação reino português para as conquistas africanas em Marrocos tinha sido de ordem religiosa e espírito de cruzada. O cronista Gomes Eanes de Zurara refere-se nesse sentido que os Infantes tinham as suas razões, os letrados as suas, mas a decisão cabia ao rei D. João I. Diz assim: “"Eu não o teria por vitória, nem o faria em boa verdade, ainda que soubesse cobrar todo o mundo por meu, se não sentisse que em alguma maneira era serviço de Deus"”. O motivo religioso, sobrepondo-se a todos os outros, foi como tal apontado, entre outros, por João de Barros, Luís de Camões, Gil Vicente.
Sem falarmos no papel dos reis portugueses na Reconquista da Península Ibérica e independentemente de nos apercebermos todo um pensamento de acordo com uma época que mantinha os valores da Cavalaria medieval, que já vinha detrás, a provar está o consentimento e bênção do papado dado ao pedido D. Dinis para combater os corsários mouros e ao de D. Duarte, em 1436, nas intervenções de ocupação de território sarraceno, infiel e ímpio, junto do Norte de África. Daí as sucessivas bulas da Cruzada que se lhe seguiram e foram dirigidas ao Reino de Portugal e à portuguesa templária Ordem de Cristo. Isto para consentir e agradecer toda a intervenção nesse sentido da conquista de os territórios "nullius diocesis" (sem diocese apostólica) para aumentar o número de cristãos e o seu prestígio. Entre outras, temos a bula Apostolice Sedis emitida em 23 de Maio de 1320 pelo Papa João XXII; a "Etsis suscepti", em 1442; a "Dum diversas", em 18 de Junho de 1452; logo depois a "Romanus Pontifex" em 8 de Janeiro de 1455 1454, enviadas pelo Papa Nicolau V; e mais tarde surge a bula "Inter cætera", em 4 de Maio de 1493, pelo Papa Calisto III.
Mas havia também outras razões para a conquista de Ceuta, mais de um século depois resumidas pelo carmelita Frei Amador Arrais, ligando-as à acção de D. Afonso IV na Batalha do Salado - “"El-Rei Dom João o primeiro, começou a conquista de África, tomãdo Septa, Baluarte da Cristandade, & Chave de toda Hespanha, Porta do comércio do poente para levante"."
Os muçulmanos dominavam o estreito de Gibraltar e eram poderosos em Granada. Pela sua posição geográfica, Ceuta era uma base naval que podia servir de apoio à navegação entre a península itálica e Portugal, permitindo também reprimir ou tolher a pirataria dos mouros nas costas do Atlântico.
No século XX, houve historiadores que julgaram o passado com as preocupações do presente, considerando a primazia do interesse económico: procurar acesso directo a fontes de fornecimento de trigo, de ouro ou de escravos no norte de África. Mas houve também historiadores, como David Lopes, rebatendo essa tese: "Ainda que Ceuta tivesse importância como centro de comércio, a sua conquista por cristãos desviaria dela o tráfico muçulmano" ,
As conquistas de Marrocos, porém, sob o impulso do Infante D. Henrique, vieram a dar lugar aos descobrimentos. Segundo Gomes Eanes de Zurara, na "Crónica do descobrimento e conquista da Guiné" (Capítulo VII), as expedições organizadas pelo Infante tinham cinco motivações:
Se, com o Infante, ao avançar pela costa de África na direcção do sul, parece haver sobretudo a intenção de envolver pela retaguarda o grande poderio islâmico, adversário da Cristandade (uma estratégia militar e diplomática tributária do espírito das Cruzadas), a crescente intervenção dos "cavaleiros-mercadores" (Magalhães Godinho) nos reinados de D. Afonso V e D. João II, acabará por levar a expansão portuguesa até ao Oriente em busca das especiarias. Em 1453, com a tomada de Constantinopla pelos Otomanos, as trocas comerciais no Mediterrâneo de Veneza e de Génova ficaram muito reduzidas. O proveito de uma rota comercial alternativa mostrava-se recompensador. Portugal iria ligar directamente as regiões produtoras das especiarias aos seus mercados na Europa. Quando se firma o projecto da descoberta do caminho marítimo para a Índia, a expansão portuguesa sem esquecer a vertente religiosa está também já dominada pelo interesse comercial.
A conquista de Ceuta em 1415 é geralmente referida como o início dos "descobrimentos Portugueses". Nela participaram os infantes D. Duarte, D. Pedro e o Infante D. Henrique que a partir de então dirige as primeiras expedições no Atlântico, como investimento do Reino de Portugal através da templária Ordem de Cristo e do seu próprio património pessoal. As primeiras navegações estão associadas à sua figura a partir da base que, saindo do porto de Castro Marim que tinha sido a primeira sede da referida ordem militar e da qual ele era o grão-mestre, estabeleceu em Lagos e na Sagres, onde foi acompanhado por um grupo de cartógrafos, astrónomos e pilotos. Além dos interesses materiais, o príncipe ambicionava ao estabelecer uma aliança com o Preste João, um príncipe cristão que governava as terras da Etiópia. Graças a essa aliança, pensava-se recomeçar as Cruzadas, mas numa escala planetária, alcançar o Paraíso (o Éden) do qual esse rei africano era o guardião, e expulsar os muçulmanos da Terra Santa para alcançar a Idade do Ouro e Jerusalém Celeste. Após a conquista os infantes foram armados cavaleiros pelo rei.
Por trás deste movimento, como dirigente governativo, estava o seu irmão Infante D. Pedro, 1.° duque de Coimbra assim como um grupo vasto de religiosos cristão e judeus, mercadores e armadores profissionais, interessados e participantes nas navegações, responsáveis por uma série importante de iniciativas a que o "navegador" aderiu. Entre eles o seu aventureiro sobrinho navegador, Infante D. Fernando, duque de Beja, pai de D. Manuel I, que deu toda a continuidade a esses intentos.
Em 1418, ainda no reinado de D. João I, e sob comando do Infante D. Henrique dá-se o redescobrimento da ilha de Porto Santo por João Gonçalves Zarco e mais tarde da ilha da Madeira por Tristão Vaz Teixeira. Trata-se de um redescobrimento pois já havia conhecimento da existência dessas ilhas no século XIV, segundo revela a cartografia da mesma época, principalmente em mapas italianos e catalães. Tratava-se de ilhas desabitadas que, pelo seu clima, ofereciam possibilidades de povoamento aos Portugueses e reuniam condições para a exploração agrícola.
Os arquipélagos da Madeira e das Canárias despertaram, desde cedo, o interesse tanto dos Portugueses como dos Castelhanos; por serem vizinhos da costa africana, representavam fortes potencialidades económicas e estratégicas. A disputa destes territórios deu origem ao primeiro conflito ibérico motivado por razões expansionistas que só terminou com a assinatura do Tratado das Alcáçovas-Toledo em 1479.
Em 1427, dão-se os primeiros contactos com o arquipélago dos Açores por Diogo de Silves. Ainda nesse ano é descoberto o grupo oriental dos Açores, São Miguel e Santa Maria. Segue-se o descobrimento do grupo central -Terceira, Graciosa, São Jorge, Pico e Faial). Em 1452 o grupo ocidental (Flores e Corvo) é descoberto por Diogo de Teive.
Em 1434 Gil Eanes contornou o Cabo Bojador, dissipando o terror que este promontório inspirava. No ano seguinte, navegando com Afonso Gonçalves Baldaia descobriram Angra de Ruivos e este último chegou ao Rio de Ouro, no Saara Ocidental. Entretanto, após a derrota portuguesa de Tânger em 1437, os portugueses adiaram o projecto de conquistar o Norte de África.
Já na regência de D. Afonso V, em 1441 Antão Gonçalves foi incumbido de descobrir o Rio do Ouro. Fez os primeiros cativos africanos: um homem de cor parda a que os portugueses chamavam de azenegues e uma moura negra. No mesmo ano, Nuno Tristão chegou ao Cabo Branco. Juntamente com Antão Gonçalves fizeram incursões ao referido Rio do Ouro, de onde foi obtido ouro em pó e alguns escravos, a primeira grande captura. A partir de então ficou generalizada a convicção de que essa área da costa africana poderia, independentemente de novos avanços, sustentar uma actividade comercial capaz de responder às necessidades de numerário que, em Portugal, como em toda a Europa, se fazia sentir. Em 1456, Diogo Gomes descobre Cabo Verde e segue-se o povoamento das ilhas ainda no século XV .
Em 1455 é emitida a bula Romanus Pontifex do Papa Nicolau V confirmando as explorações portuguesas e declarando que todas as terras e mares descobertos a sul do Bojador e do cabo são pertença dos reis de Portugal, que poderá cobrar impostos sobre a navegação e comércio.
No ano seguinte chegava a Bristol o primeiro carregamento de açúcar provindo da ilha da Madeira.
Em 1460, Pêro de Sintra atinge a Serra Leoa. Nesse ano faleceu o Infante D. Henrique. Após a sua morte, a missão é atribuída temporariamente ao seu sobrinho, o Infante D. Fernando (filho de D.Duarte), já aqui referido.
Em 1469, Afonso V, Rei de Portugal dadas as poucas receitas da exploração, concedeu o monopólio do comércio no Golfo da Guiné ao mercador de Lisboa Fernão Gomes, contra uma renda anual de 200.000 réis. Segundo João de Barros, ficava aquele "«honrado cidadão de Lisboa»" com a obrigação de continuar as explorações, pois o exclusivo era garantido com "«condição que em cada um destes cinco anos fosse obrigado a descobrir pela costa em diante cem léguas, de maneira que ao cabo do seu arrendamento desse quinhentas léguas descobertas»"». Este avanço, do qual não há grandes pormenores, teria começado a partir da Serra Leoa, onde haviam já chegado Pedro de Sintra e Soeiro da Costa.
Com a colaboração de navegadores como João de Santarém, Pedro Escobar, Lopo Gonçalves, Fernão do Pó e Pedro de Sintra, Fernão Gomes fê-lo mesmo para além do contratado. Com o seu patrocínio, os portugueses chegaram ao Cabo de Santa Catarina, já no Hemisfério Sul. João de Santarém e Pêro Escobar exploraram a costa setentrional do Golfo da Guiné, atingindo a «minha de ouro» de Sama (actualmente Sama Bay), a costa da Mina, a de Benin, a do Calabar e a do Gabão e as ilhas de São Tomé e Príncipe e de Ano Bom. Quando as expedições chegaram a Elmina na Costa do Ouro, em 1471, encontraram um florescente comércio de ouro.
Seguiram-se outros navegadores como Soeiro da Costa (que deu nome ao rio Soeiro), Fernão do Pó (que descobriu a ilha Formosa (em África), que ficou conhecida posteriormente pelo seu nome), João Vaz Corte-Real, que em 1472 descobriu a Terra Nova, e em 1473 Lopo Gonçalves (cujo nome se transmitiu ao "Cabo Lopo Gonçalves", hoje conhecido por Cabo Lopez) ultrapassou o Equador.
Em 1474, D. Afonso V entregou ao seu filho, o príncipe D. João, futuro D. João II, com apenas dezanove anos, a organização das explorações por terras africanas. Mais tarde, em 1481, o rei confirmou a missão do príncipe em novo diploma: «"…sabemos certo que ele dá, per si, e per seus oficiais, mui boa ordem à navegação destes trautos e os governa mui bem."».
Assim que lhe foi entregue a política de expansão ultramarina, D. João organizou a primeira viagem de Diogo Cão. Este fez o reconhecimento de toda a costa até à região do Padrão de Santo Agostinho. Em 1485, Diogo Cão levou a cabo uma segunda viagem até à Serra Parda.
Há notícias de carregamentos de açúcar da Madeira serem entregues em Rouen (1473) e Dieppe (1479).
Em 1479, buscando proteger o investimento resultante das descobertas, Portugal negociou com Castela o Tratado das Alcáçovas-Toledo, estabelecendo a paz e concertando a política externa Atlântica dos dois reinos rivais:
Portugal obtinha o reconhecimento do seu domínio sobre a ilha da Madeira, o Arquipélago dos Açores, o de Cabo Verde e a costa da Guiné, enquanto que Castela recebia as ilhas Canárias, renunciando a navegar ao Sul do cabo Bojador, ou seja, do Paralelo 27 no qual se encontravam.
O tratado dividia as terras descobertas e a descobrir por um paralelo na altura das Canárias, dividindo o mundo em dois hemisférios: a norte, para a Coroa de Castela; e a sul, para a Coroa de Portugal.
Preservavam-se, desse modo, os interesses de ambas as Coroas, definindo-se, a partir de então, os dois ciclos da expansão: o chamado ciclo oriental, pelo qual a Coroa portuguesa garantia o seu progresso para o sul e o Oriente, contornando a costa africana (o chamado "périplo africano"); e o que se denominou posteriormente de ciclo ocidental, pelo qual Castela se aventurou no oceano Atlântico, para oeste até ao Novo Mundo.
Em 1482 dá-se a construção da Fortaleza de São Jorge da Mina e, no ano seguinte, Diogo Cão chega ao rio Zaire. 
A Fortaleza de São Jorge da Mina e a cidade foram construídos em 1482 em redor da indústria do ouro. Com os lucros deste comércio, Fernão Gomes auxiliou o monarca na conquista de Arzila, Alcácer Ceguer e Tânger. Além da aquisição do ouro e malagueta, o comércio escravagista oferecia boas perspectivas de lucro.
Em 1487, D. João II envia Afonso de Paiva e Pêro da Covilhã em busca do Preste João e de informações sobre a navegação e comércio no Oceano Índico. Nesse mesmo ano, Bartolomeu Dias, comandando uma expedição com três Caravelas, atinge o Cabo da Boa Esperança. Estabelecia-se assim a ligação náutica entre o Atlântico e o Oceano Índico.
O projecto para o caminho marítimo para a Índia foi delineado por D. João II como medida de redução dos custos nas trocas comerciais com a Ásia e tentativa de monopolizar o comércio das especiarias. A juntar à cada vez mais sólida presença marítima portuguesa, D. João almejava o domínio das rotas comerciais e expansão do reino de Portugal que já se transformava em Império Porém, o empreendimento não seria realizado durante o seu reinado. Seria o seu sucessor, D. Manuel I que iria designar Vasco da Gama para esta expedição, embora mantendo o plano original.
Porém, este empreendimento não era bem visto pelas altas classes. Nas Cortes de Montemor-o-Novo de 1495 era bem patente a opinião contrária quanto à viagem que D. João II tão esforçadamente havia preparado. Contentavam-se com o comércio da Guiné e do Norte de África e temia-se pela manutenção dos eventuais territórios além-mar, pelo custo implicado na expedição e manutenção das rotas marítimas que daí adviessem. Esta posição é personificada na personagem do Velho do Restelo que aparece, n'Os Lusíadas de Luís Vaz de Camões, a opor-se ao embarque da armada.
Em 1492, Abraão Zacuto é expulso da Espanha por ser judeu, vindo viver para Portugal, trazendo consigo as tábuas astronómicas que ajudariam os navegadores portugueses no mar.
Face à chegada de Cristóvão Colombo à América no mesmo ano 1492, segue-se a promulgação de três bulas papais - as Bulas Alexandrinas - que concediam a Espanha o domínio dessas terras. Cientes da descoberta de Colombo, os cosmógrafos portugueses argumentaram que a descoberta se encontrava em terras portuguesas.
D. João II consegue uma renegociação, mas só entre os dois Estados, sem a intervenção do Papa, propondo estabelecer um paralelo das Ilhas Canárias. Os castelhanos recusaram a proposta inicial, mas prestaram-se a discutir o caso. Reuniram-se então os diplomatas em Tordesillas.
Como resultado das negociações, foi assinado em 7 de Junho de 1494 o Tratado de Tordesilhas entre Portugal e Castela.
Este tratado estabelecia a divisão do Mundo em duas áreas de exploração: a portuguesa e a castelhana, cabendo a Portugal as terras "descobertas e por descobrir" situadas antes da linha imaginária que demarcava 370 léguas (1.770 km) a oeste das ilhas de Cabo Verde, e à Espanha as terras que ficassem além dessa linha.
Em princípio, o tratado resolvia os conflitos que seguiram à descoberta do Novo Mundo por Cristóvão Colombo e garantia a Portugal o domínio das águas do Atlântico Sul, essencial para a manobra náutica então conhecida como "volta do mar", empregada para evitar as correntes marítimas que empurravam para norte as embarcações que navegassem junto à costa sudoeste africana, permitindo a ultrapassagem do cabo da Boa Esperança.
Nos anos que se seguiram à assinatura do Tratado de Tordesilhas (1494) Portugal prosseguiu no seu projecto de alcançar a Índia, o que foi finalmente alcançado pela frota de Vasco da Gama, na sua primeira viagem de 1497-1499.
Mantendo o plano de D. João II, o rei D. Manuel I mandou aparelhar as naus e escolheu Vasco da Gama, cavaleiro da sua casa, para capitão desta armada. Segundo o plano original, D. João II teria designado seu pai, Estêvão da Gama, para chefiar a armada; mas a esta altura já ambos tinham falecido.
A 8 de Junho de 1497 iniciou-se a expedição semi-planetária que terminaria dois anos depois com a entrada da nau Bérrio pelo rio Tejo adentro, trazendo a boa-nova. Neste dia parte do Restelo a armada chefiada por Vasco da Gama. Tratava-se de uma expedição comportando três embarcações. É a partir da viagem de Vasco da Gama que se introduzem as naus. A 20 de Maio de 1498 Vasco da Gama chega a Calecute. Estabelecia-se assim o caminho marítimo para a Índia.
Em 1499, após o retorno de Vasco da Gama, Pedro Álvares Cabral foi nomeado capitão-mor da armada que se dirigiria à Índia. A sua missão era a de estabelecer relações diplomáticas e comerciais com o Samorim, promovendo a imagem de Portugal e instalando um entreposto comercial ou feitoria, retornando com o máximo de mercadorias.
A sua foi a mais bem equipada armada do século XV, integrada por dez naus e três caravelas, transportando de 1.200 a 1.500 homens, entre funcionários, soldados e religiosos. Era integrada por navegadores experientes, como Bartolomeu Dias e Nicolau Coelho, tendo partido de Lisboa a 9 de março de 1500, após missa solene na ermida do Restelo, à qual compareceu o Rei e toda a Corte.
Mas Pedro Álvares Cabral, por alturas de Cabo Verde, desvia-se da rota. Tendo-se afastado da costa africana, a 22 de abril de 1500, após quarenta e três dias de viagem, avistou o Monte Pascoal no litoral sul da Bahia. No dia seguinte, houve o contato inicial com os indígenas. A 24 de abril, seguiu ao longo do litoral para o norte em busca de abrigo, fundeando na atual baía de Santa Cruz Cabrália, nos arredores de Porto Seguro, onde permaneceu até 2 de maio.
Cabral tomou posse, em nome da Coroa portuguesa, da nova terra, a qual denominou de "Ilha de Vera Cruz"" (mais tarde "Terra de Santa Cruz" e finalmente Brasil - face à abundante existência de madeira pau-brasil), e enviou uma das embarcações menores com a notícia, inclusive a Carta de Pero Vaz de Caminha, de volta ao reino. Retomou então a rota de Vasco da Gama rumo às Índias.
Ao cruzar o cabo da Boa Esperança, perderam-se quatro dos navios, entre os quais o de Bartolomeu Dias, navegador que o descobrira em 1488. Diogo Dias contava entre os navegadores experientes da frota de Pedro Álvares Cabral na segunda armada à Índia. É citado na Carta do Achamento do Brasil de Caminha como «homem gracioso e de prazer». A 10 de Agosto de 1500, após ter dobrado o cabo da Boa Esperança, separou-se do resto da expedição devido aos ventos, e descobriu uma ilha a que deu o nome de São Lourenço, mais tarde designada Madagáscar. Sua embarcação se perdeu durante a tormenta, e acabou sendo o primeiro capitão português a viajar pelo mar Vermelho. Incapaz de prosseguir rumo à Índia, retornou a Portugal, onde chegou com apenas sete homens.
A armada de Pedro Álvares Cabral chega a Calecute em 1501, onde ocorrem confrontos com o Samorim, com o qual acaba por romper relações. Assim, dirige-se para Sul e estabelece uma feitoria em Cochim.
A expedição de Pedro Álvares Cabral viria a abrir uma polémica historiográfica acerca do "acaso" ou da "intencionalidade" da descoberta. Note-se que uma das testemunhas que assinaram o Tratado de Tordesilhas por Portugal foi Duarte Pacheco Pereira, um dos nomes ligados a um suposto descobrimento do Brasil pré-Cabralino. Embora não existam evidências concretas a sustentar qualquer das hipóteses, certo é que por esta data já se tinha, na Europa, o conhecimento da existência de terras a leste da linha do Tratado de Tordesilhas.
Acerca da importância deste livro de marinharia diz Francisco Adolfo de Varnhagen
O Livro de Marinharia de João de Lisboa (c.1470-1525) tem 1514 como única data inscrita pelo autor
, e apresenta um notável globo terrestre, em representação polar, cuja execução coloca em causa todo o conhecimento marítimo à época da sua morte. Nesse mapa, para além de contornos muito precisos de toda a América, nomeadamente do Estreito de Magalhães, incluem-se menções explícitas ao Japão e à Nova Guiné.
Acresce um mapa da América Central e Peru que torna evidente a presença de castelos portugueses na área de influência inca, territórios que depois seriam ocupados pelos espanhóis, de acordo com a divisão de Tordesilhas.
Em 1510 Afonso de Albuquerque conquistou Goa, na Índia e pouco depois, em 1511, Malaca, na Malásia. Simultaneamente investiu esforços diplomáticos com os mercadores do sudeste asiático, como os chineses, na esperança de que estes fizessem eco das boas relações com os portugueses.
Conhecendo as ambições siamesas sobre Malaca, imediatamente enviou Duarte Fernandes em missão diplomática ao Reino do Sião (actual Tailândia), onde foi o primeiro europeu a chegar viajando num junco chinês que retornava à China, estabelecendo relações amigáveis entre os reinos de Portugal e do Sião.
Ainda em Novembro desse ano, ao tomar conhecimento da localização secreta das chamadas "Ilhas das Especiarias", ordenou a partida dos primeiros navios portugueses para o sudeste asiático, comandado pelo seu homens de confiança António de Abreu e por Francisco Serrão, guiados por pilotos malaios. Estes são os primeiros europeus a chegar às Ilhas Banda nas Molucas. A nau de Serrão encalhou próximo a Ceram e o sultão de Ternate, Abu Lais, entrevendo uma oportunidade de aliar-se com uma poderosa nação estrangeira, trouxe os tripulantes para Ternate em 1512. A partir de então os portugueses foram autorizados a erguer uma fortificação-feitoria na ilha, na passagem para o oceano Pacífico: o Forte de São João Baptista de Ternate.
Em 1513, partindo de Malaca (actual Malásia) Jorge Álvares atinge o Sul da China. A esta visita seguiu-se o estabelecimento de algumas feitorias portuguesas na província de Cantão, onde mais tarde se viria a estabelecer o entreposto de Macau. De acordo com os registos disponíveis, foi o primeiro europeu a alcançar e visitar o território que actualmente é Hong Kong.
Em 1543, Francisco Zeimoto, António Mota e António Peixoto são os primeiros portugueses a atingir o Japão. Terão aportado ao Japão a 23 de Setembro, tendo sido este primeiro contacto de europeus com o Japão, relatado pelo cronista Fernão Mendes Pinto. Segundo este, a ilha de Tanegashima teria sido o primeiro lugar visitado pelos portugueses, que espantaram os autóctones não só com o relato de terras e costumes que tinham visto como com a novidade das armas de fogo, visto que o conhecimento da pirobalística ainda não tinha chegado ao Japão. A chegada dos portugueses deu origem ao período de comércio Nanban (os portugueses eram designados por Nanban-jin, denominação que significa «bárbaros do sul»), durante o qual uma intensa interação com os poderes europeus ocorreu tanto a nível econômico como religioso.
Os descobrimentos Portugueses marcaram a primeira presença dos europeus, chegando pelos Oceanos, entre os primórdios do Século XV e a primeira metade do Século XVI, em muitos dos actuais países. Os portugueses foram os pioneiros nos países:
As Filipinas, as possessões Marianas Setentrionais (EUA) e a Polinésia Francesa (FRA) foram descobertas por um português a serviço da Espanha, Fernão de Magalhães, durante a sua viagem de circum-navegação.
As sucessivas navegações e a experiência acumulada dos pilotos levaram a uma evolução bastante rápida da ciência náutica portuguesa, tendo a investigação criado uma elite de astrónomos, navegadores, matemáticos e cartógrafos, entre os quais se destacaram Pedro Nunes com os estudos sobre a forma de determinar as latitudes por meio dos astros e D. João de Castro.
Até ao século XV os portugueses praticavam a navegação de cabotagem utilizando a barca e o barinel, embarcações pequenas e frágeis de um mastro com vela quadrangular fixa, usadas nas primeiras viagens às ilhas Canárias, Madeira e Açores, e no litoral africano até Arguim, na actual Mauritânia. Mas que não conseguiam dar resposta às dificuldades no avanço para Sul, como os baixios, os ventos fortes e as correntes marítimas desfavoráveis, sendo substituídas pelas caravelas.
A caravela foi o navio que marcou os descobrimentos portugueses, resultando do aperfeicoamento de embarcações já usadas na faina da pesca. Era e ágil e de navegação mais fácil, com uma tonelagem entre 50 a 160 toneladas e 1 a 3 mastros com velas latinas triangulares que permitiam bolinar. A pouca capacidade de carga e tripulação eram os seus principais inconvenientes, mas que não obstaram ao seu sucesso. Entre as caravelas famosas estão a Bérrio e a Caravela Anunciação.
Com a passagem das navegações costeiras às oceânicas também as naus se desenvolveram de forma assinalável em Portugal. "Nau" era o sinónimo arcaico de navio de grande porte, destinado essencialmente a transportar mercadorias. Devido à pirataria que assolava a costa, passaram a ser utilizadas na marinha de guerra. Foram introduzidas as bocas-de-fogo, que levaram à classificação das naus segundo o poder de artilharia. À medida que se foi desenvolvendo o comércio marítimo, foram sendo modificadas as suas características. A capacidade aumentou das duzentas toneladas no século XV até às quinhentas. As naus eram imponentes e tinham, em geral, duas cobertas, castelos de proa e de popa, dois a quatro mastros e velas sobrepostas. Na carreira da Índia no século XVI foram também usadas as carracas, naus de velas redondas e borda alta com três mastros que atingiam 2000 toneladas.
No século XIII era já conhecida a navegação astronómica através da posição solar. Para a navegação astronómica os portugueses, como outros europeus, recorriam a instrumentos de navegação árabes, como o astrolábio e o quadrante, que aligeiraram e simplificaram. Inventaram outros, como a balestilha, para obter no mar a altura do sol e outros astros, como o Cruzeiro do Sul descoberto após a chegada ao hemisfério Sul por João de Santarém e Pêro Escobar em 1471, que iniciaram a navegação guiada por esta constelação. 
Mas os resultados variavam conforme longo do ano, o que obrigava a correcções. Para isso os portugueses utilizaram tabelas de inclinação do Sol, as Tábuas astronómicas, preciosos instrumentos de navegação em alto-mar, que conheceram uma notável difusão no século XV. Quando se introduziram na náutica as observações astronómicas que a revolucionaram, em particular a observação de altura meridiana do Sol para com o conhecimento da declinação solar, se poder calcular a latitude do lugar, recorreu-se às tábuas "Almanach Perpetuum", do astrónomo Abraão Zacuto, publicadas em Leiria em 1496, que foram utilizadas, juntamente com o seu astrolábio melhorado, por Vasco da Gama e Pedro Álvares Cabral.
Além da exploração do litoral foram feitas também viagens para o mar largo em busca de informações meteorológicas e oceanográficas (foi nestes trajectos que se descobriram os arquipélagos da Madeira e dos Açores, o Mar dos Sargaços). O conhecimento do regime de ventos e correntes do Atlântico e a determinação da latitude por observações astronómicas a bordo, permitiu a descoberta da melhor rota oceânica de regresso de África: cruzando o Atlântico Central até à latitude dos Açores, aproveitando os ventos e correntes permanentes favoráveis, que giram no sentido dos ponteiros do relógio no hemisfério norte devido à circulação atmosférica e ao efeito de Coriolis, facilitando o rumo directo para Lisboa e possibilitando assim que os portugueses se aventurassem cada vez para mais longe da costa, manobra que ficou conhecida como "volta da Mina", ou "Volta do mar".
Pensa-se que Jehuda Cresques, filho do cartógrafo catalão Abraão Cresques terá sido um dos notáveis cartógrafos ao serviço do Infante D. Henrique. Contudo a mais antiga carta de marear portuguesa assinada é um portulano de Pedro Reinel de 1485 representando a Europa Ocidental e parte de África, que reflecte as explorações efectuadas pelo navegador Diogo Cão ao longo da costa africana. Reinel foi também autor da primeira carta náutica conhecida com uma indicação de latitudes em 1504 bem como da primeira representação da rosa-dos-ventos.
Com o seu filho, Jorge Reinel e o cartógrafo Lopo Homem, participou na elaboração do atlas conhecido por "Atlas de Lopo Homem-Reinés" ou "Atlas de Miller", de 1519. Foram considerados dos melhores cartógrafos do seu tempo, a ponto do imperador Carlos V os desejar a trabalhar para si. Em 1517 o rei D. Manuel I de Portugal passou a Lopo Homem, cartógrafo e cosmógrafo português, um alvará que lhe dava o privilégio de fazer e emendar todas as agulhas (bússolas) dos navios.
Na terceira fase da antiga cartografia náutica portuguesa, caracterizada pelo abandono da influência de Ptolemeu na representação do Oriente e por uma melhor precisão na representação das terras e continentes, destaca-se Fernão Vaz Dourado (Goa ~1520 — ~ 1580), cuja obra apresenta extraordinária qualidade e beleza, conferindo-lhe a reputação de um dos melhores cartógrafos de seu tempo. Muitas de suas cartas são de grande escala.

Sancho I (Coimbra, – Coimbra, ), apelidado de Sancho, o Povoador, foi o Rei de Portugal de 1185 até sua morte. Era filho do rei Afonso I de Portugal e sua esposa Mafalda de Saboia. Ele promoveu e apadrinhou o povoamento dos territórios do país — destacando-se a fundação da cidade da Guarda, em 1199, e a atribuição de cartas de foral na Beira e em Trás-os-Montes: Gouveia (1186), Covilhã (1186), Viseu (1187), Bragança (1187), São Vicente da Beira (1195) ou Belmonte (1199), povoando assim áreas remotas do reino, em particular com imigrantes da Flandres e da Borgonha.
Quinto filho do monarca Afonso Henriques, foi batizado com o nome de Martinho, por haver nascido no dia do santo Martinho de Tours, e não estaria preparado para reinar; no entanto, a morte do seu irmão mais velho, D. Henrique, quando Martinho contava apenas três anos de idade, levou à alteração da sua onomástica para um nome mais hispânico, ficando desde então Sancho Afonso.
Em 15 de agosto de 1170 Sancho foi armado cavaleiro pelo seu pai logo após o acidente de D. Afonso Henriques em Badajoz e tornou-se seu braço direito, quer do ponto de vista militar, quer do ponto de vista administrativo. Nestes primeiros tempos de Portugal enquanto país independente, muitos eram os inimigos da coroa, a começar pelo Reino de Leão que havia controlado Portugal até então. Para além do mais, a Igreja demorava em consagrar a independência de Portugal com a sua bênção. Para compensar estas falhas, Portugal procurou aliados dentro da Península Ibérica, em particular o reino de Aragão, um inimigo tradicional de Castela, que se tornou no primeiro país a reconhecer Portugal. O acordo foi firmado 1174 pelo casamento de Sancho, então príncipe herdeiro, com a infanta Dulce, irmã mais nova do rei .
No ano de 1178, D. Sancho faz uma importante expedição contra mouros, confrontando-os perto de Sevilha e do rio Guadalquivir, e ganha-lhes a batalha. Com essa ação, expulsa assim a possibilidade deles entrarem em território português.
Com a morte de Afonso Henriques em 1185, Sancho I torna-se no segundo rei de Portugal. Tendo sido coroado na Sé de Coimbra, manteve essa cidade como o centro do seu reino. D. Sancho deu por finda as guerras fronteiriças pela posse da Galiza e dedicou-se a guerrear os mouros localizados a Sul. Aproveitou a passagem pelo porto de Lisboa dos cruzados da terceira cruzada, na primavera de 1189, para conquistar Silves (Portugal), um importante centro administrativo e económico do Sul, com população estimada em 20.000 pessoas. Sancho ordenou a fortificação da cidade e construção do castelo que ainda hoje pode ser admirado. A posse de Silves foi efémera já que em 1190 Abu Yusuf Ya'qub al-Mansur cercou a cidade de Silves (Portugal) com um exército e com outro atacou Torres Novas, que apenas conseguiu resistir durante dez dias, devido ao rei de Leão e Castela ameaçar de novo o Norte.
Sancho I dedicou muito do seu esforço governativo à organização política, administrativa e económica do seu reino. Acumulou um tesouro real e incentivou a criação de indústrias, bem como a classe média de comerciantes e mercadores. Sancho I concedeu várias cartas de foral principalmente na Beira e em Trás-os-Montes: Gouveia (1186), Covilhã (1186), Viseu (1187), Bragança (1187), São Vicente da Beira (1195), Guarda (1199), etc, criando assim novas cidades, e povoando áreas remotas do reino, em particular com imigrantes da Flandres e Borgonha. O rei é também lembrado pelo seu gosto pelas artes e literatura, tendo deixado ele próprio vários volumes com poemas. Neste reinado sabe-se que alguns portugueses frequentaram universidades estrangeiras e que um grupo de juristas conhecia o Direito que se ministrava na escola de Bolonha. Em 1192 concedeu ao mosteiro de Santa Cruz 400 morabitinos para que se mantivessem em França os monges que lá quisessem estudar.
Outorgou o seu primeiro testamento em 1188/89 no qual doou a sua esposa os rendimentos de Alenquer, terras do Vouga, Santa Maria da Feira e do Porto. Seu último testamento foi feito em outubro de 1209 quase dois anos antes de sua morte. O seu túmulo encontra-se no Mosteiro de Santa Cruz, em Coimbra, ao lado do túmulo do pai.
O primeiro estilo oficial de D. Sancho I enquanto Rei de Portugal:
Com a Tomada de Silves, em 1189, a titulatura régia evolui para:
Quando os Almóadas retomam Silves, em 1191, D. Sancho volta a usar o seu estilo oficial original.
De sua mulher a infanta Dulce de Aragão, filha da rainha Petronilha de Aragão e , conde de Barcelona, com quem casou em 1174: 
Filhos naturais:
O rei teve dois filhos com Maria Aires de Fornelos, primeira mulher de Gil Vasques de Soverosa, filha de Aires Nunes de Fornelos e de Maior Pais de Bravães e neta de Soeiro Mendes da Maia "o Bom". Em abril de 1207, D. Sancho fez doação perpétua da Vila Nova dos Infantes e de Golães para os filhos que tive com Maria com a faculdade de os vender a quem quisessem. Em 1175, Maria com seu esposo Gil Vasques de Soverosa, e seus filhos Martim e Urraca, doou umas casas a seus parentes Marina Pais e Vasco Pires.
Havidos de Maria Pais Ribeira, dita "a Ribeirinha", filha de Paio Moniz de Ribeira e de Urraca Nunes de Bragança, filha de Vasco Pires de Bragança.
Havido de Maria Moniz de Ribeira, filha de Monio Osórez de Cabrera, conde de Cabrera e Ribera no Reino de Leão, e de Maria Nunes de Grijó, filha de Nuno Soares de Grijó e de Elvira Gomes:
! colspan="3" style="background: #FBEC5D;" | Sancho I de PortugalCasa de Borgonha11 de novembro de 1154 – 26 de março de 1211

Afonso II (Coimbra, – Coimbra, ), apelidado de Afonso, o Gordo, foi o Rei de Portugal de 1211 até sua morte. Era filho do rei Sancho I e sua esposa Dulce de Aragão.
Os primeiros anos do seu reinado foram marcados por violentos conflitos internos (1211-1216) entre Afonso II e as suas irmãs Mafalda, Teresa e Santa Sancha de Portugal (a quem seu pai legara em testamento, sob o título de rainhas, a posse de alguns castelos no centro do país - Montemor-o-Velho, Seia e Alenquer -, com as respectivas vilas, termos, alcaidarias e rendimentos), numa tentativa de centralizar o poder régio. Este conflito foi resolvido com intervenção do papa Inocêncio III. O rei indemnizou as infantas com muito dinheiro, a guarnição dos castelos foi confiada a cavaleiros templários, mas era o rei que exercia as funções soberanas sobre as terras e não as infantas como julgavam ter e que levou à guerra.
No seu reinado foram criadas as primeiras leis escritas e pela primeira vez reunidas cortes com representantes do clero e nobreza, em 1211 na cidade de Coimbra, na altura capital. Foram realizadas "inquirições" em 1220, inquéritos feitos por funcionários régios com vista a determinar a situação jurídica das propriedades e em que se baseavam os privilégios e imunidades dos proprietários. As "confirmações" validavam as doações e privilégios concedidos nos anteriores reinados, após analisados os documentos comprovativos ou por mercê real. Todo o seu reinado foi um combate constante contra as classes privilegiadas, isto porque seu pai e avô deram grandes privilégios ao clero e nobreza e Afonso II entendia que o poder real devia ser fortalecido.
O reinado de Afonso II caracterizou um novo estilo de governação, contrário à tendência belicista dos seus antecessores. Afonso II não contestou as suas fronteiras com Galiza e Leão, nem procurou a expansão para Sul (não obstante no seu reinado ter sido tomada aos mouros as cidades de Alcácer do Sal, Borba, Vila Viçosa, Veiros, em 1217, e, possivelmente também Monforte e Moura, mas por iniciativa de um grupo de nobres liderados pelo bispo de Lisboa), preferindo sim consolidar a estrutura económica e social do país. O primeiro conjunto de leis portuguesas é de sua autoria e visam principalmente temas como a propriedade privada, direito civil e cunhagem de moeda. Foram ainda enviadas embaixadas a diversos países europeus, com o objectivo de estabelecer tratados comerciais. Apesar de, como já dissemos, não ter tido preocupações militares, enviou tropas portuguesas que, ao lado de castelhanas, aragonesas e francesas, combateram bravamente na célebre batalha de Navas de Tolosa na defesa da Península Ibérica contra os muçulmanos.
Outras reformas de Afonso II tocaram na relação da coroa Portuguesa com o Papa. Com vista à obtenção do reconhecimento da independência de Portugal, Afonso Henriques, seu avô, foi obrigado a legislar vários privilégios para a Igreja. Anos depois, estas medidas começaram a ser um peso para Portugal, que via a Igreja desenvolver-se como um estado dentro do estado. Com a existência de Portugal firmemente estabelecida, Afonso II procurou minar o poder clerical dentro do país e aplicar parte das receitas das igrejas em propósitos de utilidade nacional. Esta atitude deu origem a um conflito diplomático entre o Papado e Portugal. Depois de ter sido excomungado pelo Papa Honório III, Afonso II prometeu rectificar os seus erros contra a Igreja, mas morreu em 1223 excomungado, sem fazer nenhum esforço sério para mudar a sua política.
Só após a resolução do conflito com a Igreja, logo nos primeiros meses de reinado do seu sucessor Sancho II, pôde finalmente Afonso II descansar em paz no Mosteiro de Alcobaça (foi o primeiro monarca a fazer da abadia cisterciense o panteão real).
Diz-se que D. Afonso II possa ter morrido de lepra (isso poderá ter justificado um dos seus cognomes, "o Gafo", bem como uma célebre e depreciativa frase dita por alguns elementos do povo: "Fora Gaffo!"), mas a enorme gordura que o rei possuía teria sido a sua causa de morte.
O estilo oficial de D. Afonso II enquanto Rei de Portugal:
Com a sua mulher, Urraca de Castela (1186-1220):
Filhos naturais:
|-
! colspan="3" style="background: #FBEC5D;" | Afonso II de PortugalCasa de Borgonha23 de abril de 1185 – 25 de abril de 1223 

Sancho II (Coimbra, – Toledo, ), apelidado de "o Capelo" e "o Piedoso", foi o Rei de Portugal de 1223 até ser deposto em 1247 por seu irmão mais novo Afonso III. Era o filho mais velho do rei Afonso II e sua esposa Urraca de Castela.
Sancho II viria a chefiar um reino que atravessava uma profunda crise económica que já se tinha feito sentir nos tempos do seu avô Sancho I, devido a uma série de factores conjunturais e locais, como as más colheitas e consequente subida de preços e fome, ou a escassez dos frutos de pilhagens e saques a potências inimigas nos últimos anos do seu reinado. Daí que em 1210 tenhamos registo de Sancho I, juntamente com Vasco Mendes, terem recorrido à pilhagem da quintã de um dos seus próprios paisanos, Lourenço Fernandes da Cunha, para enriquecer os cofres reais. Esta acção não parece ter sido isolada, e virá a repetir-se, seguindo o exemplo real.
Neste ano conturbado crê-se ter nascido Sancho II, provavelmente entre os dois últimos meses. O jovem Sancho esteve, pelo menos durante esses primeiros anos do reinado de Afonso, debaixo da tutelagem dos seus vassalos Martim Fernandes de Riba de Vizela e Estevainha Soares da Silva, casal nobre ligado por parentesco aos Sousa e aos de Lanhoso. Martim tinha sido alferes do rei em 1203, posição que manterá até à morte deste, para subir, com Afonso II, ao mordomado, no mesmo ano em que este assume a Coroa. Parece contudo morrer em 1212, deixando Sancho, que não podia ter mais de 2 anos, a cargo de sua mulher Estevainha. Em 1213, através de uma doação feita por Estevainha a um mosteiro, sabemos que o jovem Sancho se encontrava doente. Embora não se saiba ao certo, é provável que Sancho tenha sido criado em Coimbra e na região do Entre Douro e Minho, e que sua ama tenha sido Teresa Martins, filha de Estevainha.
No verão de 1222, Afonso II já não confirma os diplomas por sua mão, uma manifestação inequívoca de incapacidade, e Sancho, o infante herdeiro, estava ainda a um ou dois anos da idade da róbora. Numa perspectiva destas, o futuro do reino português era, a um ano da coroação de Sancho II, incerto, pelo menos o da linha de Afonso II. Façamos referência ainda a Martim e Pedro Sanches. Martim era filho bastardo de Sancho I e meio-mão do Pedro e do rei Afonso II. Pedro era irmão mais novo do rei Afonso II. O primeiro tinha feito uma investida militar contra Braga e Guimarães, desbaratando a hoste real em 1220 e assim dando o exemplo para que, em Junho de 1222, Afonso IX de Leão tomasse o castelo de Santo Estêvão de Chaves, o segundo foi promovido ilimitadamente na corte leonesa aquando da morte do seu irmão Afonso II. 
Ambos foram revestidos de tenências de terras muito perto das fronteiras portuguesas, e ambos representaram uma ameaça permanente nesta conjuntura para a sobrevivência independente do então ainda jovem reino português.
D. Sancho II é coroado na Primavera de 1223, seu pai D. Afonso II tendo morrido excomungado pelo Papa Honório III. Começava já com o pé esquerdo, visto que era filho de um casamento que ia contra a lei canónica - Afonso II e Urraca de Castela - e que era menor, não tendo ainda atingido os catorze anos e possivelmente os treze. H. Fernandes argumenta que o facto de nenhum tutor ter sido seleccionado para participar, assinando, dos documentos saídos da chancelaria de Sancho II durante a sua menoridade, e de se observar a ausência de um ritual de passagem como a investidura na cavalaria que marca a entrada de Afonso VIII na posse real do reino de Leão, viriam a ajudar o argumento a favor da sua deposição. 
Outra linha de argumento, utilizada por exemplo por Honório III em correspondência com o monarca, leva em consideração a idade tenra e primeira adolescência de Sancho II e realça o papel corruptor dos seus conselheiros régios. Tornar-se-á um dispositivo recorrente nos discursos sobre Sancho produzidos, muito para além dos primeiros anos do seu reinado. Tanto um artifício como o outro visam desculpabilizá-lo, ou simplesmente fazê-lo sobressair como fraco e incapaz de reinar.
Filhas e herdeiras de considerável feudo territorial de Sancho I, seu pai, estas tinham em Teresa, antiga rainha de Leão, um líder incontestado, visto que parecia querer assumir, tal como a sua rival Berenguela, papel nuclear na política do Ocidente peninsular. As raízes do conflito remontam ao primeiro testamento de Sancho I, redigido em 1188, que disponibilizava os castelos de Alenquer, Montemor, Viseu, Guimarães e Santa Maria para a sua mulher D. Dulce e para as suas filhas e deixava à sua filha maior D. Teresa o castelo de Montemor e Cabanões, e à mais nova, Sancha, Bouças, Vila do Conde e Fão. Há um detalhe que se revela logo de início capaz de semear a discórdia: a concessão hereditária feita a Teresa, de 12 anos, e Sancha, de 8. 
Parece residir aqui um dos pomos fomentadores da discórdia entre o herdeiro Afonso e suas irmãs, na medida em que colocava nas mãos de Teresa e de Sancha um feudo territorial de consideráveis dimensões, correspondendo aos territórios dos Castelos. No seu segundo e último testamento, Sancho reforça estas dotações prévias, Teresa ficando na posse de Montemor e Esgueira, Sancha de Alenquer, Mafalda dos mosteiros de Bouças e de Arouca e da herdade de Seia que havia sido de sua mãe.
Logo nos primeiros meses do seu precoce reinado, em 1223, o jovem Sancho assina acordo com as tias para resolver esta querela, dando-lhes tudo aquilo que Afonso II não lhes quisera reconhecer, sobretudo os castelos, conseguindo também a inclusão de Branca, não contemplada no testamento de Sancho I, com bens imóveis, e agora transformada em herdeira de Teresa na parcela de Montemor e Esgueira. Vão somar ainda à posse dos castelos às infantas Teresa e Sancha a muito elevada quantia de 4000 morabitinos anuais, a pagar sobre os direitos de Torres Vedras que entre si devem dividir. 
Ficam assim com a totalidade das rendas de outro dos centros urbanos mais significativos da Estremadura, contribuindo para cimentar a sua influência numa área onde a penetração senhorial era reduzida e que tradicionalmente fazia parte do domínio directo do rei. Crê-se que tanto este acordo como o celebrado pouco tempo depois com o Arcebispo de Braga Estêvão Soares já tivessem sido planeados nos tempos finais de Afonso II, mas que, talvez devido à doença destruidora deste, se tinham posto de parte, aguardando sua morte.
Sancho II terá possivelmente planeado uma ofensiva com o objectivo de retomar estes castelos em 1231.
D. Sancho II teve dissenções com o Bispo do Porto por ter intervindo nas graves fracturas que afectavam a relação do bispo com os seus cónegos e com a elite da cidade. Assim é então que na Primavera de 1210 o Papa Inocêncio III troca correspondência com D. Martinho Rodrigues, tratando as graves opressões e enormes injúrias perpretradas sobre ele e os seus homens bem como alguns cónegos que lhe tinham permanecido fiéis. A razão destes desacordos aparenta ter sido o facto de Rodrigues não ter aceitado a proposta de Sancho de promover a entrada solene e processional na cidade em benefício de seu filho Afonso, porque o casamento deste com Urraca era ilícito face à lei canónica, que nesta altura ainda restringia os casamentos até ao sétimo grau de parentesco. 
A reacção de D Sancho I fora uma de violência formal ritualizada, nas palavras de Hermenegildo Fernandes, visto que foram destruídas as casas dos cónegos fiéis ao bispo, forçadas as fechaduras das portas da Igreja, invadido o espaço sagrado por indivíduos excomungados, sepultos os corpos mortos em interdito. Como se isso não bastasse, D. Martinho Rodrigues foi ainda enclausurado com o seu deão no paço episcopal durante cinco meses, de onde sairá, numa fuga nocturna com destino a Roma, evitando assim a composição que D. Sancho II o queria compelir a subscrever, mas pondo em risco os seus bens, confiscados pelo porteiro régio para seu uso pessoal e do rei. Aqui encontramos a génese dos problemas que Sancho II virá a ter com Rodrigues.
Nos anos de 26, 27 e 28 a hostilidade entre rei e bispo agudiza-se, visto que falhara a hipótese de expansão para o interior (Elvas) e o rei voltava-se para os centros urbanos e portuários do litoral. Para além de Braga, o Porto, por concessão de D. Teresa, trisavó de Sancho II, era o único centro urbano com alguma relevância no reino que não tinha o rei por senhor. Enquanto se manteve, esta situação provocou um prolongado conflito entre os cidadãos e o seu bispo.
O que estava em causa era a jurisdição do Porto e algumas das rendas e direitos do bispo na sua diocese. Ao ignorar a doação feita pela sua trisavó, Sancho II procurava apropriar-se de um senhorio e aumentar o domínio real, ampliando a massa colectável. Em jogo estava também o controle dos benefícios eclesiásticos e o incumprimento da doação das dízimas por D. Afonso II às Igrejas do Reino.
Acusações parecidas podem ser verificadas no caso de Lisboa, quando paróquias vagavam por morte do prior o rei entregava-as a laicos inúteis, estranhos e desconhecidos que não querem receber ordens do presbítero e que nesse sentido ficam aquém das imposições canónicas.
Segundo H. Fernandes o sistema clientelar estava em causa, estando o direito de apresentar os clérigos no centro das práticas de distribuição de benesses em que este se apoiava, neste caso vendo-se a pressão do rei não como incidindo directamente sobre os rendimentos das igrejas mas sobre o direito de dispor deles a favor dos seus homens em detrimento do bispo. Em 1233 há novas queixas.
Estêvão Soares da Silva era um dos mais poderosos metropolitas da Hispânia Ocidental, o mais importante dos bispos portugueses. Os conflitos da Coroa com este clérigo remontam ao ano de 1219, ainda durante o reinado de Afonso II. Em Agosto de 1220 Afonso promove no território do arcebispado a primeira de numerosas inquirições que o século de 1200 verá, atingindo o arcebispo assim no coração da sua área de influência. Este processo visava robustecer os direitos reais, principalmente no Norte arqui-episcopal, segmento do reino que Afonso pior controla e que há quase dois séculos era palco de um processo senhorializador, usufruindo de benefícios como isenções fiscais. 
Assiste-se então a uma violenta disputa, que envolve a destruição dos bens do arcebispo perpetrada pels cavaleiros de Coimbra e de Guimarães, vassalos do rei e que forçará Estêvão Soares ao exílio, lançando o rei na excomunhão e o reino em interdito. O Papa Honório III pede ajuda ao rei de Leão, Afonso IX, tendo já enviado uma série de missivas a prelados desse reino e do de Castela, para conseguir apoio em favor de Estêvão Soares. Nota-se, nas palavras de H. Fernandes, que a lisonja utilizada em referência ao monarca Leonês serve evidentes desígnios políticos papais, deixando a pairar a legitimidade ou pelo menos a promessa de um silêncio cúmplice por parte do pontífice, no caso de uma intervenção leonesa em território português. Ameaça ainda Afonso II de invalidar o seu reino, tornando-o assim vulnerável a conquistas por outros reis católicos.
De facto, com o acordo assinado em mês incerto de 1223, Sancho fizera a paz com Estêvão Soares, tanto mais que este não defende o Bispo do Porto na sua contenda com o mesmo, e deixa ainda, em testemunho em 1228, 1000 morabitinos ao rei, que este ainda lhe devia dos 6000 que se obrigara a pagar no acordo de cinco anos anterior.
Um dos principais responsáveis pelo cerco de Alcácer, D. Soeiro já tinha contenda com Afonso II. As razões, segundo os diplomas papais, são a apropriação do direito de padroado, o que lhe permitira colocar nos benefícios eclesiásticos indivíduos da sua clientela; proibição do bispo construir mosteiros, igrejas e capelas, provavelmente para impedir a proliferação de instituições que escapassem a esse mesmo direito padroado régio; desprezo pela autoridade da Igreja para ministrar sacramentos, ignorando as excomunhões já lançadas e intervindo junto dos habitantes de Santarém, a outra grande cidade do bispado, para que não se fizessem absolver; violação das imunidades eclesiásticas, obrigando os clérigos a pagar direitos - vacas, porcos, carneiros - ignorando o foro judicial e eclesiástico, coagindo-os ao serviço militar, de hoste, aos encargos de manutenção das torres, muralhas e guarda delas, assaltando-lhes enfim as casas, sob o pretexto de procurar aí mulheres, barregãs, costume interdito pela ordenação régia; por último acusando o rei de ignorar ostensivamente as determinaçãos do IV Concílio de Latrão que segregava social e físicamente os judeus, minoria que o monarca, Afonso II e, na sua esteira, Sancho II, continuava a privilegiar, protegendo-os da prática do uso dos sinais distintivos e do interdito de os cristãos comerciarem com eles, perguindo por isso o bispo a quem negava a dízima e preferindo os judeus aos cristãos nos ofícios régios. Infamante entre todas, a utilização dos serviços de judeus e mouros como autores materiais dos ataques contra a Igreja. Segundo H. Fernandes estas queixas são quase padronizadas: como o próprio papa reconhece, a situação sendo similar à que opusera poucos anos antes o arcebispo de Braga Estêvão Soares a Afonso II.
Dois anos antes, em Março de 1222, Honório II entendera por bem escrever aos priores dos dominicanos, franciscanos e da Ordem de Santiago na diocese de Lisboa, dando-lhes plenos poderes para que usassem da sua discrição e entendimento para pôr cobro aos abusos do bispo olisiponense Soeiro Viegas. As acusações às quais o papa dera inteiro crédito eram referentes ao bispo e os prelados das igrejas incorrerem em práticas de extorsão, recusando ministrar os sacramentos a quem não lhes deixasse em testamento a terça ou uma determinada parte dos seus bens. Talvez houvesse portanto um conflito aberto entre a oligarquia urbana e o bispo que tenha permitido ou pelo menos potenciado os ataques que este tinha vindo a sofrer por parte do rei. O prolongamento deste conflito resultará no lançar do Interdito sobre o reino português no ano de 1231 por um grupo de juízes da Sé apostólica.
Contrariamente ao que durante muito tempo a historiografia tradicional portuguesa se esforçou por indicar, Sancho II não era um capaz chefe militar, e tampouco participou de forma activa das conquistas que se deram ao longo do Guadiana a partir do ano de 1230. O castelo de Elvas aparenta ter sido tomado "pela graça do salvador", portanto sem a intervenção de Sancho, ocupado quase que por sorte, sem confronto militar. Este padrão repetir-se-á, por exemplo, com Beja.
De certa forma, a reconquista é impulsionada pelo Papa Gregório IX, que, em 1232, concede a Sancho que não pode ser excomungado sem mandado especial da Santa Sé, desde que persista na guerra contra os sarracenos, e que portanto nenhum dos seus bispos o possa excluir da comunidade cristã. Estas absolvições continuaram, vendo-se em Junho de 1233 uma por violências cometidas por Sancho sobre clérigos "com a sua mão e com um bastão".
Embora várias cidades no Algarve e no Alentejo tenham sido conquistadas durante o reinado de Sancho II, este trabalho é protagonizado quase exclusivamente pelas Ordens Militares, como a Ordem de Santiago, que recebeu como pagamento dos serviços prestados diversas povoações, tais como Aljustrel, Sesimbra, Aljafar de Pena, Mértola, Aiamonte e Tavira, facto que porá Sancho cada vez mais dependente delas. Concentra-se em utilizá-las também para povoar as regiões desertas, outra missão pontifícia, doando-lhes terras e castelos à medida que vão conquistando. Foram emitidas, em 1234 e 1241, bulas papais de Cruzada para o reino de Portugal. Em 1241, Sancho casa com Mécia Lopes de Haro.
A 16 de agosto de 1234, D. Sancho II é excomungado pelo mesmo comité de juízes pontifícios que lançara o Interdito em 1231, reunido em Ciudad Rodrigo. Era a consequência natural da Bula "Si quam horribile" do ano anterior. O eterno e cada vez mais omnipotente chanceler de D Sancho, Mestre Vicente, é enviado em missão à Cúria Pontifícia, conseguindo assim minorar os efeitos da excomunhão sobre a autoridade de D. Sancho II, prolongando assim o seu reinado.
O isolamento político de Sancho II começa provavelmente em 1232, estando o reino com conturbações internas; Afonso de Castela entra nesse ano pelo Norte do reino em defesa de Sancho II. Resigna também em Roma o bispo de Coimbra, Pedro, aliado de Sancho. 
D. Afonso, irmão mais novo de Sancho, denuncia em 1245 o casamento de Sancho com Mécia. Nesse mesmo ano a Bula "Inter alia desiderabilia" prepara a deposição "de facto" do monarca. O papado, através de duas Breves, aconselha Afonso, Conde de Bolonha, a partir para a Terra Santa em Cruzada e também que passe a estar na Hispânia, fazendo aí guerra ao Islão. A 24 de julho, a Bula "Grandi non immerito" depõe oficialmente Sancho II do governo do reino, e Afonso torna-se regente. Os fidalgos levantam-se contra Sancho, e Afonso cede a todas as pretensões do clero no Juramento de Paris, uma assembleia de prelados e nobres portugueses, jurando que guardaria todos os privilégios, foros e costumes dos municípios, cavaleiros, peões, religiosos e clérigos seculares do reino. Abdicou imediatamente das suas terras francesas e marchou sobre Portugal, chegando a Lisboa nos últimos dias do ano.
Em 1246, Afonso segura Santarém, Alenquer, Torres Novas, Tomar, Alcobaça e Leiria; Sancho II fortifica-se em Coimbra. A Covilhã e a Guarda ficam nas mãos de Afonso. Sancho II procura a intervenção castelhana na guerra civil, depois da conquista de Jaén. Assim, o infante Afonso de Castela entra em Portugal por Riba-Côa a 20 de dezembro, tomando a Covilhã e a Guarda e devastando o termo de Leiria, derrotando a 13 de janeiro de 1247 o exército do Conde de Bolonha. Apesar de não ter perdido nenhuma das batalhas contra o irmão do Rei de Portugal, Afonso de Castela decide abandonar a empresa, levando consigo para Castela El-Rei D. Sancho II, visto que a pressão da Santa Sé aumentava. Embora no Minho continuem partidários de Sancho II e fiquem no terreno as guarnições castelhanas no castelo de Arnoia (seu grande apoiante e anticlerical), o caso encontra-se perdido. D. Sancho II redige o seu segundo e último testamento enquanto exilado em Toledo a 3 de Janeiro de 1248, e morre a 4 desse mesmo mês. Julga-se que os seus restos mortais repousem na catedral de Toledo. 
Afonso III declara-se Rei de Portugal em 1248, já após a morte do seu irmão mais velho, Sancho.
Na medida em que os conflitos com o clero ocorriam a uma escala maior que a do reino português, eles demonstram uma linha de oposição entre um modelo de sociedade teocrática, tal como o papado desde Gregório VII o vinha propondo e um outro, menos definido, mas que tem o poder dos príncipes como centro e que a recuperação do legado romano virá contribuir para unificar em torno de bases ideológicas mais sólidas. Conflitos entre o rei e os bispos, destes com os seus cabidos, intervenções papais: tudo parece convergir num ponto onde os interesses casuísticos dos grupos se encontram com processos de longa duração que afectam a própria organização social urbana. Mencione-se ainda que as sequelas destas conturbações prolongar-se-ão durante o tempo em que outros estão nos cargos de Bispo acima mencionados.
Os vestígios escritos da chancelaria de Sancho II oferecem um grande número de lacunas por vezes extensas, por exemplo de 1229 a 1235, o que H. Fernandes julga ser fruto de uma provável destruição desta documentação pelo irmão e futuro rei Afonso III. Até ao ano de 1236, o Mestre Vicente é chanceler do rei, maestro da política régia, detendo assim um cargo importante. De 1236 em diante, Sancho II traz frequentemente os seus físicos na Corte, sinal de que provavelmente já se encontrava doente. As pilhagens a partir de 1236 são protagonizadas por bandos de fidalgos com os seus homens.
José Mattoso, no seu artigo sobre a "Crise de 1245", fala numa crescente agitação social, dando para esta a justificação de um crescimento demográfico desequilibrado em relação à expansão territorial. Fala-se também num desequilíbrio conjuntural que impulsiona também o banditismo generalizado, praticado por marginais e não só, havendo também acesas lutas entre nobres e o clero.
Longe de aparecer como um rei fraco ou "rex inutilis", em diversas alturas do seu reinado, Sancho II mostrou ter um braço de ferro para tomar posições difíceis, como retaliações sobre os não-cooperantes, a ofensiva sobre os bens e benefícios eclesiásticos, o teste constante da fidelidade que havia ao monarca, entre outros exemplos, seguindo assim um pouco a veia do seu pai "falcão".
O estilo oficial de D. Sancho II enquanto Rei de Portugal: "Pela Graça de Deus, Sancho II, Rei de Portugal"
! colspan="3" style="background: #FBEC5D;" | Sancho II de PortugalCasa de Borgonha8 de setembro de 1209 – 4 de janeiro de 1248

Afonso III (Coimbra, – Alcobaça, ), apelidado de "o Bolonhês" por seu casamento com Matilde II, Condessa de Bolonha, foi o Rei de Portugal de 1248 até sua morte, e também o primeiro monarca português a utilizar o título de Rei de Algarve. Além disso, ele foi Conde de Bolonha de 1238 até 1253 em direito de sua esposa. Era o segundo filho do rei Afonso II e sua esposa Urraca de Castela, tendo ascendido ao trono depois de depôr seu irmão mais velho Sancho II.
Como segundo filho, Afonso não deveria herdar o trono destinado a Sancho e por isso viveu em França, onde se casou com Matilde II, Condessa de Bolonha em 1235, tornando-se assim conde "jure uxoris" de Bolonha, onde servia como um dirigente militar, combatendo em nome do Rei Luís IX de França e seu primo.
Todavia, em 1246, os conflitos entre Sancho II e a Igreja tornaram-se insustentáveis e o Papa Inocêncio IV nesse mesmo ano despacha a Bula "Inter alia desiderabilia" que prepara a deposição "de facto" do monarca.
O papado, através de duas Breves, ainda aconselha Afonso, Conde de Bolonha, a partir para a Terra Santa em Cruzada e também que passe a estar na Hispânia, fazendo aí guerra ao Islão. Mas a 24 de julho, a Bula "Grandi non immerito" depõe oficialmente Sancho II do governo do reino, e Afonso torna-se regente.
Os fidalgos levantam-se contra Sancho, e Afonso cede a todas as pretensões do clero no "Juramento de Paris", uma assembleia de prelados e nobres portugueses, jurando que guardaria todos os privilégios, foros e costumes dos municípios, cavaleiros, peões, religiosos e clérigos seculares do reino. Abdicou imediatamente das suas terras francesas e marchou sobre Portugal, chegando a Lisboa nos últimos dias do ano, onde se fez coroar rei em janeiro de 1248 após o exílio e morte de Sancho II em Toledo.
Até à morte de D. Sancho e a sua consequente coroação, D. Afonso apenas usou os títulos de "Visitador", "Curador" e "Defensor do Reino".
Para aceder ao trono, Afonso abdicou de Bolonha e repudiou Matilde para casar com Beatriz de Castela. Decidido a não cometer os mesmos erros do irmão, o novo rei prestou especial atenção à classe média de mercadores e pequenos proprietários, ouvindo suas queixas. Por este procedimento, Afonso III ficou conhecido também como o pai do "Estado Português", distribuindo alcaides pelos castelos e juízes pelas diferentes vilas e terras. O objectivo era a implantação de um poder legal com o qual todos os habitantes do Reino português mantivessem uma relação de igualdade.
Em 1254, na cidade de Leiria convocou a primeira reunião das Cortes, a assembleia geral do reino, com representantes de todos os espectros da sociedade. Afonso preparou legislação que restringia a possibilidade das classes altas cometerem abusos sobre a população menos favorecida e concedeu inúmeros privilégios à Igreja. Recordado como excelente administrador, Afonso III organizou a administração pública, fundou várias vilas e concedeu o privilégio de cidade através do édito de várias cartas de foral.
Em 1255, transferiu a capital do Reino de Portugal de Coimbra para Lisboa.
Foram por sua ordem feitas as Inquirições Gerais, iniciadas em 1258, como forma do rei controlar, não só o grande poder da Nobreza, mas também para saber se lhe estavam a ser usurpados bens que, por direito, pertenciam à Coroa.
Com o trono seguro e a situação interna pacificada, Afonso voltou sua atenção para os propósitos da Reconquista do Sul da Península Ibérica às comunidades muçulmanas. Durante o seu reinado, Faro foi tomada com sucesso em 1249 e o Algarve incorporado no reino de Portugal.
Após esta campanha de sucesso, Afonso teve de enfrentar um conflito diplomático com Castela, que considerava que o Algarve lhe pertencia. Seguiu-se um período de guerra entre os dois países, até que, em 1267, foi assinado um tratado em Badajoz que determina a fronteira no Guadiana desde a confluência do Caia até à foz, a fronteira luso-castelhana.
Em 1253, o rei desposou D. Beatriz, popularmente conhecida por D. Brites, filha de D. Afonso X de Castela, "O Sábio". Desde logo isto constituiu polémica pois D. Afonso era já casado com Matilde II de Bolonha.
O Papa Alexandre IV respondeu a uma queixa de D. Matilde, ordenando ao rei D. Afonso que abandone D. Beatriz em respeito ao seu matrimónio com D. Matilde. O rei não obedeceu, mas procurou ganhar tempo neste assunto delicado, e o problema ficou resolvido com a morte de D. Matilde em 1258. O infante, D. Dinis, nascido durante a situação irregular dos pais, foi então legitimado em 1263.
O casamento funcionou como uma aliança que pôs termo à luta entre Portugal e Castela pelo Reino do Algarve. Também resultou em mais riqueza para Portugal quando D. Beatriz, já após a morte do rei, recebe do seu pai, Afonso X, uma bela região a Este do Rio Guadiana, onde se incluíam as vilas de Moura, Serpa, Noudar, Mourão e Niebla. Tamanha dádiva deveu-se ao apoio que D. Brites lhe prestou durante o seu exílio na cidade de Sevilha.
No final da sua vida, viu-se envolvido em conflitos com a Igreja, tendo sido excomungado em 1268 pelo arcebispo de Braga e pelos bispos de Coimbra e Porto, para além do próprio Papa Clemente IV, à semelhança dos reis que o precederam. O clero havia aprovado um libelo contendo quarenta e três queixas contra o monarca, entre as quais se achavam o impedimento aos bispos de cobrarem os dízimos, utilização dos fundos destinados à construção dos templos, obrigação dos clérigos a trabalhar nas obras das muralhas das vilas, prisão e execução de clérigos sem autorização dos bispos, ameaças de morte ao arcebispo e aos bispos e, ainda, a nomeação de judeus para cargos de grande importância. A agravar ainda mais as coisas, este rei favoreceu monetariamente ordens religiosas mendicantes, como franciscanos e dominicanos, sendo acusado pelo clero de apoiar espiritualidades estrangeiradas. O grande conflito com o clero também se deve ao facto do rei ter legislado no sentido de equilibrar o poder municipal em prejuízo do poder do clero e da nobreza.
O rei, que era muito querido pelos portugueses por decisões como a da abolição da "anúduva" (imposto do trabalho braçal gratuito, que obrigava as gentes a trabalhar na construção e reparação de castelos e palácios, muros, fossos e outras obras militares), recebeu apoio das cortes de Santarém em Janeiro de 1274, onde foi nomeada uma comissão para fazer um inquérito às acusações que os bispos faziam ao rei. A comissão, composta maioritariamente por adeptos do rei, absolveu-o. O Papa Gregório X, porém, não aceitou a resolução tomada nas cortes de Santarém e mandou que se excomungasse o rei e fosse lançado interdito sobre o reino em 1277.
À sua morte, em 1279, D. Afonso III jurou obediência à Igreja e a restituição de tudo o que lhe tinha tirado. Face a esta atitude do rei, o abade de Alcobaça levantou-lhe a excomunhão e o rei foi sepultado no Mosteiro de Alcobaça.
O estilo oficial de D. Afonso III enquanto Rei de Portugal: "Pela Graça de Deus, Afonso III, Rei de Portugal e Conde de Bolonha". Em 1253, por suspeitar da sua esterilidade, D. Afonso repudia a esposa, D. Matilde, e abandona o título de Conde de Bolonha, passando a usar apenas o título de "Rei de Portugal". Após a conquista definitiva do Algarve e a disputa quanto ao domínio algarvio com Castela, o Tratado de Badajoz reconhece a D. Afonso III o senhorio do Algarve, evoluindo a sua titulatura régia para: "Pela Graça de Deus, Afonso III, Rei de Portugal e do Algarve".
Primeira esposa, Matilde II de Bolonha, sem descendência.
Segunda mulher, infanta Beatriz de Castela (1242-1303)
Em algumas crónicas antigas, menciona-se outra filha, Constança, no entanto, não há provas da sua existência segundo Figanière. Esta suposta filha, segundo outros historiadores, morreu muito nova em Sevilha e foi sepultada no Mosteiro de Alcobaça. No entanto, "esta referência deve (...) aplicar-se à infanta Sancha (que deve), embora com diferentes nomes, ter sido uma única infanta".
Havidos de Madragana Ben Aloandro, depois chamada "Mor Afonso", filha do último alcaide do período mouro de Faro, o moçárabe Aloandro Ben Bakr:
Havidos de Maria Peres de Enxara:
Havida em Elvira Esteves:
De outras senhoras:
! colspan="3" style="background: #FBEC5D;" | Afonso III de PortugalCasa de Borgonha5 de maio de 1210 – 16 de fevereiro de 1279

Dinis I, "O Lavrador" ou "O Poeta" (Lisboa, – Santarém, ), foi Rei de Portugal e do Algarve de 1279 até sua morte. Era o filho mais velho do rei Afonso III e sua segunda esposa Beatriz de Castela.
Em 1282 desposou Isabel de Aragão, que ficaria conhecida como Rainha Santa. Ao longo de 46 anos de reinado, foi um dos principais responsáveis pela criação da identidade nacional e o alvor da consciência de Portugal enquanto estado-nação: em 1297, após a conclusão da Reconquista pelo seu pai, definiu as fronteiras de Portugal no Tratado de Alcanizes, prosseguiu relevantes reformas judiciais, instituiu a língua portuguesa como língua oficial da corte, criou a primeira Universidade portuguesa, libertou as Ordens Militares no território nacional de influências estrangeiras e prosseguiu um sistemático acréscimo do centralismo régio. A sua política centralizadora foi articulada com importantes acções de fomento económico - como a criação de inúmeros concelhos e feiras. D. Dinis ordenou a exploração de minas de cobre, prata, estanho e ferro e organizou a exportação da produção excedente para outros países europeus. Em 1308 assinou o primeiro acordo comercial português com a Inglaterra. Em 1312 fundou a marinha Portuguesa, nomeando 1º Almirante de Portugal, o genovês Manuel Pessanha, e ordenando a construção de várias docas.
Foi grande amante das artes e letras. Tendo sido um famoso trovador, cultivou as "Cantigas de Amigo", de "Amor" e a sátira, contribuindo para o desenvolvimento da poesia trovadoresca na Península Ibérica. Pensa-se ter sido o primeiro monarca português verdadeiramente alfabetizado, tendo assinado sempre com o nome completo. Foi o responsável pela criação da primeira Universidade portuguesa, inicialmente instalada em Lisboa e depois para Coimbra.
Entre 1320 e 1324 houve uma guerra civil que opôs o rei ao futuro Afonso IV. Este julgava que o pai pretendia dar o trono a Afonso Sanches. Nesta guerra, o rei contou com pouco apoio popular, pois nos últimos anos de reinado deu grandes privilégios aos nobres. O infante contou com o apoio dos concelhos. Apesar dos motivos da revolta, esta guerra foi no fundo um conflito entre grandes e pequenos. Após a sua morte, em 1325 foi sucedido pelo seu filho legítimo, Afonso IV de Portugal, apesar da oposição do seu favorito, filho natural Afonso Sanches.
Dinis nasceu a 9 de outubro de 1261, em Lisboa, como filho do rei Afonso III de Portugal e da sua esposa Beatriz de Castela. Pertenceu, pelo lado paterno, à Casa Real Portuguesa, descendente direta da Casa Ducal da Borgonha. Pelo lado materno, descendia de importantes personalidades como Afonso X de Leão e Castela, Henrique II de Inglaterra ou Filipe da Suábia.
Pouco se sabe da sua infância, mas conhecem-se os aios encarregues da sua educação, sendo os mais conhecido Lourenço Gonçalves Magro (que seria descendente de Egas Moniz, o Aio). O infante foi mais tarde confiado aos cuidados do meirinho-mor do rei, Nuno Martins de Chacim, que Dinis depois nomearia para mordomo-mor.
Em 1265, acompanhou a sua mãe e um contingente militar, de visita ao seu avô Afonso X de Castela, em Sevilha, viagem relacionada com a questão do Algarve, com o rei de Portugal, e cuja resolução implicou o envio de reforços portugueses para a guerra na Andaluzia. Em 1278 recebe casa própria, um ano antes de ascender ao trono.
Como herdeiro da coroa, Dinis desde cedo foi envolvido nos aspectos de governação pelo seu pai, Afonso III, que, a 16 de fevereiro de 1279, deixa um reino com uma acentuada estabilidade interna, resultante de uma autoridade régia incontestada, em contraste com o estado geral em que se encontrava o reino de Castela, onde imperava um acentuado clima de ingovernabilidade e de permanentes conflitos sociais.
Foi confiado, embora já fosse maior de idade (contava com 18 anos na altura da sua ascensão ao trono), a um conselho de regência presidido por sua mãe, Beatriz, que provavelmente tentaria liderar o reino chefiando um conselho esse no qual tomava parte o mordomo-mor do seu pai, João Peres de Aboim. Porém, o jovem rei desiludiu-a rapidamente de qualquer participação na governação. O conflito com a mãe leva mesmo à intervenção do avô, Afonso X, que terá tentado encontrar-se com o neto em Badajoz, encontro que Dinis rejeitou. Beatriz acabou por voltar a Castela.
O casamento deste rei foi talvez um dos primeiros grandes sucessos da política externa portuguesa. Dinis inicia negociações com Pedro III de Aragão, para casar com a filha deste, Isabel, que na mesma altura estaria a ser reclamada por embaixadores dos reis de França e Inglaterra. Isabel era um partido extremamente valioso, uma vez que a sua figura se prestigiava pelas melhores qualidades, e ainda a importância estratégica de Aragão, tanto do ponto de vista político como económico, uma vez que o próprio Pedro III enceta uma política mediterrânica, começada pela conquista da ilha italiana da Sicília (que constituiu o reino de Trinácria), em consequência da defesa dos direitos da esposa, última descendente da casa imperial alemã de Hohenstaufen no sul italiano. Os sucessores de Pedro continuariam esta política de expansão e dominação mediterrânica.
Graças às diligências dos seus procuradores e vassalos João Velho, João Martins e Vasco Pires, negociou as claúsulas matrimoniais e ficaram encarregados de receber a noiva por palavras de presente, direito que lhes fora outorgado a 12 de novembro de 1280. Pedro III decidiu-se pelo rei português, segundo carta de 11 de fevereiro de 1282, na qual se concretizava o casamento do rei português, de 21 anos, e da princesa aragonesa, de 12. Dinis doava à sua esposa de doze castelos e três vilas. Dinis por essa altura encontrar-se-ia em Trancoso, vila que doaria também a Isabel a 26 de junho de 1282. Foi também nessa vila que se efetuou a boda "de facto", aí permanecendo até aos primeiros dias de agosto.
Os primeiros anos do reinado de Dinis viram a guerra civil em Castela, que opõe Afonso X o Sábio contra o príncipe Sancho. Em abril de 1282 Dinis envia a Castela uma embaixada de condolências pela morte do rei-trovador. Contudo a situação entre Portugal e Leão-Castela não era de todo pacífica: desde a conquista do Algarve que ambos os reis do ocidente da Península reclamam o título de "Rei do Algarve", facto que incomodava bastante o rei português.
Apesar disso as relações entre os dois reinos ainda eram estáveis, tendo-se inclusivamente aliado, em dezembro de 1288, contra Aragão, que combateram entre a primavera e o verão de 1289. A verdadeira quebra viria em 1293, quando Dinis protege o magnate castelhano João Nunes de Lara. A situação parece piorar quando Sancho concerta para o seu filho Fernando a mão da princesa Isabel, filha de Filipe IV de França.
Sancho IV falece a 25 de abril de 1295, acentuando-se a turbulência política em Castela. Sancho determinara no seu testamento que se devolvessem a Dinis de Portugal as vilas de Serpa, Moura, Mourão, Aroche e Aracena, injustamente arrebatadas a Portugal e se encontravam indevidamente retidas pelos castelhanos.
Durante a menoridade de Fernando IV de Castela, com nove anos apenas, a regência coube a sua mãe, Maria de Molina, sendo contestada pelos infantes João, senhor de Valência de Campos, irmão de Sancho IV e Henrique de Castela "O Senador", irmão de Afonso X. Coube a João tentar obter a ajuda de Dinis. Desta forma deslocou-se a Guarda para acordar um pacto, no qual Dinis apoiaria a pretensão de João para o trono de Leão, extinto desde 1230 por Fernando III de Castela. Este acordo foi ratificado a 4 de outubro de 1295.
Portugal acaba por declarar guerra a Castela, fazendo-a anunciar nas cortes de Valladolid. A notícia preocupou os castelhanos, uma vez que havia plena consciência das dificuldades que consistiria uma guerra com Portugal.
A 20 de outubro de 1295, Dinis recebe as vilas de Moura e Serpa, e os castelos de Mourão e Noudar, e ainda os castelos e as vilas de Arronches e Aracena. A devolução destes bens tornava necessária uma nova definição de fronteiras, celebrada pelo Tratado de Alcanizes, de 1297. Neste tratado ficaram combinados os casamentos dos infantes Constança e Afonso, filhos de Dinis, com o rei Fernando IV de Castela e a infanta Beatriz, respetivamente, um duplo casamento para reforçar a aliança e a garantia de paz de Castela com Portugal.
Em janeiro de 1296 o infante D. João entra em Portugal e alia-se a Dinis, que se dispõe a ajudá-lo na conquista de Leão. Entretanto, os nobres castelhanos escreviam a Dinis, a 12 de maio de 1298, para combater o infante João, claramente ignorantes de que o rei de Portugal o apoiava.
Dinis segue para Castela, para Toro, onde propõe a Maria de Molina o reconhecimento do infante rebelde como rei da Galiza, ao que Maria recusou. Com os intentos frustrados, regressa a Portugal, permanecendo no Sabugal todo o mês de agosto e a primeira quinzena de Setembro.
À data da sua subida ao trono, o país encontrava-se em conflito com a Igreja Católica, e sob interdição. D. Dinis procurou normalizar a situação assinando um tratado com o Papa Nicolau IV, onde jurava proteger os interesses de Roma em Portugal.
Os cavaleiros do Templo, após a queda de Acre, último bastião cristão no Levante, regressaram ao Ocidente. As casas desta oridem haviam acumulado várias riquezas; sendo administradores dos fundos destinados às Cruzadas, tornaram-se os primeiros "banqueiros" dos reis e talvez uma das maiores potências financeiras da Idade Média.
Filipe IV de França acabava de vencer um duelo travado entre poder civil e eclesiático, e encontrava-se endividado, com os inúmeros gastos que fazia e que eram possíveis graças aos empréstimos que a Ordem Templária lhe cedia. Não podendo pagar a excessiva dívida, pôs em prática um plano para extinguir a Ordem e assim arrecadar para si todos os tesouros e bens que aquela rica Ordem religiosa havia acumulado desde cedo. Assim, o seu chanceler, Guilherme de Nogaret, redigiu todas as acusações e atribuiu-lhes diversos crimes. A 13 de outubro de 1307, Filipe prendia uma grande parte dos cavaleiros templários. Para obter o apoio da Igreja, arranjou forma de elevar ao cargo pontifício alguém da sua confiança: Bertrand de Got, que, com o nome de Clemente V, se torna no primeiro Papa com assento em Avignon, para estar mais manobrável e disponível para ajudar Filipe, e que criaria uma disputa sobre quem era o verdadeiro Papa. Clemente ordena assim a todos os reinos onde residem Templários a proceder à confiscação dos seus bens e à condenação à morte de cada um dos seus membros.
Dinis recebe esta ordem, e como os demais reinos, teve de obedecer: os seus agentes ocuparam as fortalezas templárias, mas deram-lhes tempo para poderem fugir. Em 1309, Dinis confiscava-lhe oficialmente os seus bens, regressando todas essas povoações e castelos à Coroa. Os monarcas peninsulares haviam conseguido uma exceção à bula que obrigava a todos os bens templários a serem dados à Ordem Hospitalária. Tal foi confirmada por uma convenção que Dinis assinou com Fernando IV de Castela, que obrigava a cada um dos países a assegurar para si os bens dos Templários, e ainda assegurava uma aliança de auxílio recíproco.
Em 1319, Dinis conseguia do Papa João XXII a bula "Ad ea ex quibus", na qual se criava a Ordem de Cristo e para a qual foram transferido todo o património e também vários dos membros da extinta Ordem Templária. Foi designado para sede o Castelo de Castro Marim, criando-se desta forma a primeira ordem militar portuguesa, que chegou inclusivamente a apoiar os cavaleiros portugueses da Ordem de Santiago na sua disputa para se separarem do seu mestre castelhano. A Ordem de Santiago acabaria por formar na realidade um ramo português.
Dinis enviou, em novembro de 1300, uma embaixada a Jaime II de Aragão, sendo embaixador o conde João Afonso de Albuquerque, com a finalidade de se conseguir uma aliança entre os monarcas de Castela e Aragão.
Em resposta Jaime II enviou como embaixador a Ramón de Monros, portador de diversas cartas de Dinis, comunicando que requeria a sua presença como mediador na negociação Aragão-Castela e a de sua esposa Isabel. De facto, em 1304, Dinis e Isabel empreendem essa viagem a Aragão, podendo a rainha rever a sua família e Dinis realizar o seu propósito. Este pedido por parte de Aragão é um sinal do prestígio a nível peninsular de que se revestia este rei.
Dinis teve de enfrentar, nos primórdios do seu reinado, a oposição do seu irmão mais novo, o infante Afonso. O principal motivo da sua oposição ao irmão basear-se-ia num argumento com pouco crédito: Afonso reclamava o seu direito ao trono pois considerava Dinis um bastardo, uma vez que este nascera antes da legalização do casamento dos pais, estando Afonso III de Portugal ainda oficialmente e legalmente casado com Matilde II, Condessa de Bolonha. De facto, o segundo casamento de Afonso III foi legitimado somente em 1263, já Dinis contava dois anos, e Afonso ainda nasceria mais tarde nesse ano. A pretensão não foi considerada válida precisamente porque o casamento dos pais acabou por ser legitimado, mas acabou por estalar um conflito entre ambos, em 1281.
Afonso estava em Vide, e amuralhou esta vila, sinal que não pareceu correto a Dinis, pelo que se deslocou com um exército para lá, e Afonso acabou por fugir para Sevilha.
Dinis foi essencialmente um rei administrador e não guerreiro: envolvendo-se em guerra com o Reino de Castela em 1295, desistiu dela em troca das vilas de Serpa e Moura.
Dinis seguiria o seu pai nas políticas de legislação e centralização do poder, e promulgou um dos primeiros códigos legislativos, protegendo as classes mais baixas de abuso e extorsão. Estas leis sobreviveram integradas no "Livro das Leis e Posturas"e nas "Ordenações Afonsinas", redigidas no reinado de Afonso V de Portugal. Estes "códigos de lei" eram na verdade compilações de leis e do direito consuetudinário municipal, alteradas e reformuladas pela Coroa.
Com efeito, a incidência de questões de carácter processual com igual peso ao carácter de direito positivo das suas leis, denuncia a crescente preocupação do rei em enquadrar o direito consuetudinário (ou costumeiro) no âmbito da Coroa, e em efectivar o seu poder no terreno. As determinações sobre a actuação de alvazis (oficiais concelhios), juízes, "procuratores" e "advocati" demonstram isto, já que um poder meramente nominal sobre todos os habitantes do Reino, como era típico na Idade Média, não se compatibiliza com este esforço em esmiuçar os trâmites jurídicos, ou em moralizar o exercício da justiça. A criação de corregedores denuncia claramente o início do processo de territorialização da jurisdição da Coroa, extravasando os domínio régios, a par da crescente importância da capitalidade de Lisboa.
O reinado de D. Dinis acentuou a predilecção por Lisboa como local de permanência da corte régia. Não era uma capital oficial, mas a localização de Lisboa, o seu desenvolvimento a nível urbano, económico e mercantil vão tornando a na mais capaz para exercer a função de centro administrativo.
A articulação entre o norte e o sul do país – este sul que se torna alvo da maior atenção e permanência dos reis – fazem de Lisboa centro giratório para tornar Portugal viável. Entre o norte, onde a malha senhorial é mais densa e apertada, e o sul, onde o espaço vasto conquistado aos muçulmanos implanta sobretudo os domínios régios e as ordens militares, assim como vastos espaços de "res nullius" e torna Portugal um reino onde duas realidades diferentes se complementam.
Dinis, por carta de 6 de dezembro de 1283, escreve o seguinte:
Esta carta revoga todas os privilégios e doações, realizadas desde a sua ascensão em 1279, como consequência da sua "pequena ydade" e consequente imaturidade que então dizia manifestar. Anulava assim doações a cenóbios importantes, como o Mosteiro de Grijó, Mosteiro de Alcobaça, Sé de Tui, e a indivíduos que lhe eram chegados, como a sua barregã, Maria Rodrigues de Chacim ou mesmo a sua esposa, a Rainha Isabel, com quem casara no ano anterior.
Esta "auto-correção" poderia ter uma outra mensagem, revelada de forma subentendida: ao fazer voltar para si os bens doados até então, fazia simultaneamente uma demonstração do seu poder, força e autoridade enquanto Rei, face às influências da nobreza e do clero, que tantos problemas tinham dado ao seu tio Sancho II de Portugal, e que, graças a seu pai, Afonso III de Portugal, se mantinham (pelo menos uma boa parte e a mais importante) junto a si, na corte, exercendo, como o rei, os seus já limitados poderes a partir daí.
Sancho II fora uma das principais vítimas do fenómeno do feudalismo, que se vivia de igual forma no resto da Europa entre rei e nobreza com níveis oscilantes de autoridade, tanto da parte do rei, como da restante nobreza e clero.
A ação de Dinis teria uma outra vantagem: no princípio do seu reinado, muitas das famílias e personalidades da corte mais poderosas e prestigiantes despareciam, como foi o caso do mordomo-mor João Peres de Aboim, e dos magnates Pedro Ponces de Baião ou Gonçalo Garcia de Sousa, e várias outras que viram o seu fim nesta década de 80 que para Dinis resultou uma oportunidade de reformular os poderes da nobreza que restava e de se apoderar dos patrimónios das famílias que se extinguiam.
Seguindo-se às revogações de 1283, Dinis, no ano seguinte, ordena as primeiras Inquirições Gerais do seu reinado, à semelhança do que fizera seu pai em 1258, através das quais o rei pretende verificar o quanto a situação mudara desde aquela data: teria a nobreza aumentado o seu poder? Teria de ter receio do excessivo poder daquela classe? A inquirição revelou um aumento quantitativo e qualitativo dos abusos que a nobreza fazia nos seus domínios.
Em 1285, falecia talvez o mais agraciado aristocrata de Portugal, o Conde Gonçalo Garcia de Sousa, com uma património invejável e disputado por familiares de várias linhagens, a começar pela sobrinha, Constança Mendes de Sousa (nora do ex-mordomo-mor João de Aboim) e uma sobrinha desta, Inês Lourenço de Valadares (filha da irmã de Constança, Maria Mendes II de Sousa), que era apoiada por seu pai, Lourenço Soares de Valadares, nesta pretensão. Outras linhagens reclamavam a herança, como os Riba de Vizela, e os Briteiros, reclamando o património pela ascendente comum, Guiomar Mendes de Sousa (irmã de Gonçalo Mendes II de Sousa e esposa de João Pires da Maia).
Ora, como a contenda não se resolvia facilmente, os pretendentes à fortuna do conde terão pedido a Dinis para mediar a disputa entre eles, e desta forma ordenou uma inquirição ao património do conde no final de 1286, que se estendeu até ao ano seguinte. A esta pequena inquirição seguiram-se as Cortes de Guimarães de 1288, da qual saiu a resolução de proceder a novas Inquirições Gerais, nesse mesmo ano, e que resultaram no mais exaustivo levantamento de dados relativos às propriedades da nobreza e do clero então existentes, seguindo-se as sentenças proferidas entre 1290 e 1291.
Desta forma o rei consegue recuperar uma boa parte do património que, graças a estes levantamentos, descobriu estar nas mãos dos nobres de forma ilegal, uma vez mais pondo a nu os abusos por parte desta classe para com alguns proprietários.
Bens em Alvito, Portel, Arronches ou Portalegre, entre muitos outros, regressaram nesta altura à Coroa. è neste seguimento que favorece a já mencionada tentativa, lograda, de criar ramos independentes portugueses para as Ordens Militares de Avis e Santiago.
Mas a situação exigia um chefe político hábil, por forma a extorquir as classes privilegiadas sem a privar por completo de bens: se atende queixas de eclesiásticos relativas à usurpação continuada dos bens da Igreja por parte da nobreza, também acede aos pedidos desta quando esta reclama pelo aumento excessivo do património eclesiástico. E, desta forma, o que naturalmente traria bastante contestação por parte destas classes não parece ter acontecido nos primeiros anos de Dinis.
Porém a Igreja saiu bastante mais prejudicada: Dinis promulgou leis de amortização, que proibiam a Igreja e as Ordens religiosas de comprar terras. Teriam também de devolver tudo o que haviam adquirido desde o início do seu reinado. Mais tarde proibi-los-ia de adquirir bens de particulares.
Ainda foram feitas novas inquirições em 1301, 1303-1304 e 1307-1311, todas com motivações semelhantes. A nobreza, escrutinada desta forma, começa a influenciar o herdeiro e a virá-lo contra o seu pai, e se este já parecia bastante incomodado com a atenção aos bastardos, começa também a acreditar que o seu pai queria dar o trono ao seu bastardo favorito, Afonso Sanches. Afonso aceitou o apoio de toda a nobreza que se lhe quis juntar, esperançosa de um tempo de mudança sob o reinado do filho de Dinis. Afonso consegue ascender ao trono, mas para a nobreza nada se alterou, uma vez que Afonso acaba por seguir a política do pai e realiza as últimas inquirições medievais portuguesa que se conhecem, as Inquirições Gerais de 1343.
O final do século XIII viu a devolução, para Dinis, de muitos bens (vilas e castelos) para Portugal, pelo que se tornou necessária uma nova definição de fronteiras. A entrega destas terras foi feita ao porteiro da coroa, João Rodrigues, que por seu turno as daria ao cavaleiro Nuno Fernandes Cogominho, que assumiria a sua posse em nome do rei D. Dinis.
Desta forma, a 12 de setembro de 1297, celebrou-se o Tratado de Alcanizes, na localidade castelhana do mesmo nome. As cláusulas estabeleciam os direitos de Portugal à posse de vários castelos em Ribacôa e o castelo de Monforte. Outros castelos localizados no atual Alentejo tornaram-se nesta altura parte definitiva de Portugal (com exceção de Olivença): Campo Maior, Ouguela e S. Félix dos Galegos. Acrescentavam-se ainda os castelos de Moura e Serpa, que apesar de cedidos ainda não haviam sido devolvidos. Vários destes bens, como Serpa ou Moura, haviam sido conquistados por Afonso X de Castela aos portugueses durante a guerra de 1245-47, que opunha Afonso III de Portugal ao seu irmão Sancho II.
Por seu turno Portugal renunciava aos castelos de Aroche e Aracena, e ainda Valencia de Alcántara, Ferreira e Esparregal, na posse da Ordem de Alcântara.
O tratado estabeleceria a paz com Castela, uma paz prevista de 40 anos, de amizade e defesa mútuas, definindo-se as fronteiras actuais entre os dois países ibéricos.
No final do século XIII, a arquitetura militar europeia havia sofrido uma série de alterações que modificaram o perfil das construções e ditaram inovações radicais nas táticas militares de ataque e defesa de um castelo, tornando-os aptos, não só para defender (como faziam os castelos românicos), mas também para atacar, segundo as novas tipologias da Arquitetura gótica.
Filipe II de França foi o grande pioneiro deste grande movimento, empreendendo diversas alterações em vários dos seus castelos, dotando-os destes novos meios que os tornaram mais resistentes aos frequentes ataques sofridos numa França ainda claramente feudal.
Em Portugal, Sancho I melhorou o sistema defensivo em Coimbra, com a construção das torres de Quinária (1198) e Belcouce (1211), a Ordem do Hospital ergueu o Castelo de Belver já com novos meios, face à invasão que sofreram em 1190 de Abu Iúçufe Iacube Almançor, e a Ordem dos Templários introduziu alterações que revelam conhecimento da arquitetura praticada então na Terra Santa e no Próximo Oriente, inovações trazidas por Gualdim Pais, mestre da Ordem que presenciou a Segunda Cruzada., tendo tomado parte num cerco em Antioquia e na tomada de Ascalão (1153).
Porém, a pressão das invasões muçulmanas e uma prolongada série de maus anos agrícolas causaram um maior gasto na economia nacional, o que travou a renovação contínua de vários castelos.
Foi precisamente com Afonso III e Dinis que a situação mudou, uma vez que os cofres do Estado voltavam a ficar cheios. Se Afonso III introduziu a primeira alteração na muralha de Melgaço em 1263, que se tornara no primeiro exemplar da adaptação da nova arquitetura trazida de França pelo conde de Bolonha, seria no entanto Dinis que se empenharia a fundo num projeto de reforma da arquitetura militar em grande escala, provavelmente dos mais ambiciosos em toda a História do reino, e que seria continuado pelos seus descendentes longínquos, João II de Portugal e Manuel I de Portugal.
A cultura foi um dos seus interesses pessoais e que ganhou um grande impulso através do seu dedicado patrocínio.
A língua galego-portuguesa, derivada da língua provençal, desenvolvera-se pelo menos desde o século X, e era já utilizada para os versos dos cantares trovadorescos de autores provenientes tanto da Galiza como da própria corte do Reino de Castela, e sabe-se que o próprio Afonso X de Castela, avô de Dinis, era também trovador e tem entre as suas composições algumas escritas nesta língua. O seu pai trouxera de França as novas correntes literárias, pelo que Dinis pôde testemunhar o florescimento desta arte, que acompanhava as restantes cortes peninsulares e talvez também europeias. Dinis presenciava e também contribuía para este florescimento: foi um dos maiores e mais fecundos trovadores do seu tempo. Aos nossos dias chegaram 137 cantigas da sua autoria, distribuídas por todos os géneros (73 "cantigas de amor", 51 "cantigas de Amigo" e 10 "cantigas de escárnio e maldizer"), bem como a música original de 7 dessas cantigas (descobertas casualmente em 1990 pelo Prof. Harvey L. Sharrer, no Arquivo da Torre do Tombo, num pergaminho que servia de capa a um livro de registos notariais do século XVI, e que ficou conhecido como "Pergaminho Sharrer").
Os seus filhos bastardos Afonso Sanches e Pedro Afonso, seguiram os passos do pai, e compuseram, como ele, uma extensa obra.
Em 1290, Dinis declara o galego-português como língua oficial do Reino de Portugal, sendo consequentemente o seu uso estendido às fórmulas da prosa notarial.
A esta floração litarária corresponde um outro aspeto do desenvolvimento cultural: a atividade escolar. Domingos Anes Jardo, chanceler de Dinis e depois Bispo de Évora, terá fundado em 1286 o Colégio dos Santos Elói, Paulo e Clemente, embora mais conhecido como Hospital de S. Paulo, que servia, além de hospício para os pobres, como residência de estudantes. O rei apoia o projeto e protege a instituição.
Seriam ali sustentados religiosos que se dedicassem ao estudo da Jurisprudência ou da Teologia, ou fossem ouvintes de Gramática, Lógica e Medicina, por forma a poderem ensinar.
O rei imitaria o bispo e quatro anos, mais tarde, em 1290, criava em Lisboa o "Estudo Geral", fundado pelo seu documento "Scientiae thesaurus mirabilis", situando-se no atual Largo do Carmo, em Lisboa e aí continuando aí a obra de Jardo. Nessa instituição ensinavam-se as Artes, o Direito Civil, o Direito Canónico e a Medicina.
Em 1308 foi oficialmente transferida para Coimbra, e mais tarde foi designada de Universidade. Esta foi transferida entre Lisboa e Coimbra várias vezes, estando instalada definitivamente em Coimbra desde 1537, por decreto de um seu descendente, João III de Portugal.
Culto e curioso das letras e das ciências, terá impulsionado a tradução de muitas e importantes obras para português, entre as quais se contam os tratados de seu avô Afonso X, o Sábio. Desta forma, a sua Corte foi um dos maiores centros literários da Península Ibérica.
D. Dinis redistribuiu terras, promoveu a agricultura e fundou várias comunidades rurais, procurando que não só os camponeses e as comunidades religiosas, mas também todo o País se interessasse por esta atividade. Facilita a distribuição de propriedade,e divide terras incultas em grupos de vinte ou trinta casais, distribuindo cada um deles a uma família. Cada casal pagava um foro ou pensão ao rei, ao município ou ao doador da terra. Manda enxugar o paúl de ulmar para ser aplicado no cultivo, e aproveita as madeiras do Pinhal de Leiria para a construção de casas, armazéns e frotas. Simultaneamente protegia este pinhal, uma vez que protegia as terras agrícolas do avanço das areias costeiras.
A produção de cereais excede em breve o consumo interno e Portugal torna-se um reino exportador, estabelecendo relações comerciais com portos da Catalunha, Bretanha, Flandres, e Inglaterra, assinando em 1308 o primeiro tratado comercial com Eduardo II de Inglaterra. Para estes portos exporta-se também vinho, azeite, sal, peixe salgado, e fruta seca. Dinis ordena ainda a exploração de minas de cobre, prata, estanho e ferro.
Mesmo fora de Portugal, os mercadores portugueses começaram a ganhar privilégios: Filipe IV de França doa privilégios aos mercadores portugueses em duas ocasiões, em 1290 e em 1310, nesta data especificamente aos mercadores de Harfleur.
Este aumento comercial teve por consequência um aumento do número de feiras. Dinis continua, neste ramo, o impulso do seu pai: as regiões de Entre Douro e Minho, Beira e Alentejo cobriram-se de feiras, nomeadamente "feiras francas"de impostos, isto é, feiras com privilégios e isenções. Uma vez que as condições de circulação, os perigos dos caminhos, assim como as prisões por dívidas poderiam comprometer o sucesso das feira, tornou-se quase obrigatória nas cartas de feira a introdução da fórmula "que todos aqueles que veerem a essa feyra per razom de vender ou de comprar sejam seguros d'ida e de vynda que nom sejam penhorados en meu reyno por nenhuua divyda que devam en aqueles dias en que durar essa feyra nem en dous dias que veerem primeyros des que sayr essa feyra senom por aquelas dividas que forem feytas em essa feyra."
Para evitar a dependência de estados vizinhos no que diz respeito ao transporte de mercadoria, ordenou a construção de navios nos estaleiros do reino. Vieram inclusive marinheiros estrangeiros para instruir nesse âmbito e para dirigir as construções, e é desta forma que é atribuído como privilégio ao genovês Manuel Pessanha, o cargo de almirante, fundando uma verdadeira marinha portuguesa ao serviço da Coroa e do Reino.
Os últimos anos do seu reinado foram marcados por conflitos internos, porque, a nível externo, Portugal equiparava-se aos restantes reinos peninsulares. O herdeiro, futuro Afonso IV, receoso que o favorecimento de D. Dinis ao seu filho bastardo, D. Afonso Sanchesref name="Pero-Sanz2011"></ref> o espoliasse do trono, exigiu o poder e combateu o pai. Esta guerra, que se prolongou de 1319 a 1325, e a crise interna que provocou fez com que Portugal perdesse influência a nível internacional.
Em 1319, Afonso teria chegado a pedir inclusivamente a Maria de Molina, para que convencesse o seu pai a abdicar. Em resposta o monarca português rejeita a proposta e envia à rainha os pêsames pelas mortes dos seus filhos, D. Pedro e D. João.
O infante Afonso revolta-se, com tropas no Norte do País, exercendo violências sobre quem era fiel a seu pai. Afonso dirige-se a Coimbra, e depois toma Leiria. Dinis para aí se dirige, mas o filho, tentando evitar o encontro, desloca-se a Santarém. Reúne-se depois em Coimbra com os seus apoiantes, e daí volta a partir para Norte, com ânimo de conquista. Toma Montemor-o-Velho, Santa Maria da Feira, Vila Nova de Gaia, Porto, e é em Guimarães, no final de 1321 onde encontra a primeira resistência.
A mãe, Isabel, dirige-se também a Norte, para se encontrar com o filho e tenta convencê-lo da sua rebeldia inútil, mas sem sucesso. Dinis dirige-se a Coimbra com um exército, e o mesmo faz o seu filho, encontrando-se pela primeira vez, frente-a-frente, ambos os exércitos. Isabel, juntamente com um enteado, o Conde Pedro de Barcelos, tentam convencer pai e filho a desistirem da ideia de se enfrentarem um ao outro, dirigindo-se a cada um dos acampamentos. Tudo o que Isabel e Pedro conseguiram obter foi um armistício, mas não conseguiram evitar um combate sangrento numa ponte sobre o rio Mondego.
Com a paz estabelecida em maio de 1322, a situação pareceu acalmar, mas alguma da aristocracia e maus conselheiros voltam uma vez mais o filho contra o pai, situação que se favoreceu com o regresso de Afonso Sanches, que durante este conflito se encontrava em Castela. Afonso tenta surpreender o meio-irmão em Lisboa, mas Dinis protege o seu bastardo, proibindo Afonso de avançar sobre a cidade. A desobediência deste levou a que pai e filho se defrontassem uma vez mais, na Batalha de Alvalade, que não teve um pior desfecho porque a rainha Isabel resolveu intervir diretamente na batalha, interpondo-se entre as hostes inimigas já postas em ordem de combate. Dinis e o seu filho acabariam por fazer as pazes definitivas em 1324.
Complicações cardíacas seriam a origem dos seus problemas de saúde. Em 1322 teve um pequeno ataque cardíaco ou vascular-cerebral. Ainda viveu mais três anos debilitado, sendo levado "em andas e em colos de homens". Foi a angina de peito ou uma miocardite a causa da sua morte, em 1325.
Se o final do seu reinado foi penoso e lhe trouxe grandes amarguras, a sua decisão de transigir com os desejos do filho assegurou-lhe, pelo menos, o derradeiro consolo de morrer em paz e reconciliado com a família mais chegada. D. Dinis morreu em Santarém a 7 de janeiro de 1325, e foi sepultado no Mosteiro de São Dinis, em Odivelas.
Após a sua morte vieram a Portugal algumas embaixadas a apresentar os seus pêsames: desde Castela manifestaram as suas condolências à rainha-mãe e viúva Isabel e ao novo rei, Afonso IV, que foi simultaneamente felicitado pela subida ao trono. O próprio irmão de Isabel, Jaime II de Aragão, apresentou as suas condolências e fez esforços no sentido da reconciliação entre o novo rei e seu irmão, o infante D. Afonso Sanches.
Afonso IV, porém, continuaria a fazer guerra ao irmão exilado, e este também não desistiu de lhe tentar usurpar o trono. Afonso acaba por retirar ao irmão bastardo todas as posses que lhe haviam sido dadas pelo pai, e, após várias tentativas falhadas de Afonso Sanches para governar Portugal, os dois irmãos acabam por fazer as pazes, com a intervenção de Isabel de Aragão.
Diz a lenda de uma aldeia do concelho de Seia, Lapa dos Dinheiros, que D. Dinis terá por lá passado e, depois de ter jantado e pernoitado no lugar, deu-lhe o seu nome actual.
Nunca esquecendo o hiato de largos séculos que nos separa de D. Dinis, é possível traçar um esboço de linhas mestras da personalidade deste rei português.
Era determinado, ou mesmo obstinado, nos seus intentos, do que são exemplo a "cadência de inquirições verdadeiramente demolidora" e demais políticas de centralização régia que instituiu de forma sistemática.
Revelou-se desde cedo um grande estratega, sendo precursor de uma política governativa e legislativa não apenas reactiva, mas antes de cunho pro-activo. Beneficiando de uma análise "a posteriori", percebe-se que as decisões não iam sendo tomadas ao acaso, antes se articulando na senda de um ideal de país e nação que o Rei almejava.
À laia de exemplo, indique-se a concomitante criação de concelhos e feiras, as políticas de fortificação das fronteiras ou a crescente dependência das ordens militares do poder régio.
Por tudo isto, D. Dinis foi reconhecido como um homem sagaz e de elevada capacidade governativa, tanto por contemporâneos como por historiadores posteriores.
Não carecia D. Dinis do que hoje apelidamos de habilidade política. Sendo hábil no trato e entendedor dos Homens, D. Dinis soube ir ""atacando e apaziguando, alternadamente, os interesses senhoriais laicos e eclesiásticos: desamortizou os bens do clero, mas aceitou a concordata e restringiu os direitos de "comedoria" nos mosteiros; inquiriu os bens senhoriais, mas as leis de desamortização travam a erosão dos patrimónios senhoriais.""
A administração das propriedades régias tornou-se mais eficiente e D. Dinis ficou conhecido como um Rei rico; disso encontramos eco na "Divina Comédia" de Dante Alighieri.
Não obstante, D. Dinis é mormente celebrado em todos os registos cronísticos contemporâneos e posteriores como um Rei justo. Sabendo-se que a maior parte do trabalho legislativo do seu reinado se focou em questões de justiça processual, não será de menor relevo o facto de grande parte dessa nova legislação ir no sentido de evitar excessivas delongas e custas judiciais e impedir abusos de advogados e procuradores.
Dele pode-se ainda dizer que a determinação que tantas conquistas políticas lhe granjeou podia, por vezes, degenerar em teimosia e prepotência. Descrito por vezes como cruel, principalmente nas relações familiares: na forma como tratava o filho herdeiro D. Afonso (nunca o seu favorito) e a esposa, D. Isabel, entregando-lhe os frutos dos seus adultérios para que os criasse.
Figura incontornável da Península Ibérica de fim de Duzentos e início de Trezentos, D. Dinis foi cognominado "Pai-da-Pátria" por Duarte Nunes de Leão.
Pouco ou nada se sabia do físico do Rei D. Dinis. As fontes da época assim como autores posteriores falham em oferecer qualquer tipo de descrição física do monarca. As informações hoje existentes advêm de uma abertura acidental do túmulo de D. Dinis aquando de um processo de restauro em 1938.
Sabe-se que a figura histórica de D. Dinis tinha de altura cerca de 1,65 m. O monarca faleceu com a provecta idade de 63 anos, feito notável para a época. Aparentemente, gozou de excelente saúde durante toda a sua vida: apenas fez o primeiro testamento completo aos 61 anos, sempre viajou, participou em guerras estando já adiantado de idade e aos 60 ainda caçava. Essa suposição é confirmada pela análise dos seus restos mortais que revela que morreu com a dentadura completa.
Um traço distinto da fisionomia de D. Dinis terão sido os seus cabelos e barba ruivos. Facto curioso na família real portuguesa de então, do qual não se conhecem outros exemplos até à época de D. Dinis. Pode-se especular que a origem genética deste traço poderia vir do lado materno, pois seu tio Fernando de Castela era ruivo (recebendo ademais o epiteto de La Cerda). As hipóteses mais plausíveis serão que estes dois príncipes peninsulares tenham herdado o traço de Henrique II de Inglaterra, pai de Leonor Plantageneta, bisavó de Afonso X; ou então da mãe de Afonso X, Beatriz da Suábia, neta do famoso Imperador Frederico, o "Barba Ruiva".
Filhos naturais:
O estilo oficial de D. Dinis enquanto era: "Pela Graça de Deus, Dinis I, Rei de Portugal e do Algarve"
|-
! colspan="3" style="background: #FBEC5D;" | Dinis I de PortugalCasa de Borgonha9 de outubro de 1261 – 7 de janeiro de 1325

Afonso IV (Lisboa, – Lisboa, ), apelidado de Afonso, o Bravo, foi o Rei de Portugal e Algarve de 1325 até sua morte. Era o único filho homem do rei Dinis I e sua esposa Isabel de Aragão - canonizada como Santa Isabel. 
Apesar de ser o único filho legítimo de seu pai, D. Afonso não seria, de acordo com algumas fontes, o favorito do Rei D. Dinis, que preferia a companhia de D. Afonso Sanches, um dos seus bastardos (legitimado). Esta preferência deu lugar a uma rivalidade entre os dois irmãos que, algumas vezes, deu lugar a confrontos armados. Em 1325, D. Afonso IV tornou-se rei e, como primeira decisão, exilou Afonso Sanches para Castela, retirando-lhe de caminho todas as terras, títulos e feudos concedidos pelo pai de ambos. O exilado não se conformou e do outro lado da fronteira orquestrou uma série de manobras políticas e militares com o fim de se tornar ele próprio rei. Depois de várias tentativas de invasão falhadas, os irmãos assinaram um tratado de paz, sob o patrocínio da Rainha Santa Isabel.
Em 1309, D. Afonso IV casou com a infanta Beatriz, filha do rei Sancho IV de Castela. A primogénita desta união, a princesa D. Maria de Portugal, casou com D. Afonso XI de Castela em 1328, mas o casamento revelou-se infeliz, dado que o Rei de Castela maltratava abertamente a mulher. D. Afonso IV não ficou contente por ver sua filha menosprezada e atacou as terras fronteiriças de Castela em retaliação. A paz chegou quatro anos mais tarde e, com a intervenção da própria D. Maria de Portugal, um tratado foi assinado em Sevilha em 1339. No ano seguinte, em Outubro de 1340, tropas portuguesas participaram na grande vitória da Batalha do Salado contra os mouros merínidas.
Em 1343 houve no reino grande carestia de cereais e em 1346, a fim de fazer sua aliança com o rei de Aragão, D. Afonso IV enviou a Barcelona um embaixador para a assinatura do acordo entre o rei e D. Pedro IV de Aragão com vista à realização do casamento da infanta D. Leonor. Em 1347 ocorreu um sismo que abalou Coimbra, tendo causado enormes prejuízos, e em 1348 a peste negra, vinda da Europa, assola o país.
De todos os problemas foi a peste o mais grave, vitimando grande parte da população e causando grande desordem no reino. O rei reagiu prontamente, tendo promulgado legislação a reprimir a mendicidade e a ociosidade.
A última parte do reinado de D. Afonso IV foi marcada por intrigas políticas e conflitos internos em grande parte devidos à presença em solo português de refugiados da guerra civil entre D. Pedro I de Castela e o seu meio-irmão D. Henrique da Trastâmara.
Entre os exilados contavam-se vários nobres, habituados ao poder, que cedo criaram a sua própria facção dentro da Corte portuguesa. Quando o príncipe herdeiro D. Pedro assume D. Inês de Castro como sua preferida, os nobres castelhanos passam a gozar cada vez mais dos privilégios do poder real português.
D. Afonso IV não ficou agradado com o favoritismo concedidos aos castelhanos e procurou várias formas de afastar D. Inês do filho. Sem sucesso, pois D. Pedro assume a relação com D. Inês de Castro, sua preferida, bem como assumiu os filhos que dela teve, legitimando-os na famosa Declaração de Cantanhede, acrescentando em 1349 a recusa de tornar a casar com outra mulher que não ela. Com o passar dos anos D. Afonso IV perdeu o controlo da situação e os fidalgos pró Castela e D. Inês de Castro aumentavam o seu poder, enquanto o único herdeiro direto de D. Pedro e D. Constança Manuel de Vilhena, o futuro rei D. Fernando, crescia como uma criança doente. Preocupado com a vida do único neto que reconhecia como herdeiro e com o acréscimo de poder castelhano dentro de suas fronteiras, D. Afonso IV planeja e executa a morte de D. Inês de Castro em 1355 juntamente com Pêro Coelho, Álvaro Gonçalves e Diogo Lopes Pacheco. Tomado por violenta indignação, D. Pedro entrou em guerra aberta contra o pai que planejou e executou o assassinato de D. Inês de Castro, saqueando e queimando a região do Entre-Douro-e-Minho. A reconciliação chegou apenas em 1357, quando o rei delega em vida grande parte do poder ao príncipe herdeiro, D. Pedro. D. Afonso IV morreu pouco tempo depois.
Como rei, D. Afonso IV é lembrado como um comandante militar corajoso, daí o cognome de "Bravo". A sua maior contribuição a nível económico e administrativo foi a importância dada ao desenvolvimento da marinha portuguesa. D. Afonso IV subsidiou a construção de uma marinha mercante e financiou as primeiras viagens de exploração Atlântica. As Ilhas Canárias foram descobertas no seu reinado.
Jaz na Sé de Lisboa.
O estilo oficial de D. Afonso IV enquanto Rei era: "Pela Graça de Deus, Afonso IV, Rei de Portugal e do Algarve"
Do seu casamento com D. Beatriz de Castela (1293 - Lisboa, 25 de Outubro de 1359), infanta do Reino de Castela, filha do rei D. Sancho IV de Castela com D. Maria de Molina, nasceram:
Teve ainda uma filha ilegítima:
! colspan="3" style="background: #FBEC5D;" | Afonso IV de PortugalCasa de Borgonha8 de fevereiro de 1291 – 28 de maio de 1357

Pedro I (Coimbra, – Estremoz, ), apelidado de "o Justo" e "o Cruel", foi o Rei de Portugal e Algarve de 1357 até sua morte. Era o único filho homem do rei Afonso IV e sua esposa Beatriz de Castela.
O Infante D. Pedro nasceu na cidade de Coimbra, a 8 de Abril de 1320, filho do então infante D. Afonso e sua esposa D. Beatriz de Castela. Pedro foi o quarto filho de um total de sete, três mulheres e quatro varões: D. Maria, D. Afonso, D. Dinis, ele próprio, D. Isabel, D. João, e D. Leonor. Destes, mais de metade cedo morre (D. Afonso nado-morto à nascença; D. Dinis, D. Isabel, e D. João na sua infância). Por este motivo, D. Pedro, não sendo primogénito, torna-se herdeiro do pai e vem a suceder-lhe no trono. Pedro I sucedeu a seu pai em 1357.
Dos seus primeiros anos de vida, pouco se sabe. Conhecem-se, todavia, através de fontes escritas, a sua ama, D. Leonor; o aio e mordomo-mor Lopo Fernandes Pacheco; o guarda, Domingos Anes; o reposteiro-mor, Gonçalo Lobato; e os reposteiros, Afonso Domingues e Afonso Esteves. É também sabido que, por volta dos seus quinze anos, em 1335, já tinha casa. Os cronistas fazem menção a um defeito de gaguez e ainda, no foro psíquico, "paixões exaltadas e violentas, cóleras explosivas, perversões várias"; é igualmente caracterizado como um amante da festa e da música, cantando e dançando por Lisboa ao som de "longas" com os populares.
D. Pedro é conhecido pela sua relação com Inês de Castro, a aia galega da sua mulher Constança Manuel, que influenciou fortemente a política interna de Portugal no reinado de D. Afonso IV. Inês acabou assassinada por ordens do rei a 7 de Janeiro de 1355, mas isto não trouxe Pedro de volta à influência paterna. Contrariamente, durante alguns meses, Pedro revoltou-se contra o pai; apoiado pela nobreza de Entre Douro e Minho e pelos irmãos de Inês. A paz veio por vontade declarada do povo e perdoaram-se mútuas ofensas. Aclamado rei em 1357, Pedro anunciou em Cantanhede, em junho de 1360, o casamento com Inês, realizado em segredo antes da sua morte, sendo sua intenção a ver lembrada como Rainha de Portugal. A promessa de perdão aos responsáveis pela morte de Inês foi esquecida
Este facto baseia-se apenas na palavra do rei, uma vez que não existem registos de tal união. Dois assassinos de Inês foram capturados e executados (Pêro Coelho e Álvaro Gonçalves) com uma brutalidade tal (a um foi arrancado o coração pelo peito, e a outro pelas costas), que lhe valeram os epítetos supramencionados.
Conta também a tradição que Pedro teria feito desenterrar o corpo da amada, coroando-a como Rainha de Portugal, e obrigando os nobres a procederem à cerimónia do beija-mão real ao cadáver, sob pena de morte. Em seguida ordenou a execução de dois túmulos (verdadeiras obras-primas da escultura gótica em Portugal), os quais foram colocados no transepto da igreja do Mosteiro de Alcobaça para que, no dia do Juízo Final, os eternos amantes, então ressuscitados, de imediato se vejam...
Como rei, Pedro revelou-se bom administrador, corajoso na defesa do país contra a influência papal (foi ele que promulgou o famoso Beneplácito Régio, que impedia a livre circulação de documentos eclesiásticos no país sem a sua autorização expressa), e foi justo na defesa das camadas menos favorecidas da população. Aplicava a justiça com brutalidade, de forma «democrática», punindo exemplarmente sem olhar a quem. Para não atrasar a aplicação das sentenças, puniu com pena de morte a prática da advocacia, isto levou a protestos nas cortes de 1361. Pouco fez para refrear o poder da nobreza, mas esta temia o rei. Gostava muito de estar próximo do povo nos festejos, daí ser adorado. Na política externa, Pedro ajudou seu sobrinho, o rei de Castela na guerra contra o meio-irmão.
A sua relação com o clero foi algo conflituosa, em relação à nobreza foi magnânimo. Deu o título de conde de Barcelos a João Afonso Telo com direito hereditário e deu terras aos filhos de Inês. A Ordem de Avis entregou-a a seu filho, João, futuro rei.
A forma como exerceu a justiça, parece-nos hoje cruel, mas era costume naqueles tempos difíceis. Diz-se que mandou servir um banquete enquanto assistia à execução de Pêro Coelho e Álvaro Gonçalves. Gostava mais de ser algoz de que juiz, como atestam algumas sentenças que proferiu.
D. Pedro reinou durante dez anos, sendo tão popular ao ponto de dizer a população "que taes dez annos nunca houve em Portugal como estes que reinara el Rei Dom Pedro". O seu reinado foi o único no século XIV sem guerra e marcado com prosperidade financeira, daí ficar na memória como um bom reinado. Para Fernão Lopes foi o avô da dinastia de Avis.
Jaz no Mosteiro de Santa Maria de Alcobaça.
O estilo oficial de D. Pedro I enquanto rei era: "Pela Graça de Deus, Pedro I, Rei de Portugal e do Algarve"
Em 1329, Branca de Castela, a única filha de Pedro, infante de Castela e de Maria, infanta de Aragão foi prometida em casamento com D. Pedro, mas dada a sua debilidade e sua incapacidade o casamento não se chegou a realizar.
Seu primeiro casamento foi com Constança Manuel, filha de D. João Manuel de Castela, de quem teve a:
De seu segundo casamento com Inês de Castro (1320 - assassinada em 1355) nasceram:
De Teresa Lourenço: 
Embora havendo três filhos do seu segundo casamento e tendo vivido uma relação intensa com Inês de Castro, com quem também houve descendência, acerca do temperamento deste soberano, o cronista Fernão Lopes dedicou um capítulo que intitulou ""Como El-Rei mandou capar um seu escudeiro porque dormia com uma mulher casada", permitindo entrever que o gesto teria sido motivado por ciúmes do monarca por seu escudeiro, de nome Afonso Madeira. Madeira é descrito como um grande cavalgador, caçador, lutador e ágil acrobata, e regista: "Pelas suas qualidades, El-Rei amava-o muito e fazia-lhe generosas mercês." O escudeiro, entretanto, apaixonou-se por Catarina Tosse, esposa do Corregedor, descrita como "briosa, louçã e muito elegante, de graciosas prendas e boa sociedade". Para se aproximar dela, Madeira fez-se amigo do Corregedor, seduzindo-a e consumando a traição. O soberano, entretanto, tudo descobriu e não perdoou Madeira, castigando-o brutalmente. O cronista insiste no afeto do soberano, referindo enigmaticamente: "Como quer que o Rei muito amasse o escudeiro, mais do que se deve aqui dizer (...)", mas regista que D. Pedro mandou "cortar-lhe aqueles membros que os homens em maior apreço têm". O escudeiro recebeu assistência e sobreviveu, mas "engrossou nas pernas e no corpo e viveu alguns anos com o rosto engelhado e sem barba"". 
! colspan="3" style="background: #FBEC5D;" | Pedro I de PortugalCasa de Borgonha8 de abril de 1320 – 18 de janeiro de 1367

Disco rígido ou disco duro, popularmente chamado também de "HD" (derivação de "HDD" do inglês "hard disk drive"), "memória de massa" ou ainda de "memória secundária" é a parte do computador onde são armazenados os dados.
O disco rígido é uma memória não-volátil, ou seja, as informações não são perdidas quando o computador é desligado, sendo considerado o principal meio de armazenamento de dados em massa. Por ser uma memória não-volátil, é um sistema necessário para se ter um meio de executar novamente programas e carregar arquivos contendo os dados inseridos anteriormente quando ligamos o computador. Nos sistemas operativos mais recentes, ele é também utilizado para expandir a memória RAM, através da gestão de memória virtual. Existem vários tipos de interfaces para discos rígidos diferentes: "IDE"/"ATA", "Serial ATA", "SCSI", "Fibre channel", "SAS".
O primeiro disco rígido foi construído pela IBM em 1956, e foi lançado em 16 de Setembro de 1957. Era formado por 50 discos magnéticos contendo 50 000 setores, sendo que cada um suportava 100 caracteres alfanuméricos, totalizando uma capacidade de 5 "megabytes", incrível para a época. Este primeiro disco rígido foi chamado de "305 RAMAC (Random Access Method of Accounting and Control)" e tinha dimensões de 152,4 centímetros de comprimento, 172,72 centimetros de largura e 73,66 centímetros de altura.
Em 1973 a "IBM" lançou o modelo 3340 "Winchester", com dois pratos de 30 "megabytes" e tempo de acesso de 30 milissegundos. Assim criou-se o termo 30/30 "Winchester" (uma referência à espingarda "Winchester" 30/30), termo muito usado antigamente para designar HDs de qualquer espécie. Ainda no início da década de 1980, os discos rígidos eram muito caros e modelos de 10 "megabytes" custavam quase 2 mil dólares americanos, enquanto em 2009 compramos modelos de 1.5 "terabyte" por pouco mais de 100 dólares. Ainda no começo dos anos 80, a mesma IBM fez uso de uma versão "pack" de discos de 80 "megabytes", usado nos sistemas "IBM Virtual Machine". Os discos rigidos foram criados originalmente para serem usados em computadores em geral.
Mas no século XXI as aplicações para esse tipo de disco foram expandidas e agora são usados em câmeras filmadoras, ou camcorders nos Estados Unidos; tocadores de música como iPod, MP3 player; PDAs; videogames, e até em celulares. Para exemplos em videogames temos o Xbox360 e o Playstation 3, lançados em 2005 e 2006 respectivamente, com esse diferencial, embora a Microsoft já tivesse lançado seu primeiro Xbox (em 2001) com disco rígido convencional embutido. Já para celular os primeiros a terem essa tecnologia foram os da Nokia e da Samsung. E também devemos lembrar que atualmente o disco rigido não é só interno, existem também os externos, que possibilitam o transporte de grandes quantidades de dados entre computadores sem a necessidade de rede.
Os discos magnéticos de um disco rígido são recobertos por uma camada magnética extremamente fina. Na verdade, quanto mais fina for a camada de gravação, maior será sua sensibilidade, e consequentemente maior será a densidade de gravação permitida por ela. Poderemos, então, armazenar mais dados num disco do mesmo tamanho, criando HDs de maior capacidade. Os primeiros discos rígidos, assim como os discos usados no início da década de 80, utilizavam a mesma tecnologia de mídia magnética utilizada em disquetes, chamada "coated media", que além de permitir uma baixa densidade de gravação, não é muito durável. Os discos atuais já utilizam mídia laminada ("plated media"), uma mídia mais densa, de qualidade muito superior, que permite a enorme capacidade de armazenamento dos discos modernos.
A cabeça de leitura e gravação de um disco rígido funciona como um eletroímã semelhante aos que estudamos nas aulas de ciências e física do colegial, sendo composta de uma bobina de fios que envolve um núcleo de ferro. A diferença é que, num disco rígido, este eletroímã é extremamente pequeno e preciso, a ponto de ser capaz de gravar trilhas (pistas em Portugal) medindo menos de um centésimo de milímetro de largura. Quando estão sendo gravados dados no disco, a cabeça utiliza seu campo magnético para organizar as moléculas de óxido de ferro da superfície de gravação, fazendo com que os pólos positivos das moléculas fiquem alinhados com o pólo negativo da cabeça e, conseqüentemente, com que os pólos negativos das moléculas fiquem alinhados com o pólo positivo da cabeça. Usamos, neste caso, a velha lei "os opostos se atraem". Como a cabeça de leitura e gravação do "HD" é um eletroímã, sua polaridade pode ser alternada constantemente. Com o disco girando continuamente, variando a polaridade da cabeça de gravação, variamos também a direção dos pólos positivos e negativos das moléculas da superfície magnética. De acordo com a direção dos pólos, temos um bit 1 ou 0 (sistema binário).
Para gravar as sequências de bits 1 e 0 que formam os dados, a polaridade da cabeça magnética é mudada alguns milhões de vezes por segundo, sempre seguindo ciclos bem determinados. Cada bit é formado no disco por uma sequência de várias moléculas. Quanto maior for a densidade do disco, menos moléculas serão usadas para armazenar cada bit, e teremos um sinal magnético mais fraco. Precisamos, então, de uma cabeça magnética mais precisa. Quando é preciso ler os dados gravados, a cabeça de leitura capta o campo magnético gerado pelas moléculas alinhadas. A variação entre os sinais magnéticos positivos e negativos gera uma pequena corrente elétrica que caminha através dos fios da bobina. Quando o sinal chega à placa lógica do HD, ele é interpretado como uma sequência de bits 1 e 0. Desse jeito, o processo de armazenamento de dados em discos magnéticos parece ser simples, e realmente era nos primeiros discos rígidos (como o 305 "RAMAC" da "IBM"), que eram construídos de maneira praticamente artesanal. Apesar de nos discos modernos terem sido incorporados vários aperfeiçoamentos, o processo básico continua sendo o mesmo. 
A formatação de um disco magnético é realizada para que o sistema operacional seja capaz de gravar e ler dados no disco, criando assim estruturas que permitam gravar os dados de maneira organizada e recuperá-los mais tarde.
Existem dois tipos de formatação, chamados de formatação física e formatação lógica. A formatação física é feita na fábrica ao final do processo de fabricação, que consiste em dividir o disco virgem em trilhas, setores, cilindros e isolar os "bad blocks" (danos no HD). Estas marcações funcionam como as faixas de uma estrada, permitindo à cabeça de leitura saber em que parte do disco está, e onde ela deve gravar dados. A formatação física é feita apenas uma vez, e não pode ser desfeita ou refeita através de software. Porém, para que este disco possa ser reconhecido e utilizado pelo sistema operacional, é necessária uma nova formatação, chamada de formatação lógica. Ao contrário da formatação física, a formatação lógica não altera a estrutura física do disco rígido, e pode ser desfeita e refeita quantas vezes for preciso, através do comando Format do DOS, por exemplo. O processo de formatação é quase automático; basta executar o programa formatador que é fornecido junto com o sistema operacional.
Os sistemas de arquivos mais conhecidos são os utilizados pelo "Microsoft Windows": "NTFS", "FAT32" e "FAT 16". O FAT32 é uma versão evoluída do FAT16 introduzida a partir do MS-DOS 4.0. A partir do Windows NT foi introduzido o NTFS, que trouxe novos recursos.
Quando o computador é ligado, o POST ("Power-on Self Test"), um pequeno programa gravado em um "chip" de memória ROM na placa-mãe, que tem a função de “dar a partida”, tentará inicializar o sistema operacional. Independentemente de qual sistema de arquivos se esteja usando, o primeiro setor do disco rígido será reservado para armazenar informações sobre a localização do sistema operacional, que permitem ao "BIOS" "achá-lo" e iniciar seu carregamento.
No setor de boot é registrado onde o sistema operacional está instalado, com qual sistema de arquivos o disco foi formatado e quais arquivos devem ser lidos para inicializar o computador. Um setor é a menor divisão física do disco, e possui na grande maioria das vezes 512 Bytes (nos CD-ROMs e derivados é de 2048 Bytes). Um "cluster", também chamado de agrupamento, é a menor parte reconhecida pelo sistema operacional, e pode ser formado por vários setores. Um arquivo com um número de "bytes" maior que o tamanho do "cluster", ao ser gravado no disco, é distribuído em vários clusters. Porém, um "cluster" não pode pertencer a mais de um arquivo. Um único setor de 512 Bytes pode parecer pouco, mas é suficiente para armazenar o registro de "boot" devido ao seu pequeno tamanho. O setor de "boot" também é conhecido como "trilha MBR", "trilha 0' etc. Como dito, no disco rígido existe um setor chamado Trilha 0, e nele está gravado o (MBR) ("Master Boot Record"), que significa "Registro de Inicialização Mestre", um estilo de formatação, onde são encontradas informações sobre como está dividido o disco (no sentido lógico)e sobre a ID de cada tabela de partição do disco, que dará o "boot". O MBR é lido pelo BIOS, que interpreta a informação e em seguida ocorre o chamado "bootstrap", "levantar-se pelo cadarço", lê as informações de como funciona o sistema de arquivos e efetua o carregamento do sistema operacional. O MBR e a ID da tabela de partição ocupam apenas um setor de uma trilha, o restante dos setores desta trilha não são ocupados, permanecendo vazios, servindo como área de proteção do MBR. É nesta mesma área que alguns vírus (Vírus de Boot) se alojam.
Com a constante demanda por espaço, mais as melhorias da tecnologia de fabricação, tem havido uma mudança para setores de tamanho maior, tipicamente para 4096 Bytes. Tal mudança é para que seja melhor utilizado o espaço do disco para mais informações úteis. Cada setor precisa(para que os dados sejam confiáveis) de um conjunto de bits adicionais para verificação contra erros(para que a própria controladora consiga detectar erros de leitura física), com o aumento de capacidade dos discos, diminui-se o número de átomos para representar um determinado bit, que o torna mais frágil, aumentando o risco de perca de dados. Para não haver problemas por causa dessa fragilidade, aumenta-se o número de bits para a verificação da integridade da informação no setor, o que acaba diminuindo o espaço utilizável para os dados do usuário. Com o aumento para 4096 Bytes, cai, consideravelmente, o número de bits usado para verificação de integridade em todo o disco, pois haverá menos setores no disco, e como o mesmo número de bits, por setor, consegue ser utilizado para uma verificação de uma porção maior de dados, decai o 'desperdício' por causa da verificação da integridade.
Disquetes, "Zip-disks" e CD-ROMs não possuem MBR; no entanto, possuem tabela de partição, no caso do CD-ROMs e seu descendentes (DVD-ROM, HDDVD-ROM, BD-ROM...) possuem tabela própria, podendo ser CDFS ("Compact Disc File System", norma ISO 9660) ou UDF ("Universal Disc Format", uma implementação do padrão ISO/IEC 13346) ou, para maior compatibilidade, os dois; já os cartões de memória "Flash" e "Pen-Drives" possuem tabela de partição e podem ter até mesmo MBR, dependendo de como formatados. O MBR situa-se no primeiro setor da primeira trilha do primeiro prato do HD (setor um, trilha zero, face zero, prato zero). O MBR é constituído pelo "bootstrap" e pela tabela de partição. O "bootstrap" é o responsável por analisar a tabela de partição em busca da partição ativa. Em seguida, ele carrega na memória o Setor de "Boot" da partição. Esta é a função do "bootstrap".
A tabela de partição contém informações sobre as partições existentes no disco. São informações como o tamanho da partição, em qual trilha/setor/cilindro ela começa e termina, qual o sistema de arquivos da partição, se é a partição ativa; ao todo, são dez campos. Quatro campos para cada partição possível (por isso, só se pode ter 4 partições primárias, e é por isso também que foi-se criada a partição estendida...), e dez campos para identificar cada partição existente. Quando acaba o POST, a instrução INT 19 do BIOS lê o MBR e o carrega na memória, e é executado o "bootstrap". O "bootstrap" vasculha a tabela de partição em busca da partição ativa, e em seguida carrega na memória o Setor de "Boot" dela. A função do Setor de "Boot" é a de carregar na memória os arquivos de inicialização do sistema operacional. O Setor de "Boot" fica situado no primeiro setor da partição ativa.
A capacidade de um disco rígido atualmente disponível no mercado para uso doméstico/comercial varia de 10 a 3000 GB, assim como aqueles disponíveis para empresas, de mais de 3 "TB". O HD evoluiu muito. O mais antigos possuíam 5 MB (aproximadamente 4 disquetes de 3 1/2 HD), sendo aumentada para 30 MB, em seguida para 500 MB (20 anos atrás), e 10 anos mais tarde, HDs de 1 a 3 GB. Em seguida lançou-se um HD de 10 GB e posteriormente um de 15 GB. Posteriormente, foi lançado no mercado um de 20 GB, até os atuais HDs dos mais variados tamanhos.
No entanto, as indústrias consideram 1 GB = formula_1 "bytes", pois no Sistema Internacional de Unidades(SI), que trabalha com potências de dez, o prefixo giga quer dizer formula_2 ou formula_3 (bilhões), enquanto os sistemas operacionais consideram 1 GB = formula_4 "bytes", já que os computadores trabalham com potências de dois e 1024 é a potência de dois mais próxima de mil. Isto causa uma certa disparidade entre o tamanho informado na compra do HD e o tamanho considerado pelo Sistema Operacional, conforme mostrado na tabela abaixo. Além disso, outro fator que pode deixar a capacidade do disco menor do que o anunciado é a formatação de baixo nível (formatação física) com que o disco sai de fábrica.
"Todos os valores acima são aproximações"
Toda a vez que um HD é formatado, uma pequena quantidade de espaço é marcada como utilizada, podendo ser(dependendo do suporte do sistema de arquivos) pelo log do Journaling, mapa de clusters livres, etc.
Disco rígido externo, conhecido popularmente como HD externo, é um dispositivo de armazenamento independente, que pode ser conectado a um computador através de USB, e-Sata, FireWire ou outros meios.
Capacidade de armazenamento de discos externos: 320GB, 500GB, 640GB, 750GB, 1TB, 2TB, 3TB, 4TB, 6TB, 8TB.

Economia () é uma ciência que consiste na análise da produção, distribuição e consumo de bens e serviços. É também a ciência social que estuda a atividade económica, através da aplicação da teoria económica, tendo, na gestão, a sua aplicabilidade prática. O termo "economia" vem do grego οικονομία (de οἶκος, translit. "oikos", 'casa' + νόμος , translit. "nomos", 'costume ou lei', ou também 'gerir, administrar': daí "regras da casa" ou "administração doméstica".
Os modelos e técnicas atualmente usados em economia evoluíram da economia política do final do século XIX, derivado da vontade de usar métodos mais empíricos à semelhança das ciências naturais.
Pode representar, em sentido lato, a situação económica de um país ou região; isto é, a sua situação conjuntural (relativamente aos ciclos da economia) ou estrutural.
A economia é, geralmente, dividida em dois grandes ramos: a microeconomia, que estuda os comportamentos individuais, e a macroeconomia, que estuda o resultado agregado dos vários comportamentos individuais. Atualmente, a economia aplica o seu corpo de conhecimento para análise e gestão dos mais variados tipos de organizações humanas (entidades públicas, empresas privadas, cooperativas etc.) e domínios (internacional, finanças, desenvolvimento dos países, ambiente, mercado de trabalho, cultura, agricultura, etc.).
Outras formas de divisão da disciplina são: a distinção entre economia positiva ("o que é", que tenta explicar o comportamento ou fenômeno econômico observado) e economia normativa ("o que deveria ser", frequentemente relacionado com políticas públicas); a distinção entre economia ortodoxa, aquela que lida com o nexo "racionalidade-individualismo-equilíbrio", e a economia heterodoxa, que pode ser definida por um nexo "instituições-história-estrutura social".
Para Paul Krugman e Robin Wells,
Efetivamente, o foco de interesse da microeconomia é, antes de tudo, o estudo das escolhas dos agentes económicos, isto é, da forma como estes procedem dado um conjunto de diferentes opções, comparando os benefícios e inconvenientes para a prossecução dos seus objetivos ou para a satisfação dos seus interesses - o postulado utilitarista.
A microeconomia estuda as interações que ocorrem nos mercados em função da informação existente e da regulação estatal. Distinguem-se os mercado de bens e serviços dos mercados de fatores de produção, capital e trabalho, por terem diferentes agentes e formas de funcionamento.
A teoria compara os agregados da quantidade global demandada pelos compradores e da quantidade fornecida pelos vendedores, o que determina o preço.
Constrói modelos que descrevem como o mercado pode conseguir o equilíbrio entre o preço e a quantidade, ou como pode reagir a alterações do mercado ao longo do tempo, que é o que se denomina de mecanismo da oferta e da procura.
As estruturas de mercado, como a concorrência perfeita e o monopólio, são analisadas para tirar conclusões sobre o seu comportamento e a sua eficiência económica.
A análise de um mercado é feita a partir de hipóteses simplificadoras, como por exemplo a racionalidade dos agentes e equilíbrio parcial (parte-se do pressuposto de o mercado não é afetado pelo que se passa em outros mercados ).
Uma análise em equilíbrio geral é um estudo mais abrangente, que permite avaliar as consequências sobre os outros mercados, para compreender as interações e os mecanismos que podem levar a uma situação de equilíbrio.
A teoria microeconómica padrão assume que os agentes económicos, as famílias ou as empresas, são "racionais", isto é, supõe-se terem habilidades cognitivas e informações suficientes para, por um lado, construir critérios de escolha entre diferentes opções possíveis, por outro, para maximizar a sua satisfação dadas as restrições a que estão sujeitos. Presume-se que são capazes de identificar as restrições sobre estas escolhas, tanto restrições "internas" (as suas capacidade tecnológica, no caso das empresas, por exemplo), como as "externas" (por exemplo, as resultantes da conjuntura económica).
É o paradigma do "homo economicus", que não implica "a priori" que os critérios de escolha dos indivíduos sejam puramente egoístas. Podem perfeitamente ser "racionalmente" altruístas.
Esta teoria deve sua existência à síntese feita pela economia matemática neoclássica das décadas de 1940 e 1950, entre os contributos da corrente marginalista do século XIX e da teoria do equilíbrio geral de Walras e Pareto.
John Hicks e Paul Samuelson são considerados os pais da microeconomia tradicional atual, que podemos dividir em quatro áreas:
Em microeconomia, produção é um processo que usa insumos para criar produtos, destinados ao comércio ou ao consumo. A produção é um fluxo, logo é mensurável através de um rácio por unidade de tempo. É comum distinguir entre a produção de bens de consumo (alimentos, cortes de cabelo, etc.) vs. bens de investimento (novos tratores, edifícios, estradas, etc.), bens públicos (defesa nacional, segurança pública, proteção civil, etc.) ou bens privados (computadores novos, bananas, etc.).
As entradas para o processo de produção incluem fatores de produção básicos como o trabalho, capital (bens duradouros usados na produção, como uma fábrica) e terra (incluindo recursos naturais). Outros fatores incluem bens intermédios usados na produção dos bens finais, como por exemplo o aço no fabrico de um carro novo.
O custo de oportunidade, relacionado com o custo económico, é o valor da melhor alternativa disponível quando se tem que fazer uma escolha entre duas opções mutuamente exclusivas.
É descrita como sendo a expressão da "relação básica entre escassez e escolha".
O custo de oportunidade é um fator que garante a utilização eficiente dos recursos escassos, pois o custo é ponderado face ao valor gerado, no momento de decidir aumentar ou reduzir uma atividade.
Os custos de oportunidade não se restringem a custos monetários. Podem também ser medidos em tempo (de lazer, por exemplo) ou qualquer outra coisa que corresponda a um benefício alternativo (utilidade, no vocabulário microeconómico)
A eficiência económica descreve o quanto um sistema utiliza bem os recursos disponíveis, dada a tecnologia disponível. A eficiência aumenta se conseguirmos obter um maior resultado sem aumentar os recursos usados, ou seja, se conseguirmos reduzir o "desperdício".
Dizemos que temos uma eficiência de Pareto quando estamos num ponto onde nenhuma alteração na forma como usamos os recursos disponíveis consegue melhorar o resultado para alguém sem piorar a situação de outro.
A fronteira de possibilidades de produção (FPP) é uma ferramenta analítica que representa a escassez, custo e eficiência. No caso mais simples, estudamos uma economia que produz apenas dois bens. A FPP é uma tabela ou gráfico (ver ilustração) que mostra as várias combinações de quantidades dos dois produtos que é possível ter, dado a tecnologia e os fatores de produção disponíveis.
Cada ponto na curva mostra uma produção potencial total máxima para a economia, que é a produção máxima possível para um bem, dada uma quantidade de produção para o outro bem. É um ponto de eficiência produtiva por maximizar a produção para um total dado de insumos. Um ponto "dentro" da curva é possível mas representa ineficiência produtiva (uso de insumos com desperdício), no sentido de que é possível aumentar a produção de um ou ambos os bens no sentido nordeste em direção a um ponto na curva.
O gráfico na ilustração exemplifica uma curva com todos os pontos economicamente eficientes. O ponto A no gráfico, por exemplo, indica-nos que a produção de F de comida e C de computadores é eficiente. O mesmo se passa com F de comida e C de computadores (ponto B). Os pontos abaixo dessa linha são ineficientes, pois é possível aumentar a produção de um dos bens sem ser forçado a reduzir a produção do outro.
A escassez é representada na figura pela impossibilidade de se poder produzir para além da FPP. São os pontos acima da linha, impossíveis de atingir com os recursos e tecnologia disponíveis.
É também representada pelo declive da curva, que representa o quanto da produção de um bem diminui quando a produção do outro aumenta, numa relação inversa.
Isso ocorre porque uma maior produção de um bem requer a transferência de insumos da produção do outro bem, forçando a sua diminuição.
É um exemplo de custo de oportunidade e significa que escolher mais de um bem implica ter menos do outro.
Estar na curva pode ainda não satisfazer completamente a eficiência alocativa (também apelidado de "eficiência de Pareto") se a curva não consistir numa combinação de produtos que os consumidores tenham preferência face a outros pontos ou combinações.
Numa economia de mercado, o ponto da curva onde a economia se posiciona pode ser explicado pela escolha que os agentes acham mais preferível.
Muito da economia aplicada em políticas públicas está preocupada em determinar como a eficiência de uma economia pode ser aumentada. 
Encarar a realidade da escassez para então perceber como podemos organizar a sociedade para ter o uso mais eficiente dos recursos tem sido descrito como sendo a "essência da economia", onde a disciplina "faz a sua contribuição ímpar". 
A especialização é considerada um aspecto chave para a eficiência económica, devido a diferentes agentes (indivíduos ou países) terem diferentes vantagens comparativas.
Mesmo que um país detenha vantagem absoluta em todos os setores, tem vantagem em se especializar nas áreas onde tenha as maiores vantagens comparativas, efetuando depois trocas comerciais com outros países. Consegue desta forma obter uma maior quantidade dos produtos onde não se especializou comparado com a opção de produzir tudo por si.
Um exemplo disso é a especialização dos países desenvolvidos em produtos de alta tecnologia, preferindo adquirir os bens de manufatura aos países em desenvolvimento, onde a mão-de-obra é barata e abundante.
A teoria defende que desta forma se consegue obter um maior total de produtos e utilidade, comparando com a situação em que cada país decide pela produção própria de todos os produtos.
A teoria da vantagem comparativa é responsável pela crença generalizada dos economistas nos benefícios do comércio livre.
O conceito aplica-se a indivíduos, fazendas, fábricas, fornecedores de serviços e a economias.
Em qualquer um destes sistemas produtivos podemos ter:
A Riqueza das Nações (1776), de Adam Smith faz uma discussão notável dos benefícios da divisão do trabalho. A forma como os indivíduos podem aplicar da melhor forma o seu trabalho, ou qualquer outro recurso, é um tema central do primeiro livro da obra.
Smith afirmava que um indivíduo deveria investir recursos, por exemplo, terra e trabalho, de forma a obter o maior retorno possível.
Desta forma, as várias aplicações de um mesmo recurso devem ter uma taxa de retorno igual (ajustada pelo risco relativo associado a cada atividade). Caso contrário, acabaria por ocorrer uma realocação de recursos melhorando o retorno.
O economista francês Turgot fez o mesmo raciocínio dez anos antes, em 1766.
Estas ideias, escreveu George Stigler, são a proposição central da teoria econômica.
De forma mais geral, a teoria diz que fatores do mercado, como os custos de produção e os preços dos insumos, determinam a alocação dos fatores de produção tendo em conta a "vantagem comparativa".
São escolhidos os insumos mais baratos, de forma a ter o mais baixo "custo de oportunidade" para cada tipo de produto.
Com este processo, a produção agregada aumenta como efeito colateral.
Esta especialização da produção cria oportunidades para "ganhos com o comércio" em que os detentores dos recursos beneficiam do comércio vendendo um tipo de produto contra outros bens de maior valor.
Uma medida dos ganhos de comércio é o aumento na produção (formalmente, a soma do acréscimo do excedente do consumidor e dos lucros do produtor) resultante da especialização na produção e do consequente comércio. 
A teoria de oferta e demanda explica os preços e as quantidades dos bens transacionados numa economia de mercado e as respetivas variações.
Na teoria microeconômica em particular, refere-se à determinação do preço e quantidade num mercado de concorrência perfeita, que tem um papel fundamental na construção de modelos para outras estruturas de mercado, como monopólio, oligopólio e competição monopolística) e para outras abordagens teóricas.
Para o mercado de um bem, a "demanda" mostra a quantidade que os possíveis compradores estariam dispostos a comprar para cada preço unitário do bem. A demanda é frequentemente representada usando uma tabela ou um gráfico relacionando o preço com a quantidade demandada (ver figura).
A teoria da demanda descreve os consumidores individuais como entidades "racionais" que escolhem a quantidade "melhor possível" de cada bem, em função dos rendimentos, preços, preferências, etc.
Uma expressão para isso é 'maximização da utilidade restringida' (sendo a renda a "restrição" da demanda).
Para esse contexto, "utilidade" refere-se às hipotéticas preferências relativas dos consumidores individuais.
A utilidade e a renda são então usadas para modelar os efeitos de mudanças de preço nas quantidades demandadas.
A lei da demanda diz que, regra geral, o preço e a quantidade demandada num determinado mercado estão inversamente relacionados.
Por outras palavras, quanto mais alto for o preço de um produto, menos pessoas estarão dispostas ou poderão comprá-lo ( tudo o resto inalterado).
Quando o preço de um bem sobe, o poder de compra geral diminui ("efeito renda") e os consumidores mudam para bens mais baratos ("efeito substituição").
Outros fatores também podem afetar a demanda. Por exemplo, um aumento na renda desloca a curva da demanda em direção oposta à origem, como é exemplificado na figura.
"Oferta" é a relação entre o preço de um bem e a quantidade que os fornecedores colocam à venda para cada preço desse bem. A oferta é normalmente representada através de um gráfico relacionando o preço com a quantidade ofertada. Assume-se que os produtores maximizam o lucro, o que significa que tentam produzir a quantidade que lhes irá dar o maior lucro possível. A oferta é tipicamente representada como uma relação diretamente proporcional entre preço e quantidade (tudo o resto inalterado).
Por outras palavras, quanto maior for o preço pelo qual uma mercadoria pode ser vendida, mais produtores estarão dispostos a fornecê-la. O preço alto incentiva a produção. Em oposição, para um preço abaixo do equilíbrio, há uma falta de bens ofertados em comparação com a quantidade demandada pelo mercado. Isso faz com que o preço desça. O modelo de oferta e demanda prevê que, para curvas de oferta e demanda dadas, o preço e quantidade irão se estabilizar no preço em que a quantidade ofertada é igual à quantidade demandada. Esse ponto é a intersecção das duas curvas no gráfico acima, o equilíbrio do mercado.
Para uma determinada quantidade de um bem, o ponto do preço na curva da demanda permite determinar o "valor", ou utilidade marginal para os consumidores para essa unidade de produto. Ele indica a quantia que um consumidor estaria disposto a pagar por aquela unidade específica do bem: o seu "custo marginal". O preço no ponto de equilíbrio é determinado pela conjugação da oferta e demanda. Por isso podemos dizer que, em mercados perfeitamente competitivos, a oferta e a demanda conseguem um equilíbrio entre o custo e o valor.
Do lado da oferta, alguns fatores de produção são relativamente fixos no curto prazo, o que pode afetar os custos em caso de alteração do nível de produção. Por exemplo, equipamentos ou maquinaria pesada, espaço de fábrica adequado, e pessoal qualificado. Um fator de produção variável pode ser alterado facilmente, para se adequar ao nível de produção escolhido. Exemplos incluem: o consumo de energia elétrica, a maioria das matérias primas, horas extraordinárias e trabalhadores temporários. No longo prazo, todos os fatores de produção podem ser ajustados pela gestão. Mas estas diferenças podem resultar numa diferente elasticidade (rapidez de resposta) da curva da oferta no curto prazo, que podem implicar diferenças face aos resultados de longo prazo previstos pelo modelo.
A oferta e demanda são usadas para explicar o comportamento dos mercados de concorrência perfeita, mas sua utilidade como modelo de referência é extensível a qualquer outro tipo de mercado. A oferta e demanda também pode ser generalizada para explicar a economia como um todo. Por exemplo a quantidade total produzida e o nível geral de preços (relacionado com a inflação) estudados pela macroeconomia.
A oferta e demanda também pode ser usada para modelar a distribuição de renda pelos fatores de produção, como o capital e trabalho, através de "mercados de fatores". Num mercado de trabalho competitivo, por exemplo, a quantidade de trabalho empregada e o preço do trabalho (o salário) são modelados pela demanda por trabalho (pelas firmas) e pela oferta de trabalho (pelos potenciais trabalhadores).
A economia do trabalho estuda as interações entre trabalhadores e empregadores através desses mercados, para explicar os níveis de salários e outros rendimentos do trabalho, o desenvolvimento de competências e capital humano, e o (des)emprego.
Na análise de oferta e demanda, o "preço" de um bem equilibra as quantidades produzidas e consumidas.
Preço e quantidade são habitualmente descritos como sendo as características mais diretamente observáveis de um bem produzido no mercado.
Oferta, demanda e equilíbrio de mercado são construções teóricas que relacionam preço e quantidade. Mas traçar os efeitos dos fatores que de acordo com a teoria alteram a oferta e a demanda - e através delas, o preço e a quantidade - é o exercício habitual da microeconomia e macroeconomia aplicadas. A teoria econômica pode especificar sob que circunstâncias os preços podem funcionar como um mecanismo de comunicação "eficiente" para regular a quantidade. Uma aplicação no mundo real pode ser tentar medir o quanto as variáveis que alteram a oferta e a demanda afetam o preço e a quantidade.
A teoria elementar da oferta e demanda prediz que o equilíbrio será alcançado, mas não a velocidade de ajuste que pode ser provocado por alterações na oferta e/ou demanda. Em muitas áreas, alguma forma de "inércia" do preço é postulada para explicar porque quantidades - e não preços - sofrem ajustes no curto prazo, devido a alterações tanto no lado da oferta quanto no da demanda. Isso inclui análises padrão de ciclos econômicos na macroeconomia. A análise frequentemente gira em torno de identificar as causas para essa inércia e suas implicações para que se alcance o equilíbrio de longo prazo previsto pela teoria. Exemplos em mercados específicos incluem níveis de salário nos mercados de trabalho e preços estabelecidos em mercados que se desviam da competição perfeita.
A teoria econômica do marginalismo aplica os conceitos de marginalidade na economia. O conceito de marginalidade dá relevância ao significado da variação da quantidade de um bem ou serviço, por oposição ao significado da quantidade como um todo. Mais especificamente, o conceito central ao marginalismo propriamente dito é a utilidade marginal, mas uma corrente seguidora de Alfred Marshall baseou-se mais fortemente no conceito de produtividade marginal física para a explicação do custo.
A corrente neoclássica que emergiu do marginalismo britânico trocou o conceito de utilidade pelo de taxa marginal de substituição no papel central da análise.
O marginalismo, tal como a teoria económica clássica, descreve os consumidores como agentes que almejam alcançar a posição mais desejada, sujeita a restrições como renda e riqueza. Descreve os produtores como agentes que buscam a maximização do lucro, sujeitos às suas próprias restrições (inclusive à demanda pelos bens produzidos, tecnologia e o preço dos insumos). Assim, para um consumidor, no ponto onde a utilidade marginal de um bem alcança zero, não há mais incremento no consumo desse bem. De forma análoga, um produtor compara a receita marginal contra o custo marginal de um bem, com a diferença sendo o "lucro marginal". No ponto onde o lucro marginal alcança zero, cessa o aumento na produção do bem. Para o movimento em direção ao equilíbrio e para mudanças no equilíbrio, o comportamento também muda "na margem" - geralmente mais-ou-menos de algo, ao invés de tudo-ou-nada.
Condições e considerações relacionadas se aplicam de forma mais geral a qualquer tipo de sistema econômico, baseados no mercado ou não, onde existe escassez. A escassez é definida pela quantidade de bens produzíveis ou comerciáveis, tanto necessários quanto desejados, maior do que capacidade de produção.
As condições são em forma de restrições à produção de fatores "finitos" disponíveis. Tais restrições dos recursos descrevem um conjunto de possibilidades de produção. Para consumidores ou outros agentes, as possibilidades de produção e a escassez implicam que, mesmo que os recursos sejam plenamente utilizados, existem "trade-offs", quer seja de rabanetes por cenouras, tempo livre por salário ou consumo presente por consumo futuro. A noção marginalista de custo de oportunidade é um instrumento para medir o tamanho do trade-off entre alternativas competidoras. Tais custos, refletidos nos preços, são usados para prever as reações á política pública, mudanças ou perturbações numa economia de mercado. Também são usadas para avaliar a eficiência econômica. De forma parecida, em uma "economia planejada", relações de "preço-sombra" devem ser satisfeitas para um uso eficiente dos recursos. Nesse caso também, o marginalismo pode ser usado como ferramenta, tanto para modelar unidades ou setores de produção quanto em relação aos objetivos do planejador central.
Agir pelo interesse individual conduz muitas vezes ao interesse geral, mas nem sempre é assim. Paul Krugman e Robin Wells notam que "a mão invisível não é sempre nossa aliada"..
Uma falha de mercado é um situação na qual o mercado não consegue a alocação óptima dos recursos económicos e dos bens e serviços. Isso pode acontecer, por exemplo, no caso de um monopólio (ou de um cartel), ou de uma situação em que coexistam desemprego e falta de mão-de-obra, ou ainda a existência de poluição.
A falha de mercado, no sentido de alocação económica, é um conceito diferente da anomalia de mercado, que tem um caráter mais financeiro, não da falta de eficiência do mercado. A anomalia de mercado diz respeito ao rendimento financeiro e a uma anomalia nos preços devida a fenómenos comportamentais. Estes dois fenómenos podem ser a causa ou a consequência um do outro, ou resultar de uma causa comum.
O conceito de falha tem também um aspecto político, e por isso algo controverso, na medida em que serve para justificar intervenções políticas para “corrigir”, ou até mesmo suprimir, o mercado. Apesar disso, a generalidade dos economistas utiliza o termo mais para se referir às situações em que o funcionamento real de um mercado se afasta significativamente do mercado perfeito, devido ao efeito de três causas principais:
O autores liberais, após o surgimento da teoria da escolha pública, acrescentam uma quarta causa, que na sua opinião tem consequências bem mais graves:
A partir dos dos anos 1970, o paradigma dominante na microeconomia sofre uma inflexão de modo a melhor integrar todas as anomalias e imperfeições do mercado. Para Pierre Cahuc "a nova microeconomia foi construída progressivamente, a partir de críticas dispersas, muitas inicialmente de forma isolada, ao modelo walrasiano". De uma forma mais geral, para a economista Anne Perrot, o edifício teórico da microeconomia tradicional deixava "desarmado o economista que procurasse uma representação positiva do funcionamento do mercado". Esta mudança aconteceu num momento em que a macroeconomia buscava os seus fundamentos microeconómicos, de forma que iria gerar alguma convergência entre os dois campos.
O quadro geral da nova microeconomia é preferencialmente reduzido à análise de um só mercado e o seu estudo científico baseia-se mais em constatações que se julga serem representativas do funcionamento da economia (que são apelidados de "factos estilizados").
A nova microeconomia enfatiza os problemas relativos aos estímulos, à informação e à teoria dos jogos.
Por "estímulo" entende-se toda a ação de um agente económico (incluindo o Estado) que levem a certos agentes económicos adotar este ou aquele comportamento. Esta noção tem todo o sentido se considerarmos que a informação disponível é inevitavelmente limitada por um agente económico desejoso de incentivar outros agentes a ter comportamentos do seu interesse.
A teoria dos jogos, por seu lado, é um ramo da matemática aplicada que estuda as interações estratégicas entre agentes. Segundo essa teoria, os agentes escolhem as estratégias que maximizam os seus benefícios, sendo dadas as estratégias que os outros agentes irão escolher. Propõem um modelo formal das situações em que os decisores interagem com outros agentes.
A teoria dos jogos generaliza a abordagem de maximização desenvolvida anteriormente para a análise de mercados. Foi desenvolvida a partir do livro de 1944 "Theory of Games and Economic Behavior", de John von Neumann e Oskar Morgenstern. É também empregue em numerosos domínios não económicos: estratégia nuclear, ética, ciência política e teoria evolucionista.
A extensão da abordagem microeconómica conduziu também ao desenvolvimento da "teoria dos contratos". Esta teoria conceptualiza as organizações, instituições, famílias e empresas como conjuntos de contratos (nós de contratos, na terminologia económica).
Uma empresa é, por exemplo, um nó composto por contratos de trabalho, ligando-a aos seus assalariados, por contratos ligando-a aos seus clientes e fornecedores, por contratos de produtos bancários e financeiros, por contratos legais ligando-a ao seu Estado ou região em matéria fiscal e de regulação.
os mercados são outro caso particular de nós de contratos, neste caso de contratos de comércio.
Os Estados, no sentido das organizações políticas que administram determinados espaços geográficos, são um outro exemplo de nó contratual, representando as Constituições contratos gerais ligando estas organizações ao povo que governam.
Um aspecto importante dos contratos é, regra geral, serem "incompletos", isto é, não conseguem especificar totalmente as obrigações das partes em todas as situações possíveis.
O desenvolvimento desta teoria gerou naturalmente um aprofundamento das teorias da negociação e renegociação. De facto, o seu propósito é não só explicar como e porquê os contratos são formados entre os agentes, mas também as razões pelas quais eles os põem, ou não, em causa com o decorrer do tempo.
A nova microeconomia pode ser usada pela economia industrial, economia do trabalho e pela economia pública, devido à sua capacidade para se aproximar das preocupações práticas de certos industriais.
A macroeconomia, também conhecida como "cross-section", examina a economia como um todo, "de cima para baixo", para explicar amplos agregados e suas interações. Tais agregados incluem as medições do produto nacional bruto, a taxa de desemprego, e inflação dos preços e subagregados como o consumo todas e os gastos com investimento e seus componentes. Ela também estuda os efeitos da política monetária e política fiscal. Desde pelo menos os anos 1960, a macroeconomia tem sido caracterizada pela integração cada vez maior com a modelagem de base micro de setores, inclusive a racionalidade dos agentes, o uso eficiente da informação no mercado, e a competição imperfeita. Isso tem abordado uma antiga preocupação sobre as inconsistências no desenvolvimentos da disciplina. A análise macroeconômica também considera fatores que afetem o nível de crescimento da renda nacional no longo-prazo. Tais fatores incluem a acumulação de capital, mudança tecnológica e crescimento da força de trabalho.
A "economia do desenvolvimento" estuda fatores que explicam o crescimento econômico – o aumento na produção per capita de um país ao longo de um extenso período de tempo. Os mesmos fatores são usados para explicar diferenças no "nível" de produção per capita "entre" países. Fatores muito estudados incluem a taxa de investimento, crescimento populacional, e mudança tecnológica. Que estão representados em formas empíricas e teóricas (como no modelo de crescimento neoclássico) e na contabilidade do crescimento. O campo distinto da "economia do desenvolvimento" examina aspectos econômicos do processo de desenvolvimento em países de baixa renda focando em mudanças estruturais, pobreza, e crescimento econômico. Abordagens em economia do desenvolvimento frequentemente incorporam fatores políticos e sociais.
"Sistemas econômicos" é o da economia que estuda os métodos e instituições pelas quais sociedades determinam a propriedade, direção e alocação dos recursos econômicos e as suas respectivas trajetórias de desenvolvimento econômico. Um "sistema econômico" de uma sociedade é a unidade de análise. Entre sistemas contemporâneos em diferentes partes do espectro organizacional são os sistemas socialistas e os sistemas capitalistas, nos quais ocorre a maior parte da produção, respectivamente em empresas estatais e privadas. Entre esses extremos estão as economias mistas. Um elemento comum é a interação de influências políticas e econômicas, amplamente descritas como economia política. "Sistemas econômicos comparados" é a área que estuda a performance e o comportamento relativos de diferentes economias ou sistemas.
A contabilidade nacional é um método para listar a atividade econômica agregada de uma nação. As contas nacionais são sistemas contábeis de partidas dobradas que fornecem informações detalhadas sobre a atividade econômica de um país. Essas incluem o produto nacional bruto (PNB), que fornece estimativas para o valor monetário da produção e da renda por ano ou por trimestre. O PNB permite que se acompanhe a performance de uma economia e seus componentes ao longo de ciclos econômicos ou períodos históricos. Dados de preços pedem permitir a distinção entre valores reais e nominais, isto é, corrigir totais monetários para refletir as variações nos preços ao longo do tempo. As contas nacionais também incluem aferições do estoque de capital, riqueza de uma nação, e fluxos internacionais de capital.
A economia tem inúmeros campos de estudo, abordando temáticas específicas. Os códigos de classificação JEL constituem um sistema de classificação dos assuntos em economia muito usado em publicações da área.
A economia política junta economia, legislação e ciência política para explicar como as instituições políticas e o sistema económico (capitalista, socialista ou misto) interagem. Estuda questões como impacto na política seguida pelos governos de factores como monopólios, comportamento para obtenção de rendimento e externalidades.
Para o prémio Nobel da economia Edmund Phelps "a economia política é o estudo das estrutras alternativas de rendimentos entre as quais a sociedade pode - e deve - escolher: como os mecanismos de um dado sistema, os impostos, subsídios, obrigações, deveres etc. atuam sobre os indivíduos e até que ponto funcionam bem ou mal?".
A economia pública ocupa-se do sector produtor de bens públicos e é frequentemente considerado um ramo da economia cujo objeto é o fornecimento de bens coletivos gratuitos cujos custos são financiados através de impostos.
De forma mais geral, integra também a produção de bens de mercado por empresas públicas. Estuda também as políticas que um Estado deve conduzir para promover o desenvolvimento económico e o bem-estar da população e os problemas de desigualdade social e redistribuição da riqueza.
Finanças públicas é o ramo da economia que lida com os gastos e receitas das entidades do setor público, geralmente o governo. Aborda questões como incidência fiscal (quem realmente paga um imposto), análise custo-benefício de programas do governo, efeitos na eficiência econômica e distribuição de renda de diferentes tipos de gastos e políticas fiscais. Essa última, um aspecto da teoria da escolha pública, modela o comportamento do setor público de forma análoga à microeconomia, envolvendo interações de eleitores, políticos e burocratas interessados em si mesmos.
A economia do bem-estar é um ramo normativo da economia que usa técnicas da microeconomia para determinar a eficiência de alocação e a distribuição de renda que lhe está associada. Visa medir o bem-estar social examinando as atividades econômicas dos indivíduos que compõem a sociedade.
A análise econômica do direito ("Economic Analysis of Law" ou "Law and Economics" em inglês) é a disciplina que procura explicar os fenómenos jurídicos através de métodos e conceitos da ciência económica. Usa de conceito econômicos para explicar os efeitos de normas legais a fim de determinar ou prever se serão economicamente eficientes.
São feitas críticas à intervenção pública. Para os economistas da teoria da escolha pública, os políticos e funcionários procuram o seu interesse individual e não o interesse geral. os primeiros procuram ser reeleitos, e os últimos procurar melhorar os seus rendimentos e poderes.
A busca de renda (do inglês "rent-seeking") retrata o comportamento de indivíduos e organizações que procuram obter rendimentos através de regulamentação que lhe seja favorável, ao invés de o conseguir através de uma atividade realmente criadora de riqueza. Por exemplo, estudos neste domínio evidenciam a existência de esforços para assegurar situações de monopólio.
A economia industrial, também conhecida nos Estados Unidos como organização industrial, estuda o comportamento estratégico das empresas, a estrutura dos mercados e suas interações. As estruturas comuns do mercado incluem competição perfeita, competição monopolística, várias formas de oligopólio e monopólio.
A economia gerencial aplica análise microeconômica para especificar decisões nas organizações. Ela se aproveita pesadamente de métodos quantitativos como pesquisa operacional e programação e também de métodos estatísticos como a regressão ausentes a certeza e informação perfeita. Um tema unificador é a tentativa de otimizar decisões de negócios, inclusive minimização de custo por unidade e maximização de lucro, dados os objetivos da firma e limitações impostas pela tecnologia e condições de mercado.
Segundo alguns autores, as necessidades do ser humano como indivíduo, tais como se alimentar, se abrigar e até mesmo respirar, exigem consumo de produtos conseguidos com uma atividade econômica, nesse caso chamada de "Economia Individual". Os extremos são os exemplos históricos ou literários clássicos como o de Santo Antão que viveu numa caverna do deserto da Arábia e que plantava trigo e fabricava pão para se sustentar; e de Robinson Crusoé que praticou várias atividades econômicas para se manter enquanto esteve isolado numa ilha oceânica. Outros autores, como Oscar Dias Corrêa, preferem não reconhecer tais atividades como econômicas ou pertencentes ao estudo da Economia .
Nas famílias primitivas autossuficientes já se identificavam as diversas fases da Economia: o produto de todos (da caça, pesca, plantação e colheita) era distribuído pelos chefes da família e consumido. O grupo necessitava de um planejamento rudimentar das atividades, que ficava a cargo do chefe familiar que o aplicava de forma autoritária e que, além de distribuir as atividades, podia também racionar o consumo .
O comércio internacional estuda os determinantes dos fluxos de bens e serviços através das fronteiras internacionais. Também estuda a quantidade e forma de distribuição dos ganhos com o comércio.
Aplicações em política incluem a capacidade de estimar os efeitos da alteração de taxas alfandegárias e quotas de comércio.
A primeira teoria de comércio internacional (teoria clássica de comércio internacional) foi formulada no início do século XIX por David Ricardo, também sendo conhecida por Teoria das Vantagens Comparativas ou Princípio das Vantagens Comparativas.
Finanças internacionais é uma área de estudo da macroeconomia que estuda os fluxos de capital através das fronteiras internacionais e os efeitos desses movimentos nas taxas de câmbio. O aumento do comércio de bens, serviços e capitais entre países é um dos maiores efeitos da globalização contemporânea.
A área de estudo da "economia do desenvolvimento" aborda os aspetos económicos do processo de desenvolvimento nos países em vias de desenvolvimento, focando na mudança estrutural, pobreza e crescimento económico. As abordagens à economia do desenvolvimento incorporam frequentemente fatores sociais e políticos.
"Sistemas económicos" é o ramo da economia que estuda os métodos e instituições através dos quais as sociedades determinam a propriedade, direção, e alocação dos recursos económicos. O "sistema económico" de uma sociedade é a unidade de análise.
Os extremos do espetro de sistema económicos são as economias planificadas e os sistemas capitalistas, onde a maioria da produção é efetuada, respetivamente, em organizações detidas pelo estado ou pela iniciativa privada.
Como meio termo temos as economias mistas. Um elemento comum a qualquer dos sistemas é a interação entre o poder económico e político, largamente descrito pela economia política.
A economia da agricultura é uma das mais antigas e mais bem estabelecidas áreas da economia. É o estudo das forças econômicas que afetam o setor agrícola e o impacto do setor agrícola no resto da economia. É uma área da economia que, graças à necessidade de se aplicar a teoria microeconômica a situações complexas do mundo real, tem contribuído com avanços importantes de aplicação mais geral; o papel do risco e da incerteza, o comportamento das famílias e as ligações entre direito de propriedade e incentivos. Mais recentemente áreas como o comércio internacional de "commodities" e meio ambiente tem recebido grande atenção.
A economia da informação examina como a informação (ou sua falta) afeta o processo decisório econômico. Um importante foco da disciplina é o conceito de assimetria de informação, onde um participante possui mais ou melhor informação que a outra. A existência da assimetria de informação abre espaço para o surgimento de problemas como risco moral e seleção adversa estudada na teoria dos contratos. A economia da informação tem relevância em muitas áreas como finanças, seguros, direito, e processo decisório em condições de risco e incerteza.
A economia do trabalho procura entender o funcionamento do mercado e a sua dinâmica relacionada ao trabalho. Os mercados de trabalho funcionam através das interações entre trabalhadores e empregadores. A economia do trabalho observa os ofertantes de força-de-trabalho (trabalhadores), seus demandantes (empregadores) e tenta entender os padrões resultantes de salários e outras rendas do trabalho, de emprego e desemprego. Usos práticos incluem a assistência na formulação de políticas de pleno emprego.
A economia enquanto uma disciplina contemporânea se fia em estilos rigorosos de argumentação. Os objetivos incluem a formulação de teorias que sejam mais simples, mais frutíferas e mais confiáveis do que outras teorias ou nenhuma teoria. A análise pode começar com um simples modelo que propõe uma hipótese de uma variável a ser explicada por outra variável. Com frequência uma hipótese em economia é somente qualitativa, não "quantitativa". Isto é, a hipótese implica a "direção" de uma mudança em uma variável, não o "tamanho" da mudança, para uma certa mudança de outra variável. Para clareza de exposição, a teoria pode proceder com a suposição de "ceteris paribus", isto é, mantendo constante outros termos explicatórios que não aquele em questão. Por exemplo, a teoria quantitativa da moeda prediz um aumento no valor nominal da produção a partir de um aumento da oferta de moeda, "ceteris paribus".
A teoria econômica é aberta às críticas de que ela confia em suposições irrealistas, não-verificáveis ou altamente simplificadas. Um exemplo é a suposição da maximização do lucro pelas firmas competitivas. Respostas de executivos a perguntas sobre os fatores que afetam as suas decisões podem mostrar nenhum cálculo desse tipo.
A ciência econômica como disciplina acadêmica frequentemente usa métodos geométricos, além de métodos literários. Outros métodos quantitativos e matemáticos também são frequentemente usados para análises rigorosas da economia ou de áreas dentro da economia. Tais métodos incluem os seguintes.
A economia matemática se refere a aplicações de métodos matemáticos para representar a teoria econômica ou analisar problemas surgidos na economia. Esses métodos incluem cálculo e álgebra matricial. Autores citam suas vantagens na formulação e derivação de relações centrais em um modelo econômico com clareza, generalidade, rigor, e simplicidade. Por exemplo, o livro de Paul Samuelson "Fundamentos da Análise Econômica" (1947) identifica uma estrutura matemática comum através de vários campos da disciplina.
A econometria aplica métodos matemáticos e estatísticos para analisar dados relacionados com modelos econômicos. Por exemplo, uma teoria pode levantar a hipótese de que pessoas com mais educação irão ter renda mais alta, na média, do que uma pessoa com menos educação, mantido o resto constante. Estimativas econométricas podem delimitar a magnitude e a significância estatística da relação. A econometria pode ser usada para tecer generalizações quantitativas. Essas incluem testar ou refinar uma teoria, descrever uma relação de variáveis no passado e prever variáveis futuras.
A teoria dos jogos é um ramo da matemática aplicada que estuda as interações estratégicas entre agentes. Nos jogos estratégicos, agentes escolhem estratégias que irão maximizar suas vantagens, dadas as estratégias que os outros agentes escolherem. Ela fornece uma abordagem formal para a modelação de situações sociais em que os decisores interagem com outros agentes.
A teoria dos jogos generaliza as abordagens ao problema da maximização desenvolvidas para analisar mercados como o modelo de oferta e demanda. O campo de estudo remonta ao clássico de 1944 "Theory of Games and Economic Behavior" de John von Neumann e Oskar Morgenstern. Tem encontrado aplicações significativas em muitas áreas fora da economia, incluindo a formulação de estratégia nuclear, ética, ciência política, e teoria evolucionária.
A profissionalização da economia, refletida no crescimento dos cursos de graduação, tem sido descrita como "a principal mudança na economia desde 1900".
A maioria das principais universidades e faculdades tem um curso, escola ou departamento que atribui títulos académicos na área.
O Prêmio Nobel de Economia é um prêmio anual concedido a economistas que tenham feito contribuições notáveis à disciplina.
No mundo profissional, os economistas encontram ocupação como consultores, principalmente nos setores bancário e financeiro. No setor público podem trabalhar em várias agências e departamentos como o tesouro nacional, o Banco Central, e entidades oficiais de estatística, entre outros.
O pensamento econômico na Antiguidade remonta às civilizações mesopotâmicas, Grega, Romana, Indiana, Chinesa, Persa e àrabe. Dentro os autores mais notáveis estão Aristóteles, Chanakya, Qin Shi Huang, Tomás de Aquino e Ibn Khaldun. Joseph Schumpeter considerou inicialmente a escolástica tardia do período que vai do século XIV ao XVII como a "que chega mais perto do que qualquer outro grupo de ser os 'fundadores' da economia científica quanto às teoria monetária, de juros e do valor dentro de uma perspectiva das leis naturais. Depois de descobrir a obra "Muqaddimah" de Ibn Khaldun, no entanto, Schumpeter mais tarde considerou Ibn Khaldun o mais próximo antecedente da economia moderna, uma vez que muitas das suas teorias econômicas não eram conhecidas na Europa até épocas modernas.
Dois outros grupos, mais tarde chamados de ' mercantilistas e 'fisiocratas', influenciaram mais diretamente o desenvolvimento subsequente da disciplina. Ambos os grupos estavam associados com a ascensão do nacionalismo econômico e do capitalismo moderno na Europa. O mercantilismo era uma doutrina econômica que floresceu do século XVI ao XVIII através de uma prolífica literatura de panfleto quer de autoria de mercantes ou estadistas. Defendiam a ideia de que a riqueza de uma nação dependia da sua acumulação de ouro e prata. Nação que não tinham acesso à minas poderiam obter ouro e prata através do comércio internacional apenas se vendessem bens ao exterior e restringissem as importações que não fossem de ouro e prata. A doutrina advogava a importação de matérias-primas baratas para serem transformadas em produtos manufaturados destinados à exportação e também o intervencionismo estatal no sentido de impor tarifas protecionistas à importação de produtos manufaturados e a proibição de manufaturas nas colônias.
Os fisiocratas, um grupo de pensadores e escritores franceses do século XVIII, desenvolveram a ideia da economia como um fluxo circular. Adam Smith descreveu esse sistema com "todas as suas imperfeições" como "talvez a mais pura aproximação da verdade que já foi publicada" no assunto. Os fisiocratas acreditavam que somente a produção agrícola gerava um claro excedente sobre o custo, de forma que a agricultura constituía a base de toda riqueza. Assim, eles se opunham às políticas mercantilistas de promoção das manufaturas e do comércio em detrimento da agricultura, inclusive tarifas de importação. Advogavam a substituição do complexo e custoso sistema de arrecadação de tributos por um único imposto sobre a renda dos proprietários de terra. Variações sobre tal imposto fundiário foram retomadas por economistas posteriores (inclusive Henry George um século mais tarde) como uma fonte de receita que não distorcia tanto a economia. Como reação às copiosas regulamentações mercantilistas, os fisiocratas defendiam uma política de laissez-faire, que consistia numa intervenção estatal mínima na economia.
Apesar das discussões sobre produção e distribuição terem uma longa história, a ciência econômica no seu sentido moderno como uma disciplina separada é convencionalmente datada a partir da publicação de "A Riqueza das Nações" de Adam Smith em 1776. Nesse trabalho, ele descreve a disciplina nesses exatos termos:
Smith se referia à disciplina como 'economia política', mas esse termo foi gradualmente substituído por ciência econômica ("economics") depois de 1870.
A publicação da obra A Riqueza das Nações de Adam Smith em 1776, tem sido descrita como o "efetivo nascimento da economia como uma disciplina separada." O livro identificava o trabalho, a terra e o capital como os três fatores de produção e maiores contribuidores para a riqueza de uma nação. Para Smith, a economia ideal seria um sistema de mercado auto-regulador que automaticamente satisfaria as necessidades econômicas da população. Ele descreveu o mecanismo de mercado como uma "mão invisível" que leva todos os indivíduos, na busca de seus próprios interesses, a produzir o maior benefício para a sociedade como um todo. Smith incorporou algumas das ideias dos fisiocratas, inclusive o laissez-faire, nas suas próprias teorias econômicas, mas rejeitou a ideia de que somente a agricultura era produtiva.
Na sua famosa analogia da mão invisível, Smith argumentou em favor da noção, aparentemente paradoxal de que os mercados competitivos tendem a satisfazer às necessidades sociais mais amplas, apesar de ser guiado por interesses-próprios. A abordagem geral que Smith ajudou a formular foi chamada do economia política e mais tarde de economia clássica e incluiu nomes notáveis como Thomas Malthus, David Ricardo e John Stuart Mill, que escreveram de 1770 a 1870, aproximadamente.
Enquanto Adam Smith enfatizou a produção de renda, David Ricardo na sua distribuição entre proprietários de terras, trabalhadores e capitalistas. Ricardo enxergou um conflito inerente entre proprietários de terras e capitalistas. Ele propôs que o crescimento da população e do capital, ao pressionar um suprimento fixo de terras, eleva os aluguéis e deprime os salários e os lucros.
Thomas Robert Malthus usou a ideia dos retornos decrescentes para explicar as baixa condições de vida na Inglaterra. De acordo com ele, a população tendia a crescer geometricamente sobrecarregando a produção de alimentos, que cresceria aritmeticamente. A pressão que uma população crescente exerceria sobre um estoque fixo de terras significa produtividade decrescente do trabalho, uma vez que terras cada vez menos produtivas seriam incorporadas à atividade agrícola para suprir a demanda. 
O resultado seria salários cronicamente baixos, que impediriam que o padrão de vida da maioria da população se elevasse acima do nível de subsistência. Malthus também questionou a automaticidade da economia de mercado para produzir o pleno emprego. Ele culpou a tendência da economia de limitar o gasto por causa do excesso de poupança pelo desemprego, um tema que ficou esquecido por muitos anos até que John Maynard Keynes a reviveu nos anos 1930.
No final da tradição clássica, John Stuart Mill divergiu dos autores anteriores quanto a inevitabilidade da distribuição de renda pelos mecanismos de mercado. Mill apontou uma diferença dois papéis do mercado: alocação de recursos e distribuição de renda. O mercado pode ser eficiente na alocação de recursos mas não na distribuição de renda, ele escreveu, de forma que seria necessário que a sociedade intervenha.
A teoria do valor foi importante na teoria clássica. Smith escreveu que "o preço real de qualquer coisa… é o esforço e o trabalho de adquiri-la" o que é influenciado pela sua escassez. Smith dizia que os aluguéis e os salários também entravam na composição do preço de uma mercadoria. Outros economistas clássicos apresentaram variações das ideias de Smith, chamada 'Teoria do valor-trabalho'. Economistas clássicos se focaram na tendência do mercado de atingir o equilíbrio no longo prazo.
A economia marxista, mais tarde chamada marxiana, descende da economia clássica, em particular da obra de Karl Marx. O primeiro volume da obra de Marx, O Capital, foi publicada em alemão em 1867. Nela, Marx foca escreve sobre sua "teoria do valor-trabalho" e o que ele considera a exploração do trabalho pelo capital. Assim, a teoria do valor-trabalho, além de ser uma simples teoria dos preços, se transformou em um método para medir a utilização do trabalho num sistema capitalista, apesar de disfarçadas pela economia política "vulgar".
Um corpo teórico mais tarde chamado de 'economia neoclássica' ou 'economia marginalista' se formou entre 1870 e 1910. A expressão economics foi popularizada na língua inglesa por economistas neoclássicos como Alfred Marshall, como substituto para 'economia política'. A economia neoclássica sistematizou a oferta e demanda como determinantes conjuntos do preço e da quantidade transacionada em um equilíbrio de mercado, afetando tanto a alocação da produção quanto a distribuição de renda. Ela dispensou a teoria do valor-trabalho em favor da teoria do valor-utilidade marginal no lado da demanda e uma teoria mais geral de custos no lado da oferta.
Na microeconomia, a economia neoclássica diz que os incentivos e os custos tem um papel importante no processo de tomada de decisão. Um exemplo imediato disso é a teoria do consumidor da demanda individual, que isola como os preços (enquanto custos) e a renda afetam a quantidade demandada. Na macroeconomia é refletida numa antiga e duradoura síntese neoclássica com a macroeconomia keynesiana.
A economia neoclássica é a base do que hoje é chamada economia ortodoxa, tanto pelos críticos quanto pelos simpatizantes, mas com muitos refinamentos que ou complementam ou generalizam as análises anteriores , como a econometria, a teoria dos jogos, a análise das falhas de mercado e da competição imperfeita, assim como o modelo neoclássico do crescimento econômico para a análise das variáveis de longo-prazo que afetam a renda nacional.
A economia keynesiana deriva de John Maynard Keynes, em particular do seu livro "A Teoria Geral do Emprego, do Juro e da Moeda" (1936), que deu início à macroeconomia como um campo de estudo distinto. O livro foca nos determinantes da renda nacional no curto prazo, em que os preços são relativamente inflexíveis. Keynes tentou explicar com riqueza de detalhes teóricos por que o alto desemprego poderia não ser auto-corrigido devido a baixa "demanda efetiva" e por que mesmo a flexibilidade dos preços e a política monetária pode não ser suficiente para corrigir a situação. Expressão como "revolucionário" foram aplicadas ao livro devido ao seu impacto na análise econômica.
A economia keynesiana teve dois sucessores. A economia pós-keynesiana que busca resgatar as principais contribuições da Teoria Geral de Keynes, tendo economistas com pontos de vista plurais. É geralmente associada à Universidade de Cambridge e à obra de Joan Robinson. A nova economia keynesiana também está associada com desenvolvimentos à maneira keynesiana. No Brasil, grandes centros Keynesianos estão em Campinas, UNICAMP e no Rio de Janeiro, UFRJ.
Na verdade, a economia keynesiana não estabelece restrição alguma de preços e salários, o que Keynes disse foi o seguinte: em uma recessão, caso exista flexibilidade de preços e salários, o problema econômico será mais grave e ocorrerá de forma cumulativa. Por que? Na lógica individual da empresa (a microeconômica), com a crise faz sentido para a empresa reduzir salários e demitir funcionários. Contudo, aplicando a lógica para todo um setor ou para toda economia, a facilidade de reduzir salários e demitir acaba por deprimir ainda mais a economia, pois se de um lado o trabalhador é um custo para a empresa individual, de outro ele é consumidor de outras empresas. Caso ocorra o fato de muitos serem desempregados e a redução da renda for acentuada, a demanda agregada se reduzirá ainda mais. Desta forma o faturamento dos vários setores se reduzirá ainda mais, e o esforço de redução de custos inicial será solapado e o processo entra em nova espiral, agravando a crise, com mais queda de faturamento, mais redução de renda, mais desemprego.
Economia keynesiana significa estudar como a economia funciona na realidade, na qual os agentes modificam suas decisões frente a mudança de expectativas sobre o futuro (que não é passível de certeza matemática) Economia keynesiana enfatiza que o objetivo da produção é o lucro, mas que os agentes não maximizam previamente o lucro, dependem das decisões de todos os demais agentes sobre o que eles vão fazer com seu dinheiro, isto é, quanto as pessoas vão consumir de sua renda, quanto vão poupar, de que forma vão poupar, e além da poupança, como vão aplicar seu estoque de riqueza, qual taxa de retorno desejam, com qual liquidez e a que risco. Sendo isto válido para o público em geral, empresários, banqueiros e instituições financeiras .
Outras escolas reconhecidas ou linhas de pensamento relacionadas a um estilo próprio de fazer economia, disseminadas por um grupo bem conhecido de acadêmicos incluem a Escola Austríaca, Escola de Chicago, a Escola de Friburgo, a escola de Lausanne e a escola de Estocolmo.
Dentro da macroeconomia há, em ordem geral de aparecimento na literatura: economia clássica, economia keynesiana, a síntese neoclássica, economia pós-keynesiana, monetarismo, nova economia clássica e Economia pelo lado da oferta. Novos desenvolvimentos alternativos incluem economia ecológica, economia evolucionária, teoria da dependência, economia estruturalista, teoria dos juros da abstinência e teoria do sistema-mundo.
Discussões influentes nos primórdio da economia política estavam relacionadas com a "riqueza" amplamente definida, como na obra de David Hume e Adam Smith. Hume argumentava que ouro adicional sem incremento da produção só servia para aumentar os preços. Smith também descreveu a riqueza real não em termos de ouro e prata como anteriormente, mas como a "produção anual do trabalho e da terra da sociedade."
John Stuart Mill definiu a economia como "a ciência prática de produção e distribuição de riqueza"; esta foi a definição adotada pelo "Concise Oxford English Dictionary" apesar de não incluir o papel vital do consumo. Para Mill, a riqueza é definida como o estoque de coisas úteis.
Definições da disciplina em termos de riqueza enfatizam a produção e o consumo. Essa definição foi acusada pelos críticos por ser estreita demais, colocando a riqueza à frente do homem. Por exemplo, John Ruskin chamou a economia política de "a ciência de ficar rico" and a "bastard science."
Definições mais amplas se desenvolveram para incluir o estudo do homem, da atividade humana e do seu bem-estar. Alfred Marshall, no seu livro "Principles of Economics", escreveu, "A Economia Política ou Economia é um estudo da humanidade nos negócios da vida cotidiana; ela examina essa parte do indivíduo e da ação social que é mais fortemente ligada ao uso dos requisitos materiais para o bem-estar."
Uma das características de qualquer ciência é o uso do método científico, com a exigência de estabelecer hipóteses e fazer predições que possam ser testadas com dados empíricos, onde os resultados são passíveis de serem demonstrados e repetidos, através da reprodução das mesmas condições da experiência.
Em economia são conduzidos algumas experiências em áreas aplicadas, em particular nos sub-campos da economia experimental e comportamento do consumidor, focados na experimentação usando sujeitos humanos; e no sub-campo da econometria, focada em testar hipóteses quando os dados estatísticos não são gerados em experimentos controlados. No entanto, à semelhança das outras ciências sociais, pode ser difícil os economistas conduzirem certos experimentos formais devido a questões práticas e morais envolvendo sujeitos humanos.
O estatuto das ciências sociais como ciências empíricas, ou mesmo ciências, tem sido objeto de discussão desde o século XX. Alguns filósofos e cientistas, notavelmente Karl Popper, afirmam que nenhuma hipótese, proposição ou teoria empírica podem ser considerada científica se nenhuma observação puder ser feita que a possa contradizer, insistindo numa falseabilidade estrita (ver positivismo).
Os críticos alegam que a economia não pode atingir sempre a falseabilidade popperiana, mas os economistas apontam os muitos exemplos de experimentos controlados que fazem exatamente isso, apesar de conduzidos em laboratório.
Enquanto a economia tem produzido teorias que se correlacionam com os comportamentos observados na sociedade, a economia não gera leis naturais ou constantes universais devido à sua dependência de argumentos não-físicos. Isso tem levado alguns críticos a argumentar que a economia não é uma ciência.
Em geral, os economistas respondem que, enquanto esse aspecto apresenta sérias dificuldades, eles de fato testam as suas hipóteses usando métodos estatísticos como a econometria usando dados gerados no mundo real.
O campo da economia experimental tem feito esforços para testar pelo menos algumas das predições de teorias econômicas em ambientes simulados em laboratório – um esforço que rendeu a Vernon Smith e Daniel Kahneman o Prêmio Nobel em Economia em 2002.
Apesar de que a maneira convencional de conectar um modelo econômico com o mundo é através da análise econométrica, a professora e economista Deirdre McCloskey, através da crítica McCloskey, cita muitos exemplos em que professores de econometria usaram os mesmos dados para tanto provar e negar a aplicabilidade das conclusões de um modelo. Ela argumenta que muito dos esforços dispendidos por economistas em equações analíticas é essencialmente esforço desperdiçado (posição seguida por economistas brasileiros como Pérsio Arida).Os econometristas respondem que essa é uma objeção a qualquer ciência, não apenas à economia. Críticos de McCloskey replicam dizendo que, entre outras coisas, ela ignora exemplos em que a análise econômica é conclusiva e que as suas afirmações são ilógicas.
Alguns economistas, como ganhador do Prêmio Nobel Friedrich Hayek, são da opinião que a tendência para a economia imitar os métodos e procedimentos das ciências físicas leva a resultados não-científicos, por se tratar da aplicação mecânica e não-crítica de hábitos de pensamento vindos de áreas sem as especificidades das ciências sociais. A área econômica também é conhecida por ser excessivamente abstrata e se fechar para o mundo real.
A economia já foi apelidada de "ciência sombria" ("The dismal science" no original em inglês), de forma humorística e até mesmo depreciativa. A expressão é atribuída ao historiador vitoriano Thomas Carlyle, no século XIX. Afirma-se que Carlyle apelidou a economia de "ciência sombria" como resposta aos escritos do reverendo Thomas Robert Malthus do final do século XVIII, que sinistramente previa a fome como resultado do crescimento projetado da população exceder o taxa de aumento da oferta de alimentos. No entanto, a expressão foi efetivamente usada por Carlyle no contexto de um debate com John Stuart Mill sobre a escravidão, no qual Carlyle argumentava a favor e Mill contra.
Também existe controvérsia acerca da relação entre a economia e a política.
Alguns economistas, como John Stuart Mill ou Leon Walras, defenderam que a produção de riqueza não deveria estar ligada à sua distribuição. A primeira está no campo da "economia aplicada" enquanto a segunda pertence à "economia social" e é em grande parte uma questão de poder e política.
Certos modelos usados por economistas são criticados, até por outros economistas, pela sua dependência de pressupostos irrealistas, não-observáveis ou não-verificáveis. Uma resposta a essas críticas é que os pressupostos irrealistas resultam de abstrações que simplificam detalhes pouco importantes, e que tais abstrações são necessárias em um mundo real complexo. Isso significa que os pressupostos simplificadores, ao invés de afetar o valor epistêmico da economia, são essenciais para a formação do conhecimento em economia. Os economistas são também criticados por ignorar o papel da dívida das sociedades. A classe é considerada fechada em relação ao mundo real, e de se achar acima da mesma. A profissão é tida também como uma religião.
Um estudo chamou essa explicação de "defesa abstracionista" e concluiu que essa defesa não invalida a crítica aos pressupostos irrealistas.
No entanto não existe um consenso sobre esta questão, e diferentes campos da economia chegaram a conclusões suportadas em evidências empíricas com diferentes graus intensidade.
Os conceitos que costumam ser considerados como "axiomas" são simplificações da realidade mas que se espera serem consistentes com a observação empírica.
Alguns exemplos crenças ou axioma compartilhados por muitos economistas do "mainstream" são:
A questão dos pressupostos é delicada. Por um lado eles permitem que os problemas sejam "tratáveis". Por outro não podem ser demasiado simplificados sob pena de não conseguir retratar eficazmente o comportamento dos agentes económicos.
A economia é um campo de estudo com várias escolas e correntes de pensamento. Como resultado, há uma distribuição significativa de opiniões, abordagens e teorias. Algumas dessas chegam a conclusões opostas ou, devido à diferenças nos pressupostos, se contradizem.
Alguns economistas, como John Stuart Mill ou Leon Walras, defenderam a ideia de que a produção de riqueza não deveria ser limitada à sua distribuição. A produção estaria mais no campo da "economia aplicada" enquanto a distribuição na "economia social" e seria em grande medida uma questão política.
éia
A economia "per se", como ciência social, não se baseia em atos políticos de qualquer governo ou outra organização política, no entanto, muitos políticos ou indivíduos em posições de mando que podem influenciar as vidas de outras pessoas são conhecidas por usarem arbitrariamente uma infinidade de conceitos da teoria econômica e retórica como veículos para legitimar agendas e sistemas de valor, e não limitam suas observações aos assuntos relevantes para as suas responsabilidades. A íntima relação de teoria e prática econômica com a política é um foco de disputas que pode nublar ou distorcer as ideias originais mais despretenciosas da economia, e é frequentemente confundida com agendas sociais específicas e sistemas de valor.
Questões como a independência do banco central, políticas do banco central e retórica nos discursos de presidentes do banco central sobre as premissas das políticas macroeconômicas (monetária e fiscal) dos Estados, são focos de dissenso e criticismo.
Por exemplo, é possível associar a promoção da democracia por parte dos EUA pela força no século XXI, o trabalho de Karl Marx no século XIX ou o embate entre capitalismo e comunismo durante a guerra fria como questões de economia. Apesar da economia não fazer quaisquer juízos de valor, essa pode ser uma das razões pelas quais a economia pode ser vista como não baseada na observação empírica e no teste de hipóteses. Como uma ciência social, a economia tenta se focar nas consequências e eficiências observáveis de diferentes sistemas econômicos sem necessariamente fazer nenhum juízo de valor a respeito de tais sistemas - por exemplo, ao examinar a economia de sistemas autoritários, igualitários, ou mesmo um sistema de castas sem fazer quaisquer julgamentos a respeito da moralidade de qualquer um deles.
A relação entre ética e economia é complexa. Muitos economistas consideram escolhas normativas e juízos de valor - como o que seria preciso ou necessário, ou o que seria melhor para a sociedade - questões pessoais ou políticas fora do âmbito da economia. Uma vez que um governo ou economia estabelece um conjunto de objetivos, a economia pode fornecer "insight" sobre a melhor forma de se atingi-los.
Outros enxergam a influência das ideias econômicas, como aquelas que permeiam o capitalismo moderno, promovendo um determinado sistema de valores com os quais eles podem ou não concordar. (Veja, por exemplo, consumismo e Dia do Compre Nada.) De acordo com alguns pensadores, uma teoria econômica também é, ou implica, uma teoria de raciocínio moral.
A premissa do consumo responsável é que o consumidor deve levar em consideração preocupações éticas e ambientais, além das tradicionais considerações econômicas e financeiras, quando tomar decisões de compra.
Por outro lado, a alocação racional dos recursos limitados em prol do bem e segurança públicos também é uma área da economia. Alguns tem apontado que não estudar as melhores formas de alocar recursos para metas como saúde e segurança, o meio ambiente, justiça, ou assistência a desastres seria uma forma de ignorância voluntária que resultaria em menos bem-estar ou mesmo em mais sofrimento. Nesse sentido, não seria ético ignorar o lado econômico de tais questões.
Alguns poderiam dizer que estruturas de mercado e outras formas de distribuição de bens escassos, sugeridos pela economia, afetam não apenas seus "desejos e vontades" mas também "necessidades" e "hábitos". Muito da chamada "escolha" econômica é considerada involuntária, certamente dada por condicionamento social porque as pessoas passaram a esperar uma certa qualidade de vida. Isso leva a uma das mais debatidas áreas na política econômica hoje, a saber, o efeito e eficácia das políticas de bem-estar. Os libertários enxergam isso como uma falha com respeito ao raciocínio econômico - eles argumentam que a redistribuição de riqueza é moral e economicamente errada. Já os socialistas vêem aí uma falha da economia em respeitar a sociedade, argumentando que as disparidades de renda não deveriam ter sido permitidas para começar. Essa controvérsia levou à economia do trabalho no séc XIX e na economia do bem-estar no século XX antes de serem incluídas na teoria do desenvolvimento humano.
O antigo nome da economia, "economia política", ainda é frequentemente usado em vez de "economia", especialmente por algumas escolas como a marxista. O uso dessa expressão normalmente sinaliza um desacordo fundamental com a terminologia ou paradigma da economia de mercado. A economia política traz explicitamente considerações políticas e sociais em sua análise e é, portanto, amplamente normativa.
A economia marxista geralmente nega o "trade-off" de tempo por dinheiro. No ponto de vista marxista, é o trabalho que define o valor das mercadorias. As relações de troca dependem de que haja trabalho prévio para a determinação de preços. Os meios de produção são portanto a base compreender a alocação de recursos entre as classes, já que é nesta esfera que a riqueza é produzida. A escassez de qualquer recurso físico em particular é subsidiário à questão central das relações de poder atrelada ao monopólio dos meios de produção

Eric Steven Raymond (4 de Dezembro de 1957 em Boston, Massachusetts), conhecido também como ESR, é um hacker e escritor americano. Depois da publicação em 1997 do seu livro "A Catedral e o Bazar", Raymond foi por alguns anos frequentemente citado como um porta-voz extra-oficial para o movimento open source. É quem mantém o "Jargon File", mais conhecido como "The Hacker's Dictionary" (O Dicionário dos Hackers).
Um ícone no movimento do Open Source e do software livre, é responsável pela famosa frase: ""Havendo olhos suficientes, todos os erros são óbvios". Que é o enunciado da Lei de Linus, em alusão ao criador do Linux, o finlandês Linus Torvalds.
Nascido em Boston, Massachusetts, em 1957, Raymond viveu na Venezuela quando criança, e em outros três continentes, antes de se fixar na Pensilvânia, em 1971. Seu envolvimento com a cultura hacker começou em 1976, e ele contribuiu pela primeira vez para um projeto de código aberto em 1982. Desde então, suas atividades de desenvolvimento de softwares de código aberto incluíram manter o cliente de e-mails fetchmail, contribuir de modos de edição para o editor Emacs, co-escrever porções da biblioteca GNU ncurses, e contribuir para as bibliotecas giflib/libungif, libpng e algumas das padrões do Python. Enquanto isso, ele escreveu alguns documentos HOWTO, incluindo vários do corpo do Projeto de Documentação do Linux.
Raymond cunhou o aforismo "Havendo olhos suficientes, todos os erros são óbvios"". Atribui os créditos da inspiração para esta citação a Linus Torvalds em seu livro A Catedral e o Bazar, de 1999.
Alguns dos projetos em quais ESR teve participação:

Engenharia é a aplicação do conhecimento científico, econômico, social e prático, com o intuito de inventar, desenhar, construir, manter e melhorar estruturas, máquinas, aparelhos, sistemas, materiais e processos. É também profissão em que se adquire e se aplicam os conhecimentos matemáticos e técnicos na criação, aperfeiçoamento e implementação de utilidades que realizem uma função ou objetivo.
Nos processos de criação, aperfeiçoamento e complementação, a engenharia conjuga os vários conhecimentos especializados no sentido de viabilizar as utilidades, tendo em conta a sociedade, a técnica, a economia e o meio ambiente.
A "engenharia" é uma área bastante abrangente que engloba uma série de ramos mais especializados, cada qual com uma ênfase mais específica em determinados campos de aplicação e em determinados tipos de tecnologia.
O engenheiro é o profissional que exerce a prática de engenharia.
Em muitos países, o exercício da profissão de engenheiro obriga, para além da habilitação com um curso superior de engenharia, a uma licença ou certificação profissional atribuída pelo estado, por uma associação profissional, ordem ou instituição de engenheiros ou por um outro tipo de órgão de regulamentação profissional. Conforme o país, aos profissionais devidamente certificados ou licenciados está reservado o uso exclusivo do título profissional de "engenheiro" ou estão reservados outros títulos formais como "engenheiro profissional", "engenheiro encartado", "engenheiro incorporado", "engenheiro diplomado" ou "Engenheiro Europeu".
Normalmente, a lei restringe a prática de determinados atos de engenharia aos profissionais certificados e habilitados para tal, ainda que a prática dos restantes não esteja sujeita a essa restrição.
Para além da certificação como engenheiro propriamente dito, em alguns países existe a certificação como técnico de engenharia ou engenheiro técnico, associada aos profissionais com uma habilitação correspondente a um curso superior de 1º ciclo na área da engenharia.
O conceito de engenharia existe desde a antiguidade, a partir do momento em que o ser humano desenvolveu invenções fundamentais como a roda, a polia e a alavanca. Cada uma destas invenções é consistente com a moderna definição de engenharia, explorando princípios básicos da mecânica para desenvolver ferramentas e objetos utilitários.
O termo "engenharia" em si tem uma etimologia muito mais recente, derivando da palavra "engenheiro", que apareceu na língua portuguesa no início do século XVI e que se referia a alguém que construía ou operava um engenho. Naquela época, o termo "engenho" referia-se apenas a uma máquina de guerra como uma catapulta ou uma torre de assalto. A palavra "engenho", em si, tem uma origem ainda mais antiga, vindo do latim "ingenium" que significa "gênio" ou seja uma qualidade natural, especialmente mental, portanto uma invenção inteligente.
Mais tarde, à medida que o projeto de estruturas civis como pontes e edifícios amadureceu como uma especialidade técnica autónoma, entrou no léxico o termo "engenharia civil" como forma de distinção entre a atividade de construção daqueles projetos não militares e a mais antiga especialidade da engenharia militar. Hoje em dia, os significados originais dos termos "engenharia" e "engenharia civil" estão já largamente obsoletos, mas ainda são usados como tal em alguns países ou dentro do contexto de algumas forças armadas.
O Farol de Alexandria, as Pirâmides do Egipto, os Jardins Suspensos da Babilónia, a Acrópole de Atenas, o Parténon, os antigos aquedutos romanos, a Via Ápia, o Coliseu de Roma, Teotihuacán e as cidades e pirâmides dos antigos Maias, Incas e Astecas, a Grande Muralha da China, entre muitas outras obras, mantêm-se como um testamento do engenho e habilidade dos antigos engenheiros militares e civis.
O primeiro engenheiro civil conhecido pelo nome foi Imhotep. Como um dos funcionários do faraó Djoser, Imhotep provavelmente projetou e supervisionou a construção da Pirâmide de Djoser, uma pirâmide de degraus em Saqqara, por volta de 2630 a.C.-2611 a.C.. Este poderá também ter sido o responsável pelo primeiro uso da coluna na arquitetura.
Os antigos gregos desenvolveram máquinas tanto no domínio civil como no militar. A Máquina de Anticítera (o primeiro computador mecânico conhecido) e as invenções mecânicas de Arquimedes são exemplos da primitiva engenharia mecânica. Estas invenções requereram um conhecimento sofisticado de engrenagens diferenciais e planetárias, dois princípios-chave na teoria das máquinas que ajudou a projetar as embraiagens empregues na Revolução Industrial e que ainda são amplamente utilizadas na atualidade, em diversos campos como a robótica e a engenharia automóvel.
Os exércitos chineses, gregos e romanos empregaram máquinas e invenções complexas como a artilharia que foi desenvolvida pelos gregos por volta do século IV a.C.. Estes desenvolveram a trirreme, a balista e a catapulta. Na Idade Média, foi desenvolvido o trabuco.
Nos séculos XV e XVI, a engenharia naval emerge em Portugal. Os novos tipos de navios então desenvolvidos, como a caravela, a nau redonda e o galeão, irão ser fundamentais nos grandes descobrimentos marítimos.
William Gilbert é considerado o primeiro engenheiro eletrotécnico, devido à publicação da obra "De Magnete" em 1600, o qual foi o criador do termo "eletricidade".
A primeira máquina a vapor foi construída em 1698 por Thomas Savery, que assim é considerado o primeiro engenheiro mecânico moderno. O desenvolvimento deste aparelho deu origem à Revolução Industrial nas décadas seguintes, permitindo o início da produção em massa.
Com a ascensão da engenharia como profissão, durante o século XVIII, o termo tornou-se mais estritamente empregue para designar as atividades para cujos fins eram aplicadas a matemática e a ciência. Além disso, além das engenharias militar e civil, também foram incorporadas na engenharia o que antes eram conhecidas como "artes mecânicas".
A engenharia elétrica pode traçar as suas origens às experiências de Alexandre Volta em 1800, às experiências de Michael Faraday, Georg Ohm e outros, bem como à invenção do motor elétrico em 1872. O trabalho de James Maxwell e de Heinrich Hertz no final do século XIX deu origem à eletrónica.
As invenções de Thomas Savery e de James Watt deram origem à moderna engenharia mecânica. O desenvolvimento de máquinas especializadas e de ferramentas para a sua manutenção durante a Revolução Industrial levaram ao crescimento acentuado da engenharia mecânica.
A engenharia química tal como a engenharia mecânica, desenvolveu-se no século XIX, durante a Revolução Industrial. A produção à escala industrial precisava de novos materiais e de novos processos. Por volta de 1880, a necessidade da produção em larga escala de químicos era tanta que foi criada uma nova indústria, dedicada ao desenvolvimento e fabricação em massa de produtos químicos em novas fábricas. A função do engenheiro químico era a de projetar essas novas fábricas e processos.
A engenharia aeronáutica lida com o projeto de aeronaves. Nos tempos modernos, começou-se também a designá-la como "engenharia aeroespacial", dando ênfase à expansão daquele campo da engenharia que passou também lidar com o projeto de veículos espaciais. As suas origens podem ser traçadas até aos pioneiros da aviação da viragem do século XIX para o século XX. Os conhecimentos primitivos de engenharia aeronáutica eram largamente empíricos, com alguns conceitos e perícias a serem importados de outros ramos da engenharia. A partir dos experimentos muito bem sucedidos realizados por Alberto Santos Dumont no inicio do Século XX, como o primeiro voo com balão dirigível com motor a gasolina realizado em 1901, o primeiro no mundo a descolar a bordo de um avião impulsionado por um motor a gasolina em 23 de outubro de 1906, voando cerca de 60 metros a uma altura de dois a três metros com o "Oiseau de Proie"' (francês para "ave de rapina"), no Campo de Bagatelle, em Paris e apenas alguns anos depois dos bem sucedidos voos dos irmãos Wright, a década de 1920 viu um desenvolvimento intensivo da engenharia aeronáutica, através do desenvolvimento de aviões militares da época da Primeira Guerra Mundial. Entretanto, as pesquisas, para fornecer bases científicas fundamentais, continuaram através da combinação da física teórica com experiências.
Durante a Segunda Guerra Mundial, inicia-se o desenvolvimento da engenharia de computação. A expansão radical da informática depois do final da guerra tornou tanto os engenheiros de computação como os engenheiros informáticos em alguns dos maiores grupos de profissionais da engenharia.
Tradicionalmente, a engenharia lidava apenas com objetos concretos e palpáveis. Modernamente, porém, esse cenário mudou. A engenharia lida agora também com entidades não-palpáveis, tais como custos, obrigações fiscais, aplicações informáticas e sistemas.
Na engenharia, os conhecimentos científicos, técnicos e empíricos são aplicados para exploração dos recursos naturais e para a concepção, construção e operação de utilidades.
Os engenheiros aplicam as ciências físicas e matemáticas na busca por soluções adequadas para problemas ou no aperfeiçoamento de soluções já existentes. Mais do que nunca, aos engenheiros é agora exigido o conhecimento das ciências relevantes para os seus projetos, o que resulta que eles tenham que realizar uma constante aprendizagem de novas matérias ao longo de todas as suas carreiras.
Se existirem opções múltiplas, os engenheiros pesam as diferentes escolhas de projeto com base nos seus méritos e escolhem a solução que melhor corresponda aos requisitos. A tarefa única e crucial do engenheiro é identificar, compreender e interpretar os constrangimentos de um projeto, de modo a produzir o resultado esperado. Normalmente, não basta construir um produto tecnicamente bem sucedido, sendo também necessário que ele responda a outros requisitos adicionais.
Os constrangimentos podem incluir as limitações em termos físicos, criativos, técnicos ou de recursos disponíveis, a flexibilidade para permitir modificações e adições futuras, além de fatores como os custos, a segurança, a atratividade comercial, a funcionalidade e a suportabilidade. Através da compreensão dos constrangimentos, os engenheiros obtêm as especificações para os limites dentro dos quais um objeto ou sistema viável pode ser produzido e operado.
Tipicamente, os engenheiros irão tentar prever o quão bem os seus projetos se irão comportar em relação às suas especificações, antes de ser iniciada a produção em larga escala. Para isso, irão empregar, entre outros: protótipos, maquetes, simulações, testes destrutivos, testes não destrutivos e testes de esforços. Testar assegura que o produto irá comportar-se de acordo com o esperado.
Como profissionais, os engenheiros levam a sério a sua responsabilidade em produzir projetos que se comportem conforme o esperado e que não causem males não intencionados ao grande público. Tipicamente, os engenheiros incluem uma margem de segurança nos seus projetos para reduzir o risco de falha inesperada. contudo, quanto maior a sua margem de segurança, menos eficiente se poderá tornar o projeto.
A "engenharia" também se ocupa do estado dos produtos falhados. A sua aplicação é muito importante a seguir a desastres como o colapso de pontes ou a queda de aviões, onde uma análise cuidadosa é necessária para descobrir as causas das falhas ocorridas. Este estudo poderá ajudar o projetista a avaliar o seu projeto com base em condições reais ocorridas no passado com projetos semelhantes.
Tal como nas restantes atividades científicas e tecnológicas, os computadores e os programas informáticos desempenham um papel cada vez mais importante na engenharia. Existem inúmeras aplicações assistidas por computador específicas para a engenharia. Os computadores podem ser usados para gerarem modelos de processos físicos fundamentais, que podem ser resolvidos através de métodos numéricos.
Umas das ferramentas mais utilizadas pelos engenheiros são as aplicações de desenho assistido por computador (CAD), que lhes permitem criar desenhos e esquemas em 2D e modelos em 3D. As aplicações CAD, juntamente com as aplicações de maquete digital (DMU) e de engenharia assistida por computador (CAE), incluindo as de análise de elementos finitos e de elementos analíticos permitem criar modelos de projetos que podem ser analisados sem a necessidade da construção de protótipos dispendiosos em termos de custo e de tempo.
Estas aplicações permitem que os produtos e componentes sejam verificados para detecção de falhas, avaliados em termos de montagem e ajustamento e estudados em termos de ergonomia. Também permitem a análise das caraterísticas dinâmicas dos sistemas como as tensões mecânicas, temperaturas, emissões eletromagnéticas, correntes elétricas, tensão elétrica, vazão e cinemática. O acesso e a distribuição de toda esta informação é geralmente organizado através do uso de aplicações de gestão de dados do produto (PDM).
Existem também uma série de ferramentas para suporte de tarefas específicas de engenharia, como as aplicações de fabricação assistida por computador (CAM) que geram instruções para as máquinas de controlo numérico computorizado (CNC), as de gestão de processos de fabrico (MPM) para a engenharia de produção, as de desenho de eletrónica assistido por computador (ECAD ou EDA) para desenho de esquemas de circuitos elétricos e de circuitos impressos para a engenharia eletrónica, as de manutenção, reparação e operações para a gestão da manutenção e as de arquitetura, engenharia e construção (AEC) para a engenharia civil.
Recentemente, o uso do computador no auxílio ao desenvolvimento de utilidades passou a ser coletivamente conhecido como gestão do ciclo de vida do produto.
A "engenharia" é uma ciência bastante abrangente que é muitas vezes subdividida em diferentes ramos ou especialidades. Cada uma destas especialidades preocupa-se com um determinado tipo de tecnologia ou com um determinado campo de aplicação. Apesar de inicialmente um engenheiro se formar normalmente numa especialidade específica, ao longo da sua carreira na maioria dos casos, irá tornar-se polivalente, penetrando com o seu trabalho em diferentes áreas da engenharia. 
Historicamente, existiam a engenharia militar e a engenharia naval. A partir da engenharia militar começou por desenvolver-se o ramo da engenharia civil. Posteriormente, a engenharia civil (em sentido lato) subdividiu-se em diversas especialidades tradicionais:
Paralelamente, algumas das ciências agrárias aproximaram-se da engenharia e acabaram por nela se integrar, originando especialidades como:
Com o surgimento das engenharias relacionadas com a agricultura, surge a dicotomia entre estas e a engenharia industrial que agrupa as especialidades tradicionais da engenharia civil, mecânica, elétrica, química e de minas. A engenharia industrial irá contudo deixar de ser um agrupamento de especialidades e tornar-se ela própria numa especialidade da engenharia, vocacionada para o aperfeiçoamento de processos e da gestão industrial através da integração dos fatores tecnológicos, humanos e económicos.
Posteriormente, com o rápido avanço da tecnologia, foram-se desenvolvendo e ganhando proeminência diversos novos campos da engenharia, como os de manufatura, materiais, produção, aeronáutica, computação, informática, eletromecânica, mecatrónica, robótica, nanotecnologia, nuclear, molecular, ambiente, geológica, alimentar e biomédica. Alguns dos novos campos da engenharia resultam da subdivisão de especialidades tradicionais ou, pelo contrário, da combinação de diferentes especialidades.
O prestígio da engenharia fez com que áreas fora dela também a ela se quisessem associar. Surgiram assim campos exteriores ao que convencionalmente é considerado engenharia, mas também referidos como tal, sendo alguns exemplos a "engenharia jurídica", a "engenharia financeira", a "engenharia comercial" e a "engenharia social".
Quando uma nova área da engenharia emerge, normalmente é inicialmente definida como uma sub-especialidade ou como uma derivação de especialidades já existentes. Frequentemente, existe um período de transição entre o aparecimento do novo campo e o crescimento do mesmo até ter uma dimensão ou proeminência suficientes para poder ser classificado como nova especialidade da engenharia. Um indicador chave para essa emergência é o número de cursos criados nessa especialidade nas principais instituições de ensino superior.
Existe uma considerável sobreposição de matérias comuns a todas as especialidades da engenharia. Quase todas elas, por exemplo, fazem grande aplicação da matemática, da física e da química.
Existe uma sobreposição entre a prática da ciência e a da engenharia. Na engenharia aplica-se a ciência. Ambas as atividades baseiam-se na observação atenta dos materiais e dos fenómenos. Ambas usam a matemática e critérios de classificação para analisarem e comunicarem as observações.
Espera-se que os cientistas interpretem as suas observações e façam recomendações versadas para ações práticas baseadas nessas interpretações. Os cientistas podem também desempenhar tarefas totalmente de engenharia como a do desenho de aparelhos experimentais ou a da construção de protótipos. Reciprocamente, no processo de desenvolvimento de tecnologia, os engenheiros ocasionalmente apanham-se a explorar novos fenómenos, transformando-se assim, momentaneamente, em cientistas.
No entanto, a pesquisa em engenharia tem um carácter diferente da pesquisa científica. Em primeiro lugar, frequentemente lida com áreas em que a física e a química básicas são bem conhecidas, mas os problemas em si são demasiado complexos para serem resolvidos de uma forma exata. Exemplos, são o uso de aproximações numéricas nas equações de Navier-Stokes para a descrição do fluxo aerodinâmico sobre uma aeronave ou o uso da regra de Miner para cálculo dos danos provocados pela fadiga do material. Em segundo lugar, a pesquisa em engenharia emprega muitos métodos semiempíricos que são estranhos à pesquisa científica pura, sendo um exemplo o do método da variação de parâmetros.
Essencialmente, pode dizer-se que os cientistas tentam entender a natureza enquanto que os engenheiros tentam fazer coisas que não existem na natureza.
O estudo do corpo humano, em algumas das suas formas e propósitos, constitui uma importante ligação entre a medicina e alguns campos da engenharia. A medicina tem como objetivo sustentar, aumentar e até substituir funções do corpo humano, se necessário, através do uso da tecnologia.
A moderna medicina pode substituir várias funções do corpo através do uso de próteses e órgãos artificiais e pode alterar significativamente várias dessas funções através de dispositivos como implantes cerebrais e marca-passos. A biónica é um campo específico que se dedica ao estudo dos implantes sintéticos em sistemas naturais.
Reciprocamente, alguns campos da engenharia olham para o corpo humano como uma máquina biológica que merece ser estudada e dedicam-se a melhorar muitas das suas funções através da substituição da biologia pela tecnologia. Isto levou a campos como a inteligência artificial, as redes neurais, a lógica difusa e a robótica. Existem também interações substanciais entre a engenharia e a medicina.
Ambos os campos fornecem soluções para problemas do mundo real. Isto, frequentemente, requer avançar mesmo antes de um fenómeno ser completamente compreendido em termos científicos o que faz com que a experimentação e o conhecimento empírico sejam uma parte integral tanto da medicina como da engenharia.
A medicina ocupa-se do estudo do funcionamento do corpo humano o qual, como uma máquina biológica, tem muitas funções que podem ser modeladas através do uso de métodos da engenharia. O coração, por exemplo, funciona como uma bomba hidráulica, o esqueleto funciona como uma estrutura e o cérebro produz sinais elétricos. Estas semelhanças, bem como a crescente importância da aplicação dos princípios da engenharia à medicina levou ao desenvolvimento da engenharia biomédica, que usa conceitos de ambas.
Novos ramos emergentes da ciência, como a biologia de sistemas, vêm adaptando ferramentas analíticas tradicionalmente usadas na engenharia, como a modelação de sistemas e a análise computacional, para a descrição de sistemas biológicos.
A moderna engenharia deriva em parte do que, antigamente, eram consideradas as artes mecânicas. Ainda se mantêm muitas ligações entre as modernas artes e a engenharia, que são diretas em alguns campos como os da arquitetura, da arquitetura paisagista e do "design" industrial, ao ponto destas disciplinas serem parte integrantes dos currículos de alguns cursos superiores de engenharia.
De entre as figuras históricas famosas, Leonardo da Vinci é um bem conhecido artista e engenheiro do Renascimento, constituindo um exemplo da ligação entre as artes e a engenharia.
A ciência política, pegou no termo "engenharia" e empregou-o no âmbito do estudo de vários assuntos como a engenharia social e a engenharia política, que lidam com a formação das estrutura política e social usando uma metodologia da engenharia associada aos princípios da ciência política.
Até ao século XX, na maioria dos países, o ensino da engenharia era realizado em escolas superiores especializadas não universitárias, uma vez que tradicionalmente o ensino das universidades se concentrava em áreas como as humanidades, a medicina e o direito. Hoje em dia, no entanto, além de continuar a ser realizado em escolas especiais, o ensino da engenharia é já realizado na maioria das grandes universidades.
Na maioria dos países, os cursos que dão acesso à profissão de engenheiro têm uma duração mínima de quatro ou cinco anos. Nos países cujos sistemas de ensinos seguem os moldes do Processo de Bolonha, a formação de um engenheiro implica a realização do 2º ciclo do ensino superior, incluindo normalmente um total de cinco anos de estudos e a realização de uma dissertação, tese ou estágio final. Em alguns destes países, a conclusão do 1º ciclo de um curso superior de engenharia poderá dar acesso à profissão de engenheiro técnico ou de técnico de engenharia.
É difícil determinar quais eram as mais antigas escolas de engenharia, uma vez que o ensino de matérias que hoje fazem parte da engenharia vem já desde a antiguidade. No entanto, segundo os padrões modernos podem apontar-se as seguintes escolas precursoras deste ensino:
Em 2017, a consultoria britânica "Quacquarelli Symonds" (QS) publicou recentemente a atualização de 2017 do seu ranking de cursos de Engenharia Civil  com o MIT ficando em primeiro lugar.
O ensino da engenharia no Brasil tem origem em 1699, altura em que o Rei D. Pedro II de Portugal ordena a criação aulas de fortificação em vários pontos do Ultramar Português. O objetivo era formar técnicos de engenharia militar nos territórios ultramarinos, de modo a que estes estivessem menos dependentes de engenheiros vindos do Reino. Em território brasileiro, seriam criadas destas aulas no Rio de Janeiro, em Salvador da Baía e no Recife.
No entanto, a mais antiga escola a ministrar cursos de engenharia segundo os moldes modernos foi a Real Academia de Artilharia, Fortificação e Desenho, fundada em 1792 no Rio de Janeiro pela rainha D. Maria I de Portugal, segundo o modelo da academia com o nome semelhante existente em Lisboa. A atual Escola Politécnica do Rio de Janeiro e o Instituto Militar de Engenharia consideram-se sucessores daquela academia, razão pela qual este último reivindica ser a mais antiga escola de engenharia das Américas.
Os profissionais de engenharia e de áreas correlatas são regulamentados pelo Conselho Federal de Engenharia e Agronomia e fiscalizados pelos conselhos regionais.
Há um crescente déficit de engenheiros no Brasil devido, em grande parte, ao alto índice de evasão dos estudantes da graduação na área. A Federação Nacional dos Engenheiros estima que seriam necessários ao menos 60 mil novos engenheiros formados por ano em um “cenário de expansão econômica”. Todavia, em 2011, esse número foi de apenas 42,8 mil segundo Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira – Inep.
Em 2017, a consultoria britânica "Quacquarelli Symonds" (QS) publicou recentemente a atualização de 2017 do seu ranking de cursos de Engenharia Civil  com a USP ficando em primeiro lugar no Brasil. 
Em Portugal, o ensino do que é hoje a engenharia remonta à formação em artes mecânicas e em ciências físicas e matemáticas, realizadas desde a Idade Média. Destaca-se o ensino da construção naval, já com metodologias técnicas e científicas avançadas, que leva ao desenvolvimento de novos tipos de navios, permitindo as grandes explorações marítimas portuguesas.
O ensino da moderna engenharia começou a desenvolver-se na primeira metade do século XVII, com a necessidade de engenheiros militares em virtude da Guerra da Restauração. Para a formação dos mesmos, em 1647, o Rei D. João IV funda a Aula de Fortificação e Arquitetura Militar em Lisboa. Em 1699, o Rei D. Pedro II ordena a criação de aulas de fortificação em vários locais do Ultramar, como Angola e Brasil. Em 1707, a Aula de Fortificação e Arquitetura Militar é transformada na Academia Militar da Corte, sendo também criadas academias militares provinciais, a primeira das quais em Viana do Minho e, posteriormente, também em Elvas e Almeida. Em 1779, aquelas academias são extintas, ao mesmo tempo que é criada a Academia Real de Marinha, cujos estatutos prevêm a existência de uma escola de engenharia e fortificação, a qual seria frequentada pelos candidatos a engenheiros militares, depois da frequência do Curso Matemático dos Oficiais Engenheiros realizado na Academia de Marinha.
A referida escola de engenharia e fortificação só virá a ser criada pela Rainha D. Maria I, a 2 de janeiro de 1790, na forma da Academia Real de Fortificação, Artilharia e Desenho (ARFAD). Esta é considerada a primeira escola moderna de engenharia portuguesa e uma das primeiras do mundo. Na ARFAD era realizado um curso militar, que para os candidatos a oficiais engenheiros tinha a duração de quatro anos, incluindo as cadeiras de fortificação regular, de fortificação irregular, de arquitetura civil e de hidráulica, além de uma aula de desenho. A admissão no curso de oficiais engenheiros implicava a habilitação com os dois primeiros anos do curso matemático da Academia Real da Marinha ou, em alternativa, a habilitação com um curso preparatório na Faculdade de Matemática da Universidade de Coimbra.
Durante o século XIX, o ensino superior de engenharia irá desenvolver-se com a criação de diversas escolas militares e civis. Em 1837, são criadas a Escola Politécnica de Lisboa e a Escola do Exército - por remodelação, respetivamente da Academia Real da Marinha e da ARFAD - mantendo-se o sistema da primeira ministrar os preparatórios científicos dos cursos de engenharia a serem realizados na segunda. Além do curso de engenharia militar, a Escola do Exército passa também a ministrar o curso de engenharia civil. Em 1837, é também criada a Academia Politécnica do Porto, com os cursos completos de engenheiros civis nas especialidades de minas, de pontes e estradas e de construtores navais, além dos preparatórios para acesso à Escola do Exército. Em 1896, o Instituto Industrial e Comercial de Lisboa passa a ministrar um curso superior industrial, diplomando engenheiros industriais.
No século XX, o ensino da engenharia passa pela primeira vez a ser realizado na universidade, quando a Academia Politécnica do Porto é integrada na nova Universidade do Porto, criada em 1911, com os seus cursos de engenharia a estarem na génese da atual Faculdade de Engenharia daquela Universidade. Ao mesmo tempo, o Instituto Industrial e Comercial de Lisboa é desdobrado, com o seu ensino de engenharia a dar origem ao Instituto Superior Técnico. Entretanto, na sequência da reforma do ensino superior agrícola, o antigo curso de agronomia dá origem aos cursos de engenheiro agrónomo e de engenheiro silvicultor do Instituto Superior de Agronomia.
Também se desenvolve o ensino médio técnico industrial, cujos diplomados passam a ser considerados engenheiros auxiliares em 1918 e agentes técnicos de engenharia em 1926. Os institutos industriais são transformados em estabelecimentos de ensino superior em 1974, passando a ministrar cursos de bacharelato, cujos diplomados passam a ser engenheiros técnicos.
Atualmente, o ensino da engenharia é realizado em universidades e institutos politécnicos, tanto públicos como privados. São oferecidas várias centenas de cursos de engenharia de 1º e de 2º ciclo. No entanto, apenas uma pequena percentagem destes está acreditada, pela Ordem dos Engenheiros ou pela Ordem dos Engenheiros Técnicos, dando aos seus diplomados um acesso automático às profissões, respetivamente, de engenheiro e de engenheiro técnico.

Engenharia química é o ramo da engenharia responsável por projetar, construir e operar plantas químicas industriais. É também conhecida como engenharia universal por ser um ramo da engenharia que combina conhecimentos de química, biologia, física, computação e matemática para projetar, construir, e operar plantas químicas de matérias-primas em produtos finais através de processos químicos, biológicos ou físicos, chamados de operações unitárias.
Numa definição mais formal, dada pelo "American Institute of Chemical Engineers" (AIChe): “Engenharia química é a área/profissão que dedica-se à concepção, desenvolvimento, dimensionamento, melhoramento e aplicação dos Processos e dos seus Produtos. Neste âmbito inclui-se a análise econômica, dimensionamento, construção, operação, controle e gestão das Unidades Industriais que concretizam esses Processos, assim como a investigação e formação nesses domínios”.
Embora a engenharia química tenha sido concebida inicialmente na Inglaterra, sofreu seu desenvolvimento principal nos Estados Unidos, impelida primeiramente pelo petróleo e indústrias químicas pesadas, e depois pela indústria petroquímica, com a produção de plásticos, borracha sintética e fibras sintéticas a partir do petróleo e do gás-natural. No início do século passado, a engenharia química adaptou para grande escala os processos físicos de separação tais como destilação, absorção e extração, que ja eram feitos em laboratorios , os quais foram combinados os princípios de transferência de massa, fluidodinâmica e transferência de calor com a finalidade de projetar equipamentos.
Os projetos de engenharia química são baseados em três leis fundamentais: conservação de massa, conservação de energia e conservação de quantidade de movimento. A transferência de massa e a transferência de calor entre os processos são determinados através da aplicação das leis fundamentais da Física. Na aplicação de tais leis os engenheiros químicos utilizam os princípios da termodinâmica, cinética química e fenômenos de transporte.
A tarefa complexa de dimensionamento e análise de equipamentos da engenharia química pode ser auxiliada pela simulação de processos. Os simuladores (ASCEND, Aspen Plus, CFX, Design II, Dymola, EMSO, Hysys, Petro-SIM, Pro II, SysCAD, DWSim, dentre outros) resolvem os balanços de massa e energia e são normalmente acompanhados de uma biblioteca de equipamentos que representam as mais diversas operações unitárias da engenharia química. Simulação é apenas mais uma ferramenta que o engenheiro químico pode lançar mão. Porém o domínio dos conceitos básicos são insubstituíveis.
O Engenheiro Químico deve ser um profissional apto a aperfeiçoar e elaborar novos métodos para fabricação de produtos químicos e outros produtos sujeitos a tratamento químico, projetar e controlar a construção, a montagem e o funcionamento de instalação e fábricas onde se realiza o preparo ou o tratamento químico, realizar investigações com o objetivo de verificar as diferentes etapas operacionais, as possibilidades de produção para fins comerciais e a maneira pela qual se podem reduzir os custos de produção e conseguir um melhor controle de qualidade, fiscalizar a montagem de instalações novas ou modificações de instalações já existentes, e inspecionar e coordenar atividades dos trabalhadores encarregados dos equipamentos e sistemas químicos.
Algumas das características de formação profissional são:

O período clássico é o período da música erudita ocidental entre a segunda metade do e o início do , caracterizada pela claridade, simetria e equilíbrio. Os compositores mais conhecidos do período são Joseph Haydn (1732-1809), Wolfgang Amadeus Mozart (1756-1791) e Ludwig van Beethoven (1770-1827), embora este último, mostrava características do romantismo desde sua Terceira Sinfonia.
Na cultura ocidental, a segunda metade do século XVIII coincidiu com a última parte do período do iluminismo. Este movimento, humanitário e secular por natureza, enfatizava a razão, a lógica e o conhecimento. Aqueles que se baseavam na religião, na superstição e no poder supremo para manterem as posições de poder, viram a sua autoridade questionada e eventualmente reduzida. A crença nos direitos humanos e na irmandade sobrepôs-se ao direito divino dos reis, até então considerado inegável. Ambas as revoluções americana e francesa foram combatidas durante esta metade do século. Considerando este período como um grande ponto de reviravolta, os filósofos e escritores promoveram a razão em detrimento do costume ou da tradição como o melhor guia da conduta humana. Uma mudança paralela ocorreu na música ocidental durante a segunda metade do século XVIII. Denominado normalmente "período clássico", este período musical era caracterizado pela objectividade (controlo, brilho e requinte), claridade, periodicidade (fraseologia regular) e equilíbrio.
Na história da música ocidental, o estilo que se desenvolveu durante os anos precedentes (1720/30 - 1770) é conhecido por "pré-clássico" ou menos pejorativo, o estilo de "meados do século". O gosto musical alterou-se profundamente como aconteceu com as artes visuais. Tal como estas últimas que revelaram uma preferência pelo equilíbrio e pela claridade da estrutura, também estas características tornaram-se pontos fulcrais para os compositores. No início, a composição musical passou de um estilo ornado do período Barroco para um estilo popular de extrema simplicidade. Os compositores deste período criaram obras que transpareciam claridade e acessibilidade acima de tudo; na verdade, reagiam contra o denso estilo polifónico do último período barroco. Estas características encontram-se nas sinfonias de compositores como Giovanni Battista Sammartini (1700/01-1775) e Johann Stamitz (1717-1757). Estes traços de claridade e simplicidade, juntamente com uma elaboração sistemática de ideias, uma aproximação universal à expressão musical e uma preocupação com o equilíbrio entre estrutura e expressão, formam a base do estilo clássico.
Embora muitos compositores tenham vivido e composto durante o período clássico, as três maiores figuras são Franz Joseph Haydn (1732-1809), Wolfgang Amadeus Mozart (1756-1791) e Ludwig van Beethoven (1770-1827). Cada um contribuiu significativamente para a sinfonia, a sonata para piano, a música de câmara- o quarteto de cordas em particular - e para a música de igreja. Todos utilizaram a forma sonata, que constitui o cerne do período clássico. A estrutura da sonata clássica, dependendo primeiro e principalmente do movimento harmónico, foi a forma predominante numa vasta série de primeiros movimentos de sinfonias, sonatas e obras de câmara. Foi também utilizada de outras formas, assim como em movimentos lentos e conclusivos dos géneros mencionados, em movimentos de grande magnitude, aberturas e em algumas partes de óperas. Neste último campo, Haydn e Mozart escreveram obras que foram bem recebidas pela audiência de então; contudo, só Mozart foi incluído no actual repertório lírico.
Os historiadores teriam inserido facilmente Haydn e Mozart no período clássico. A vida de ambos encaixa-se nitidamente no período em questão; além disso, neles encontra-se uma exploração preliminar do estilo dos meados do século, que depois é convertido num estilo mais pessoal e totalmente desenvolvido, trazendo consigo os traços esperados de um compositor clássico. Beethoven é mais problemático porque a sua música abrange os períodos clássico e romântico. As suas primeiras obras (até cerca de 1802) inserem-se no estilo do período em questão. As últimas obras, cheias de drama, tensão, exploração harmónica e estrutural são melhor discutidas dentro do contexto do século XIX.
Esta é uma linha do tempo com os principais e mais influentes compositores clássicos, separados por período e estética musical.
Nota: Algumas datas são aproximadas.

O Esperanto é a língua artificial mais falada no mundo (Esperantujo, 120 países). Ao contrário da maioria das outras línguas planejadas, o esperanto já saiu dos níveis de projeto (publicação de instruções) e semilíngua (uso em algumas poucas esferas da vida social). 
Seu iniciador, o médico judeu Ludwik Lejzer Zamenhof, publicou a versão inicial do idioma em 1887 com a intenção de criar uma língua de mais fácil aprendizagem e que servisse como língua franca internacional para toda a população mundial (e não, como muitos supõem, para substituir todas as línguas existentes).
O esperanto é empregado em viagens, correspondência, intercâmbio cultural, convenções, literatura, ensino de línguas, televisão e transmissões de rádio. Alguns sistemas estatais de educação oferecem cursos opcionais de esperanto, e há evidências de que auxilia na aprendizagem dos demais idiomas.
Apesar da facilidade gramatical, o Esperanto enfrenta dificuldade de ser adotado como língua auxiliar universal porque as pessoas, em geral, preferem línguas naturais, adotadas pela sociedade de maneira espontânea e não programada, a línguas planejadas.
"Esperanto" é formado pela junção do radical "esper" (em Esperanto, com origem no latim "sperare", "esperar"), da desinência "ant" (própria do particípio presente) e da desinência "o" (dos substantivos). Significa, portanto, "o que espera", "o que tem esperança".
"esper-": radical do verbo, em Esperanto, "esperi" (ter esperança)
"-ant-": sufixo do particípio ativo presente
"-o": terminação para substantivos
Na língua portuguesa, também é possível encontrar a forma do partícipio ativo em substantivos:
Ludwik Lejzer Zamenhof vivia em Białystok (atualmente na Polônia, na época Império Russo). Em Białystok, moravam muitos povos e falavam-se muitas línguas, o que dificultava a compreensão, mesmo nas mais cotidianas situações, o que o motivou a criar uma língua auxiliar neutra, a fim de solucionar o problema.
Durante a adolescência, criou a primeira versão da "lingwe universala", uma espécie de esperanto arcaico. O seu pai, entretanto, fê-lo prometer deixar de trabalhar no seu idioma para se dedicar aos estudos. Zamenhof então foi para Moscou estudar medicina. Em uma de suas visitas à terra natal, descobriu que seu pai queimara todos os manuscritos do seu idioma.
Zamenhof pôs-se então a reescrever tudo, adicionando melhorias e fazendo a língua evoluir.
O primeiro livro sobre o esperanto foi lançado em 26 de julho de 1887, em russo, contendo as 16 regras gramaticais, a pronúncia, alguns exercícios e um pequeno vocabulário. Logo depois, mais edições do "Unua Libro" foram lançadas em alemão, polaco e francês. O número de falantes cresceu rapidamente nas primeiras décadas, primordialmente no Império Russo e na Europa Oriental, depois na Europa Ocidental, nas Américas, na China e no Japão. Muitos desses primeiros falantes vinham de outro idioma planificado: volapük. As primeiras revistas e obras originais em esperanto começaram a ser publicadas.
Em 1905, aconteceu o primeiro Congresso Universal de Esperanto, em Bolonha-sobre-o-Mar, na França, juntando quase mil pessoas, de diversos povos. Em 1906, foi fundado, no Brasil, o primeiro grupo esperantista: o Suda Stelaro, em Campinas.
Todo o movimento esperantista avançava a passos largos e seguros, mas, com o advento das duas guerras mundiais, o movimento teve um recuo: as tropas comandadas por Hitler perseguiam e matavam os esperantistas na Alemanha e nos países dominados por esta; as tropas de Stalin faziam o mesmo na Rússia; a família de Zamenhof foi dizimada; no Japão e na China, a perseguição ao esperanto também ganhou proporções assustadoras.
Após a segunda guerra mundial, o esperanto reergueu-se. Em 1954, a Organização das Nações Unidas para a Educação, a Ciência e a Cultura passou a reconhecer formalmente o valor do esperanto para a educação, a ciência e a cultura, e, em 1985, a mesma Organização das Nações Unidas para a Educação, a Ciência e a Cultura recomendou, aos países-membros, a difusão do esperanto.
Após 1995, com a popularização e disseminação da internet, o movimento esperantista ganhou uma nova força propulsora. Uma evidência do maior interesse contemporâneo pelo esperanto é o considerável número de artigos na : mais de , em dezembro de 2013, com índice de profundidade 18 — número maior que o de muitas línguas étnicas.
O esperanto é uma língua aglutinante, sem gêneros gramaticais para entidades assexuadas, sem conjugação de verbos variáveis por pessoa ou número e com três modos — indicativo, imperativo e subjuntivo, além das formas nominais do verbo e seis particípios; tem apenas dois casos morfológicos: o acusativo e o nominativo.
Como uma língua construída, o esperanto não é relacionado genealogicamente a nenhuma língua étnica; pode ser descrito como uma língua de léxico predominantemente românico e de morfologia aglutinante. A fonologia, a gramática, o vocabulário e a semântica são baseados em línguas indo-europeias ocidentais. Os fonemas são essencialmente eslavos, assim como muito da semântica, enquanto o vocabulário é derivado primordialmente de línguas românicas, com uma menor contribuição de línguas germânicas e algumas palavras de várias outras línguas (o dicionário etimológico de esperanto "Konciza Etimologia Vortaro", de André Cherpillod, faz referência a 110 línguas).
A pragmática e outros aspectos da língua não descritos especificamente nos documentos originais de Zamenhof foram influenciados pelas línguas nativas dos primeiros falantes, principalmente russo, polonês, alemão e francês. A relação entre grafemas e fonemas é biunívoca (uma letra para cada som e um som para cada letra) e a morfologia é extremamente regular e fácil de aprender.
Tipologicamente, a ordem sintática padrão do esperanto é sujeito-verbo-objeto e adjetivo-substantivo. Novas palavras podem ser formadas a partir de processos de construção com morfemas já existentes na língua, ou podem ser introduzidas como neologismos.
O esperanto tem cinco vogais e 23 consoantes, das quais duas são semivogais. Não há tons. A sílaba tônica é sempre a penúltima (paroxítona), a não ser que a palavra tenha apenas uma vogal ou que a vogal final tenha sido omitida (situação em que é tónica a última sílaba; neste caso, é graficamente substituída por um apóstrofo: "kastelo" = "kastel"’) - recurso estilístico para a poesia.
A gramática segue poucas regras simples, entre elas as chamadas 16 regras do esperanto, sendo porém necessário algum estudo para uma aprendizagem satisfatória.
As palavras são formadas pela junção regular de radicais (prefixos, sufixos e outros), de modo que "novas" palavras criadas "ad hoc" são compreendidas trivialmente através da sua análise morfológica (inconsciente, no caso de falantes fluentes).
As diferentes classes gramaticais são marcadas por desinências próprias: substantivos recebem a desinência "-o", adjetivos recebem a desinência "-a", advérbios derivados recebem a desinência "-e" e todos os verbos recebem uma de seis desinências de tempos e modos verbais.
A pluralidade é marcada nos substantivos e adjetivos concordantes pela desinência "j", e o caso acusativo é marcado pela desinência "n", cuja ausência indica o nominativo. Assim, "bela birdo" significa "bela ave", "belaj birdoj", "belas aves", e "belajn birdojn", como em "mi vidas belajn birdojn" ("eu vejo belas aves"), "belas aves" complementando diretamente uma ação (nesse caso, sendo vistas).
As seis inflexões são três tempos e três modos verbais. O tempo presente é marcado por "as", o futuro por "os", e o passado por "is"; o modo infinitivo é marcado por "i", o condicional por "us", e o volitivo (imperativo + conjuntivo) por "u". Assim: "mi vidas", "vejo"; "mi vidos", "verei"; "mi vidis", "vi"; "vidi", "ver"; "mi vidus", "eu veria"; "ni vidu", "vejamos". As desinências não variam de acordo com a pessoa.
Além dessas formas, o verbo pode se apresentar na forma de particípio. São os particípios do esperanto:
Terminados em -"a", os particípios são usados com o verbo esti (ser/estar) para a formação de tempos compostos. A desinência -"a" pode também designar um adjetivo do particípio. Trocando-se o -"a" por -"o", constrói-se um substantivo do particípio, e por -"e", um advérbio do particípio.
O vocabulário original do esperanto foi definido em "Lingvo internacia", publicado por Zamenhof em 1887. Trata-se de uma compilação de 900 radicais, passíveis de expansão para dezenas de milhares de palavras com prefixos, sufixos e composição. Em 1894, Zamenhof publicou o primeiro dicionário de esperanto, "Universala Vortaro", com uma maior quantidade de radicais. As próprias regras da língua permitem a introdução de novos radicais de acordo com a necessidade, recomendando apenas que isso seja feito a partir das formas mais internacionais.
Desde então, muitas palavras têm sido "emprestadas", basicamente mas não apenas de línguas da Europa ocidental. Nem todas as novas palavras propostas entram em uso generalizado, mas muitas o fazem, especialmente termos técnicos e científicos. Termos para uso cotidiano, por sua vez, geralmente são feitos a partir de outros radicais — por exemplo, "komputilo" (computador) a partir de "komputi" (computar) com o uso do sufixo "il" (para indicar ferramentas). Há frequentes debates entre esperantófonos sobre a justificabilidade da introdução de uma palavra em particular e sobre as possibilidades de alcançar o sentido pretendido através da construção de palavras com elementos já existentes.
O esperanto é escrito através de uma versão modificada do alfabeto latino, ao qual foram incluídas seis letras com sinais diacríticos: ĉ, ĝ, ĥ, ĵ, ŝ e ŭ. A língua não inclui as letras q, w, x e y, que podem porém ser encontradas em textos no seio de palavras não-assimiladas oriundas de outras línguas.
O alfabeto contém 28 letras:
a b c ĉ d e f g ĝ h ĥ i j ĵ k l m n o p r s ŝ t u ŭ v z
Todas as letras são pronunciadas como seus equivalentes minúsculos no Alfabeto Fonético Internacional, à exceção das seguintes:
A impossibilidade de se escrever as letras com sinais diacríticos em certos meios fez com que se adotassem convenções substitutivas. Zamenhof, ainda nos primeiros anos da língua, recomendou o uso de "h" após as letras "c", "g", "h", "j" e "s" para formar "ĉ", "ĝ", "ĥ", "ĵ" e "ŝ". Uma convenção semelhante, mas com o "x", usando-o também para o "ŭ" ("cx" = "ĉ", "ux" = "ŭ", etc.), foi criada originalmente para utilização em telegrafia, evitando situações de ambiguidade entre o "h" ortográfico e este "h" substituto de diacrítico; muito usado recentemente, principalmente em meio eletrônico, com a relativa popularização da internet.
Em setembro de 2006, a Seção de Pronúncia da Academia de esperanto propôs uma resolução sobre o uso de sistemas diferentes de escrita sob circunstâncias e necessidades especiais: a "substituição [das letras acentuadas por outros signos ou combinação de signos], quando for apenas um meio técnico que não objetive reformas da ortografia do esperanto, e quando ele não causar confusão alguma, não deve ser visto como contrária ao Fundamento". Assim, o uso do esperanto em código Morse, braile, taquigrafia e com a letra x em substituição aos sinais diacríticos é considerado correto por esta Academia, sob circunstâncias específicas.
Muitos esperantófonos tomaram a iniciativa de aprender esperanto pelo chamado "lingva problemo" (literalmente, problema linguístico). Uma das maiores faces desse problema é o chamado imperialismo cultural, que encerra, em si, o favorecimento a poucos grupos linguísticos, e a pouca praticidade da estrutura vigente de comunicação entre sujeitos sociais de línguas diferentes. Vários estudiosos têm se debruçado sobre esses aspectos. Izabel Cristina Oliveira Santiago levanta várias ocasiões históricas em que o custo de traduções alcança níveis questionáveis: "Nova Délhi, 1968. A Conferência da Organização das Nações Unidas sobre Comércio e Desenvolvimento custou mais de 2 milhões de dólares dos Estados Unidos, sendo que mais da metade disso foi gasto com o uso de apenas quatro línguas — tidas como predominantes. [...] só em 1976, por exemplo, em vez de serem investidos na alimentação das multidões de famintos, 700 mil dólares dos Estados Unidos foram gastos para traduzir, em seis línguas, os relatórios sobre a fome mundial." O psicólogo e ex-tradutor das Organização das Nações Unidas, Claude Piron (Bélgica, 1931 - 22 de janeiro de 2008), dedicou-se à temática, abordando-a sob um ponto de vista psicológico a partir de vastíssimo material bibliográfico e documental, tratando a insistência no atual modelo de comunicação internacional como uma neurose.
Esperantófonos são mais numerosos na Europa e Ásia Oriental do que nas Américas, África e Oceania, e mais numerosos em áreas urbanas do que em rurais. Na Europa, é mais comum nos países do norte e do leste; na Ásia, na China, na Coreia, no Japão e no Irã; nas Américas, no Brasil, na Argentina e no México; na África, no Togo e em Madagascar.
Uma estimativa do número de esperantófonos foi feita por Sidney S. Culbert, um professor de psicologia aposentado da Universidade de Washington e esperantista de longa data que rastreou e avaliou esperantófonos em áreas de amostragem em dezenas de países por mais de vinte anos. Culbert concluiu que entre um e dois milhões de pessoas falam esperanto no nível 3 da escala ILR (competência linguística para trabalho profissional). A estimativa de Culbert não foi feita apenas para o esperanto; incluía-se numa listagem de estimativas para todas as línguas com mais de um milhão de falantes, publicada anualmente no "The World Almanac and Book of Facts". Uma vez que Culbert nunca publicou os resultados detalhados para países e regiões particulares, é difícil verificar a precisão de seus resultados.
Como uma língua planejada, o esperanto realmente não possuía a princípio uma cultura, mas os quase 130 anos de história e divulgação da língua geraram o que poderíamos chamar assim. Algumas pessoas acusam-no quanto a ser um "idioma universal" por não apresentar cultura, literatura, falantes nativos e por outras razões. Em contrapartida, já há elementos de cultura própria do esperanto, há um acervo considerável de músicas e obras literárias originais na língua (inclusive alguns escritores, como William Auld, já foram indicados ao Nobel de Literatura por suas obras originais em esperanto), há pessoas que têm o esperanto como língua materna (na maioria dos casos, poliglotas) e a língua é usada em todos os continentes.
O esperanto não veio de uma cultura específica, mas formou uma. Esperantistas falam em esperanto e sobre esperanto, usando termos, gírias, sarcasmos e uma série de expressões próprias do meio esperantista, alguns aspectos comuns de todos os esperantistas podem definir tal cultura.
A literatura em esperanto, consistindo de obras traduzidas e escritas diretamente na língua é altamente universalista, pois são adicionadas à literatura esperantista as melhores obras de cada nação, juntamente com os aspectos particulares de cada uma, assim como as crenças e costumes típicos de cada povo. Nas obras escritas diretamente em esperanto, vemos a mesma universalidade presente em toda a cultura esperantista.
Devido à ideia inicial de fraternidade do esperanto, a tolerância e respeito aos costumes e crenças dos vários povos consiste em um dos componentes dessa cultura; o repúdio ao imperialismo cultural é comum entre os esperantistas, e o desejo de intercâmbio e contato com outros povos apresenta-se na absoluta maioria dos esperantistas, muitas vezes consistindo um dos motivos do aprendizado da língua. Isso é comprovado na leitura do Manifesto de Praga, documento que sintetiza os objetivos comuns a todos os falantes do esperanto.
Além do desenvolvimento da cultura em torno da língua, é interessante notar que a causa esperantista parece atingir um grupo especial de indivíduos, tendo eles em comum o desejo de democracia e igualdade entre as nações. A constante entrada desses indivíduos no meio esperantista, faz com que sua cultura se desenvolva e se torne mais universalista a cada dia. Um excelente exemplo das particularidades da cultura esperantista são as expressões idiomáticas surgidas ao longo da evolução da língua, frutos diretos da comunicação internacional entre esperantistas.
Um argumento comum dos esperantistas é que o esperanto é uma língua democrática, pois através dela uma cultura não é imposta aos novos falantes, como é o caso do inglês, então caberia perguntar se essa cultura nova, gerada ao longo da evolução esperantista pós guerras não seria imposta aos povos que a adotarem como língua auxiliar. Isso certamente pode acontecer, mas por ser altamente universalista, ela tenderia a não causar males às culturas locais, e sim absorver para si mais e mais dessas culturas locais, a cultura da língua esperantista, se adotada pelos povos, seria então uma cultura comum, gerada por todas as nações, e que poderia até mesmo servir para aproximar algumas populações. No Manifesto de Praga, a democracia cultural é tratada como algo extremamente forte no esperanto.
Os Congressos Universais de Esperanto, realizados anualmente desde 1905 (excluindo-se o período das grandes guerras), alimentam e aprimoram a cultura esperantista. Nesses congressos é visível a plena existência de uma cultura geral, independente da nacionalidade de cada participante. Os Discursos de Zamenhof mostram alguns indícios dessas características de forma clara.
Há alguns símbolos atribuídos pelo movimento esperantista a si mesmo ou à língua. Não há unanimidade no movimento esperantista a respeito da política do uso de símbolos, mas a maioria dos esperantistas reconhecem três símbolos: a estrela verde, a bandeira e o "Jubilea Símbolo". Argumenta-se contra a estrela e a bandeira que elas dão um ar nacionalista ao objeto representado, podendo também ser confundido com ideários de outra natureza (o Islão e o movimento dito comunista, por exemplo).
O mais simples e antigo dos símbolos é a estrela verde de cinco pontas, usada, por exemplo, como broche ou adesivo para automóvel. Segundo a tradição, as cinco pontas representam os cinco continentes (segundo cálculo tradicional) e o verde simboliza a esperança. Zamenhof, entretanto, em 1911, já não tinha mais certeza de sua origem; a cor lhe fora proposta pelo irlandês A. Richard Henry Geoghegan, que depois lhe esclareceu que se tratava da cor nacional da Irlanda. Já em 1893, Louis de Beaufront propunha o uso do verde e da estrela em tudo que se relacionasse ao movimento. A consolidação da estrela como símbolo do esperanto data dos últimos anos do século XIX; da estrela na cor verde, provavelmente apenas em 1904.
A bandeira é uma espécie de extensão da estrela verde, retomando a mesma cor e significados, com a adição do branco, para representar paz e neutralidade. Era originalmente a bandeira do clube de esperanto de Bolonha-sobre-o-Mar (França). Foi adotada generalizadamente nessa cidade por ocasião do primeiro Congresso Universal de Esperanto, em 1905.
O "jubilea simbolo" ("símbolo do jubileu") é um símbolo alternativo proposto para o esperanto, contendo a ideia interna da língua: juntar todos. As suas duas metades laterais representam a letra latina E (Esperanto) e a letra cirílica Э (Эсперанто), simbolizando a união do ocidente e do oriente. A ideia de usar as duas letras ocorreu por causa da Guerra Fria, quando as duas grandes potências estatais a se enfrentar tinham como línguas maternas o inglês (com alfabeto latino) e o russo (com alfabeto cirílico).
A sua elaboração foi promovida através de um concurso em 1983, por ocasião do centenário da língua (1987). A ideia original é do brasileiro Hilmar Ilton S. Ferreira. O símbolo é usado com cores diferentes, com ou sem contornos, de acordo com a opção do usuário.
Existem diversos movimentos sociais e culturais que apoiam o esperanto de alguma forma.
Entre eles, podemos destacar o anarquismo. Paul Bertelot, anarquista francês, em 1905, criou a revista Revuo Esperanto, que é, até hoje, o órgão oficial de divulgação da Associação Universal de Esperanto. Bertelot viajou pela Europa divulgando o esperanto entre os trabalhadores, ajudou a organizar o primeiro congresso de esperanto e fundou clubes esperantistas na América do Sul, morrendo prematuramente no Brasil em 1910. A seção libertária da Sennacieca Asocio Tutmonda ("Associação Mundial Anacional"), criada na década de 1920, até hoje é atuante. No Brasil, desde 2005, funciona o grupo de propaganda e ação esperantista-anarquista Fenikso Nigra.
O Centro de Mídia Independente (CMI) é uma rede internacional formada por produtores de informação de ordem política e social que se autodeclaram independentes de quaisquer interesses empresariais ou governamentais. O site brasileiro do CMI possui versão em esperanto.
Bona Espero é uma escola e internato localizada no município de Alto Paraíso de Goiás, região norte do estado de Goiás, a 412 quilômetros de Goiânia (capital do estado) e a 280 quilômetros de Brasília (capital federal), que abriga crianças carentes da região onde a utilização e o ensino do esperanto é comum no dia a dia. A instituição vem sendo visitada por muitos esperantistas ao longo de seus mais de 50 anos de existência. Foi fundada por um grupo nordestino de esperantistas; hoje, é administrada pelo casal Gratapagglia, por Ursula (alemã) e Giuseppe (italiano), além de outros três diretores.
Alguns grupos religiosos ao redor do mundo apoiam, de alguma forma, o esperanto.
Em 1910, foi fundada a União Internacional Católica Esperantista, cujo órgão, a revista Espero Katolika, é o periódico em esperanto mais antigo ainda em atividade.
Papas católicos romanos (incluindo pelo menos o Papa João Paulo II e Bento XVI) usaram o esperanto ocasionalmente no "urbi et orbi" multilíngue.
A "Kristana Esperantista Ligo Internacia" (Liga Internacional Cristã Esperantista) foi formada logo cedo na história do esperanto e é de orientação predominantemente protestante, mas também são filiados a ela católicos romanos e ortodoxos.
Há alguns apologistas e professores cristãos que usam o esperanto como um meio de comunicação. O pastor nigeriano Bayo Afolaranmi tem um grupo no Yahoo! chamado "Spirita nutraĵo" (alimento espiritual), que hospeda mensagens semanais desde 2003.
Em 1908, o espírita Camilo Chaigneau escreveu um artigo intitulado "O Espiritismo e o Esperanto" na revista de Gabriel Delanne (depois reproduzido no periódico "La Vie d'Outre-Tombe", de Charleroi, e na revista brasileira Reformador em 1909), recomendando o uso de Esperanto em uma "revista central" para todos os espíritas no mundo.
O esperanto, então, foi divulgado ativamente no Brasil por espíritas. Este fenómeno originou-se através de Ismael Gomes Braga e Francisco Valdomiro Lorenz, sendo o último um emigrante de origem checa que foi pioneiro de ambos os movimentos neste país.
Assim, a Federação Espírita Brasileira publica livros didáticos de esperanto, traduções das obras básicas do espiritismo e encoraja os espíritas a se tornarem esperantistas.
Por causa disso, no Brasil, muitos não-esperantistas mal-informados têm a impressão de que o esperanto é "língua de espírita"; a contradizê-lo é de notar a discrepância entre o número relativamente elevado de espíritas entre os esperantófonos brasileiros (entre um quarto e um terço) e a insignificância do recíproco (número de espíritas brasileiros que falam esperanto, cerca de 1%). Este fenómeno não se verifica noutros países.
A Fé Bahá'í encoraja o uso de uma língua auxiliar, e, sem endossar nenhuma língua específica, vê no esperanto um grande potencial para esse papel. Considera-se, entretanto, que qualquer língua ao ser adotada poderá ser modificada e adaptada através de um consenso com representação de todos os países.
Lidja Zamenhof, filha do fundador do esperanto, tornou-se Bahá'i.
Vários volumes de escritos da Fé Bahá'i já foram traduzidos para esperanto.
Zamenhof promoveu uma doutrina filosófica e religiosa chamada homaranismo, mas temeu que se confundissem as ideias da doutrina com o ideal pró-esperanto. Por esse e outros motivos, não se empenhou tanto em sua divulgação. Todavia, a maior parte dos adeptos do homaranismo hoje são esperantistas, tendo conhecido a doutrina através do esperanto.
Ayatollah Khomeini do Irã fez um chamado oficial aos islâmicos ao aprendizado do esperanto e elogiou o uso dessa língua como um meio para melhor compreensão entre povos de diferentes religiões. Após sugerir que o esperanto substituísse o inglês como uma língua franca internacional, a língua foi introduzida nos seminários de Qom. Uma tradução do Corão em esperanto foi publicada pelo estado pouco tempo depois Khomeini e o governo iraniano passaram a fazer oposição ao esperanto em 1981 após notar que seguidores da Fé Bahá'i estavam interessados no esperanto.
A religião oomoto encoraja o uso do esperanto entre seus seguidores, e inclui Zamenhof entre seus espíritos divinos.
A Congregação Cristã no Brasil recebeu uma versão em Esperanto, intitulada de "Kristana Kongregacio en Brazilo".
A primeira tradução da Bíblia para esperanto foi uma tradução do Tanakh (Velho Testamento), feita por Zamenhof. A tradução foi revisada e comparada com traduções para outras línguas por um grupo de clérigos britânicos, antes de sua publicação na "British and Foreign Bible Society" em 1910. Em 1926, ela foi publicada junto com uma tradução do Novo Testamento, numa edição geralmente chamada de "Londona Biblio". Nos anos 1960, "Internacia Asocio de Bibliistoj kaj Orientalistoj" tentou organizar uma nova e ecumênica versão da Bíblia em esperanto. Desde então, o pastor luterano Gerrit Berveling traduziu os Livros Deuterocanônicos, além de novas traduções dos Evangelhos, algumas das epístolas do Novo Testamento e alguns livros do Tanakh; estes foram publicados em várias brochuras separadas, ou em série na revista "Dia Regno", mas os deuterocanônicos apareceram numa edição recente da "Londona Biblio".
O esperanto é, frequentemente, usado para se ter acesso a uma cultura internacional, dispondo ele de um vasto leque de obras literárias, tanto traduzidas como originais. Há mais de 25 000 livros em esperanto, entre originais e traduções, além de mais de uma centena de revistas editadas regularmente. Muitos esperantófonos usam a língua para viajar livremente pelo mundo usando o Pasporta Servo, rede internacional de hospedagem solidária. Outros têm correspondentes em vários países diferentes através de serviços como o Esperanto Koresponda Servo.
Com o desenvolvimento da internet e sua maior popularização, as iniciativas de imprensa em esperanto têm se tornado mais fáceis, e pouco a pouco ela se desenvolve.
Atualmente, vários Estados subvencionam transmissões regulares em esperanto de suas estações de rádio oficiais, como República Popular da China, Polónia (diariamente), Cuba, Itália e Vaticano. Em menor escala, várias estações de rádio mantêm programas em ou sobre esperanto, como a Rádio Rio de Janeiro, que tem um departamento dedicado exclusivamente ao esperanto.
Anualmente, de 1 200 a 3 000 esperantistas encontram-se anualmente no Congresso Universal de Esperanto.
A língua mostra-se útil essencialmente para a troca de informações entre indivíduos de etnias diferentes que, doutra maneira, só seria realizada através de elementos mediadores (uma língua estranha a pelo menos um deles, um intérprete, organizações privadas, Estados etc.).
Comparado a uma língua étnica, o esperanto apresentou algumas utilidades particulares:
Num estudo, um grupo de estudantes do ensino secundário estudou esperanto durante seis meses e, depois, francês durante ano e meio, obtendo um melhor conhecimento de francês do que o grupo-controle, que estudou só o francês durante dois anos.
É provável que outras línguas planificadas também apresentem esse efeito no mesmo grau que o esperanto, mas devido ao maior número de falantes e melhor disponibilidade de material didático, a língua esperantista parece ser a mais recomendável para obter o efeito propedêutico.

Os recém-chegados são muito bem-vindos à Wikipédia. Esperamos que se sintam bem por aqui e esperamos que de forma construtiva para o projeto. A Wikipédia possui um ambiente democrático e igualitário, no sentido em que as opiniões não valem mais só porque são defendidas por quem está aqui há mais tempo. No entanto, isso não significa que não existam regras na Wikipédia. 
Essas regras existem por boas razões e foram estabelecidas com o tempo e com a experiência. Não são regras obrigatórias, mas condensam alguma sabedoria obtida com a experiência e devem ser levadas em consideração pelos recém-chegados.
Existem alguns erros que os recém-chegados costumam cometer. A lista que se segue existe para que esses erros sejam evitados.
Esta lista está limitada aos erros "mais comuns e importantes" na Wikipédia. Para ver outras "regras" ou sugestões, consulte as .
Como qualquer texto da Wikipédia pode ser por qualquer pessoa, sendo inevitável que isso aconteça (exceto nas ), cada artigo da Wikipédia acaba por ter vários autores. Estes autores ficam guardados na base de dados automaticamente, desde que o usuário esteja . A lista de autores de cada artigo pode ser consultada no separador "" de cada artigo. Por esses motivos, não assine as suas contribuições no próprio artigo.
O uso exclusivo de letras maiúsculas num artigo prejudica sua leitura além de significar "gritaria" no internetês, o que pode ser considerado má educação.
Por exemplo, não se deve usar letras maiúsculas nos l e p de "língua portuguesa". Isso facilita a leitura e a escrita de ligações para o artigo. A ligação deve ter esta aparência: língua portuguesa. Deixar com "Iniciais Maiúsculas Tudo o que For Ligação Deixa Tudo com Aparência Muito Estranha".
Algo comum para os novos editores é inserir informações no artigo por ter visto, lido ou ouvido na mídia. Ao editar, procure sempre , referenciando de forma correta o seu texto. Procure ler as regras para uma boa edição, que estão descritas no .
A Wikipédia é uma enciclopédia escrita em português vernacular e culto, portanto cuidado com os vícios de linguagem e não utilize o "internetês" (vícios da Internet), tais como "aki" (aqui), "vc" (você), "k" ou "q" (que) e "lol" (risos). Evite também utilizar gírias ou expressões idiomáticas que possam dificultar a compreensão a usuários que não utilizem a sua variante do português.
Você provavelmente vai cometer erros — acontece com todo mundo, de diferentes formas. Mas nós estamos sempre corrigindo os erros de outros colegas. E tudo termina bem. Por isso, ! No entanto, tente sempre aprimorar suas edições, minimizando o trabalho alheio de correção.
Um engano comum dos leitores recentes da Wikipédia é achar que existe um único autor ou responsável por cada artigo. Isso faz as pessoas sentirem-se limitadas ao alterar artigos, fazendo sugestões e críticas nas , quando podiam estar alterando os artigos. O fato é que nenhum artigo tem um autor oficial, mesmo quando apenas uma pessoa trabalhou nele. Na teoria, qualquer pessoa pode escrever em qualquer artigo e se você vir algum problema num artigo e puder corrigi-lo, por favor, "faça-o na hora". Não é preciso ir antes à página de discussão, a menos que considere necessário explicar o que você alterou (geralmente não é preciso) ou que você queira esclarecer algo antes de alterar. Como foi dito acima, !
Nas é muito fácil as pessoas envolverem-se emocionalmente nos debates dos vários tópicos. A não ser que isso resulte num artigo "melhorado" (algo pouco habitual), por favor não entre em debates inúteis. Há muitos outros "sites" na Internet onde se pode envolver em debates e tentar persuadir os outros dos seus pontos de vista controversos. Isso não é mesmo nada apropriado na Wikipédia, pois estamos a tentar concentrar-nos na criação de uma enciclopédia. Por favor veja .
Alguns novos utilizadores veem logo que há aqui uma comunidade especial, esforçando-se para trabalhar em conjunto à volta de um consenso amigável. Outros cometem o erro de entrarem nas disputas da Wikipédia como se estas fossem "flame wars" da Usenet. A Wikipédia não é isso. Claro que há discussões acesas, mesmo entre os membros mais antigos. No entanto, parece ser certo que a maioria de nós não está cá para isso e ficamos envergonhados quando isso acontece. Estamos aqui para escrever uma enciclopédia. Torna-se necessário obedecer a . "Veja também ."
Perceba que a Wikipédia é um trabalho em curso, onde muitas pessoas inteligentes e bem educadas estão a trabalhar nela e preocupam-se com ela. E pensaram muito nela. Algumas pessoas, recém-chegadas, falham na compreensão de como e por que é que a Wikipédia funciona e começam a pedir mais controle, ou então julgam o projeto baseando-se em artigos novos, incompletos e inadequados. De uma forma geral, se quer sentir-se confortável aqui, tolere alguma (temporária) imperfeição. Tenha em conta que estamos todos a trabalhar nisto, e está ficando cada vez melhor. Veja Wikipédia e as para mais informações gerais sobre o projeto. Veja as .
Nunca edite comentários alheios em páginas de discussão, mesmo que encontre erros ortográficos ou de digitação. Se achar importante que tais erros sejam corrigidos, procure contatar o usuário, exortando-o a que corrija seus erros. Não é autorizada a edição de comentários alheios. A reincidência em tais atos será interpretada como .
Na eventualidade de haver textos com conteúdo ofensivo ou , contrariando as boas , tente convencer o autor através de sua a remover o conteúdo. Caso não seja atendido e esteja convicto da violação das normas, exponha o caso em .
Quando um programa de televisão ou telejornal é extinto, usa-se o termo "foi", tempo verbal no passado, como padrão para definir a obra. O uso do termo verbal no presente - "é um programa de televisão" - é equivocado.
1º Exemplo correto:
Já no caso das novelas, seriados e séries extintas o uso do termo "foi", tempo verbal no passado, é equivocado. Ao final de uma obra de dramaturgia mantêm-se como padrão o uso do tempo verbal no presente: "é".
2º Exemplo correto:
Pense duas vezes antes de alterar uma . Somente altere o que for imprescindível, tal qual a correção de um atalho. Considere a possibilidade de sugerir a ele(a) a alteração em mente, enviando uma mensagem para a página de discussão dele(a).
Para facilitar a compreensão das discussões, sugere-se que todo o novo comentário seja inserido sempre no final da discussão ou no final da respetiva secção e assinado com quatro tiles: ~~~~.

Enciclopédia (do grego antigo transl.: "enkyklopaideía", formado a partir de "circular" + "educação") é uma coletânea de textos bastante numerosos, cujo objetivo principal é descrever o melhor possível o estado atual do conhecimento humano. Pode-se definir como uma obra que trata de todas as ciências e artes do conhecimento do homem atual. Pode ser tanto um livro de referência para praticamente qualquer assunto do domínio humano como também uma obra na "internet".
As enciclopédias podem ser divididas em dois grupos: "genéricas", que coletam conhecimentos de todo o conhecimento humano (como, por exemplo, a Encyclopædia Britannica), ou especializadas, com tópicos relacionados a um assunto específico (como, por exemplo, uma enciclopédia de medicina ou de matemática).
O termo "enciclopédia" começou a ser utilizado em meados do século XVI, embora trabalhos de formato similar já existissem em épocas anteriores.
A palavra "enciclopédia" provém do Grego Clássico ἐγκύκλιος παιδεία" (transliterado: "enkyklios paideia"), literalmente "educação circular", isto é, "conhecimento geral". Embora a noção de um compêndio de conhecimento remonte a milhares de anos, o termo foi utilizado pela primeira vez no título de um livro publicado em 1541 por Joachimus Fortius Ringelbergius, "Lucubrationes vel potius absolutissima kyklopaideia" (Basileia, 1541). A palavra "enciclopédia" foi utilizada primeiramente como um substantivo, no título do livro do enciclopedista croata Skalić, "Encyclopaedia seu orbis disciplinarum tam sacrarum quam prophanarum epistemon" (Enciclopédia, ou conhecimento do mundo das disciplinas, Basel, 1559). Um dos mais antigos usos em francês foi realizado por François Rabelais em sua obra "Pantagruel", em 1532.
Várias enciclopédias têm nomes que incluem o sufixo "-pedia", como por exemplo a Banglapedia, uma enciclopédia sobre as questões relevantes para Bengala, ou a própria Wikipédia, uma enciclopédia redigida com o sistema wiki.
A enciclopédia como conhecemos hoje foi desenvolvida a partir do dicionário no século XVIII. Um dicionário concentra-se principalmente em palavras e as suas definições e, normalmente, dá uma informação limitada, a análise do uso linguístico ou o contexto para cada termo definido. Essa definição linguística pode deixar de informar ao leitor o significado, a importância ou as limitações de um prazo, ou as relações do termo com um vasto campo de conhecimento.
Para fazer face a essas necessidades, um artigo de enciclopédia aborda, além da palavra, o próprio conceito e também o tema ou disciplina, tratando-os com profundidade, a fim de transmitir o conhecimento acumulado sobre esse tema. Uma enciclopédia muitas vezes também inclui mapas e ilustrações, bem como bibliografias e estatísticas. Historicamente, tanto a enciclopédia como o dicionário foram pesquisados e escritos com o fim de contribuir para a educação e informação, muitas vezes com a contribuição de peritos, ou especialistas.
Algumas obras intituladas "dicionário" são, de facto, similares a uma enciclopédia, especialmente as ligadas a área determinada (como os "Dictionary of the Middle Ages", "Dictionary of American Naval Fighting Ships" e "Black's Law Dictionary"). O "Dicionário Macquarie", reconhecido como o dicionário oficial da Austrália, tornou-se um dicionário enciclopédico após a sua primeira edição, em reconhecimento do uso de nomes próprios em comum, e as palavras derivadas de tais nomes próprios, típicos de uma básica obra enciclopédica.
Grande parte dos escritos que procuravam englobar o conhecimento humano na Antiguidade eram de estilo "específico", ou especializado (geralmente relacionados à natureza ou à filosofia). Alguns dos grandes filósofos da Antiguidade já haviam tentado escrever sobre todos os campos de conhecimento estudados.
Na China antiga, no século III AEC, foi escrito a enciclopédia chinesa mais antiga conhecida, o Erya. O autor do livro é desconhecido, embora seja tradicionalmente atribuída a Duque de Zhou, Confúcio ou os seus discípulos.
Aristóteles escreveu um conjunto de obras sobre os seres vivos, que foram preservadas: "De anima", "Parva naturalia", "Historia animalium", "De partibus animalium", "De motu animalium", "De incessu animalium" e "De generatione animalium". Muitas delas tratam de assuntos bastante teóricos, discutindo os motivos dos fenômenos da vida; outras são mais descritivas, compreendendo um vasto volume de fatos. Em "Historia animalium", o filósofo grego apresentou uma descrição muito detalhada de aproximadamente 550 espécies, incluindo vertebrados e invertebrados. Também tratou de descrever as aparências externa e interna, os costumes dos animais, redigiu uma comparação detalhada entre as espécies e tentou descrever suas principais características e diferenças.
Quatro séculos após a obra de Aristóteles ser publicada, Plínio, o Velho coligiu, em sua obra "Naturalis historiae", todas as informações que pôde encontrar sobre plantas, animais, minerais e diversos outros tópicos, repartidos em 37 partes. A primeira obra apresenta um índice e uma bibliografia por completo. Os livros II a VI tratam, respectivamente, sobre a astronomia e a geografia; os livros VII a XI, tratam sobre a zoologia; os XII a XIX, sobre a botânica e a agricultura; os XX a XXVII, sobre apenas a botânica médica; os livros XXVIII a XXXII descrevem diferentes remédios e antídotos retirados de diferentes animais e do próprio homem; e os livros XXXIII a XXXVII tratam unicamente sobre mineralogia e metais. Essa obra, em conjunto, é considerada uma grande enciclopédia sobre a natureza.
No século X, em Constantinopla, apareceu uma obra coletiva greco-bizantina de grande interesse para o conhecimento da Antiguidade Grega. Trata-se de uma compilação de obras e personagens classificadas de forma inovadora por ordem alfabética que se apresenta, portanto, como a primeira enciclopédia: a Suda. Apesar de várias imprecisões e erros, a Suda contém informações inestimáveis, uma vez que seus autores tiveram acesso a obras agora perdidas. Esse cobiçado livro, nos dias atuais, é conhecido como a primeira enciclopédia de que se tem notícia, pela amplidão de conhecimento atingido (porém, não se extinguem possibilidades de terem existidas outras obras, talvez mais completas, de não tanto sucesso).
Santo Isidoro de Sevilha, um dos maiores estudiosos do início da Idade Média, é amplamente reconhecido como sendo o autor da primeira enciclopédia de que se tem conhecimento dos tempos medievais, o "Etymologiae" (publicado em torno do ano de 630), no qual ele compilou a mais ampla possível aprendizagem disponível na sua época, criando uma enorme leva de conhecimento de 448 capítulos em 20 volumes; é muito valioso não só pela sua importância, mas também por causa das citações e fragmentos de textos de outros autores que teriam sido perdidos, nos tempos atuais não se tem mais vestígios e que não tinha sido feito pelo Santo Isidoro.
"De Rerum proprietatibus" (1240) de Bartholomeus Anglicus foi a mais lida e citada enciclopédia na Baixa Idade Média, enquanto "Speculum Majus" (1260) de Vicente de Beauvais foi a mais ambiciosa enciclopédia do período tardo-medieval, com mais de 3 milhões de palavras.
As primeiras compilações de conhecimento muçulmanas de que se tem notícia na Idade Média incluía muitas obras já completas, e um desenvolvimento respeitosamente vasto do que, agora, chamamos método científico, método histórico, e citação. Por volta do ano 960, os Irmãos da Pureza de Baçorá se empenharam na confecção de sua obra "Enciclopédia dos Irmãos da Pureza". Obras notáveis incluem: enciclopédia de ciências de Abu Bakr al-Razi, a prolífica produção de Al-Kindi de 270 livros, e a enciclopédia médica de Ibn Sina, que foram, por séculos, padrões de referência para trabalhos. Também notáveis são obras de história universal (ou sociologia), como "História de Profetas e Reis" de Asharites, al-Tabri, al-Masudi, Tabari, Ibn Rustah, al-Athir, e Ibn Khaldun, cuja "Muqadimmah" contém alertas quanto a confiança em registos escritos que permanecem totalmente aplicáveis hoje. Esses estudiosos tiveram uma incalculável influência sobre os métodos de investigação e edição, em parte devido à prática islâmica isnad que destacou a fidelidade do registo escrito, verificando fontes, e céticos inquéritos.
Hoje em dia, é creditada a criação da primeira enciclopédia moderna à "Encyclopédie", de 28 volumes, 71 818 artigos, e 2 885 ilustrações, editada por Jean le Rond d’Alembert e Denis Diderot em 1772, tendo como colaboradores Rousseau, Voltaire, Montesquieu e outros ensaístas ilustres. Porém, antes destes respeitáveis iluministas terem atingido um grau de amplitude muito superior, John Harris havia escrito anteriormente, em 1704, a "Lexicon technicum", e a ele é creditado o estabelecer do formato moderno de uma enciclopédia, tal como a conhecemos hoje.
No século seguinte, George Wilhem Hegel publicou a sua "Enciclopédia das Ciências Filosóficas", em que se cristaliza a ideia de enciclopédia como apresentação sistemática de uma ciência ou de um conjunto de ciências.
O formato hierárquico e sua natureza em permanente evolução tornam obras enciclopédicas alvos perfeitos para publicação em formato digital e praticamente todas as grandes enciclopédias tiveram uma versão em CD-ROM no final do século XX. A versão em CD-ROM conta com a vantagem de ser portátil e de produção extremamente econômica. Além disso, uma enciclopédia em formato digital pode ter conteúdos como animações e áudio, impossíveis de serem inseridos numa tradicional publicação escrita. A inclusão de hyperlinks ligando artigos relacionados também é uma enorme vantagem do formato digital.
Por fim, o advento da internet possibilitou a criação das enciclopédias livres, sendo atualmente as mais conhecidas: a Everything2, a Encarta, a h2g2 e a Wikipédia. Nestas, pela primeira vez na história da humanidade, qualquer pessoa pode fazer contribuições e corrigir e/ou ampliar as entradas já existentes, o que resulta num banco de dados universal que é continuamente aperfeiçoado. Este tipo de enciclopédia permite ainda que o significado de um determinado verbete seja consultado em vários idiomas, expandindo os resultados da pesquisa. As enciclopédias impressas modernas do século XX realmente não tem mais valor. Os negociantes de livros em segunda mão não podem vendê-los, e até mesmo algumas associações de caridade as recusam como doações.

A Encyclopædia Britannica é uma enciclopédia generalista de língua inglesa publicada pela Encyclopædia Britannica, Inc., uma editora privada. Os verbetes na "Britannica" têm como público alvo diretamente os leitores adultos cultos; a enciclopédia é escrita por 19 editores em tempo integral e conta com a colaboração de mais de quatro mil peritos. É amplamente considerada como a mais acadêmica das enciclopédias.
A "Britannica" inicialmente foi publicada entre 1768 e 1771, em Edimburgo, Reino Unido, e depressa aumentou em popularidade e tamanho, com a sua terceira edição, em 1801, alcançando os vinte volumes. O aumento de tamanho implicou a contratação de colaboradores, e as suas 9.ª (1875–1889) e 11.ª edições (1911) são consideradas como marcos no que toca a enciclopédias acadêmicas e de estilo literário. Começando com a 11.ª edição, a "Britannica" foi gradualmente diminuindo e simplificando os seus artigos a fim de os tornar mais acessíveis, e alargar a sua expansão ao mercado nos Estados Unidos. Em 1933, a "Britannica" tornou-se a primeira enciclopédia a adotar a política "em contínua revisão", que resulta em que a enciclopédia seja continuamente reimpressa e cada verbete seja atualizado regularmente.
A edição atual (a 15.ª) tem uma única estrutura dividida em três partes: a "Micropædia", de 12 volumes, contém verbetes menores (geralmente tendo menos de 750 palavras), a "Macropædia", de 17 volumes, com longos artigos (tendo de duas a 310 páginas cada) e a "Propædia", num só volume, que pretende fornecer um esboço do conhecimento humano, de modo hierárquico. A "Micropædia" é destinada a pesquisa rápida e a servir como guia para a "Macropædia"; os leitores são aconselhados a estudar o esboço da "Propædia" a fim de entender o contexto do assunto e para encontrar outros artigos, mais detalhados. O tamanho da "Britannica" tem-se mantido muito constante ao longo dos últimos 70 anos, com cerca de 40 milhões de palavras e meio milhão de tópicos. Embora a sua publicação tenha sede nos Estados Unidos desde 1901, a "Britannica" manteve a ortografia inglesa tradicional.
Ao longo da História, a "Britannica" tem tido dificuldade em permanecer rentável — um problema enfrentado por muitas enciclopédias. Alguns verbetes, em determinadas edições anteriores da "Britannica", foram acusados de imprecisão, viés ou falta de qualificação dos colaboradores. A precisão de partes da edição mais recente (de 2005) tem sido igualmente questionada, embora tais críticas tenham sido contestadas pela gestão da "Britannica". Apesar disso, a "Britannica" mantém a sua reputação como fonte de pesquisa confiável. Em 3 de março de 2012, foi anunciado que a "Encyclopædia Britannica", agora com sede em Chicago, não iria publicar mais versões impressas em papel focando-se apenas na sua versão "online".
A propriedade da "Britannica" mudou muitas vezes ao longo do tempo, tendo passado por vários donos como: a editora escocesa A & C Black, Horace Everett Hooper, Sears Roebuck e William Benton. O presente dono da Encyclopædia Britannica, Inc. é Jacqui Safra, de nacionalidade suíça, milionário e ator. Os recentes avanços das tecnologias da informação e o aumento das enciclopédias eletrônicas tais como a "Encarta" e a Wikipédia reduziram a procura de enciclopédias impressas. A fim de permanecer competitiva, a "Encyclopædia Britannica, Inc." tem enfatizado a boa reputação da "Britannica", reduzindo seu preço e os custos de produção e desenvolvido versões eletrônicas em CD-ROM, DVD e World Wide Web. Desde os primeiros anos da década de 1930, a editora promoveu também trabalhos de referência spin-off.
A "Britannica" foi impressa em 15 edições oficiais, com suplementos multi-volumes da 3.ª a 5.ª edições (ver a Tabela abaixo). Estritamente falando, a décima edição foi apenas um suplemento da 9.ª, assim como as edições 12.ª e 13.ª foram suplementos da 13.ª edição. A 15.ª edição sofreu uma mudança drástica, em termos de organização, em 1985, mas a atualização, versão corrente, continuou conhecida como 15.ª edição.
Ao longo de sua história, a "Britannica" foi desenvolvida com dois objetivos: ser um excelente livro de referências e providenciar material educacional para quem tenha desejo de estudar. Em 1974, a 15.ª edição adotou um terceiro alvo: sistematizar todo o conhecimento humano.
A história da "Britannica" pode ser dividida em cinco fases principais em que se destacam mudanças maiores, tanto na gestão quanto na reorganização do seu conteúdo. Na primeira fase (edições 1 a 6, 1768–1826), a "Britannica" foi gerida por seus fundadores originais, Colin Macfarquhar e Andrew Bell, e por seus amigos e conhecidos, tais como Thomas Bonar, George Gleig e Archibald Constable. A "Britannica" foi primeiramente publicada entre 1768 e 1771 em Edimburgo como "Encyclopædia Britannica, ou, Um dicionário de arte e ciência, compilado sob um novo plano". Foi concebida como uma reacção conservadora à provocativa "Encyclopédie" francesa de Denis Diderot (publicada entre 1751 e 1766), que por sua vez havia sido inspirada pela anterior "Chambers Cyclopaedia". A "Britannica" foi, primeiramente, uma empresa escocesa e tinha como símbolo o cardo, o emblema nacional da Escócia. A criação da enciclopédia é um dos mais famosos e perseverantes legados do Iluminismo Escocês. Nesta fase, a "Britannica" deixou de ser um conjunto de três volumes (1.ª edição) compilados por um jovem editor — William Smellie — para se tornar uma obra de vinte volumes escrita por numerosas autoridades. Embora várias outras enciclopédias tenham competido com a "Britannica", como a "Rees's Cyclopaedia" e a "Encyclopaedia Metropolitana", de Samuel Taylor Coleridge, estes rivais ou faliram ou ficaram inacabados por desentendimentos entre os editores. No fim desta fase, a "Britannica" tinha constituído uma rede de ilustradores, primeiramente entre os conhecidos de seus editores, sendo os mais relevantes Constable e Gleig.
Durante a segunda fase (edições 7 a 9, 1827–1901), a "Britannica" foi gerida pela editora de Edimburgo, A & C Black. Embora alguns colaboradores fossem recrutados novamente através de relacionamentos, sendo Macvey Napier o mais relevante, outros foram atraídos pela reputação sempre crescente da "Britannica". Os colaboradores muitas vezes vinham de outros países e incluíam algumas das autoridades mais respeitadas nas suas áreas. Na sétima edição foi incluído, pela primeira vez, um índice geral de todos os artigos, prática que se manteve até 1974. O primeiro editor-chefe nascido em Inglaterra foi Thomas Spencer Baynes, que supervisionou a produção da famosa 9.ª edição; nomeada "Edição Acadêmica", a 9.ª edição é muitas vezes considerada como sendo a "Britannica" mais direcionada ao uso acadêmico alguma vez produzida. No entanto, no fim do século XIX, a 9.ª edição estava desatualizada e a "Britannica" enfrentava sérias dificuldades financeiras.
Na terceira fase (10.ª a 14.ª edições, 1901–1973), a "Britannica" foi gerida por negociantes estadunidenses, que introduziram técnicas de venda agressivas, tais como o marketing direto e venda porta a porta, a fim de aumentar os lucros. Os donos norte-americanos simplificaram, gradualmente, os verbetes da "Britannica", fazendo-a menos acadêmica, mas mais inteligível para o mercado das massas. A décima edição foi rapidamente produzida, como suplemento da 9.ª, mas a 11.ª edição ainda é prezada pela sua excelência; o seu dono, Horace Everett Hooper, esforçou-se na busca da sua perfeição. Quando Hooper entrou em dificuldades financeiras, a "Britannica" passou a ser gerida por Sears Roebuck durante cerca de 18 anos (1920–1923, 1928–1943). Em 1932, a vice-presidente de Sears, Elkan Harrison Powell, assumiu a presidência da "Britannica"; em 1936, começou a política de revisão contínua (ainda praticada), que faz com que cada verbete seja verificado e possivelmente revisado pelo menos duas vezes em cada década. Esta foi uma grande mudança pois, com a prática anterior, os artigos não eram alterados a não ser aquando de uma nova edição, com cerca de 25 anos de intervalo, com alguns artigos sendo transportados de edições anteriores sem alteração. Powell, agressivamente, desenvolveu novos produtos educacionais, que se baseavam na reputação da "Britannica". Em 1943, a posse passou de Sears Roebuck para William Benton, diretor da "Britannica" até sua morte, em 1973. Benton fundou ainda a Fundação Benton, que geriu a "Britannica" até 1996. Em 1968, perto do fim desta fase, a "Britannica" celebrou o seu bicentenário.
Na quarta fase (15.ª edição, 1974–1994), a "Britannica" introduziu a sua 15.ª edição, que foi reorganizada em três partes: a "Micropædia", a "Macropædia" e a "Propædia". Sob influência de Mortimer J. Adler (membro do quadro de editores da "Encyclopædia Britannica" desde o seu ingresso na companhia, em 1949, e seu presidente desde 1974; diretor dos planos para realização da 15.ª edição da "Britannica", desde 1965), a "Britannica" procurou não só ser uma boa obra de referência e uma ferramenta educacional, mas também sistematizar todo o conhecimento humano. A ausência de um índice separado e o agrupamento de artigos em duas enciclopédias paralelas (a "Micro-" e a "Macropædia") provocaram uma "tempestade de críticas" sobre a 15.ª edição, inicialmente. Em resposta, a 15.ª edição foi totalmente reorganizada e indexada para novo lançamento em 1985. A segunda versão da 15.ª edição continua a ser revisada e publicada; a versão mais recente foi impressa em 2007. O título oficial da 15.ª edição é "Nova Encyclopædia Britannica", e está ainda a ser promovida como "Britannica 3".
Na quinta fase (1994–presente), foram desenvolvidas versões digitais da "Britannica", lançadas em disco óptico e internet. Em 1996, a "Britannica" foi comprada à Fundação Benton por Jacqui Safra, bastante abaixo do seu valor, devido às dificuldades financeiras por que a editora passava. A editora Encyclopædia Britannica, Inc. dividiu-se em 1999. Uma parte manteve o nome da companhia e desenvolveu a versão impressa; a outra parte, Britannica.com Inc., desenvolveu as versões digitais. Desde 2001, estas duas companhias partilharam um único CEO, Ilan Yeshua, que continuou a estratégia de expansão da "Encyclopædia Britannica, Inc." de Elkan Harrison Powell em lançar novos produtos sob a marca "Britannica".
A "Britannica" foi dedicada aos monarcas britânicos de 1788 a 1901 e, após sua venda a uma sociedade estadunidense, ao monarca britânico e ao presidente dos EUA. Assim, a 11.ª edição foi "dedicada, com permissão, a Sua Majestade Jorge V, Rei da Grã-Bretanha e Irlanda e dos Domínios Britânicos de além-mar, Imperador da Índia, e a William Howard Taft, Presidente dos Estados Unidos da América." A ordem destas duas dedicatórias mudou com os poderes relativos dos EUA e da Grã-Bretanha, e com as vendas relativas da "Britannica" nesses países; a versão de 1954 da 14.ª edição é "dedicada, com permissão aos Chefes de Estado das Duas Nações Anglófonas, Dwight D. Eisenhower, Presidente dos Estados Unidos da América, e a sua Majestade, Isabel II." De acordo com esta tradição, a versão de 2007 da corrente 15.ª edição é "dedicada, com permissão, ao ex Presidente dos Estados Unidos da América, George W. Bush, e a sua Majestade, Elizabeth II."
Desde a 3.ª edição, a "Britannica" usufruiu de uma reputação excelente, tanto popular como crítica. Várias edições, desde a 3.ª a 9.ª foram pirateadas para venda nos EUA, começando com a Dobson's Encyclopædia. No lançamento da 14.ª edição a revista "Time" batizou a "Britannica" como "O Patriarca das Bibliotecas". Em um anúncio relacionado, o naturalista William Beebe foi citado como dizendo que a "Britannica" estava "além de comparação porque não há nenhum concorrente."
Referências à "Britannica" podem ser encontradas em meio da literatura inglesa, notadamente na obra de Arthur Conan Doyle, em seu personagem mais conhecido, Sherlock Holmes, na história "The Red-Headed League". Este conto foi realçado pelo Lord Mayor of London, Gilbert Inglefield, durante o bicentenário da "Britannica"
A obra goza de reputação popular como o sumário de todo o conhecimento humano. A fim de aprimorar seus conhecimentos, muitos se dedicaram à leitura de toda a enciclopédia, levando de 3 a 22 anos para consegui-lo. Quando Fat'h Ali Shah Qajar se tornou o Xá da Pérsia, em 1797, foi-lhe ofertado um conjunto completo da 3.ª edição da "Britannica", que ele leu na íntegra; depois deste feito, ele estendeu o seu título real, incluindo "O Mais Formidável Senhor e Mestre da "Encyclopædia Britannica"”. O escritor George Bernard Shaw afirma ter lido inteira a 9.ª edição — excepto os artigos científicos — e Richard Evelyn Byrd levou a "Britannica" como material de leitura para a sua estadia de cinco meses no Polo Sul, em 1934. Mais recentemente, A.J. Jacobs, um editor da revista Esquire, leu a versão inteira de 2002 da 15.ª edição, descrevendo as suas experiências num livro, em 2004, intitulado "The Know-It-All: One Man's Humble Quest to Become the Smartest Person in the World" (“O Sabe-tudo: Um homem humilde indaga como se tornar a pessoa mais inteligente do mundo”, em livre tradução). Apenas duas pessoas se conhece como tendo lido duas edições diferentes: o autor C. S. Forester e Amos Urban Shirk, um negociante estadunidense, que leu a 11.ª e a 14.ª edições, dedicando, para isso, cerca de três a quatro horas e meia por noite para ler a 11.ª. Vários editores-chefes da "Britannica" provavelmente leram as suas edições na íntegra, tais como William Smellie (1.ª edição), William Robertson Smith (9.ª edição), e Walter Yust (14.ª edição).
A "Britannica" tem recebido diversas premiações ao longo de sua existência. A versão on-line ganhou, em 2005, o Prêmio Codie para "Melhor Serviço Online de Informação ao Cliente"; os prêmios Codie são concedidos anualmente pela "Software and Information Industry Association" a fim de reconhecer os melhores produtos entre as categorias de software. Em 2006, a "Britannica" foi de novo finalista. Similarmente, a versão CD/DVD-ROM da "Britannica" recebeu, em 2004, o Prêmio de Distinção, pela "Association of Educational Publishers", e prêmio Codie, em 2001 e 2002.
Como enciclopédia generalista, a "Britannica" procura descrever a mais ampla gama de assuntos possível. Os temas são escolhidos, em parte, por referência no "Esboço do Conhecimento" da "Propædia". Grande parte da "Britannica" é dedicada à geografia (26% da "Macropædia"), biografia (14%), biologia e medicina (11%), literatura (7%), física e astronomia (6%), religião (5%), arte (4%), filosofia ocidental (4%), e direito (3%). Um estudo complementar da "Micropædia" descobriu que 25% dos verbetes eram do ramo da geografia, 18% de ciências exatas, 17% das ciências humanas, 17% eram biografias, e 25% sobre todos os outros ramos das humanidades. Em 1992, um revisor escreveu que "o alcance, a profundidade, a exatidão da análise [da "Britannica"] são insuperáveis por qualquer outra enciclopédia generalista."
A "Britannica" não trata os tópicos equivalentes com igual riqueza de detalhes; por exemplo, o verbete Budismo e a maioria das outras religiões são cobertas por um único verbete da "Macropædia", enquanto que 14 verbetes são dedicados ao Cristianismo, representando cerca de metade de todos os verbetes sobre religião. No entanto, tem recebidos louvores por ser considerada a menos "enviesada" de todas as enciclopédias generalistas, comercializadas para leitores ocidentais e prezada pelas suas biografias de mulheres importantes de todas as eras.
A "Britannica" também tem recebido fortes críticas, especialmente quando as suas edições se tornam desatualizadas. É dispendioso produzir uma nova edição, completa, da "Britannica," e os seus editores, em geral, atrasam as novas edições, tanto quanto sensatamente possível (por norma, cerca de 25 anos). Por exemplo, apesar da política de revisão contínua, a 14.ª edição ficou significativamente desatualizada após 35 anos (1929–1964). Quando o físico norte-americano Harvey Einbinder detalhou os seus erros no seu livro de 1964, "The Myth of the Britannica", o feito resultou em que a enciclopédia produziu a 15.ª edição, que requereu dez anos de trabalho. Continua sendo difícil manter a "Britannica" atualizada; um crítico escreveu, recentemente, que "não é difícil encontrar verbetes desatualizados ou a precisar de revisão", constatando que os artigos maiores, da "Macropædia", correm mais riscos de estarem desatualizados do que os mais curtos, da "Micropædia". A informação na "Micropædia" por vezes é inconsistente com a matéria correspondente no verbete da "Macropædia", principalmente porque uma delas está desatualizada. As bibliografias dos artigos da "Macropædia" obtiveram mais críticas por estarem mais desatualizadas do que pelos artigos em si.
Historicamente, dentre os autores da "Britannica"' foram incluídas autoridades eminentes, tais como Albert Einstein, Marie Curie e Leon Trotsky. No entanto, alguns dos seus colaboradores têm sido criticados pela sua falta de conhecimento técnico específico:
Várias autoridades, desde Virginia Woolf até professores académicos, têm criticado a "Britannica" por esta conter opiniões burguesas e antiquadas sobre as artes, a literatura e as ciências sociais. Por exemplo, a 11.ª edição foi acusada de negligenciar a obra de Sigmund Freud. Um professor contemporâneo da Universidade Cornell, Edward B. Titchener, escreveu, "a "Britannica" não reproduz a atmosfera filosófica dos seus dias e sua geração… Apesar da aura de autoridade, e apesar da fiscalização do pessoal, a grande maioria dos artigos secundários, em geral psicologia;… não estão adequados aos parâmetros da cultura do leitor."
Pelos padrões modernos, as edições passadas da "Britannica" contiveram artigos cobertos de racismo e sexismo. A 11.ª edição caracteriza a Ku Klux Klan como que protegendo a raça branca e restaurando a ordem aos Estados Sulistas depois da guerra civil, citando a necessidade de "controlar os negros" para "prevenir qualquer combinação de raças" e "a frequente ocorrência do crime de violação de mulheres brancas, por homens negros." Similarmente, o verbete sobre "Civilização" argumenta sobre eugenia, afirmando que é irracional "propagar pessoas com baixo grau de inteligência, aumentando as fileiras dos pobres, deficientes e criminosos, que hoje em dia constituem obstáculo a ameaçar o progresso racial." A 11.ª edição não biografou Marie Curie, apesar de ela ter recebido o Nobel de Física de 1903 e o Nobel de Química de 1911, embora seja brevemente mencionada na biografia do marido Pierre Curie. A "Britannica" empregava uma vasta equipa feminina, que escreveu centenas de verbetes, pelos quais não obtiveram qualquer crédito.
Em 1912, o matemático L. C. Karpinski criticou a 11.ª edição da "Britannica" pelas suas muitas imprecisões em artigos de história da matemática, nenhum dos quais havia sido escrito por especialistas da área. Em 1917, o crítico de arte Willard Huntington Wright publicou o livro, "Misinforming a Nation", que trouxe a público as imprecisões na língua inglesa da 11.ª edição, particularmente nos verbetes sobre humanidades. Muito das críticas de Wright foram também endereçadas a edições posteriores da "Britannica". No entanto, o seu livro foi acusado de polêmico por alguns órgãos da imprensa de seu tempo; por exemplo, o "New York Times" descreveu-o como "livro maldoso e frívolo", enquanto o "The New Republic" opinava que "é uma infelicidade para o propósito do Sr. Wright, o facto de ter procedido de modo anticientífico e ter justificado tão pouco a sua crítica" Outro crítico, o escritor inglês e antigo padre Joseph McCabe, afirmou em seu livro "Lies And Fallacies of The Encyclopædia Britannica" (1947), que a "Britannica" era susceptível à pressão editorial da Igreja Católica Romana.
A "Britannica" sempre admitiu que os erros eram inevitáveis numa enciclopédia. Falando da 3.ª edição (1788-97), seu editor-chefe George Gleig escreveu que “a perfeição parece ser incompatível com a natureza do trabalho de construir-se algo como este planejado, e que alberga tamanha variedade de assuntos”. Mais recentemente (março de 2006), a Britannica trouxe uma mensagem onde lia-se que “nós nunca insinuamos que a "Britannica" é livre de erros, nunca fizemos tal afirmação”.
O sentimento é expressado pelo editor original da obra, William Smellie:
Desde 1985, a enciclopédia está dividida em quatro partes: a "Micropædia," a "Macropædia," a "Propædia," e os dois volumes do índice. Seus verbetes estão contidos na "Micro-" e "Macropædia" com doze e 17 volumes, respectivamente, cada um deles contendo aproximadamente mil páginas. A versão de 2007 traz 699 artigos na "Macropædia", que variam em tamanho de duas até 310 páginas, contendo referências e nome dos autores; em contrapartida, a "Micropædia" possui cerca de 65 mil verbetes, a grande maioria dos quais (em volta de 97%) contendo menos que 750 palavras, nenhuma referência e nenhum colaborador assinando. Estes artigos foram planejados para oferecer uma informação rápida, e para auxiliar a localização rápida do conteúdo disponível na "Macropædia" que, por sua vez, possui artigos elaborados por autoridades e bem-escritos dentro de cada especialização, contendo dados reunidos sobre o tema que não se encontram noutra parte. O mais longo artigo, com 310 páginas é sobre os Estados Unidos da América, e é resultado da fusão dos artigos de todos os 50 estados. As informações podem ser encontradas seguindo-se as referências cruzadas entre "Micro" e "Macropædia" - embora elas sejam escassas, sendo calculada uma média de uma referência cruzada por página. Conseqüentemente, recomenda-se aos leitores que façam a busca no índice alfabético inicialmente, ou à "Propædia", que organizam o conteúdo geral através de tópicos.
O lema da "Propædia" é "Esboço do Conhecimento" ("Outline of Knowledge"), indicando que pretende realizar uma organização lógica para todo o conhecimento humano. Efetivamente, esse esboço é usado pelos editores da enciclopédia para decidir quais artigos devem ser incluídos nas duas outras subdivisões. Também tem a pretensão de servir de guia ao consulente, sugerindo-lhe os artigos que deverá ler para ter um conhecimento mais aprofundado sobre o tópico. As bibliotecas, entretanto, constataram que este volume é raramente utilizado, e os revisores sugeriram que fosse abolido da enciclopédia. A "Propædia" também possui transparências coloridas da anatomia humana, e vários apêndices contendo a listagem dos membros administrativos, conselheiros e colaboradores de todas as três subdivisões da obra.
Vistas juntas, "Micropædia" e "Macropædia" contêm cerca de 40 milhões de palavras e 24 mil imagens. Os dois volumes de índice têm 2.350 páginas, listando 225.274 tópicos junto com 474.675 sub-entradas sob esses tópicos. A ortografia britânica é preferida sobre a norte-americana, em geral; como exemplo, a palavra "colour" é usada ao invés de "color", "centre" no lugar de "center" e "encyclopaedia" em vez de "encyclopedia". Entretanto, algumas exceções ocorrem, como uso de "defense" ao invés do britânico "defence". A solução alternativa encontrada é o uso de referências cruzadas como em "Color: "see" Colour."
Desde 1936 os artigos são revisados em períodos regulares, considerando que a cada ano ao menos 10% deles sejam revisados. De acordo com um dos sítios da "Britannica", 46% dos artigos são revisados a cada três anos; entretanto, em outro sítio, é informado que apenas 35% dos verbetes sofrem revisão neste período.
A ordenação alfabética dos artigos na "Micro-" e "Macropædia" segue a regras rígidas.
Diacríticos e letras não usadas no inglês são ignorados, enquanto entradas numéricas como ""1812, War of" são ordenadas como se os números fossem escritos na forma cardinal ("Eighteen-twelve, War of"). Verbetes com nomes iguais recebem a seguinte ordem: primeiro as pessoas, depois os lugares e por último as coisas. Governantes com nomes idênticos são seqüenciados primeiro pelo país, e em seguida pela cronologia; Assim, Carlos III da França ("Charles III of France") precede a Carlos I do Reino Unido ("Charles I of England"), por ser listado na "Britannica" como rei da Grã-Bretanha e Irlanda ("Great Britain and Ireland") - ou seja, são listados como se seus nomes fossem escritos assim: "Charles, France, 3" e "Charles, Great Britain and Ireland, 1". De forma similar, os lugares de nomes iguais são organizados alfabeticamente pelos países, e depois pela condição das subdivisões políticas.
Existem diversas edições abreviadas da enciclopédia "Britannica". A "Concise", por exemplo, reúne num só volume 28 mil verbetes curtos que condensam os 32 volumes da edição integral. A "Compton's by Britannica", que incorpora o formato da Enciclopédia Compton, e dirigida a crianças e adolescentes entre 10-17 anos, consiste em 26 volumes e 11 mil páginas.
Outros produtos incluem o "My First Britannica", voltado para crianças entre 6 a 12 anos, e a "Britannica Discovery Library", escrita para crianças com idades de 3 a 6 anos.
Desde 1938 a Encyclopædia Britannica, Inc. edita anualmente o "Book of the Year" ("Livro do Ano"), reunindo os eventos ocorridos no último ano, e que estão disponíveis on-line a partir da edição de 1994 (com os eventos de 1993, portanto).
A companhia ainda edita material especializado de referência, trabalhos como "Shakespeare: The Essential Guide to the Life and Works of the Bard"" ("Shakespeare: O Guia Essecial da Vida e da Obra do Bardo") (Wiley, 2006).
O "Britannica Ultimate Reference Suite 2006 DVD" contém mais de cem mil artigos. Inclui 73.645 artigos da "Britannica" impressa, com restante de material da "Britannica Student Encyclopædia", da "Britannica Elementary Encyclopædia" e do "Britannica Book of the Year" (1993–2004), e ainda alguns artigos "clássicos" das primeiras versões da enciclopédia. O pacote inclui uma gama de conteúdos adicionais, como mapas, vídeos, clipes sonoros, animações e ligações à web. Também oferece ferramentas de estudo e entradas de dicionário e léxico da Merriam-Webster.
A "Encyclopædia Britannica On-line" é um site com mais de 120 mil artigos atualizados regularmente. Possui referências diárias, atualizações e ligação para notícias do "The New York Times" e da "BBC". A assinatura do conteúdo pode ser anual, mensal ou semanal. Planos especiais de assinatura são oferecidos a escolas, faculdades e bibliotecas; estes subscritores institucionais são uma parte importante dos negócios da "Britannica". Alguns artigos têm acesso livre, mas são exibidas apenas algumas linhas de texto. Iniciado no começo de 2007, a "Britannica" vem disponibilizando ligações para artigos com acesso livre, em sítios externos. Tais ligações externas melhoram com frequência o ranking dos artigos nos resultados dos buscadores.
Em 20 de fevereiro de 2007 a "Encyclopædia Britannica, Inc." anunciou que irá trabalhar com a companhia de buscas em telefonia móvel AskMeNow a fim de lançar uma enciclopédia móvel. Os usuários poderão enviar uma pergunta por mensagem de texto, e a AskMeNow procurará num dos 28 mil verbetes da "Britannica" uma resposta concisa para a questão. Tópicos diários, que serão enviados diretamente aos celulares dos usuários, também fazem parte do plano.
A versão impressa de 2007 da "Britannica" ostenta 4.411 colaboradores, com figuras proeminentes, entre eles o Nobel de Economia Milton Friedman, o astrônomo Carl Sagan e o cirurgião Michael DeBakey. Um quarto dos colaboradores já faleceu, alguns há tempo tão distante como em 1947 (caso de Alfred North Whitehead), enquanto outro quarto é aposentado ou emérito. A maioria (98%, aproximadamente), contribui para um único artigo; entretanto, 64 contribuíram em três artigos, 23 ajudaram em quatro, dez contribuíram em cinco e oito contribuíram em mais de cinco verbetes. Uma exceção prolífica foi o Drª. Christine Sutton, da Universidade de Oxford, que contribuiu em 24 artigos sobre física de partículas.
Dale Hoiberg, um sinólogo, é presentemente o vice-presidente sênior e editor-chefe da Britannica. Seus predecessores como editores-chefes foram Hugh Chisholm (1902–1924), James Louis Garvin (1926–1932), Franklin Henry Hooper (1902–1938), Walter Yust (1938–1960), Harry Ashmore (1960–1963), Warren E. Preece (1964–1968, 1969–1975), Sir William Haley (1968–1969), Philip W. Goetz (1979–1991), e Robert McHenry (1992–1997). Anita Wolff e Theodore Pappas são editora assistente e editor executivo, respectivamente. Editores executivos anteriores incluem John V. Dodge (1950–1964) e Philip W. Goetz.
A "Britannica" mantém um departamento editorial com cinco editores seniores, e nove editores associados, supervisado por Dale Hoiberg e outros quatro. O departamento editorial auxilia na autoria dos artigos da "Micropædia" e nalgumas seções da "Macropædia".
A "Britannica" possui um quadro de conselheiro editoriais, que correntemente inclui 14 acadêmicos distintos:
A "Propædia" e seu "Outline of Knowledge" são feitos por dúzias de conselheiros editoriais sob a direção de Mortimer J. Adler. Metade destes conselheiros já é falecida, incluindo antigos chefes dos editores dessa seção: René Dubos (m. 1982), Loren Eiseley (m. 1977), Harold D. Lasswell (m. 1978), Mark Van Doren (m. 1972), Peter Ritchie Calder (m. 1982) e Mortimer J. Adler (m. 2001). A "Propædia" lista ainda quatro mil colaboradores que foram consultados, mas que não assinaram os artigos da "Micropædia".
Em janeiro de 1996, a "Britannica" pertencente à Benton Foundation (Fundação Benton), foi comprada pelo milionário suíço das finanças Jacqui Safra, e que atualmente é o presidente do quadro administrativo. Em 1997, Don Yannias, sócio de longa data e conselheiro de negócios de Safra, tornou-se o executivo-chefe da Encyclopædia Britannica, Inc.. Uma nova companhia, a Britannica.com Inc., foi iniciada em Spin-off em 1999, para desenvolver uma versão digital da "Britannica", tendo Yannias a chefia desse empreendimento, enquanto o cargo equivalente da Encyclopædia Britannica, Inc. permaneceu acéfalo por dois anos. A gestão de Yannias deu prejuízos, grandes demissões e perdas financeiras. Em 2001, ele foi finalmente substituído por Ilan Yeshua, que reuniu a direção das duas companhias. Yannias retornou mais tarde como administrador financeiro, mas não mais integrou o Conselho de Administração da "Britannica".
Em 2003, o então consultor administrativo Jorge Aguilar-Cauz foi nomeado presidente da Encyclopædia Britannica, Inc. Cauz é executivo sênior e reporta-se diretamente ao Conselho Administrativo da empresa. Apesar de seu estilo dominador e acadêmico, realizou alianças agressivas com outras empresas e estendeu a marca Britannica como um marco e como produto de referência educativa, continuando uma estratégia iniciada ainda em meados dos anos 30 por seu predecessor Elkan Harrison Powell.
Sob a propriedade de Safra a companhia sofreu dificuldades financeiras, o que foram enfrentadas com a redução dos preços de seus produtos e implementação de drásticos cortes de gastos. De acordo com um relatório de 2003 do "New York Post", a administração da "Britannica" demitiu os empregados do plano 401(k) e encorajou o uso de imagens sem direito autoral. Estas mudanças, porém, tiveram impactos negativos, como por exemplo a demora de seis meses no pagamento dos colaboradores independentes, e seu pessoal passou vários anos sem melhoria de salários
A Encyclopædia Britannica, Inc. possui atualmente as marcas registradas das palavras "Britannica", "Encyclopædia Britannica", "Macropædia", "Micropædia", e "Propædia", como também do seu logotipo em formato de cardo. Vem exercendo seus direitos de copyright desde 2005
Por ser uma obra genérica, a "Britannica" não compete com enciclopédias especializadas, como por exemplo uma "Encyclopaedia of Mathematics" ou um "Dictionary of the Middle Ages" ("dicionário da Idade Média"), obras que podem dedicar muito mais espaço aos temas específicos de que tratam. Em seus primeiros anos, o principal concorrente, em língua inglesa, era a enciclopédia geral de Ephraim Chambers e, logo após, "Rees's Cyclopaedia" e a "Encyclopaedia Metropolitana", de Coleridge. No século XX, os mais diretos competidores foram "Collier's Encyclopedia," a "Encyclopedia Americana," e o "World Book Encyclopedia". Cada uma dessas publicações tinha qualidades para tornar-se excelente, com escrita excepcionalmente clara ou ilustrações soberbas. Não obstante, era consideração geral que a "Britannica" possuía maior autoridade do que qualquer outra enciclopédia em língua inglesa, especialmente em razão de sua extensa abrangência e por possuir em seus quadros autores eminentes. Entretanto, a versão impressa da Britannica é mais cara do que a de seus competidores.
Desde o começo dos anos 90 que a "Britannica" enfrenta o desafio de novas fontes de informação digitais. A internet, facilitada com o desenvolvimento dos sistemas de busca, cresceu como uma fonte comum de informação para muitas pessoas, provendo acesso fácil e rápido a fontes originais seguras e opiniões de expertos, graças em parte a iniciativas como o Google Books, o MIT e seu "MIT OpenCourseWare", e ainda a "PubMed Central" - uma biblioteca livre da National Library of Medicine. Em geral, a internet tende a prover cobertura mais atual do que a mídia impressa, devido à facilidade de atualização. Em campos com rápidas mudanças tal como ciência, tecnologia, política, cultura e história moderna, a "Britannica" luta para manter-se atualizada, um problema que foi sistematicamente analisado, inicialmente por seu ex-editor Walter Yust. Embora a enciclopédia esteja disponível atualmente em multimídia e ainda na internet, sua primazia é desafiada por outras enciclopédias on-line, como a "Encarta" e a "Wikipédia".
A "Encyclopædia Britannica" foi comparada com outras enciclopédias impressas, tanto qualitativa como quantitativamente. O comparativo mais famoso foi feito em nos anos 90 por Kenneth Kister, que traçou um paralelo desta com a "Collier's Encyclopedia" e a "Encyclopedia Americana". Para a análise "quantitativa", dez artigos foram escolhidos ao acaso: circuncisão, Charles Drew, Galileu, Philip Glass, cardiopatia ("doenças cardíacas"), QI, urso panda, assédio sexual, Santo Sudário e Uzbequistão - e notas (A-D, F) foram atribuídas em quatro categorias: amplitude, precisão, clareza e atualização. Em todas as quatro categorias avaliadas, e para as três enciclopédias, as médias atribuídas ficaram entre B- e B+, principalmente porque nenhuma delas apresentava, em 1994, nenhum verbete sobre assédio sexual. Na categoria precisão, a "Britannica" recebeu um "D" e oito "A"s. A "Encyclopedia Americana" teve oito "A"s, e a "Collier's" recebeu um "D" e sete "A"s; Assim a "Americana" ficou com 95%, enquanto as duas outras tiveram 92% no quesito "precisão". A edição de 1994 da "Britannica" falhou por publicar uma história polêmica sobre Charles Drew, que havia sido desmentida há muito tempo. No quesito cronologia, a "Britannica" recebeu aprovação de 86%, a "Americana" 90% e a "Collier's" 85%. Depois de uma análise comparativa mais completa entre as três enciclopédias, Kister recomendou a "Collier's Encyclopedia" como a superior entre as três, considerando principalmente a escrita excelente, apresentação equilibrada e facilidade na consulta.
O mais notável competidor da "Britannica" em matéria de enciclopédias digitais em CD/DVD-ROM é a Encarta, uma moderna enciclopédia de multimédia que incorpora três enciclopédias impressas: "Funk and Wagnalls", "Collier's" e "New Merit Scholar". A "Encarta" é a mais vendida enciclopédia multimédia, tomando por base a venda a varejo no mercado norte-americano entre janeiro de 2000 a fevereiro de 2006
Ambas ocupam a mesma faixa de preços, sendo que em 2007 o último CD ou DVD da "Encyclopædia Britannica" valia 50 dólares estadunidenses e o DVD da "Microsoft Encarta Premium 2007" valia 45 dólares estadunidenses. A "Britannica" possui cem mil artigos, além do Dicionário "Merriam-Webster" (somente na edição norte-americana), e oferece edições mais simplificadas para as escolas primárias e secundárias. A "Encarta" possui 66 mil verbetes, uma interface amigável personalizada, mapas interativos, matemática, gramática e ferramentas para trabalhos escolares, dicionários de língua inglesa em versões dos EUA e do Reino Unido, e uma edição para jovens. Assim como a "Encarta", a "Britannica" foi criticada por ter edição parcial, dirigida ao público estadunidense; verbetes referentes ao Reino Unido são bem menos atualizados, os mapas dos EUA são mais detalhados que dos demais países e falta um dicionário do Reino Unido.
As duas enciclopédias estão disponíveis on-line por assinatura, embora mantenham parte do conteúdo para livre acesso.
Alternativas on-line para a "Britannica" incluem a Wikipédia, uma iniciativa livre e pioneira na Web, com conteúdo livre. A "Wiki" recebe um tráfego 450 vezes maior que a versão on-line da "Britannica", segundo estatísticas independentes de visita em páginas feitas pela Alexa, nos primeiros três meses de 2007. Julgando pelos mais recentes dados de número de artigos ou palavras, a versão anglófona da "Wikipédia" é 20 vezes maior que a "Britannica".
Uma diferença fundamental entre as duas enciclopédias reside na autoria dos verbetes. Os 699 artigos da Macropædia em geral são produzidos por colaboradores identificados, e os 65 mil da Micropædia são fruto do corpo editorial e identifica apenas os consultores. Assim, um verbete da "Britannica" ou identifica seu autor ou um grupo de possíveis autores (o corpo editorial). Com exceção destes últimos, a maioria dos colaboradores da "Britannica" é de peritos em suas áreas, inclusive com laureados pelo prêmio Nobel. Em contrapartida, os artigos da "Wikipédia" são escritos por uma comunidade de editores de níveis variados de conhecimento: a maioria dos editores não atribui nenhuma especialização em particular; dentre aqueles que o fazem, muitos são anônimos e não possuem alguma credencial verificável.
Outra diferença é a velocidade de mudanças nos verbetes: a "Britannica" é publicada em modo impresso em intervalos de poucos anos, ao passo em que os artigos da "Wiki" mudam com frequência. Esta vem recebendo críticas em vários aspectos, e argumenta-se que não se pode esperar que venha competir com a "Britannica" em termos de precisão.
Em 14 de dezembro de 2005, o jornal científico "Nature" informou que existiam 162 erros na "Wikipédia" contra 123 na "Britannica", dentro de 42 verbetes sobre ciências gerais, fortuitamente selecionados. Em sua réplica, detalhada em 20 páginas, a Encyclopædia Britannica, Inc. caracterizou o estudo da "Nature" como falho e enganado, e exigiu uma "imediata" retratação. Observou que dois dos artigos eram estudos feitos pelo "livro do ano" da edição, e não eram enciclopédicos; outros dois pertenciam à "Compton's Encyclopedia" (chamadas pelo sítio oficial da companhia de "Britannica Student Encyclopedia" - "enciclopédia estudantil"). A refutação menciona que alguns dos artigos apreciados pelos revisores eram combinados de vários verbetes, e que os outros artigos eram apenas excertos e foram penalizados por omissões factuais. A companhia também observou que vários fatos classificados pela "Nature" como erros eram variações menores de ortografia, e vários dos demais alegados erros eram questão de interpretação. A "Nature" defendeu sua publicação e não se retratou, declarando ainda que, como estava a comparar a "Wikipédia" com a versão na rede da "Britannica", utilizou-se do material que esta última disponibilizava em seu sítio da Web.
A Barsa, fundada no Brasil em 1949, hoje pertence ao grupo espanhol Planeta. Embora seu conteúdo seja oriundo da original da matriz, a marca acabou adquirindo uma identidade própria, a ponto de tornar-se a mais importante enciclopédia lusófona. Foi editada no país sob os auspícios da Encyclopædia Britannica do Brasil Publicações Ltda. Na década de 1970, sob a direção do Imortal da ABL, Antônio Houaiss, lançou a Enciclopédia Mirador Internacional
Alguns produtos tiveram existência curta devido à evolução tecnológica, como foi o caso da "Videopédia". Dentre os principais produtos da Barsa estão:
Composta em três mídias distintas, a enciclopédia possui atualizações semanais pela Internet, através de seu sítio. Possui um “Conselho Acadêmico” do qual fazem parte catorze universidades.
Possui mais de 122 mil verbetes, dos quais 500 são desenvolvidos para concentrar as informações temáticas, ilustrada em mais de dez mil fotografias, 900 desenhos, 500 mapas e 300 tabelas
A Barsa Society possui diversos lançamentos em várias mídias. São produtos como livros de Direito, Enciclopédia Multimédia do corpo humano (em 6 cd-roms) , tradutores etc.
A Barsa está presente em vários países de língua castelhana, como Argentina, Chile, Espanha, México e Venezuela e também em Portugal.
Sítio oficial
Verbetes históricos
Edições anteriores (em domínio público nos EUA)
Eventos recentes
Histórico da empresa

Esta é uma lista de escultores.

Em ciência da computação, uma expressão regular (ou os estrangeirismos regex ou regexp
, abreviação do inglês "regular expression") provê uma forma concisa e flexível de identificar cadeias de caracteres de interesse, como caracteres particulares, palavras ou padrões de caracteres. Expressões regulares são escritas numa linguagem formal que pode ser interpretada por um processador de expressão regular, um programa que serve um gerador de analisador sintático ou examina o texto e identifica as partes que casam com a especificação dada.
O termo deriva do trabalho do matemático norte-americano Stephen Cole Kleene, que desenvolveu as expressões regulares como uma notação ao que ele chamava de álgebra de conjuntos regulares. Seu trabalho serviu de base para os primeiros algoritmos computacionais de busca, e depois para algumas das mais antigas ferramentas de tratamento de texto da plataforma Unix.
O uso atual de expressões regulares inclui procura e substituição de texto em editores de texto e linguagens de programação, validação de formatos de texto (validação de protocolos ou formatos digitais), realce de sintaxe e filtragem de informação.
Uma expressão regular (ou, um padrão) descreve um conjunto de cadeias de caracteres, de forma concisa, sem precisar listar todos os elementos do conjunto. Por exemplo, um conjunto contendo as cadeias ""Handel", "Händel" e "Haendel" pode ser descrito pelo padrão codice_1. A maioria dos formalismos provê pelo menos três operações para construir expressões regulares.
Uma barra vertical (codice_2) separa alternativas. Por exemplo, codice_3 pode casar "psicadélico" ou "psicodélico".
Parênteses (codice_4, codice_5) são usados para definir o escopo e a precedência de operadores, entre outros usos. Por exemplo, codice_3 e codice_7 são equivalentes e ambas descrevem "psicadélico" e "psicodélico".
Um quantificador após um "token" (como um caractere) ou agrupamento especifica a quantidade de vezes que o elemento precedente pode ocorrer. Os quantificadores mais comuns são o ponto de interrogação codice_8, o asterisco codice_9 e o sinal de adição codice_10.
codice_8 indica que há zero ou uma ocorrência do elemento precedente. Por exemplo, codice_12 casa tanto "acção" quanto "ação". codice_9 indica que há zero ou mais ocorrências do elemento precedente. Por exemplo, codice_14 casa "ac", "abc", "abbc", "abbbc", e assim por diante.
codice_10 indica que há uma ou mais ocorrências do elemento precedente. Por exemplo, codice_16 casa "abc", "abbc", "abbbc", e assim por diante, mas não "ac"".
Essas construções podem ser combinadas arbitrariamente para formar expressões complexas, assim como expressões aritméticas com números e operações de adição, subtração, multiplicação e divisão. De forma geral, há diversas expressões regulares para descrever um mesmo conjunto de cadeias de caracteres. A sintaxe exata da expressão regular e os operadores disponíveis variam entre as implementações.
A origem das expressões regulares está na teoria dos autômatos e na teoria das linguagens formais, e ambas fazem parte da teoria da computação. Esses campos estudam modelos de computação (autômatas) e formas de descrição e classificação de linguagens formais. Na década de 1950, o matemático Stephen Cole Kleene descreveu tais modelos usando sua notação matemática chamada de "conjuntos regulares", formando a álgebra de Kleene. A linguagem SNOBOL foi uma implementação pioneira de casamento de padrões, mas não era idêntica às expressões regulares. Ken Thompson construiu a notação de Kleene no editor de texto QED como uma forma de casamento de padrões em arquivos de texto. Posteriormente, ele adicionou essa funcionalidade no editor de texto Unix ed, que resultou no uso de expressões regulares na popular ferramenta de busca grep. Desde então, diversas variações da adaptação original de Thompson foram usadas em Unix e derivados, incluindo expr, AWK, Emacs, vi e lex.
As expressões regulares de Perl e Tcl foram derivadas da biblioteca escrita por Henry Spencer, e no Perl a funcionalidade foi expandida posteriormente. Philip Hazel desenvolveu a PCRE (Perl Compatible Regular Expressions), uma biblioteca usada por diversas ferramentas modernas como PHP e o servidor Apache. Parte do desenvolvimento do Perl 6 foi melhorar a integração das expressões regulares de Perl, e aumentar seu escopo e funcionalidade para permitir a definição de gramáticas de expressão de analisadores sintáticos. O resultado foi uma mini-linguagem, as regras do Perl 6, usada para definir a gramática do Perl 6 assim como fornecer uma ferramenta para programadores da linguagem. Tais regras mantiveram as funcionalidades de expressões regulares do Perl 5.x, mas também permitiram uma definição BNF de um analisador sintático descendente recursivo.
O uso de expressões regulares em normas de informação estruturada para a modelagem de documentos e bancos de dados começou na década de 1960, e expandiu na década de 1980 quando normas como a ISO SGML foram consolidadas.
Expressões regulares podem ser expressas através da teoria de linguagens formais. Elas consistem de constantes e operadores que denotam conjuntos de cadeias de caracteres e operações sobre esses conjuntos, respectivamente. Dado um alfabeto finito Σ, as seguintes constantes são definidas:
As seguintes operações são definidas:
As constantes e os operadores acima formam a álgebra de Kleene.
Para evitar parênteses, é assumido que o fecho de Kleene possui a maior prioridade, depois a concatenação e por fim a alternância. Se não houver ambiguidades, os parênteses podem ser omitidos. Por exemplo, codice_17 pode ser escrito como codice_18, e codice_19 pode ser escrito como codice_20.
A definição formal de expressões regulares é concisa e evita a utilização dos quantificadores redundantes codice_8 e codice_10, que podem ser expressados respectivamente por codice_26 e codice_27. Por vezes o operador de complemento ~ é adicionado; ~"R" denota o conjunto das cadeias de caracteres de Σ* que não estão em "R". Esse operador é redundante, e pode ser expressado usando outros operadores, apesar da computação para tal representação ser complexa.
Expressões regulares podem expressar linguagens regulares, a classe de linguagens aceita por um autômato finito. Entretanto, há uma diferença significativa na compactação. Algumas classes de linguagens regulares podem ser descritas somente por autômatos que crescem exponencialmente em tamanho, enquanto o tamanho das expressões regulares requeridas só pode crescer linearmente. Expressões regulares correspondem ao Tipo-3 das gramáticas da Hierarquia de Chomsky. Por outro lado, existe um mapeamento simples de expressões regulares para máquinas de estado finito não-determinísticas que não leva ao crescimento desgovernado do tamanho. Por essa razão, essas máquinas não determinísticas são geralmente usadas como representação alternativa das expressões regulares.
É possível escrever um algoritmo que, para duas expressões regulares dadas, decide se as linguagens descritas são essencialmente iguais. Reduz-se cada expressão na máquina de estado finito mínima, e determina-se se ambas as máquinas mínimas são isomórficas (equivalentes).
Vale notar que diversas implementações de expressões regulares implementam funcionalidades que não podem ser expressadas na álgebra de Kleene; ver abaixo mais sobre o assunto.
De 1986, a norma IEEE POSIX 1003.2 (POSIX.2) padroniza expressões regulares, e fornece duas especificações, a saber:
A sintaxe tradicional de expressões regulares em Unix seguiu convenções comuns, mas diferiu entre as implementações. A norma IEEE POSIX BRE ("Basic Regular Expressions", do inglês, expressões regulares básicas) foi desenvolvida primordialmente por compatibilidade com a sintaxe tradicional, mas fornecia uma norma comum que desde então foi adotada por diversas ferramentas.
Na sintaxe de BRE, a maioria dos caracteres são tratados como literais — eles casam somente com eles próprios (por exemplo, codice_28 casa "a"). As exceções são chamadas metacaracteres ou metassequências, definidos abaixo:
Uma característica da BRE é que os metacaracteres geralmente exigem barras invertidas para serem tratador como tal. Por exemplo, em BRE, codice_29 é composto somente por literais, e casará somente "a{1,2}"". Para casar entre uma a duas ocorrências de "a", deve-se usar a expressão regular codice_30. A motivação desse sistema é a compatibilidade com sistemas antigos, já que na época da padronização já havia código Unix legado que usava chaves como literais.
O significado dos metacaracteres serem escapados com a barra invertida é revertido na sintaxe POSIX ERE ("Extended Regular Expression", do inglês, expressões regulares estendidas). Isso significa que não são usadas barras invertidas para identificar metacaracteres. Pelo contrário, elas servem justamente para transformar metacaracteres em literais. Retomando o exemplo da seção anterior, em ERE, codice_29 casa uma a duas ocorrências de "a", enquanto codice_30 casa o literal "a{1,2}".
Os seguintes metacaracteres foram adicionados:
Ferramentas que adotaram a sintaxe incluem MySQL e PHP, esta, que suporta também as derivações de Perl no modelo do PCRE.
Já que diversos grupos de caracteres dependem duma configuração de locale específica, a POSIX define algumas classes (ou categorias) de caracteres para fornecer um método padrão de acesso a alguns grupos específicos de caracteres bastante utilizados, como mostrado na seguinte tabela:
Notar que as doze classes definidas acima também estão definidas na biblioteca padrão do C, na seção de funções de testes de caracteres do cabeçalho codice_33.
Tais classes só podem ser usadas dentro de expressões de listas de caracteres. Diferentes locales podem fornecer classes adicionais. Uma extensão não POSIX difundida é codice_34 (atalho do Perl codice_35), geralmente definida como codice_36 ou traço baixo (codice_37) e codice_38, contendo somente caracteres ASCII (codice_39).
Pode-se negar uma classe de caracteres precedendo um acento circunflexo ao nome da classe. Por exemplo, para negar codice_40 usa-se codice_41.
A norma POSIX define ainda dois metacaracteres especiais que servem para casar os limites de palavras nas cadeias de caracteres. Nesse contexto da POSIX, uma palavra é formada por caracteres codice_36 ou traço baixo (codice_37). Assim como as âncoras, esses metacaracteres não casam pedaços do texto, elas servem apenas como uma referência. Eles são:
Perl possui uma sintaxe mais consistente e rica que as normas POSIX BRE e ERE. Um exemplo é que codice_44 sempre escapa um caractere não alfanumérico. Devido ao poder de expressão, outras ferramentas adotaram a sintaxe do Perl, como por exemplo Java, JavaScript, PCRE, Python, Ruby e .NET. Algumas linguagens e ferramentas como PHP suportam diversos tipos de expressões regulares.
Um exemplo de funcionalidade possível em Perl mas não em POSIX é a quantificação preguiçosa. Os quantificadores padrões das expressões regulares são "gananciosos", isto é, casam o quanto puderem, voltando atrás somente se necessário para casar o resto da expressão regular. Por exemplo, um novato no assunto tentando encontrar a primeira instância de um item entre os símbolos < e > no texto ""Outra explosão ocorreu em <26 de janeiro> de <2004>" provavelmente usaria o padrão codice_45, ou similar. Entretanto, esse padrão retornará "<26 de janeiro> de <2004>" ao invés de "<26 de janeiro>", como esperado, pois o quantificador codice_9 é ganancioso — ele consumirá a quantidade máxima de caracteres, e "26 de janeiro> de <2004" possui mais caracteres que "26 de janeiro".
Apesar desse problema ser evitável de diferentes formas (por exemplo, especificando o que não casar: codice_47), a maioria das ferramentas permitem que um quantificador seja preguiçoso, ou não ganancioso, ao suceder o quantificador com um ponto de interrogação. No exemplo anterior, a alternativa seria codice_48. Seguem os quantificadores não gulosos:
O PERL define algumas sequências de escape que servem como atalhos para certos metacaracteres:
Além dos quantificadores preguiçosos e das novas sequências de escape, o Perl também adicionou uma forma nova de casamento de padrões que estendem a POSIX. São um conjunto de metacaracteres que seguem o padrão codice_49, listados abaixo:
Diversas funcionalidades encontradas em bibliotecas atuais de expressões regulares provem um poder de expressão que excede as linguagens regulares. Por exemplo, a habilidade de agrupar subexpressões com parênteses e chamar novamente o valor casado na mesma expressão significa que o padrão pode casar cadeias de palavras repetidas como "papa" ou "WikiWiki"", os chamados quadrados na teoria de linguagens formais. O padrão para essas cadeias é codice_50. Entretanto, a linguagem de quadrados não é regular, nem livre de contexto. Casamento de padrões com um número indeterminado de referências anteriores, como suportado em ferramentas atuais, é NP-difícil.
Entretanto, as ferramentas que fornecem tais construções ainda usam o termo expressões regulares para os padrões, o que leva a uma nomenclatura que difere da teoria das linguagens formais. Por essa razão, algumas pessoas usam o termo "regex" ou simplesmente "padrão" para descrever esse conceito mais abrangente.
Existem pelo menos dois algoritmos fundamentalmente diferentes entre si que decidem se e como uma expressão regular casa uma cadeia de caracteres.
O mais antigo e mais rápido faz uso dum princípio da teoria de linguagens formais que permite a todas as máquinas de estado finito não determinísticas serem transformadas em máquinas de estado finito determinísticas. Geralmente chamado de DFA, o algoritmo realiza ou simula tal transformação e então executa a máquina determinística resultante na cadeia de caracteres, um símbolo de cada vez. Esse último processo tem complexidade linear relativa ao tamanho da cadeia de caracteres. Mais precisamente, uma cadeia de caracteres de tamanho "n" pode ser testada numa expressão regular de tamanho "m" no tempo "O"("formula_1") ou "O"("formula_2"), dependendo dos detalhes de implementação. Esse algoritmo é rápido, mas pode ser usado somente para casamentos e não para a nova chamada de grupos de captura, quantificação preguiçosa e diversas outras funcionalidades encontradas nas bibliotecas modernas de expressões regulares. Também é possível executar a máquina não determinística diretamente, construindo cada estado da máquina determinística quando necessário e então descartando-o no próximo passo. Isso evita a quantidade exponencial de memória necessária para a construção completa da máquina determinística, ainda que garantindo a busca em tempo linear.
O outro algoritmo é casar o padrão com a cadeia de caracteres através de "backtracking". Geralmente chamado de NFA, Seu tempo de execução pode ser exponencial, o que pode acontecer em implementações simples no casamento de expressões como codice_51, que forçam o algoritmo a considerar um número exponencial de subcasos. Implementações modernas geralmente identificam tais casos, e aceleram e abortam a execução. Apesar dessas implementações com "backtracking" garantirem tempo exponencial no pior caso, elas fornecem mais flexibilidade e poder de expressão.
Originalmente, as expressões regulares eram usadas com caracteres ASCII, mas várias implementações atuais suportam Unicode. Na maioria dos casos não há diferença entre conjuntos de caracteres, mas algumas questões são relevantes ao suportar Unicode.
Uma delas é a codificação suportada, já que algumas implementações esperam UTF-8, enquanto outras podem esperar UTF-16 ou UTF-32. Outra questão é estender as funcionalidades disponíveis para ASCII no Unicode. Por exemplo, em implementações ASCII, conjuntos de caracteres na forma codice_52 são válidos para quaisquer "x" e "y" no intervalo [0x00,0x7F] desde que o código de "x" seja menor que o código de "y". A escolha natural seria permitir o mesmo em Unicode no intervalo de códigos [0,0x10FFFF], o que não é possível pois algumas implementações não permitem que conjuntos de caracteres ultrapassem os blocos de código disponíveis.
Do ponto de vista dos detalhes técnicos do Unicode, também surgem questões. Como a normalização, pois, em Unicode, mais de um código pode representar o mesmo caractere. Por exemplo, o caractere "é" pode ser representado por U+0065 (letra latina "e" minúsculo) combinado com U+0301 (diacrítico "acento agudo"), mas também pode ser representado como U+00E9 (letra latina "e" com diacrítico "acento agudo"). Também há os códigos de controle Unicode, as marcas de ordem de byte e as marcas de direção de texto, que devem ser tratados separadamente.
Expressões regulares são usadas por diversos editores de texto, utilitários e linguagens de programação para procurar e manipular texto baseado em padrões. Por exemplo, Perl e Tcl possuem suporte a expressões regulares nativamente. Diversos utilitários de distribuições Unix incluem o editor de texto ed, que popularizou o conceito de expressão regular, e o filtro grep.
Outro uso é a validação de formatos de texto (validação de protocolos ou formatos digitais). Por exemplo, ao receber a entrada dum campo de formulário duma aplicação que supõe receber um endereço de "email", pode-se usar uma expressão regular para garantir que o que foi recebido de fato é um endereço de "email".
Mais um uso é a implementação interna dum sistema de realce de sintaxe, como encontrado em ambientes de desenvolvimento integrado. Expressões regulares podem ser usadas para encontrar palavras reservadas, literais e outros tokens específicos, e para alterar a formatação do texto de acordo com o casamento feito.
Um uso difundido de expressões regulares é a filtragem de informação em bancos de dados de texto. Por exemplo, num arquivo de texto contendo cadastros de pessoas e suas datas de aniversário como a seguir:
Pode-se filtrar pessoas que nasceram num determinado ano, mês ou dia. Por exemplo, o uso do padrão codice_53 identifica o nome das pessoas que nasceram em outubro (mês 10). Para o cadastro acima seriam retornados dois grupos de captura, codice_54 contendo ""João Alberto" e codice_55 contendo "Carlos Silva". Explorando o exemplo anterior e o uso de validação de formatos digitais, é possível usar expressões regulares para validar as datas presentes no arquivo de texto de aniversários acima. O padrão codice_56 é usado para validar uma data entre 1900-01-01 e 2099-12-31. Atentar que a separação entre ano, mês e dia pode se dar através de hífen, espaço em branco, barra ou ponto. Mas deve-se usar o mesmo símbolo de separação entre ano e mês e entre mês e dia, o que é possível através da nova chamada do grupo de captura anterior (o trecho codice_55 do padrão). Atentar também que o padrão é incompleto na medida em que não diferencia a quantidade de dias em cada mês, o que resulta no casamento de até "2000-02-31"" (31 de fevereiro), incorreta de acordo com o calendário gregoriano.

"O artigo Eventos redireciona para esta página. Para ver outros conceitos homônimos, veja Evento."
Entretenimento ou entretimento é qualquer ação, evento ou atividade com o fim de entreter e suscitar o interesse de uma audiência. É a presença de uma audiência que torna qualquer atividade privada de recreação ou lazer em entretenimento. A audiência pode ter um papel passivo, como quando se assiste a uma peça teatral, ópera, programa de televisão ou filme; ou um papel ativo, como no caso dos jogos. O entretenimento pode ser público ou privado e envolver uma atuação formal e pré-determinada, como no caso do teatro ou dos concertos, ou uma atuação espontânea, como no caso dos jogos. Muitas das formas de entretenimento são transversais ao longo da História e das culturas e evoluem em função das alterações culturais e tecnológicas. Os filmes e os jogos eletrônicos, por exemplo, embora façam uso de novos suportes e "media", continuam a narrar histórias e a fazer uso da música. Os festivais dedicados à música, cinema ou dança permitem o entretenimento de uma audiência ao longo de vários dias consecutivos.
Algumas das atividades que outrora foram consideradas entretenimento, como as execuções públicas, foram sendo sucessivamente removidas da esfera pública. Outras atividades que ao longo da História foram competências essenciais de determinadas profissões, como o manejo de espadas ou o tiro com arco, são hoje desportos de competição, tornando-se ao mesmo tempo formas de entretenimento à medida que se tornam apelativos para uma audiência cada vez maior. O que um grupo ou indivíduo interpreta como entretenimento pode ser encarado como trabalho por outros.
O entretenimento proporciona divertimento, satisfação pessoal e boa disposição. Em determinadas circunstâncias e contextos, o entretenimento tem adjacente um propósito sério, como no caso de celebrações, festividades religiosas ou sátiras. Como tal, existe a possibilidade de que o que aparenta ser entretenimento possa também ser uma forma de desenvolvimento cultural e intelectual. O apelo do entretenimento, a par com a sua capacidade de usar diferentes "media" e do seu potencial para adaptações criativas, tem assegurado a continuidade e longevidade de muitas formas, temas, imagens e estruturas sociais.
O entretenimento é diferente de atividades como a educação ou o "marketing", embora essas atividades tenham aprendido a recorrer ao apelo do entretenimento como ferramenta auxiliar. A importância e o impacto do entretenimento é reconhecida no meio acadêmico e a sua crescente sofisticação tem influenciado a prática em campos tão diversos como a museologia.
A psicologia determina que a função do entretenimento é a obtenção de gratificação pessoal ou coletiva. Normalmente, não se espera mais nenhum resultado ou benefício quantificável. O entretenimento tem mecanismos opostos à educação, a qual é concebida com a função de desenvolver as capacidades de compreensão ou de ajudar as pessoas na aprendizagem, e do "marketing", cuja função é aliciar as pessoas a comprar produtos. No entanto, a fronteira tem-se tornado ténue à medida que a educação procura incorporar elementos recreativos e o entretenimento e o "marketing" procuram incorporar elementos educativos. Estas simbioses são conhecidas pelos neologismos de "edutainment" ou "infotainment". No entanto, muitas situações em que se combina entretenimento com educação são tentativas sérias de conjugar as melhores valências de cada um.
O entretenimento pode ir para além da simples gratificação e ser um veículo de transmissão de elementos culturais na audiência. Muitas das grandes questões filosóficas e existenciais podem proporcionar uma infinidade de narrativas, apresentadas na forma de histórias, argumentos de cinema ou teatro, poesia, literatura, dança, banda desenhada ou jogos. Entre as obras dramáticas que articulam questões filosóficas contam-se exemplos tão diversos como o influente Hamlet de Shakespeare, que explora temas como a traição, vingança, incesto, corrupção e moralidade, ou The Matrix, que explora a natureza do conhecimento. Os romances proporcionam igualmente um vasto leque de exploração de questões filosóficas ao mesmo tempo que entretêm os leitores. Um dos exemplos de uma obra criativa que apresenta questões filosóficas de forma entretida é "The Hitchhiker's Guide to the Galaxy"; inicialmente um programa de humor radiofónico, a história tornou-se tão popular que foi adaptada para a literatura, cinema, televisão, teatro, banda desenhada, "audiobook", jogos eletrónicos, e traduzida para várias línguas. Os temas apresentados vão desde o sentido da vida à ética do entretenimento, inteligência artificial, Deus ou métodos filosóficos.
A narração de histórias desempenha um papel importante na maior parte das formas de entretenimento desde a pré-história, e cujo método simples ainda hoje é um comportamento cultural frequente.
A mesma peça dramática pode ser apresentada num teatro ao ar livre, num "music hall", numa sala de cinema ou através de um dispositivo eletrónico pessoal, como um "tablet". A alteração do contexto histórico, cultural, tecnológico e económico influencia a escolha ou a preferência por determinados recintos de entretenimento, embora as características principais de cada um deles pouco se tenha alterado ao longo dos séculos. Desde a antiguidade que existem estruturas arquitetónicas dedicadas em exclusivo às formas de entretenimento, como teatros, auditórios e estádios. Um dos recintos mais notáveis é o Coliseu de Roma, onde eram apresentados ao público espetáculos, competições, corridas e desportos.
Algumas formas de entretenimento tornaram-se controversas, tendo algumas sido proibidas. A caça de animais selvagens é ainda hoje vista por alguns como entretenimento, embora outras formas de entretenimento com recurso a animais se tenham tornado extremamente controversas. A caça desportiva, enquanto forma de entretenimento público e espetáculo, foi introduzida no Império Romano a partir de Cartago.
Algumas das formas de entretenimento, sobretudo música e peças dramáticas, deram origem a inúmeras variantes de forma a responder a um vasto leque de preferências pessoais e expressões culturais. Muitas das formas de entretenimento estão incorporadas ou são apoiadas por outras formas. Por exemplo, muitas das peças dramáticas recorrem à música para realçar a sua expressividade. Outras formas incorporam jogos ou desporto de forma a serem mais atrativas. É relativamente comum que a origem de algumas formas de entretenimento tenham tido origem em atividades tidas como sérias ou necessárias (como a corrida ou o salto), que evoluem para competição e, consequentemente, para entretenimento. Os combates de gladiadores, populares durante a época Romana, são um bom exemplo de uma atividade que combina desporto, castigos corporais e entretenimento. Exemplos de entretenimento violento como este têm servido como argumento para a posição de que o entretenimento contemporâneo é menos violento do que no passado, apesar do recurso à violência como forma de entretenimento nos "media" modernos. Muito do equipamento para atividades outrora necessárias, como a pesca, foi alvo de inovações tecnológicas em função da sua função recreativa.
Embora a maior parte das formas de entretenimento tenha sido constante ao longo da História, algumas formas bastante populares em épocas passadas já não são vistas como aceitáveis. Por exemplo, durante vários séculos a participação popular no julgamento e castigo de criminosos e proscritos, ou outras cerimónias de humilhação pública eram vistas como entretenimento. Mesmo a execução de penas capitais como o enforcamento e a decapitação, exibidas em público como medida de dissuacção, eram vistas em parte como entretenimento, chegando-se mesmo a optar por execuções com processos demorados, como o apedrejamento, de forma a prolongar o espetáculo público. Os castigos públicos enquanto entretenimento só cessaram no século XIX, fruto da crescente contestação na classe média.
O entretenimento infantil centra-se em jogos e brincadeiras, e é fundamental na aprendizagem, desenvolvimento e formação de personalidade da criança. Os adultos ensinam e transmitem várias formas de entretenimento e muitas das atividades apelativas às crianças, como os fantoches, palhaços, pantominas ou banda desenhada são também apreciadas por adultos.
A maior parte das formas de entretenimento pode ser adaptada para se ajustar ao interesse e capacidade das crianças. Durante o século XX, tornou-se evidente que o desenvolvimento psicológico das crianças se processa em estágios e que as suas capacidades são diferentes das dos adultos. Começam a surgir histórias e atividades desenvolvidas especificamente para uma audiência infantil, na forma de livros, filmes ou jogos. São implementados sistemas de classificação etária de forma a orientar melhor o público.
Na atualidade, tal como acontece para os adultos, estão disponíveis várias formas de entretenimento para crianças através da internet, o que constitui uma alteração significativa em relação a épocas anteriores. A quantidade de tempo dispendida pelas crianças em entretenimento proporcionado pela televisão ou computadores, a par do assinalável colapso da relação da criança com o meio envolvente, tem sido alvo de diversas críticas pelo efeito negativo que acarreta a nível da imaginação, cognição e bem-estar psicológico.<ref name=http://www.guardian.co.uk/commentisfree/2012/nov/19/children-lose-contact-with-nature></ref>
A música é um componente fundamental em muitas formas de entretenimento e em vários artes performativas. É usada para realçar determinados aspectos de uma narrativa, é indispensável na dança (1) e na ópera, e é muito frequentemente incorporada em filmes e peças de teatro.
A música é em si própria uma forma autónoma de entretenimento popular e universal. (2, 4, 5, 6, 7, 8, 9) De acordo com o ritmo, instrumentos, estilo e forma de atuação, a música pode ser dividida em vários géneros, como a música clássica, o jazz, "folk" (3, 5, 8) ou o rock (6, 9). Até ao século XX, as atuações musicais estavam ao alcance de apenas uma minoria capaz de pagar a atuação dos intérpretes. A introdução do registo em suportes pré-gravados, para venda ou difusão radiofónica, fez com que a música passasse a ser um bem de consumo, disponível de forma barata a milhões de pessoas.
Todas as atuações musicais constituem uma forma de entretenimento, independentemente de serem ou não amplificadas (4, 6, 7, 9, 10) ou de serem interpretadas a solo (4, 6), em coro (2), orquestra (5, 8) ou conjunto (3). As atuações ao vivo são realizadas em recintos próprios, com tamanho variável, interiores ou exteriores e desde gratuitos a caros. Os diferentes tipos de audiência têm diferentes expectativas em relação aos intérpretes e ao seu próprio papel durante a atuação. Por exemplo, determinadas audiências preferem a audição em silêncio e são entretidas puramente pela excelência da música ou da interpretação (5, 8), enquanto que outro tipo de audiência recebe o entretenimento através do ambiente e participação coletiva (7, 9). Grande parte dos ouvintes é entretida pela audição em privado de música pré-gravada (10).
Os instrumentos usados em entretenimento musical podem ser constituídos apenas pela voz (2, 6), serem apenas instrumentais (1, 3), ou serem alguma conjugação de ambos (4, 5, 7, 8). A audiência pode ser individual (10), móvel (3), pequena (1, 2) ou grande (6, 7, 8, 9). O canto é normalmente acompanhado por instrumentos, embora algumas formas usem apenas a voz.
Algumas formas de entretenimento (excluem-se atividades comerciais):
Alguns lugares também são considerados entretenimento, como os seguintes:

A é uma área de Engenharia que lida com grandezas elétricas de pequena amplitude e de elevadas frequências, os chamados sinais elétricos ou eletrônicos. A engenharia eletrônica cuida da energia elétrica sob os microaspectos de controle, automação e telecomunicação.
O estudo da engenharia eletrônica fornece meios para o desenvolvimento de componentes, dispositivos, sistemas e equipamentos como: transistores, circuitos integrados e placas de circuito impresso. Nos Estados Unidos, assim como no Brasil, os cursos de engenharia eletrônica são tradicionalmente dados como conteúdo da engenharia elétrica, tal como definido pelo MEC e CREA no Brasil.
A engenharia eletrônica a partir do desenvolvimento tecnológico nas indústrias do telégrafo, no final do século 19; e do rádio e telefone no início do século 20. A maior parte do desenvolvimento dessa disciplina ocorreu durante o período da segunda guerra mundial, com o advento do radar, do sonar, dos sistemas de comunicação e de outros sistemas com fins de aplicação bélica. Durante os anos que precederam a segunda guerra o assunto era conhecido como "engenharia de rádio" e apenas no final dos anos 50 o termo engenharia eletrônica começou a surgir.
Em 1948 surgiu o transistor e em 1960 o circuito integrado (CI) viria a revolucionar a indústria eletrônica. 
Historicamente considerada mera subdivisão da engenharia elétrica, especialmente durante a "era da válvula", ganhou autonomia plena com o advento da "era do semicondutor", rapidamente sucedida pela era da miniaturização em larga escala.
A engenharia eletrônica, constitui-se atualmente de várias subdivisões e ramos, cada vez mais numerosos. Algumas das especialidades e áreas de estudos incluem:

A Ecologia é a especialidade da biologia que estuda o meio ambiente e os seres vivos que vivem nele, ou seja, é o estudo científico da distribuição e abundância dos seres vivos e das interações que determinam a sua distribuição. As interações podem ser entre seres vivos e/ou com o meio ambiente. A palavra tem origem no grego ""oikos", que significa casa, e "logos"", estudo. 
Como matéria pode ser dividida em Autoecologia (é um dos dois grandes ramos em que Schot dividiu a ecologia), Demoecologia e Sinecologia. Entretanto, diversos ramos têm surgido utilizando diversas áreas do conhecimento: Biologia da Conservação, Ecologia da Restauração, Ecologia Numérica, Ecologia Quantitativa, Ecologia Teórica, Macroecologia, Ecofisiologia, Agroecologia, Ecologia da Paisagem. Ainda pode-se dividir a Ecologia em Ecologia Vegetal e Animal e ainda em Ecologia Terrestre e Aquática.
O meio ambiente afeta os seres vivos não só pelo espaço necessário à sua sobrevivência e reprodução, mas também às suas funções vitais, incluindo o seu comportamento, através do metabolismo. Por essa razão, o meio ambiente e a sua qualidade determinam o número de indivíduos e de espécies que podem viver no mesmo habitat. Por outro lado, os seres vivos também alteram permanentemente o meio ambiente em que vivem. O exemplo mais dramático de alteração do meio ambiente por organismos é a construção dos recifes de coral por minúsculos invertebrados, os pólipos coralinos. As relações entre os seres vivos do ecossistema também influencia na distribuição e abundância deles próprios. Como exemplo, incluem-se a competição pelo espaço, pelo alimento ou por parceiros para a reprodução, a predação de organismos por outros, a simbiose entre diferentes espécies que cooperam para a sua mútua sobrevivência, o comensalismo, o parasitismo e outros.
A maior compreensão dos conceitos ecológicos e da verificação das alterações de vários ecossistemas pelo homem levou ao conceito da Ecologia Humana que estuda as relações entre o homem e a biosfera, principalmente do ponto de vista da manutenção da sua saúde, não só física, mas também social. Com o passar do tempo surgiram também os conceitos de conservação que se impuseram na atuação dos governos, quer através das ações de regulamentação do uso do ambiente natural e das suas espécies, quer através de várias organizações ambientalistas que promovem a disseminação do conhecimento sobre estas interações entre o homem e a biosfera. Há muitas aplicações práticas da ecologia, como a biologia da conservação, gestão de zonas úmidas, gestão de recursos naturais (agricultura, silvicultura e pesca), planejamento da cidade e aplicações na economia.
A Ecologia tem uma complexa origem, em grande parte devido a sua natureza multidisciplinar.
Os antigos filósofos da Grécia, incluindo Hipócrates e Aristóteles, foram os primeiros a registrar observações sobre história natural. No entanto, os filósofos da Grécia Antiga consideravam a vida como um elemento estático, não existindo a noção de adaptação. Tópicos mais familiares do contexto moderno, incluindo cadeias alimentares, regulação populacional e produtividade, não foram desenvolvidos antes de 1700. Os primeiros trabalhos foram do microscopista Antoni van Leeuwenhoek (1632–1723) e do botânico Richard Bradley(1688-1732). O biogeógrafo Alexander von Humboldt (1769–1859) foi outro pioneiro do pensamento ecológico, um dos primeiros a reconhecer gradientes ecológicos e fazer alusão às relações entre espécies e área.
No início do século XX, a ecologia foi uma forma analítica de história natural. Seguindo a tradição de Aristóteles, a natureza descritiva da história natural examina a interação dos organismos com o seu meio ambiente e suas comunidades. Historiadores naturais, incluindo James Hutton e Jean-Baptiste de Lamarck, contribuíram com obras significativas que lançaram as bases das modernas ciências ecológicas. O termo "ecologia" é de origem mais recente e foi escrito pelo biólogo alemão Ernst Haeckel no seu livro "Generelle Morphologie der Organismen" (1866). Haeckel foi um zoólogo, artista, escritor e professor de anatomia comparada.
As opiniões divergem sobre quem foi o fundador da teoria ecológica moderna. Alguns marcam a definição de Haeckel como o início, outros atribuem a Eugenius Warming com a escrita de "Oecology of Plants: An Introduction to the Study of Plant Communities" (1895). A ecologia pode também ter começado com Carl Linnaeus, principal pesquisador da economia da natureza no início do século XVIII. Ele fundou um ramo de estudo ecológico que chamou de economia da natureza. Os trabalhos de Linnaeus influenciaram Darwin no "The Origin of Species" onde adota a frase de Linnaues "economia ou política da natureza". Linnaeus foi o primeiro a enquadrar "o equilíbrio da natureza", como uma hipótese testável. Haeckel, que admirava o trabalho de Darwin, definiu ecologia com base na economia da natureza, o que levou alguns a questionar se a ecologia é sinônimo dos conceitos de Linnaues para a economia da natureza.
A síntese moderna da ecologia é uma ciência jovem, que substancial atenção formal no final do século XIX e tornando se ainda mais popular durante os movimento ambientais da década de 1960, embora muitas observações, interpretações e descobertas relacionadas a ecologia estendem-se desde o início dos estudos da história natural. Por exemplo, o conceito de balanço ou regulação da natureza pode ser rastreado até Herodotos (morto em 425 ac.), que descreveu mutualismo no Rio Nilo, quando crocodilos abrem a boca permitindo escolopacídeos remover sanguessugas.
Contribuições mais ampla para o desenvolvimento histórico das ciências ecológicas, Aristóteles é considerado um dos primeiros naturalistas que teve um papel influente no desenvolvimento filosófico das ciências ecológicas. Um dos alunos de Aristóteles, Teofrasto, fez observações ecológicas sobre plantas e postulava uma postura filosófica sobre as relações autônomas entre as plantas e seu ambiente, que está mais na linha com o pensamento ecológico moderno. Tanto Aristóteles e Teofrasto fizeram observações detalhadas sobre as migrações de plantas e animais, biogeografia, fisiologia e seus hábitos no que poderia ser considerado um análogo do nicho ecológico moderno. Hipócrates, outro filósofo grego, também é creditado com referência a temas ecológicos em seus primeiros desenvolvimentos.
De Aristóteles a Darwin o mundo natural foi predominantemente considerado estático e sem mudanças desde criação original. Antes do livro "The Origin of Species" teve pouca valorização ou entendimento das dinâmicas relações entre os organismos e suas adaptações e modificações relacionadas ao meio ambiente. Enquanto Charles Darwin é o mais conhecido por seus trabalhos em evolução, ele é também um dos fundadores de ecologia de solo. Em "The Origin of Species" Darwin faz nota a o primeiro experimento ecológico publicado em 1816. Na ciência que antecederam a Darwin a noção de evolução das espécies foi ganhando apoio popular. Este paradigma científico mudou a maneira que os pesquisadores se aproximaram das ciências ecológicas.
Alguns sugerem que o primeiro texto ecológico ("Natural History of Selborne") foi publicado em 1789, por Gilbert White (1720–1793). O primeiro livro ecológico da América foi publicado em 1905 por Frederic Edward Clements. No livro, Clements passa a ideia que as comunidades de plantas são como superorganismos. Essa publicação lança o debate entre o holismo ecológico e individualismo que durou até a década de 1970. O conceito de Clements para superorganismo propõem quem os ecossistemas progridem por um regulado e determinado estágio de desenvolvimento, análogo ao estágios de desenvolvimento de um organismo, cujas partes função para manter a integridade do todo. O paradigma de Clements foi desafiado por Henry Gleason. De acordo com Gleason, comunidades ecológicas se desenvolvem a partir da associação única de organismos individuais. Essa mudança de percepção colocado o foco para as histórias de vida de organismos individuais e como isso se relaciona com o desenvolvimento de comunidades.
A teoria de superorganismo de Clements não foi completamente rejeitada, mas alguns sugerem que ela foi uma aplicação além do limite do holismo. Holismo continua a ser uma parte crítica da fundamentação teórica contemporânea em estudos ecológicos. Holismo foi primeiro introduzido em 1926 por uma polarizada figura histórica, um general da África do Sul chamado Jan Christian Smuts. Smuts foi inspirado pela teoria de superorganismo de Clement's e desenvolveu e publicou o conceito de holismo, que contrasta com a visão política do seu pai sobre o Apartheid . Quase ao mesmo tempo, Charles Elton pioneiro no conceito de cadeias alimentares no livro "Animal Ecology". Elton definiu relações ecológicas usando conceitos de cadeias alimentares, ciclos de alimentos, o tamanho de alimentos, e descreveu as relações numéricas entre os diferentes grupos funcionais e suas relativas abundâncias. 'ciclos alimentares' foram substituídos por 'teias tróficas `em posteriores textos ecológicos um texto posterior ecológica.
Ecologia desenvolveu-se em muitas nações, incluindo na Rússia com Vladimir Vernadsky que fundou o conceito de biosfera na década de 1920 ou Japão com Kinji Imanishi e seu conceito de harmonia na natureza e segregação de habitat na década de 1950. O reconhecimento científico ou a importância das contribuições para a ecologia de outras culturas é dificultada por barreiras linguísticas e de tradução.
Como ecologia lida sempre com ecossistemas em mudança, por isso, tempo e espaço devem ser levados em conta quando são descritos fenômenos ecológicos. No que diz respeito ao tempo, pode levar milhares de anos para um processo ecológico amadurecer. O tempo de vida de uma árvore, por exemplo, pode passar através de diferentes estágios sucessionais até atingir a maturidade de uma floresta. O processo ecológico ainda é estendido mais ao longo do tempo até a arvore cair e decompor.
Ecossistemas são também classificados em diferentes escalas espaciais. A área de um ecossistema pode variar muito, de muito pequeno a muito vasto.
Por exemplo, várias gerações de um pulgão e seus predadores podem existir sobre uma única folha, e dentro de cada um destes pulgões podem existir diversas comunidades de bactérias. A escalada do estudo deve ser muito ampla para estudar árvores de uma floresta, onde vivem pulgões e bactérias. Para entender o crescimento das arvores, por exemplo, o tipo de solo, umidade, inclinação do terreno, abertura do dossel e outras variáveis locais devem ser examinadas. Para entender a ecologia de uma floresta, complexos fatores locais, como clima também devem ser levados em conta.
Estudos ecológicos de longo prazo promovem importantes registros para entender melhor os ecossistemas no espaço e no tempo. O International Long Term Ecological Network gerencia e faz intercambio de informação entre locais de pesquisas. O mais longo experimentos existente é o Park Grass Experiment que início em 1856. Outro exemplo inclui o Hubbard Brook Experimental Forest em operação desde 1960. Em ecologia também é complicado o fato de que os padrões de pequena escala não necessariamente explicam os fenômenos de grande escala. Estes fenômenos operam em diferentes escalas no ambiente, que vão desde a escala molecular a escala planetaria, e requerem diferentes conjuntos de explicação.
Para estruturar o estudo da ecologia em um quadro de entendimento o mundo biológico é conceitualmente organizado em uma estrutura hierárquica, variando de uma escala de genes, para células, tecidos, órgãos, organismos, espécies, até o nível de biosfera. Ecossistemas são primeiramente pesquisados em seus principais níveis de organização, incluindo (1)organismos, (2) populações e (3) comunidades. Ecólogos estudam ecossistemas por amostragem de um certo número de indivíduos que representam uma população. Os ecossistemas consistem nas comunidades que entre elas e com o meio ambiente. E em ecologia, comunidades são criadas por interação de populações de diferentes espécies de uma área.
Biodiversidade é simplesmente a forma resumida para a diversidade biológica. Biodiversidade descreve todas as variantes da vida de genes a ecossistemas, e é uma área complexa que abrange todos os níveis biológicos de organização. Há muitos índices, maneiras para medir e representar a biodiversidade. Biodiversidade inclui diversidade de espécies, diversidade de ecossistemas, diversidade genética e os complexos processos que operam em e entre esses diversos níveis. Biodiversidade executa um importante papel na saúde ecológica, quanto na saúde dos humanos. Prevenindo ou priorizando a extinção das espécies é uma maneira de preservar a biodiversidade, nas populações, a diversidade genética entre elas e os processos ecológicos, como migração, que estão sendo ameaçados em escala global e desaparecendo rapidamente. Prioridades de conservação e técnicas de gestão requerem diferentes abordagens e considerações para abordar toda gama ecológica da biodiversidade. População e migração de espécies, por exemplo, são os mais sensíveis indicadores de serviços ecológicos que sustentam e contribuem para o capital natural e para o "bem estar" do ecossistema. O entendimento da biodiversidade tem uma aplicação pratica para o planejamento da conservação dos ecossistemas, para tomar decisões ecologicamente responsáveis nas gestão de empresas de consultoria, governos e empresas.
O nicho ecológico é um conceito central na ecologia de organismos. São muitos as definições do nicho ecológico desde 1917 , mas George Evelyn Hutchinson fez um avanço conceitual em 1957 e introduziu a definição mais amplamente aceita: "O nicho é o grupo de condições bioticas e abióticas nas quais uma espécie é capaz de persistir e manter estável o tamanho da população." O nicho ecológico é dividido em nicho fundamental e nicho efetivo. O nicho fundamental é o grupo de condições ambientais sobre qual uma espécie é apta a persistir. O nicho efetivo é o grupo de condições ambientais ótimas sobre a qual uma espécie é apta a persistir. Organismos tem traços fundamentais que são excepcionalmentes adaptados ao nicho ecológico. Um traço é uma propriedade mensurável do organismo que fortemente influencia sua performance. Padrões biogeográficos e escalas de distribuição são explicados e previstos através do conhecimento e compreensão das exigências do nicho da espécie. Por exemplo, a adaptação natural de cada espécie no seu nicho ecológico significa que ela é apta para excluir competitivamente outras espécies similarmente adaptada que tem uma escala geográfica de sobreposição. Isso é chamado de princípio de exclusão competitiva Importante do conceito do nicho é o habitat. O habitat é o ambiente sobre a qual uma espécies sabemos que ocorre e o tipo de comunidade que é formada como resultado. Por exemplo, habitat pode se referia a um ambiente aquático ou terrestre que pode ser categorizado como ecossistemas de montanha ou Alpes.
Organismos são sujeitos a pressões ambientais, mas eles também podem modificar seus habitats. O feedback positivo entre organismos e seu ambiente pode modificar as condições em uma escala local ou global (Ver Hipótese Gaia) e muitas vezes até mesmo após a morte do organismo, como por exemplo deposição de esqueletos de sílica ou calcário por organismos marinhos. Este processo de engenharia de ecossistemas também pode ser chamado de construção de nicho. Engenheiro de ecossistemas são definidos como:”...organismos que diretamente ou indiretamente modulam a disponibilidade de recursos para outras espécies, causando mudanças nos estados físicos nos matérias bióticos ou abióticos. Assim eles modificam, mantem e criam habitats."
O conceito de engenharia ecológica foi estimulado por uma nova apreciação do grau de influencia que os organismos tem no ecossistemas e no processo evolutivo. O conceito de construção de nicho destaca um prévio subvalorizado mecanismo de feedback na seleção natural transmitindo forças no nicho abiótico. Um exemplo de seleção natural através de engenharia de ecossistemas ocorre em nichos de insetos sociais, incluindo formigas, abelhas, vespas e cupins. Lá é uma emergência de homeostase na estrutura do nicho que regula, mantém e defende a fisiologia no interior da colônia. Montes de cupins, por exemplo, mantém uma temperatura interna constante através de chaminés de ar condicionado. A estrutura dos nichos é sujeita as forças da seleção natural. Além disso, o nicho pode sobreviver a sucessivas gerações, o que significa que os organismos herdam o material genético e um nicho, que foi construído antes do seu tempo.
A população é a unidade de analise da ecologia de populações. Uma população consiste nos indivíduos de uma mesma espécie que vivem, interagem e migram através do mesmo nicho e habitat . Uma primárias lei da ecologia de populações é a Teoria Populacional Malthusiana. Este modelo prevê que: "...uma população pode crescer (ou declinar) exponencialmente enquanto o ambiente experimentado por todos os indivíduos da população se mantém constante..." 
Esta premissa Malthusiana fornece a base para a formulação de teorias preditivas e testes que se seguem. Modelagens simples de populações usualmente começam com quatro variáveis incluído nascimento, morte, imigração e emigração. Modelos matemáticos são usados para calcular a mudança demográfica na população usando modelos nulos. Um modelo nulo é usado como uma hipótese nula para os testes estatísticos. A hipótese nula parte da pressuposto que processos aleatórios criam os padrões observados. Alternativamente o padrão observado difere significantemente do modelo aleatório e exige mais explicação. Modelos podem ser matematicamente complexos quando “...varias hipóteses competitivas são simultaneamente confrontadas com os dados." Um exemplo de um modelo introdutório de população descreve uma população fechada, como em uma ilha, onde a imigração e emigração não ocorre. Nestes modelos de ilha as taxas per capita de variação são descritos como:
formula_1,
onde "N" é o número total de indivíduos na população, "B" é o número de nascimentos, "D" é o número de mortos, "b" e "d" são as taxas per capita de nascimento e morte respectivamente, e "r" é a taxa per capita de mudança populacional. Esta formula pode ser lida como a taxa de mudança na população ("dN/dT") é igual aos nascimentos menos as mortes (B - D).
Usando estas técnicas de modelagem, os modelo de crescimento populacional de Malthus`s foi mais tarde transformado em um modelo conhecido como a equação logística:
formula_2,
onde "N" é o número de indivíduos medidos como densidade de biomassa, "a" é a taxa per capita máxima de mudança, e "K" é a capacidade de suporte da população. A formula pode ser lida assim, a taxa de mudança na população ("dN/dT") é igual ao crescimento ("aN") que é limitado pela capacidade de suporte "(1-N/K)". A disciplina de ecologia de populações baseia-se estes modelos introdutórios para entender os processos demográficos em populações real e conduz testes de hipóteses estatísticos. O campo da ecologia populacional, muitas vezes utiliza os dados sobre história de vida e álgebra matricial para desenvolver matrizes de projeção em fecundidade e sobrevivência. Esta informação é usada para o gerenciamento de estoques da vida selvagem e fixação de quotas de colheita.
As populações são também estudadas através do conceito de metapopulações.
O conceito de metapopulação foi introduzido em 1969 :"como uma população de populações que vai se extinguindo e recolonizando localmente." Ecologia de metapopulações é uma abordagem estatística que é frequentemente usada na biologia da conservação. A pesquisa com metapopulações simplifica a paisagem em manchas com diferentes níveis de qualidade. Como o modelo de seleçãor/K, o modelo de metapopulações pode ser usado para explicar a evolução da história de vida, como a estabilidade ecológica da metamorfose dos amfibios, que deslocam nos estágios de vida de manchas aquáticas para manchas terrestres. Na terminologia de metapopulação existem emigrantes (indivíduos que deixam um fragmento), imigrantes (indivíduos que se movem nos fragmentos) e os sítio (site) são classificados ou como fontes ou sumidouros. Um sítio (site) é um termo genérico que se refere a lugares onde as amostras das populações, tais como lagoas ou definidas áreas de amostragem em uma floresta. Sítios fontes são locais produtivos que geram uma oferta sazonal de organismos jovens que migram para outros fragmentos. Sítios sumidouros são locais improdutivos que só recebem os migrantes e estes vão se extinguir a menos que resgatados por um sítios fonte adjacentes ou as condições ambientais tornam-se mais favoráveis. Modelos de metapopulação examinar a dinâmica dos fragmentos ao longo do tempo para responder perguntas sobre ecologia espacial e demográfica. A ecologia de metapopulações é um processo dinâmico de extinção e colonização. Pequenos fragmentos de menor qualidade são mantidos ou resgatados por um fluxo sazonal de novos imigrantes. Uma estrutura de metapopulação dinâmica evolui de ano para ano, onde alguns fragmentos são sumidouros em anos secos e se tornam fontes de quando as condições são mais favoráveis. Ecologistas utilizam uma mistura de modelos de computador e estudos de campo para explicar a estrutura das metapopulações.
Ecologia de comunidades é uma subdisciplina da ecologia que estuda a distribuição, abundância, demografia e interações entre populações coexistentes. Um exemplo do um estudo na ecologia de comunidades medida da produção primária em uma área alagada em relação as taxas de decomposição em consumo. Isto requer o entendimento da conexão da comunidade entre plantas (produtores primários) e os decompositores (fungos e bactérias). ou a analise da dinâmica predador presa afetando a biomassa de anfíbios . Teias alimentares e níveis tróficos são dois modelos conceituais bastante utilizados para explicar a ligações entre espécies.
Teias alimentares são um tipo de mapa conceitual que ilustra os caminhos ecológicos reais, usualmente começando com a energia solar sendo usado pelas plantas durante a fotossíntese. As plantas crescem acumulando carboidratos que são consumidos pelos herbívoros. Passo a passo as linhas ou relações são elaboradas até uma teia de vida ser ilustrada.
Existem diferentes dimensões ecológicas que podem ser mapeados para criar teias alimentares mais complicadas, incluindo: composição de espécies (Tipo de espécies), riqueza de espécies (número de espécies), biomassa (o peso seco de plantas e animais), produtividade (taxa de conversão de energia e nutrientes em crescimento) e estabilidade (teias alimentares ao longo do tempo). Um diagrama ilustrando a composição da teia alimentar mostra como uma mudança em uma única espécies pode diretamente ou indiretamente influenciar muitas outras espécies.
Estudos de microcosmos são usados para simplificar as pesquisas com teias alimentares em unidades semi isoladas como pequenas molas, logs decadentes, e experimentos de laboratório usando organismos que se reproduzem rapidamente, como as Daphnia alimentando-se de algas em ambientes controlados. Princípios adquiridos em teias alimentares de modelos experientais de microcosmos são usados para extrapolar pequenas cinceitos dinâmicos em grandes sistemas. Food-chain length is another way of describing food-webs as a measure of the number of species encountered as energy or nutrients move from the plants to top predators.
Existem diferentes formas de cálculo de comprimento cadeia alimentar, dependendo do que os parâmetros da dinâmica da cadeia alimentar estão sendo considerados: conectância, energia ou interação. Em um simples exemplo de predador presa, um cervo é um passo removido em come plantas (comprimento de cadeia = 1) e um lobo que come o cervo é dois passos removido (comprimento de cadeia = 2). A quantidade relativa ou a força de influência que estes parâmetros são as questões acessadas da cadeia alimentar sobre:
As condições e recursos são dois fatores que determinam qual será o habitat dos organismos. Condições, são características físicas e químicas do ambiente, um elemento importante na diferenciação de condições e recursos é que as condições não diminuem pelas atividades dos indivíduos, já os recursos são consumidos pelos seres vivos. A partir daí surge um fator determinante, há uma competição interespecífica ou intraespecífica para obtenção de determinado recurso.
Links na teia alimentar primeiramente conectam relações alimentares entre espécies. Biodiversidade dentro do ecossistema pode se organizar em dimensões verticais e horizontais. A dimensão vertical representa as relações alimentares da base da cadeia alimentar até os predadores de topo. A dimensão horizontal representa a abundancia relativa ou biomassa de casa nível Quando a abundancia relativa ou biomassa de cada grupo alimentar é empilhada em seus respectivos grupos tróficos eles naturalmente formam uma espécie de ‘piramide de números’. Grupos funcionais são amplamente categorizados como autotróficos (ou produtores primários), heterotríficos (ou consumidores), e detritívoros (ou decompositores). Heterotrófagos podem ser subdivididos em diferentes grupos funcionais, incluindo: consumidores primários (herbívoros), consumidores secundários (predadores que consomem exclusivamente herbívoros) e consumidores terciários (predadores que consomem tanto herbívoros quanto outros predadores). Onívoros não se encaixam perfeitamente nessas categorias funcionais porque consomem tanto tecidos vegetais e tecidos animais. Tem sido sugerido, entretanto, que os onívoros têm uma maior influência funcional como predadores, porque em relação aos herbívoros são relativamente ineficientes na pastagem.
Ecólogos coletam dados em níveis tróficos e teias alimentares para modelar estatisticamente e calcular parâmetros matemáticos, tais como aqueles usados em outros tipos de análise de rede, para estudar os padrões emergentes e propriedades compartilhadas entre os ecossistemas. O arranjo piramidal emergente de níveis tróficos com quantidades de transferência de energia diminuindo à medida que as espécies se tornam mais distantes da fonte de produção é um dos vários padrões que repetem entre os ecossistemas. O tamanho de cada nível trófico na pirâmide geralmente representa a biomassa, que pode ser medida como o peso seco dos organismos. Autótrofos podem ter a maior proporção mundial de biomassa, mas eles são rivalizados de perto ou mesmo superados pelos microrganismos.
A decomposição da matéria orgânica morta, como folhas caindo no chão da floresta, se transforma em solo que a alimenta a produção de plantas. A soma total dos ecossistemas do planeta terra é chamado de pedosfera, onde é encontrada uma proporção muito grande da biodiversidade. Invertebrados que se alimentam e rasgam folhas maiores, por exemplo, criar pequenos pedaços que alimentam organismos menores na cadeia de alimentação. Coletivamente, estes são os detritívoros que regulam a formação do solo. As raízes das árvores, fungos, bactérias, minhocas, formigas, besouros, centopéias, mamíferos, aves, répteis e anfíbios todo o contribuem para criar a cadeia trófica da vida nos ecossistemas do solo. Como organismos se alimentam e deslocam fisicamente materiais para solos, este processo ecológico importante é chamado bioturbação. Biomassa de microrganismos do solo são influenciadas por feedback (retroalimentantação) na dinâmica trófica da superfície solar exposta. Estudos paleecológicos de solos colocam a origem da bioturbação a um tempo antes do período Cambriano. Outros eventos, como a evolução das árvores e anfíbios no período devoniano teve um papel significativo no desenvolvimento dos solos e trofismo ecológico.
Grupos tróficos funcionais separam hierarquicamente em uma piramide trófica porque requerem adaptações especializadas para realizar fotossíntese ou predação, mas raramente são eles tem uma combinação de ambas habilidades funcionais. Isso explica por que adaptações funcionais em trofismo organizam diferentes espécies emergente em um grupo funcional. Níveis tróficos são parte de um holístico ou complexo sistema visto no ecossistema. Cada nível trófico contém espécies independentes que se agrupam, porque compartilham funções ecológicas comuns. Agrupamento de espécies funcionalmente similar em um sistema trófico dá uma imagem macroscópica do amplo design funcional.
Links em uma teia alimentar ilustram diretas relações tróficas entre espécies, mas podem também efeitos indiretos que podem alterar a abundancia, distribuição ou biomassa do nível trófico. Por exemplo, predadores comendo herbívoros indiretamente influenciam a controle e regulação da produção primária nas plantas. Embora predadores não comem plantas diretamente, eles regulam a população de herbívoros que diretamente são ligados diretamente as plantas. A rede de relações de efeitos diretos e indiretos é clamada de cascata trófica. Cascata trófica são separadas em cascatas a nível de espécie, onde apenas um subconjunto da dinâmica da teia alimentar é impactado por uma mudança no número da população, e cascadas ao nível de comunidade, onde uma mudança no número da população pode ter um efeito dramático na teia alimentar inteira, como a distribuição de biomassa de plantas.
Uma espécie chave é uma espécie que ocupa um papel particularmente forte ou central em uma teia alimentar. Uma espécie chave ocupa um papel desproporcional em manter processos ecológicos. A perda de uma espécie chave resulta na extinção de outras espécies e um efeito cascata alterando o dinâmica trófica e conexões na teia alimentar. Espécies chaves, como os engenheiros de ecossistemas, tem um papel estruturador, apesar de ter níveis relativamente baixos de representação da biomassa na pirâmide trófica. Lontras do mar ("Enhydra lutris") são um exemplo clássico de espécies chave porque limitam o densidade de ouriços que se alimentam de algas. Se as lontras são removidas do sistema, os ouriços pastam até que as algas marinha desaparecer e isso tem um efeito dramático na estrutura da comunidade. A caça de lontras do mar, por exemplo, é considerado em ter indiretamente levado a extinção do dugongo-de-steller ("Hydrodamalis gigas"). Enquanto o conceito de espécies chaves tem sido muito usado como uma ferramenta de conservação biológica, ele foi criticado por estar mal definido. Diferentes ecossistemas expressam diferentes complexidades e por isso é
claro como aplicável que o modelo de espécies chave pode ser aplicado.
Unidades ecológicas de organização são definidas através de referência de algumas magnitudes de espaço e tempo no planeta. Comunidades de organismos, por exemplo, são muitas vezes arbitrariamente definidas, mas os processos de vida interagem com os diferentes níveis e organizam em conjuntos mais complexos.
Biomas, por exemplo, são uma grande unidade de organização que categorizam regiões de ecossistemas da Terra, de acordo com a fisionomia e composição da vegetação. Diferentes pesquisas tem aplicados diferentes métodos para definir limites continentais de domínios de biomas, por diferentes tipos de função da comunidade de vegetação, que são limitada na distribuição do clima, precipitação e outras variáveis ambientais. Exemplos de nomes de biomas incluem: florestas tropicais, florestas temperadas decíduas, taiga, tundra, desertos quentes e desertos polares. Outras pesquisas tem recentemente iniciado a categorizar outros tipos de biomas, como microbioma humano e oceânico. Para os microrganismos o corpo humano é o habitat e uma paisagem. O microbioma tem sido descoberto através de avanços na genética molecular, revelando uma desconhecida riqueza de microorganismos no planeta. O microbioma oceânico desempenha um significante papel na ecologia biogeoquímica dos oceanos.
A maior escala de organização ecológica é a biosfera. A biosfera é a soma total dos ecossistemas do planeta. Relações ecológicas regulam o fluxo de energia, nutrientes e clima, todos subindo até a escala planetária. Por exemplo, a história dinâmica da composição de CO e O na atmosfera foi em grande parte por fluxos de gases biogênicos provenientes da respiração e fotossíntese, com níveis flutuando no tempo em relação a ecologia e evolução dos animais e plantas. Quando partes de subcomponetes são organizadas em um todo, muitas vezes propriedades emergentes descrevem a natureza do sistema. Teorias ecológicas tem sido usadas para explicar os fenômenos emergentes de auto regulação na escala planetária. Isso é conhecido como Hipótese Gaia . The Gaia hypothesis is an example of holism applied in ecological theory. A ecologia do planeta age como uma única unidade regulatória e holística chamada de hipótese Gaia. A hipótese Gaia afirma que existe um feedback emergente gerado pelo metabolismo dos organismos vivos que mantem a temperatura da Terra e condições da atmosfera dentro de uma estreita escala de tolerância auto regulável.
A maioria dos seres vivos presentes nos mais diversos ambientes são ectodérmicos, ou seja, precisam de fontes externas de calor para regularização do seu metabolismo. Os endotérmicos por sua vez, necessitam de uma grande carga de energia para a manutenção da sua temperatura corporal já que, estes não regulam sua temperatura interna dependendo apenas do ambiente, porém os endotérmicos apresentam algumas vantagens quando se refere a mobilidade dos seus indivíduos, já que, estes não estão tão interligados ao ambiente, isso ajuda bastante na fuga dos predadores e também na obtenção de recursos, visto que essas espécies requerem uma grande quantidade de alimento para suprir suas necessidades. De acordo com a sazonalidade de determinados habitats, onde em um mesmo ano o ser vivo pode ficar exposto a temperaturas negativas em um período, e em outro à temperaturas bastante elevadas, surgiram-se ao longo do tempo vantagens evolutivas que permitiram a esses animais se adequarem ao clima predominante em um determinado momento, um exemplo desse avanço evolutivo é a raposa do ártico onde este apresenta uma pelagem espessa e branca (proteção e camuflagem) no inverno e fina e marrom no verão.
A migração é um conceito de constante movimentação de massas de populações. Esses movimentos são incentivados pela busca de recursos tais como: água, alimento e/ou acasalamento, temperatura, e/ou para fugirem de inimigos que se instalaram no seu biótopo, normalmente em busca de melhores condições de vida. Geralmente a estadia dessas espécies migratórias nestes habitats são passageiras, já que, devido ao grande número de indivíduos, estes ambientes não são capazes de suprir as necessidades desse grupo por muito tempo, estimulando novas migrações, o que irá depender também da sazonalidade de determinada região. Tais fatos alteram a constituição gênica de uma população que adquire e desenvolvem novas características necessárias para a sobrevivência em determinados territórios.
sites
animal, migração.1 fot., color. In Britannica Escola Online. Web, 2013. Disponível em:, Acesso em: 13 de abril de 2013.
Livro
RIDLEY, Mark. Evolução. 3a. ed. Porto Alegre: ArtMed Editora, 2006.
Ecologia e evolução são consideradas disciplinas irmãs, sendo ramos da ciência da vida. Seleção Natural, Historia de vida, desenvolvimentos, adaptação, populações, e herança estão presentes em teorias evolutivas e ecológicas. Morfologia, comportamento e/ou traços genéticos, por exemplo, podem ser mapeados em árvores evolutivas para estudar a desenvolvimento histórico da espécie e também organizar a informação em relação a adaptações ecológicas. Em outras palavras, adaptação é explicada em relação a origem histórica de traços e condições ecológicas e que está sujeita a forças da seleção natural. Nesse quadro, ferramentas analíticas de ecólogos e evolucionistas se sobrepõem para organizar, classificar e investigar a vida por meio de princípios sistemáticos comuns, como filogenéticos ou taxonômicos de Lineu As duas disciplinas frequentenmente aparecem juntas como no título do jornal "Trends in Ecology and Evolution". Não há uma fronteira nítida que separa a ecologia da evolução e que diferem suas áreas de aplicação. Ambas as disciplinas descobrem e explicam emergentes e únicos processos que operam em diferentes escalas espaciais e temporais da organização. Embora a fronteira entre a ecologia e evolução nem sempre é clara, é óbvio que os ecólogos estudam os fatores abióticos e bióticos que influenciam o processo evolutivo.

Educação engloba os processos de "ensinar" e "aprender".
No centro de um sistema educativo deve situar-se o ser humano a educar, num horizonte de plenitude. A tarefa educativa consiste, na verdade, na capacidade de identificar e de acompanhar esta presente inquietação do homem, mantendo vivo o amor pelo saber, despertando o coração e pondo em marcha a sua razão e a sua liberdade.
É um fenômeno observado em qualquer sociedade e nos grupos constitutivos dessas, responsável pela sua manutenção, perpetuação, transformação e evolução da sociedade a partir da instrução ou condução de conhecimentos, disciplinamentos (educar a ação), doutrinação, às gerações que se seguem, dos modos culturais de ser, estar e agir necessários à convivência e ao ajustamento de um membro no seu grupo ou sociedade. Ou seja, é um processo de socialização que visa uma melhor integração do indivíduo na sociedade ou no seu próprio grupo.
Enquanto processo de sociabilização, a educação é exercida nos diversos espaços de convívio social, seja para a adequação do indivíduo à sociedade, do indivíduo ao grupo ou dos grupos à sociedade. Nesse sentido, educação coincide com os conceitos de socialização e endoculturação, mas não se resume a estes. A prática educativa formal — que ocorre nos espaços escolarizados, que sejam da Educação Infantil à Pós Graduação — dá-se de forma intencional e com objetivos determinados, como no caso das escolas. No caso específico da educação formal exercida na escola, pode ser definida como Educação Escolar.
De acordo com a UNESCO a educação também é exercida para além do ambiente formal das escolas e adentra em outras perspectivas caracterizadas como: educação não formal e educação informal. Segundo a organização, a partir das Conferências Internacionais de Educação de Adultos - CONFINTEA compreende-se por educação não formal todo processo de ensino e aprendizagem ocorrido a partir de uma intencionalidade educativa mas sem a obtenção de graus ou títulos, sendo comum em organizações sociais com vistas a participação democrática. E educação informal como aquela ocorrida nos processos quotidianos sociais, tais como com a família, no trabalho, nos círculos sociais e afetivos.
No caso específico da educação exercida para a utilização dos recursos técnicos e tecnológicos e dos instrumentos e ferramentas de uma determinada comunidade, dá-se o nome de Educação Tecnológica. Outra prática seria a da Educação Científica, que dedica-se ao compartilhamento de informação relacionada à Ciência (no que tange a seus conteúdos e processos) com indivíduos que não são tradicionalmente considerados como parte da comunidade científica. Os indivíduos-alvo podem ser crianças, estudantes universitários, ou adultos dentro do público em geral. A educação sofre mudanças, das mais simples às mais radicais, de acordo com o grupo ao qual ela se aplica, e se ajusta a forma considerada padrão na sociedade.
No entanto, Educar não pode limitar-se a instruir, a transmitir informação, nem a transmitir competências; integra não só questões de autonomia, mas também problemas de autoridade, de tradição e de transmissão da cultura. 
De acordo com a Lei de Diretrizes e Bases da Educação Nacional a educação no Brasil se divide em:
No Brasil, a educação é regulamentada pela Lei de Diretrizes e Bases da Educação Nacional, pelo Fundo de Manutenção e Desenvolvimento da Educação Básica e pelo Fundo de Manutenção e Desenvolvimento do Ensino Fundamental e de Valorização do Magistério.
A principal meta do Plano de Desenvolvimento da Educação (PDE) é uma educação básica de qualidade, para isso deve-se investir na educação profissional e na educação superior. Para isso se tornar realidade deve acontecer o envolvimento de todos: pais, alunos, professores e gestores, em busca da permanência do aluno na escola. Com o PDE o Ministério da Educação pretende mostrar tudo o que se passa dentro e fora da escola e realizar uma grande prestação de contas. As iniciativas do MEC devem chegar a sala de aula para beneficiar a criança para atingir a qualidade que se deseja para a educação brasileira.
O PDE foi editado pelo Governo Federal, por premissas à visão sistêmica da educação, a sustentação da qualidade do ensino e a prioridade a educação básica.
Em Portugal o ensino curricular é um complemento ao ensino oficial.
Em Portugal, a educação é regulamentada pela Lei de Bases do Sistema Educativo que estabelece o quadro geral do sistema educativo nacional.
A nível institucional, a educação inicia-se num âmbito não obrigatório com o Pré-escolar, destinado a crianças com idades compreendidas entre os 3 anos e a entrada na escolaridade obrigatória.
A escolaridade obrigatória denomina-se como "ensino regular", tem a duração de 12 anos, e compreende a idades dos 6 anos até aos 18 anos e organiza-se em três ciclos sequenciais.
1.º ciclo:
O ensino é global e visa o desenvolvimento de competências básicas em Língua Portuguesa, Matemática, Estudo do Meio e Expressão Plástica. Com a implementação da escola a tempo inteiro, através do alargamento do horário de funcionamento para um mínimo de oito horas diárias, as escolas promovem actividades de enriquecimento curricular, nomeadamente o ensino obrigatório do Inglês, o apoio ao estudo para todos os alunos, a actividade física e desportiva, o ensino da Música e de outras expressões artísticas e de outras línguas estrangeiras. 
O 1º ciclo funciona em regime de monodocência, com recurso a professores especializados em determinadas áreas.
2.º ciclo:
Está organizado por disciplinas e áreas de estudo pluridisciplinares.
No 3.º ciclo, o ensino está organizado por disciplinas. Os principais objectivos deste ciclo são o desenvolvimento de saberes e competências necessários à entrada na vida activa ou ao prosseguimento de estudos.
3.º ciclo:
Funciona em regime de pluridocência, com professores especializados nas diferentes áreas disciplinares ou disciplinas.
Aos alunos que completam com sucesso o 3.º ciclo é atribuído o diploma do ensino básico.
Ensino secundário:
Está organizado segundo formas diferenciadas, orientadas quer para o prosseguimento de estudos quer para o mundo do trabalho. O currículo dos cursos de nível secundário tem um referencial de três anos lectivos e compreende quatro tipos de cursos:
Para conclusão de qualquer curso de nível secundário os alunos estão sujeitos a uma avaliação sumativa interna. Para além dessa avaliação, os alunos dos cursos científico-humanísticos são também submetidos a uma avaliação sumativa externa, através da realização de exames nacionais, em determinadas disciplinas previstas na lei.
Aos alunos que tenham completado este nível de ensino é atribuído um diploma de estudos secundários. Os cursos tecnológicos, artísticos especializados e profissionais conferem ainda um diploma de qualificação profissional de nível 3.
Ensino Pós-secundário não superior
Após a conclusão do ensino Secundário umas das opções que o sistema educacional português disponibiliza são os cursos de especialização tecnológica (CET) possibilitam percursos de formação especializada em diferentes áreas tecnológicas, permitindo a inserção no mundo do trabalho ou o prosseguimento de estudos de nível superior. 
A formação realizada nos CET é creditada no âmbito do curso superior em que o aluno seja admitido. A conclusão com aproveitamento de um curso de especialização tecnológica confere um diploma de especialização tecnológica (DET) e qualificação profissional de nível 4, podendo ainda dar acesso a um certificado de aptidão profissional (CAP).
Educação e Formação de Jovens e Adultos
A educação e formação de jovens e adultos oferece uma segunda oportunidade a indivíduos que abandonaram a escola precocemente ou que estão em risco de a abandonar, bem como àqueles que não tiveram oportunidade de a frequentar quando jovens e, ainda, aos que procuram a escola por questões de natureza profissional ou valorização pessoal, numa perspectiva de aprendizagem ao longo da vida.
No sentido de proporcionar novas vias para aprender e progredir surgiu a Iniciativa "Novas Oportunidades" que define como um dos objectivos principais alargar o referencial mínimo de formação ao 12.º ano de escolaridade e cuja estratégia assenta em dois pilares fundamentais:
• Elevar a formação de base da população activa;
• Tornar o ensino profissionalizante uma opção efectiva para os jovens.
As diferentes modalidades de educação e formação de jovens e adultos permitem adquirir uma certificação escolar e/ou uma qualificação profissional, bem como o prosseguimento de estudos de nível pós-secundário não superior ou o ensino superior.
A educação e formação de jovens e adultos compreendem as seguintes modalidades:
• Sistema de Reconhecimento, Validação e Certificação de Competências (RVCC).
Existe uma valorização e reconhecimentos das aprendizagens adquiridas ao longo da vida, por via formal, informal e não-formal, permitindo aos alunos obter uma dupla certificação académica e profissional. A formação adquirida permite o acesso a empregos mais qualificados e melhor perspectiva de formação ao longo da vida. Este Sistema tem lugar nos Centros Novas Oportunidades, disseminados por todo o país;
• Cursos de Educação e Formação (CEF) para alunos a partir dos 15 anos.
Os CEF são uma oportunidade para os jovens poderem concluir a escolaridade obrigatória, incentivando-os para o prosseguimento de estudos/formação, assim como para a aquisição de competências profissionais, através de soluções flexíveis, de acordo com os seus interesses e face às necessidades do mercado de trabalho.
São destinados a jovens com idade igual ou superior a 15 anos e inferior a 23 anos, em risco de abandono escolar ou que já abandonaram.
• Cursos de Educação e Formação de Adultos (EFA) e Formações Modulares.
Possibilitam a aquisição de habilitações escolares e/ou competências profissionais, com vista a uma reinserção ou progressão no mercado de trabalho a jovens com idade igual ou superior a 18 anos, que pretendam completarmos o 9º ou 12º ano de escolaridade e desejem obter uma qualificação profissional de nível 2 ou 3.
• "Acções de curta duração S@bER +"
Destinadas a maiores de 18 anos, procura, através de formações de curta duração, motivar a população adulta a melhorar as suas qualificações escolares ou profissionais e a encontrar as respostas adequadas aos contínuos desafios que enfrenta. Apresentam uma estrutura curricular flexível e diferenciada em função dos interesses e das necessidades do público-alvo.
Ensino Superior
O ensino superior actualmente está estruturado de acordo com os princípios de Bolonha e visa a assegurar uma sólida preparação científica, cultural, artística e tecnológica que habilite para o exercício de actividades profissionais e culturais e para o desenvolvimento das capacidades de concepção, de inovação e de análise crítica.
Em Portugal, organiza-se num sistema binário: o ensino universitário e o ensino politécnico, administrados por instituições do ensino superior públicas, privadas ou cooperativas.

Editores gráficos ou editores de imagens são programas de computador que tem como objetivo facilitar a alteração e criação de imagens digitais. Existem três tipos de editores para cada necessidade. São eles:
Estes programas também possuem geralmente um vasto leque de filtros para exportação de arquivos. Alguns deles são BMP, JPG, GIF, TIFF, TGA, XPM, SVG, PostScript.

Um ou, ainda, e-mail, é um método que permite compor, enviar e receber mensagens através de sistemas eletrônicos de comunicação. O termo "e-mail" é aplicado tanto aos sistemas que utilizam a Internet e que são baseados nos protocolos POP3, IMAP e SMTP, como àqueles sistemas conhecidos como intranets, que permitem a troca de mensagens dentro de uma empresa ou organização e que são, normalmente, baseados em protocolos proprietários.
O correio eletrônico é mais antigo que a internet, e foi, de fato, uma ferramenta crucial para criá-la, mas, na história moderna, os serviços de comunicação globais iniciaram no início da ARPANET. Padrões para codificação de mensagens de "e-mail" foram propostas em 1973 (RFC 561). A conversão da ARPANET à internet no início de 1980 produziu o núcleo dos serviços atuais. Um "e-mail" enviado no início de 1970 parece muito semelhante a uma mensagem de texto dos dias atuais.
O correio eletrônico é, frequentemente, chamado pelo seu nome em inglês, mesmo em textos em português. Existem diversas grafias, que, ocasionalmente, provocam discussões entre os adeptos de cada forma:
Também há variações na forma plural do termo. Em inglês americano, "email" é usado como um substantivo coletivo (como o termo correspondência para itens enviados pelo sistema postal), mas, no inglês britânico, é mais comumente usado como um substantivo comum, com a forma plural "emails".
A história do correio postal e a primeira menção à transmissão de mensagens têm origem na Grécia antiga, em 190 a.C., quando um general da cidade de Atenas enviou um mensageiro para comunicar aos atenienses a vitória de seu exército sobre os Persas.
É justamente daí que se origina a palavra "correio", do original "correr". Reza a história que o mensageiro de Atenas, Filípides, correu aproximadamente 42 quilômetros para levar a mensagem, e apenas balbuciou "Vitória" antes de cair morto de exaustão. Homenageou-se, posteriormente, essa distância como padrão das maratonas.
Há registros, do século XV a.C., de redes postais entre egípcios e babilônicos, transmitidas por meio de tábuas de argila. É também dos egípcios que vem o registro do primeiro sistema de correio. O historiador Xenofonte escreveu:
Já os romanos, para registrarem suas mensagens, utilizavam tábuas cobertas com cera quente (os "tabularis") ou pergaminhos e papiros. Essas informações eram trocadas continuamente entre Roma, seus exércitos e funcionários espalhados nos vastos territórios conquistados. No entanto, com a queda do Império Romano, os correios praticamente desapareceram.
Muitos povos trocavam mensagens utilizando pombos-correios, grous e andorinhas. Esses pássaros eram pintados com cores de determinado significado, de acordo com um código estabelecido, e depois soltos. Ou tinham mensagens amarradas aos seus pés e seguiam uma rota pré-ensinada.
O telégrafo, criado por Samuel Morse, que teve sua primeira transmissão em 1844, foi a primeira intervenção da eletricidade na mediação da comunicação entre pessoas.
Em 1876, Alexander Graham Bell descreve sua primeira experiência bem-sucedida com o telefone. Outra forma de transmissão de mensagem é o fax. Apesar de ter sido inventado antes do telefone, só se popularizou em 1966, quando foi lançado o aparelho de fax operado em linha telefônica.
O correio eletrônico é anterior ao surgimento da Internet. Os sistemas de "e-mail" foram uma ferramenta crucial para a criação da rede internacional de computadores.
O primeiro sistema de troca de mensagens entre computadores que se tem notícia foi criado em 1965, e possibilitava a comunicação entre os múltiplos usuários de um computador do tipo "mainframe". Apesar da história ser um tanto obscura, acredita-se que os primeiros sistemas criados com tal funcionalidade foram o Q32 da SDC e o CTSS do MIT.
O sistema eletrônico de mensagens transformou-se rapidamente em um ""e-Mail" em rede", permitindo que usuários situados em diferentes computadores trocassem mensagens. Também não é muito claro qual foi o primeiro sistema que suportou o "e-Mail" em rede. O sistema AUTODIN, em 1966, parece ter sido o primeiro a permitir que mensagens eletrônicas fossem transferidas entre computadores diferentes, mas é possível que o sistema SAGE tivesse a mesma funcionalidade algum tempo antes.
A rede de computadores ARPANET fez uma grande contribuição para a evolução do "e-Mail". Existe um relato que indica a transferência de mensagens eletrônicas entre diferentes sistemas situados nesta rede logo após a sua criação, em 1969. A data de 29 de Outubro de 1969 é a da primeira mensagem enviada para computadores situados em locais distantes. O texto dessa primeira mensagem continha apenas duas letras e um ponto - "LO.". O investigador da Universidade da Califórnia em Los Angeles (UCLA) Leonard Kleinrock queria escrever "LOGIN", mas o sistema foi abaixo a meio da transmissão. A mensagem seguiu do computador do laboratório de Kleinrock na UCLA para o de Douglas Engelbart no Stanford Research Institute, utilizando como suporte a recém-criada rede da ARPA (Advanced Research Projects Agency).
O programador Ray Tomlinson iniciou o uso do sinal @ para separar os nomes do usuário e da máquina no endereço de correio eletrônico em 1971. É considerado um dos inventores do e-mail, e foi de fato uma ferramenta crucial para criá-la, também criou outros programas parecidos com o "e-mail": SNDMSG e READMAIL. A primeira mensagem enviada por Ray Tomlinson não foi preservada; era uma mensagem anunciando a disponibilidade de um "e-Mail" em rede. A ARPANET aumentou significativamente a popularidade do correio eletrônico.
O Departamento de Informática da Universidade do Minho enviou pela primeira vez em Portugal um "e-mail" em 15 de agosto de 1986.
O conteúdo do "e-mail" eram "pormenores técnicos sobre uma tecnologia que estava a dar os primeiros passos - a Internet". O receptor da mensagem foi a Universidade de Manchester, no Reino Unido.
O envio e recebimento de uma mensagem de "e-mail" é realizada através de um sistema de correio eletrônico. Um sistema de correio eletrônico é composto de programas de computador que suportam a funcionalidade de cliente de "e-mail" e de um ou mais servidores de "e-mail" que, através de um endereço de correio eletrônico, conseguem transferir uma mensagem de um usuário para outro. Estes sistemas utilizam protocolos de Internet que permitem o tráfego de mensagens de um remetente para um ou mais destinatários que possuem computadores conectados à Internet.
O formato na Internet para mensagens de "e-mail" é definido na CRF 2822 e uma série de outras RFCs (RFC 2045 até a RFC 2049) que são conhecidas como MIME.
Mensagens de "e-mail" consistem basicamente de duas seções principais:
O corpo é separado do cabeçalho por uma linha em branco.
Hoje, os grandes sítios da Internet criaram uma série de facilidades para o usuário. Note que essa variação é só uma facilidade e não um novo tipo de "e-mail". Entre estas podemos citar:
Alguns sítios restringem alguns tipos de "e-mail". Esse tipo de restrição normalmente é usado a fim de evitar a atuação de um "spammer" ou divulgador não autorizado de mensagens em massa. Normalmente esse tipo de mensagem eletrônica é mais usado em empresas.
Normalmente, é usado por autoridades e seu uso é controlado.
Por medida de segurança, alguns organismos e entidades internacionais ou mesmo ligados a Governos categorizam o "e-mail" como:
Os norte-americanos chegam ao cúmulo de dar níveis e subníveis a esse tipo de mensagem;
Entretanto, vêm crescendo o uso da criação de chaves criptográficas pessoais (facilidade provida por aplicativos especializados), assegurando a privacidade das informações "de qualquer importância" de cada indivíduo.
Tais chaves possuem uma grande flexibilidade, escalabilidade e confiabilidade.
Algumas dicas de segurança:
Especial ou categorizado em níveis, que são de uso exclusivo dos provedores de Internet. Servem para testes e para verificar se funciona ou não o seu sistema anti-"spam" (contra as mensagens eletrônicas em massa).
Com a popularização da Internet através dos provedores gratuitos (cujos usuários ganhavam também uma caixa de correio eletrônico grátis), muitos sítios começaram a oferecer endereços de "e-mail" gratuitos desvinculados de qualquer outro serviço. Essas mensagens de "e-mail" podem ser lidas com o uso do próprio navegador, sem a necessidade de um programa específico, sendo por isso também chamados "webmail".
O correio eletrônico tornou-se popular devido a sua grande facilidade em quebrar barreiras geográficas. Pessoas que estão em diferentes continentes podem se comunicar livremente (desde que possuam computadores ou qualquer outro dispositivo com tal funcionalidade conectados a Internet), enviando e recebendo mensagens a qualquer hora do dia e para qualquer parte do mundo.
Observa-se que o correio eletrônico deixa de ser apenas um meio de troca de mensagens entre pessoas para se tornar um grande fator na produtividade das empresas. Grandes empresas estão, cada vez mais, usando o correio eletrônico para desempenhar papéis decisivos em suas negociações. Dentro disso, uma intranet pode ser estabelecida para tornar a comunicação de funcionários com outros grupos, tornando assim mais fácil o trabalho e eliminando mensagens em massa e outras mensagens indesejadas.
A Campaign Monitor, produtora de um "software" de mesmo nome, tem medido a popularidade de clientes de "e-mail" e "webmail" entre as bilhões de mensagens enviadas pelo seu sistema. Esta amostra pode dar uma panorama geral dos programas ou plataformas de correio-e mais utilizados atualmente. Em setembro de 2012, a medição apresentou os seguintes resultados:
Outra tendência que se verifica é o crescimento da leitura de correio eletrônico em aparelhos móveis. A popularidade destes dispositivos também é corroborada pelo relatório citado.
As aplicações de correio eletrônico normalmente oferecem ao usuário uma série de facilidades. A maior parte delas fornece um editor de textos embutido e a possibilidade do envio de arquivos anexados a correspondência. Além disso, a maioria das aplicações permite o envio de correspondências para um único destinatário ou o envio para mais de uma pessoa ou para um grupo de pessoas.
Embora não tenham sido desenvolvidos como uma ferramenta de trabalho cooperativo, os serviços de correio eletrônico adaptaram-se muito bem ao ambiente de grupos de trabalho, se tornando indispensáveis nas organizações, agilizando processos, democratizando o acesso as informações e diminuindo os custos. Esta é uma das formas mais usadas para o estabelecimento de comunicações por meio do computador.
Muitas organizações também usam o correio eletrônico como forma de troca de mensagens, mas, se quiserem usar recursos de "groupware", poderão incluí-los de forma simples e com baixo custo, com uma boa segurança.
A desvantagem está na falta de conhecimento da grande maioria dos internautas e, ainda, os "spammers" ou geradores de "spam", grandes remetentes de vírus. Como podemos ver em seguida:
É aconselhável nunca abrir "e-mail" desconhecido, exceto se for de um site confiável, não sem antes observar os procedimentos de segurança.
Com o grande aumento do uso da Internet e do correio eletrônico na vida das pessoas, tornou-se grande o número de pessoas maliciosas que tentam utilizar esses meios para realizar fraudes.
O grande foco desses fraudadores são pessoas que utilizam sítios de instituições financeiras na Internet. Os fraudadores eletrônicos utilizam a grande facilidade com que uma caixa de correio pode ser forjada e falsificada. Eles utilizam listas e programas para envio de "spam" em grande escala juntamente com arquivos executáveis e serviços de hospedagem gratuitos e que não necessitem de identificação legítima.
Esses fraudadores enviam mensagens de "e-mail" se passando por bancos e outras instituições financeiras, solicitando dados pessoais, número de conta corrente, cartão bancário e, às vezes, até mesmo o número de senhas de clientes. Esses clientes desavisados enviam esses dados pensando se tratar realmente de um pedido dessas instituições, sem saberem que estão a se tornar vítimas de fraudadores. Cada vez mais, cresce o número de pessoas que tem suas contas fraudadas, compras através de seus cartões e outros tipos de fraudes. A falta de legislação e meios de segurança que controlem esse tipo de ação tem se tornado um fator positivo para que esses fraudadores continuem a atuar. Além disso não há nenhum mecanismo que permita rastrear, identificar e coibir a ação desses fraudadores tornando assim cada vez mais difícil a atuação das autoridades nesses casos. Mensagens de "e-mail" indesejadas de instituições que queiram solicitar dados pessoais devem ser ignoradas, pois essas não enviam tais mensagens para seus clientes.
A melhor maneira de se prevenir contra fraudes ao utilizar o correio eletrônico é mesmo procurar o máximo de informações sobre sua origem e desconfiar de qualquer indício que possa levantar alguma suspeita. Mensagens de "e-mail" que foram enviadas por pessoas ou empresas desconhecidas encabeçam essa lista. Deve-se ter uma atenção especial com estes tipos de mensagem, pois podem instalar programas-espiões maliciosos, que podem capturar dados que estejam ou foram digitados no computador em que tais programas sejam executados, tornando assim fácil a obtenção de dados de seus usuários.

Etimologia (do grego antigo ἐτυμολογία, composto de ἔτυμος "étymos" e -λογία "-logia") é a parte da gramática que trata da história ou origem das palavras e da explicação do significado de palavras através da análise dos elementos que as constituem. Por outras palavras, é o estudo da composição dos vocábulos e das regras de sua evolução histórica.
Algumas palavras derivam de outras línguas, possivelmente de uma forma modificada (as palavras-fontes são chamadas étimos). Por meio de antigos textos e comparações com outras línguas, os etimologistas tentam reconstruir a história das palavras - quando eles entram em uma língua, quais as suas fontes, e como a suas formas e significados se modificaram.
Os etimólogos também tentam reconstruir informações sobre línguas que são velhas demais para que uma informação direta (tal como a escrita) possa ser conhecida. Comparando-se palavras em línguas correlatas, pode-se aprender algo sobre suas línguas afins compartilhadas. Deste modo, foram encontrados radicais de palavras que podem ser rastreadas por todo o caminho de volta até a origem da família de línguas indo-europeias.
A própria palavra etimologia vem do grego ἔτυμον (étimo, o verdadeiro significado de uma palavra, de 'étymos', verdadeiro) e λόγος (lógos, ciência, tratado).
n" → "schatrayn" → "shadrayn" / "shadran" → (árabe) "al xedrech" → "alxedrez" → "ajedrez" (castelhano) e "xadrez" (português). No oriente se tornou "Xiangqi" (China) e ("xiangi" → "xongi") "Shogi" (Japão).
O estudo da origem das palavras pode, contudo, levar a armadilhas e a falácias etimológicas, que formam a pseudoetimologia ou a etimologia popular. Um exemplo, bastante discutido, é o da palavra cadáver que, segundo alguns autores, teria origem na inscrição latina "caro data vermibus" (carne dada aos vermes), que supostamente seria inscrita nos túmulos. Na verdade, não se encontrou, até hoje, nenhuma inscrição romana deste género. Hoje é defendido pelos etimologistas que a palavra deriva da raiz latina "cado", que significa "caído". A favor desta teoria está o facto de santo Isidoro de Sevilha referir que o corpo deixa de ser cadáver a partir do momento em que é sepultado.
Ciências etimologicas

Editor de som é um software que tem a função de manipular ondas sonoras e ficheiros de áudio.
A maioria tem funções básicas como:

A experiência de Miller e Urey foi uma experimento cientifico concebida para testar a hipótese de Oparin e Haldane sobre a origem da vida.
Segundo o experimento, as condições na Terra primitiva favoreciam a ocorrência de reações químicas que transformavam compostos inorgânicos em compostos orgânicos precursores da vida. Em 1953, Stanley L. Miller e Harold C. Urey da Universidade de Chicago realizaram uma experiência para testar a hipótese de Oparin e Haldane que ficou conhecida pelos nomes dos cientistas. Esta experiência tornou-se na experiência clássica sobre a origem da vida.
A experiência de Miller consistiu basicamente em simular as condições da Terra primitiva postuladas por Oparin e Haldane. Para isso, criou um sistema fechado, sem oxigênio gasoso, onde inseriu os principais gases atmosféricos, tais como hidrogênio, amônia, metano, além de vapor d'água. Através de descargas elétricas, e ciclos de aquecimento e condensação de água, obteve após algum tempo, diversas moléculas orgânicas (aminoácidos). Deste modo, conseguiu demonstrar experimentalmente que seria possível aparecerem moléculas orgânicas através de reações químicas na atmosfera utilizando compostos que poderiam estar nela presentes. Estas moléculas orgânicas são indispensáveis para o surgimento da vida.
Reanálises publicadas em outubro de 2008 do material original da experiência, mostraram a presença de 22 aminoácidos ao contrário dos 5 publicados no artigo original. Antigos resultados mostram uma forte evidência de estas moléculas orgânicas específicas poderem ser sintetizadas de reagentes inorgânicos atmosféricos. Comprovando então a hipótese da vida heterotrófica.
A primeira etapa das reações químicas da mistura de gases deu origem ao cianeto de hidrogênio (HCN), formaldeido (CHO) e outros compostos químicos como o acetileno, cianoacetileno, etc:
O formaldeido, a amônia e o HCN reagiram entre si em um processo conhecido como Síntese de aminoácido de Strecker para formar aminoácidos e outras biomoléculas:
Além disso, a água e o formaldeído reagiram pelo processo conhecido como Reação de Butlerov para produzir vários açúcares , tais como a ribose. 
As experiências mostraram que compostos orgânicos simples, proteínas e outras macromoléculas podem ser formados a partir de gases com a adição de energia.

A Europa Ocidental ou Oeste Europeu é uma parte da Europa cujas fronteiras dependem da definição. Estas fronteiras, no entanto, estão sujeitas a consideráveis flutuações e sobreposições, o que dificulta a sua diferenciação. O conceito de Europa Ocidental também está associado à noção de Mundo Ocidental.
Antes da Segunda Guerra Mundial e a Guerra Fria, os termos "Europa Ocidental" eram muito usados para designar as partes da Europa que tinham raízes católicas ou protestantes, ou seja, as áreas ocupadas por Andorra, Alemanha, Áustria, Bélgica, Croácia, Dinamarca, Eslováquia, Eslovénia, Espanha, Finlândia, França, Hungria, Irlanda, Islândia, Itália, Letónia, Liechtenstein, Lituânia, Luxemburgo, Malta, Mónaco, Noruega, Países Baixos, Polônia, Portugal, Reino Unido, República Tcheca, San Marino, Suécia, Suíça e Vaticano. Foi nestes países que as culturas ocidentais nasceram e floresceram, acabando por disseminar-se por todo o mundo.
Durante a Guerra Fria, quando a Europa Ocidental designava os países membros da NATO e sob influência norte-americana, o termo era frequentemente usado como contraponto ao Leste Europeu, que estava sob influência soviética. As fronteiras entre os países do Ocidente e do Leste estavam bem defendidas e patrulhadas, especialmente do lado oriental. A estas fronteiras dava-se também o nome de Cortina de Ferro.
Até há pouco tempo, podia-se dizer com segurança que a Europa Ocidental correspondia aos países da União Europeia, adicionando-se a Islândia, a Suíça, o Liechtenstein, Andorra, a Noruega, San Marino, Mónaco e o Vaticano.
Segundo a Organização das Nações Unidas, utilizando o critério de divisão por regiões geográficas, a Europa ocidental atualmente compreenderia a Alemanha, a Áustria, a Bélgica, a França, Liechtenstein, Luxemburgo, Mónaco, os Países Baixos e a Suíça. Já para a Unesco, segundo critérios histórico-sócio-culturais, a Europa Ocidental compreenderia os atuais territórios da Alemanha, Andorra, Bélgica, Dinamarca, Espanha, Finlândia, França, Grécia, Islândia, Irlanda, Itália, Liechtenstein, Luxemburgo, Malta, Mónaco, Noruega, Países Baixos, Portugal, Reino Unido, São Marino, Suécia e Suíça. 
Note-se que, exceção à parte oriental da Alemanha (que foi reunificada em 1990), por qualquer dos 2 critérios (como pode-se observar nos mapas ao lado), estão excluídos do presente conceito de Europa Ocidental todos os países que, como acordado na Conferência de Ialta, caíram na zona de influência soviética, sendo governados por regimes comunistas durante a Guerra Fria, incluindo os que faziam então parte da não alinhada Yugoslávia.
A República Federal da Alemanha é o país com o maior produto interno bruto da Europa, e o terceiro a nível mundial em termos nominais e quinto em paridade do poder de compra. Membro-fundador da União Europeia e membro do NATO e do G8, tem uma grande importância na geopolítica e economia mundial.
Desde a revolução industrial que o país tem sido criador, inovador e beneficiário de uma economia globalizada. A exportação de bens produzidos na Alemanha é um dos principais fatores da riqueza alemã. A Alemanha é maior exportador mundial com 1130 bilhões de dólares exportados em 2006 (países da Eurozona incluído) e gerou um superavit comercial de 165 bilhões de euros. O setor de serviços contribui com 70% do PIB, a indústria 29,1% e a agricultura 0,9%. A maioria dos produtos alemães são em engenharia, especialmente automóvel,máquina, metal, e produtos químicos
Com mais de 85 milhões de habitantes, a Alemanha é o pais mais populoso da União Europeia, apesar de sua taxa de natalidade seja de 1,39 filhos por mulher, uma das mais baixas do mundo. A Alemanha tem um grande número de cidades grandes, sendo as mais populosas Berlim, Hamburgo, Munique, Colônia, Frankfurt am Main e Estugarda (Stuttgart). De longe a maior aglomeração é a região do Reno-Ruhr, que inclui Düsseldorf e cidades como Colônia (Köln), Essen, Dortmund, Duisburgo e Bochum.
Sua língua, o alemão é falado por aproximadamente 100 milhões de falantes nativos e mais 80 milhões de falantes não-nativos. O alemão é a língua principal de aproximadamente 90 milhões de pessoas (18%) na UE. 67% dos cidadãos alemães dizem serem capazes de comunicar-se em pelo menos uma língua estrangeira, 27% em pelo menos duas línguas além da materna.
A República da Áustria é um país montanhoso, com de extensão territorial. A língua oficial é o alemão, a primeira língua de 97% da população. A Áustria foi a terra natal de vários compositores famosos tais como Wolfgang Amadeus Mozart, Joseph Haydn, Johann Strauss I, entre outros. A sua capital e principal cidade, Viena, é desde o século XVIII um dos mais importantes centros culturais europeus e mundiais.
Como membro da União Europeia, a Áustria possui um produto interno bruto de US$, o 35º maior do mundo. A Áustria, em vários momentos, tentou unir-se à Alemanha, mas nunca o conseguiu.
O Reino da Bélgica tem uma área de , distribuídos por três regiões principais: a planície costeira (localizada a noroeste), o planalto central e as elevações das Ardenas (situadas a sudeste). A sua população é cerca de 10,4 milhões, entre os quais 6,2 milhões são flamengos (na Flandres e Bruxelas), 3,2 milhões de valões, 900 mil habitantes em Bruxelas e 70 mil germanófonos.
É membro da União Europeia e da (NATO). A base da sua economia é a metalurgia, produtos químicos (farmacêuticos), electrónico ,têxteis, vidros,chocolates, diamantes e móveis.
Espanha (em castelhano e galego: "España"; em catalão e valenciano: "Espanya"; em basco: "Espainia"; em aranês: "Espanha"), oficialmente , é um país situado na Europa meridional, na Península Ibérica. Com uma área de , a Espanha é, depois da França, o segundo maior país da Europa Ocidental e da União Europeia.
O país foi uma importante fonte de influência para outras regiões no mundo durante a Era Moderna quando se tornou um império mundial, que deixou como legado mais de 400 milhões de falantes do espanhol espalhados pelo mundo.
A Espanha contemporânea é uma democracia organizada sob a forma de um governo parlamentar sob uma monarquia constitucional. Sendo também membro das Organização das Nações Unidas (ONU), da União Europeia (UE), da Organização do Tratado do Atlântico Norte (OTAN), da Organização para a Cooperação e Desenvolvimento Econômico (OCDE) e da Organização Mundial do Comércio (OMC).
A Finlândia (em finlandês: e em sueco: ), oficialmente República da Finlândia, é um país nórdico situado na região da Fino-Escandinávia. Faz fronteira com a Suécia a oeste, com a Rússia a leste e com a Noruega ao norte, enquanto a Estônia está ao sul através do Golfo da Finlândia. A capital do país é Helsinque.
Cerca de 5,3 milhões de pessoas vivem na Finlândia, sendo que a maior parte da população está concentrada no sul do país. É o oitavo maior país da Europa em extensão e o país menos densamente povoado da União Europeia. A língua materna de quase toda a população é o finlandês, que é uma das línguas fino-úgricas e é mais estreitamente relacionado com o estoniano.
A França, foi o primeiro dos grandes Estados europeus a ser formado, sendo sua capital em Paris. Incluindo os territórios ultramarinos, a França tem uma superfície de 675 417 km² e por volta de 64,5 milhões de habitantes. O francês é o idioma oficial, segundo a constituição, outros 77 línguas e dialetos existem no país. Uma das grandes incentivadoras e membro-criador da União Europeia, o país foi uma potência colonial no passado, e ainda possui territórios e dependências ultramarinas, em diversos lugares ao redor do mundo.
A França é um país rico, que disputa com a Alemanha e o Reino Unido a liderança da economia na União Europeia, porque é a segunda economia da Europa e a quinta maior do mundo. Paris é a segunda cidade mais populosa do continente, e figura como uma cidade global. Seu monumento mais emblemático é a Torre Eiffel.
Grécia (, ), é um país europeu localizado na parte meridional da região balcânica. Localizada no sudeste da Europa, junto de Ásia e África, a Grécia é considerada o berço da civilização ocidental, por ser a região onde nasceram a democracia, a filosofia ocidental, os Jogos Olímpicos, a Literatura ocidental, bem como a ciência política, se definiu os primeiros princípios matemáticos, assim como o teatro e a historiografia modernos.
Irlanda ( e ), oficialmente República da Irlanda ( e ), é um Estado soberano da Europa que ocupa cerca de cinco sextos da ilha homônima. É uma república constitucional governada como uma democracia parlamentar, com um presidente eleito servir como chefe de Estado. A Irlanda tem o sétimo mais alto Índice de Desenvolvimento Humano (IDH) do mundo, além de ótimas classificações em índices que medem o grau de democracia e liberdades como a de imprensa, econômica e política. Além da União Europeia (UE), a Irlanda também é membro do Conselho da Europa, da Organização para a Cooperação e Desenvolvimento Econômico (OCDE), da Organização Mundial do Comércio (OMC) e das Organização das Nações Unidas (ONU). Sua capital é Dublin e sua população é estimada em 4,58 milhões de habitantes.
O Estado moderno irlandês foi fundado em 1922 como o Estado Livre Irlandês, um domínio dentro do Império Britânico, na sequência do Tratado Anglo-Irlandês que pôs fim à Guerra de Independência da Irlanda. Seis dos nove condados da província nortista do Ulster foram então estabelecidos como a Irlanda do Norte, uma parte do Reino Unido, com o qual o Estado irlandês divide a sua única fronteira terrestre.
Outro país insular europeu pertencente à Europa Ocidental pelo critério histórico-sociocultural, é a Islândia (; ), situada no Oceano Atlântico Norte. O seu território abrange a ilha homônima e algumas pequenas ilhas no Oceano Atlântico, localizadas entre a Europa continental e a Groenlândia. O país conta com uma população de quase 320 mil habitantes em uma área de cerca de 103 mil quilômetros quadrados. A sua capital e maior cidade é Reiquiavique, cuja área metropolitana abriga cerca de dois terços da população nacional. Devido à sua localização na Dorsal Meso-Atlântica, a Islândia tem uma grande atividade vulcânica e um importante gradiente geotérmico, o que afeta muito a sua paisagem. O interior é constituído principalmente por um planalto caracterizado por campos de areia, montanhas e glaciares. Aquecida pela corrente do Golfo, a Islândia tem um clima temperado em relação à sua latitude e oferece um ambiente habitável.
Itália (), oficialmente República Italiana (), é uma república parlamentar unitária localizada no centro-sul da Europa (Europa meridional). Ao norte, faz fronteira com França, Suíça, Áustria e Eslovênia ao longo dos Alpes. Ao sul, que consiste na totalidade da península Itálica, Sicília, Sardenha, as duas maiores ilhas no Mar Mediterrâneo, e muitas outras ilhas menores ficam no entorno do território italiano. Os Estados independentes de San Marino e do Vaticano são enclaves no interior de Itália, enquanto Campione d'Italia é um enclave italiano na Suíça. Com 60,6 milhões de habitantes, é a sexta nação mais populosa da Europa e a 23ª do mundo.
Roma, a capital italiana, foi durante séculos o centro político e religioso da civilização ocidental, como a capital do Império Romano, e como sede da Santa Sé. Após o declínio dos romanos, a Itália sofreu inúmeras invasões de povos estrangeiros. Séculos mais tarde, Itália tornou-se o berço das repúblicas marítimas e do "Renascimento", um movimento intelectual extremamente frutífero que viria a ser parte integrante na formação subsequente do pensamento europeu.
A Itália contemporânea nasceu como um Estado unitário, quando em 17 de março de 1861, a maioria dos estados da península e as duas principais ilhas foram unidas sob o comando do rei da Sardenha Vitor Emanuel II da casa de Saboia.
Liechtenstein ou Listenstaine (forma usada oficialmente pela União Europeia) é um minúsculo principado, localizado no centro da Europa, encravado nos Alpes, entre a Áustria, a leste, e a Suíça a oeste. Tem uma população de pouco mais de 34 mil habitantes que moram no principado de apenas 160 km².
O Grão-Ducado do Luxemburgo caracteriza-se por uma economia de boa renda e crescimento contínuo, tem o maior PNB (Produto Nacional Bruto) per capita do mundo ($US), além de baixíssimos índices de inflação e desemprego. O setor industrial era dominado praticamente pelo aço, mas recentemente se diversificou ao incluir o ramo químico e a borracha.
O Principado do é o segundo menor Estado independente do mundo (depois do Vaticano), constituindo um principado encravado no sul da França, (Costa Azul) a dezoito quilômetros de Nice e perto da fronteira com a Itália. Além das finanças, a economia monegasca é movimentada em grande parte pelo setor imobiliário: as duzentas empresas de construção civil são a força motriz da economia. O turismo é uma das mais importantes fontes de renda do país. O setor hoteleiro é dinâmico: quartos que recebem, ao ano, 225 mil visitantes.
Apenas 16% dos habitantes são monegascos. Os demais habitantes são franceses (47%), italianos (16%) e outros (21%). O idioma oficial é o francês, mas falam-se várias outras línguas devido às variadas origens de seus habitantes. Dentre estas as principais são o monegasco, o inglês e o italiano.
A Noruega (bokmål: "Norge"; nynorsk "Noreg"), oficialmente Reino da Noruega, é um país nórdico da Europa setentrional que ocupa a parte ocidental da Península Escandinava, a ilha de Jan Mayen e o arquipélago ártico de Svalbard, através do Tratado de Svalbard. A parte continental do país divide fronteira a leste com a Suécia e ao norte com a Finlândia e a Rússia. O Reino Unido e as Ilhas Faroe estão a oeste, através do Mar do Norte, a Islândia e a Groenlândia estão a oeste, através do mar da Noruega, e a Dinamarca fica próxima ao extremo sul do país, através do estreito de Skagerrak.
A Noruega mantém o modelo social escandinavo baseado na saúde universal, no ensino superior subsidiado e em um regime abrangente de previdência social. A Noruega foi classificada como o melhor país do mundo em desenvolvimento humano em todos os relatórios desde 2001 (com dados referentes entre 1999 e 2010)
Apesar de ter rejeitado a adesão à União Europeia em dois referendos, a Noruega mantém laços estreitos com a UE e com seus países membros, bem como com os Estados Unidos. A Noruega continua a ser um dos maiores contribuintes financeiros da Organização das Nações Unidas e participa com as forças da ONU em missões internacionais, como no Afeganistão, Kosovo e Darfur.
Os Países Baixos (incorretamente chamados de Holanda) é um dos países mais densamente povoados do globo. São popularmente conhecidos por seus diques, suas tulipas, seus moinhos, seus tamancos e sua tolerância social. Suas políticas liberais são frequentemente mencionadas e usadas como (bons ou maus) exemplos nos demais países.
Um dos fatores culturais que mais destaca os Países Baixos são os pintores renomados ao longo dos séculos. Durante o século XVII, quando o país era uma República e bem próspera, houve o surgimento de grandes artistas e aquela época ficou conhecida como a Era dos Mestres neerlandeses, entre eles, Rembrandt van Rijn, Johannes Vermeer, Jan Steen e Jacob van Ruysdael. Grandes Pintores do século XIX e XX foram Vincent van Gogh e Piet Mondriaan.
Portugal, oficialmente República Portuguesa, é um país soberano unitário localizado no Sudoeste da Europa, cujo território se situa na zona ocidental da Península Ibérica e em arquipélagos no Atlântico Norte. Portugal é a nação mais a ocidente do continente europeu. O nome do país provém da sua segunda maior cidade, Porto, cujo nome latino era "Portus Cale".
O território dentro das fronteiras actuais da República Portuguesa tem sido continuamente povoado desde os tempos pré-históricos: ocupado por celtas, como os galaicos e os lusitanos, foi integrado na República Romana e mais tarde colonizado por povos germânicos, como os suevos e os visigodos, e no século VIII as terras foram conquistadas pelos mouros. Durante a Reconquista cristã foi formado o Condado Portucalense, primeiro como parte do Reino da Galiza e depois integrado no Reino de Leão. Com o estabelecimento do Reino de Portugal em 1139, cuja independência foi reconhecida em 1143, e a estabilização das fronteiras em 1249, Portugal tornou-se o mais antigo Estado-nação da Europa.
Nos séculos XV e XVI, como resultado de pioneirismo na era dos Descobrimentos, Portugal expandiu a influência ocidental e estabeleceu um império que incluía possessões na África, Ásia, Oceania e América do Sul, tornando-se a potência económica, política e militar mais importante de todo o mundo. O Império Português foi o primeiro império global da história e também o mais duradouro dos impérios coloniais europeus, abrangendo quase 600 anos de existência, no entanto a importância internacional do país foi bastante reduzida a partir do século XVII, em consequência da União Ibérica. Após a Revolução de 1910, a monarquia foi deposta e iniciada a Primeira República Portuguesa, cuja instabilidade culminou na instauração de um regime autoritário, o Estado Novo. A democracia representativa foi instaurada após a Revolução dos Cravos, em 1974, que terminou a Guerra Colonial Portuguesa, quando as últimas províncias ultramarinas de Portugal se tornaram independentes, sendo as mais proeminentes Angola e Moçambique.
Reino Unido (), oficialmente Reino Unido da Grã-Bretanha e Irlanda do Norte (), é um país insular soberano localizado na costa noroeste da Europa continental. O Reino Unido inclui a ilha da Grã-Bretanha, a parte nordeste da ilha da Irlanda, além de muitas outras ilhas menores. A Irlanda do Norte é a única parte do Reino Unido com uma fronteira terrestre, sendo a mesma com a República da Irlanda. Rodeado pelo Oceano Atlântico, o Mar do Norte, o Canal da Mancha e o Mar da Irlanda, a maior ilha, a Grã-Bretanha, é conectada com a França pelo Eurotúnel.
O Reino Unido é uma união política de quatro nações constituintes: Escócia, Inglaterra, Irlanda do Norte e País de Gales. A nação é governada por um sistema parlamentar com a sede do governo em Londres, a capital, e é uma monarquia constitucional com a rainha Isabel II sendo a chefe de Estado. As dependências da Coroa das Ilhas do Canal (ou Ilhas Anglo-Normandas) e a Ilha de Man, formalmente possessões da Coroa, não fazem parte do Reino Unido, mas formam uma confederação com ele. O Reino Unido tem quatorze territórios ultramarinos, todos remanescentes do Império Britânico, que no seu ápice, possuía quase um quarto da superfície terrestre mundial, fazendo desse o maior império da história. Como resultado do império, a influência britânica pode ser vista na língua, cultura e sistemas judiciários de muitas de suas ex-colônias como o Canadá, Austrália, Índia e os Estados Unidos. A rainha Elizabeth II permanece como a chefe da Comunidade das Nações ("Commonwealth") e chefe de Estado de cada uma das monarquias na Commonwealth.
Suécia (), oficialmente Reino da Suécia (em sueco: "Konungariket Sverige"), é um país nórdico, localizado na Península Escandinava. A Suécia divide fronteiras terrestres com a Noruega, a oeste, e com a Finlândia, a nordeste, além de estar ligada à Dinamarca através da Ponte do Øresund, no sul.
Com km², a Suécia é o terceiro maior país da União Europeia em termos de área e possui uma população total de cerca de 9,2 milhões de habitantes. A Suécia tem uma baixa densidade populacional, com cerca de 21 habitantes por quilômetro quadrado, mas com uma densidade consideravelmente maior na metade sul do país. Cerca de 85% da população vive em áreas urbanas. A capital e maior cidade da Suécia é Estocolmo (com uma população de 1,3 milhões na área urbana e de 2 milhões na área metropolitana), centro do poder político e econômico do país. A Suécia é membro fundador da ONU, da União Europeia desde 1 de Janeiro de 1995, e da OCDE.
A Suécia é uma monarquia constitucional com um sistema parlamentar de governo e é uma economia altamente desenvolvida e diversificada. O país ocupa o quarto lugar do mundo no índice de democracia, depois da Islândia, da Dinamarca e da Noruega.
A Suíça, oficialmente Confederação Helvética é uma das economias mais ricas do mundo, e é sede de inúmeros bancos privados e de organizações internacionais. A sua história é marcada pela sua neutralidade política perante as outras nações e representa um marco de liberdade e de democracia para o mundo inteiro.

A Europa é, por convenção, um dos seis continentes do mundo. Compreendendo a península ocidental da Eurásia, a Europa geralmente divide-se da Ásia a leste pela divisória de águas dos montes Urais, o rio Ural, o mar Cáspio, o Cáucaso, e o mar Negro a sudeste. A Europa é limitada pelo oceano Glacial Ártico e outros corpos de água no norte, pelo oceano Atlântico a oeste, pelo mar Mediterrâneo ao sul, e pelo mar Negro e por vias navegáveis interligadas ao sudeste. No entanto, as fronteiras para a Europa, um conceito que remonta à Antiguidade clássica, são um tanto arbitrárias, visto que o termo "Europa" pode referir-se a uma distinção cultural e política ou geográfica.
A Europa é o segundo menor continente em superfície do mundo, cobrindo cerca de ou 2% da superfície da Terra e cerca de 6,8% da área acima do nível do mar. Dos cerca de 50 países da Europa, a Rússia é o maior tanto em área quanto em população (sendo que a Rússia se estende por dois continentes, a Europa e a Ásia) e o Vaticano é o menor. A Europa é o quarto continente mais populoso do mundo, após a Ásia, a África e a(s) América(s), com 740 milhões de habitantes em 2015, cerca de 11% da população mundial naquele ano, isto é, a cada 100 pessoas no mundo neste período, 11 viviam no continente. No entanto, de acordo com a Organização das Nações Unidas (estimativa média), o peso europeu pode cair para cerca de 7% em 2050. Em 1900, por exemplo, a população europeia representava 25% da população mundial (ou seja, a cada 4 habitantes do mundo naquele ano, 1 vivia dentro dos limites do continente).
A Europa, nomeadamente a Grécia Antiga, é considerada o berço da cultura ocidental. Tendo desempenhado um papel preponderante na cena mundial a partir do , especialmente após o início do colonialismo. Entre os séculos XVI e XX, as nações europeias controlaram em vários momentos as Américas, a maior parte da África, a Oceânia e grande parte da Ásia. Ambas as guerras mundiais foram em grande parte centradas na Europa, sendo considerado como o principal fator para um declínio do domínio da Europa Ocidental na política e economia mundial a partir de meados do , com os Estados Unidos e a União Soviética ganhando maior protagonismo. Durante a Guerra Fria, a Europa estava dividida politicamente ao longo da Cortina de Ferro entre a Organização do Tratado do Atlântico Norte, a oeste, e o Pacto de Varsóvia, a leste. A vontade de evitar outra guerra acelerou o processo de integração europeia e levou à formação do Conselho Europeu e da União Europeia na Europa Ocidental, os quais, desde a queda do Muro de Berlim e do fim da União Soviética em 1991, têm vindo a expandir-se para o leste. A moeda da maior parte dos países da União Europeia, o euro, é mais comumente usada por europeus; O Acordo de Schengen aboliu controles de imigração fortes nas fronteiras de países membros da União Europeia. O hino à Alegria é o hino do Conselho Europeu e da União Europeia.
O uso do termo "Europa" desenvolveu-se gradualmente ao longo da história. Na antiguidade, o historiador grego Heródoto provavelmente em referência a mapas de Hecateu de Mileto embora sem o nomear explicitamente, descreve o mundo como tendo sido dividido em três continentes, sendo eles a Europa, a Ásia e a Líbia (África), com o Nilo e o rio Fásis formando de suas fronteiras, embora também afirme que alguns consideravam o rio Don, em vez do Fásis, como a fronteira entre Europa e Ásia. Flávio Josefo e o Livro dos Jubileus descrevem os continentes como as terras dadas por Noé aos seus três filhos, sendo a Europa definida entre as Colunas de Hércules no Estreito de Gibraltar, separando-a da África, e o rio Don, separando-o da Ásia.
A definição cultural da Europa como terras da cristandade latina consolidou-se no , significando um novo local cultural criado através da confluência de tradições germânicas e da cultura cristã-latina, definidas em parte, em contraste com o Islão e Império Bizantino, e limitado a norte pela Ibéria (no Cáucaso), Ilhas Britânicas, França, Alemanha ocidental cristianizada, e as regiões alpinas do norte e no centro da Itália. Esta divisão, tanto geográfica como cultural, foi utilizada até a Baixa Idade Média, quando foi desafiada pela Era dos descobrimentos. O problema da redefinição da Europa, finalmente foi resolvido em 1730 quando, em vez de canais, o geógrafo e cartógrafo sueco von Strahlenberg propôs os Montes Urais como a fronteira mais importante do leste, uma sugestão que foi aceita na Rússia e em toda a Europa.
A Europa está agora em geral, definida pelos geógrafos, como a península ocidental da Eurásia, com seus limites marcados por grandes massas de água para o norte, oeste e sul; limites da Europa para o Extremo Oriente são normalmente tomadas para os Urais, o rio Ural, e o Mar Cáspio, a sudeste, as montanhas do Cáucaso, o Mar Negro e nas vias que ligam o Mar Negro ao Mar Mediterrâneo.
Às vezes, a palavra "Europa" é utilizada de forma geopoliticamente limitada para se referir apenas à União Europeia ou, ainda mais exclusiva, a um núcleo cultural definido. Por outro lado, o Conselho da Europa tem 47 países membros, e apenas 28 estados-membros estão na UE. Além disso, pessoas que vivem em áreas insulares, como a Irlanda, o Reino Unido, no Atlântico Norte e Mediterrâneo e ilhas também na Escandinávia podem rotineiramente se referir a parte "continental" ou ao "continente" da Europa ou simplesmente como "o continente".
Na mitologia grega, Europa era uma princesa fenícia que Zeus sequestrou depois de assumir a forma de um touro branco deslumbrante. Ele a levou para a ilha de Creta, onde ela deu à luz Minos, Radamanto e Sarpedão. Para Homero, Europa (em grego: , "") era uma rainha mitológica de Creta e não uma designação geográfica. Mais tarde, o termo "Europa" foi usado para se referir ao centro-norte da Grécia, e em , seu significado foi estendido para as terras ao norte.
O nome "Europa" é de etimologia incerta. Uma teoria sugere que a palavra é derivada do grego εὐρύς ("eurus"), que significa "largo, amplo" e ὤψ/ὠπ-/ὀπτ- ("ōps"/"ōp"-/"opt-") significa "olho, rosto, semblante", portanto "" seria algo como "ampla contemplação". "Amplo" era um epíteto da própria Terra na religião protoindo-europeia. Outra teoria sugere que o termo é baseado em uma palavra semita como o mesmo significado do acadiano "erebu", algo como "para ir para baixo, pôr-se" (cf. Ocidente), um cognato do fenício "ereb" "noite; oeste" e do árabe do Magreb, do hebraico "ma'ariv" (ver "Érebo", PIE "*hregʷos", "escuridão"). No entanto, M. L. West afirma que "fonologicamente, a correspondência entre o nome de Europa e qualquer forma da palavra semítica é muito pobre".
As principais línguas do mundo mais usam palavras derivadas de "Europa" para se referir ao "continente" (península). O chinês, por exemplo, usa a palavra ' (歐洲); este termo também é usado para se referir à União Europeia nas relações diplomáticas em língua japonesa, apesar do termo katakana ' ser mais comumente usado. No entanto, em algumas línguas turcas, o nome originalmente persa "Frangistan" (terra dos francos) é usado casualmente para se referir à grande parte da Europa, além de nomes oficiais, como "Avrupa" ou "Evropa".
Os "Homo erectus" e os Neanderthalis habitavam a Europa bem antes do surgimento dos humanos modernos, os "Homo sapiens". Os ossos dos primeiros europeus foram achados em Dmanisi, Geórgia, e datados de 1,8 milhões de anos. O primeiro aparecimento do povo anatomicamente moderno na Europa é datado de Evidências de assentamentos permanentes datam do na Bulgária, Roménia e Grécia. O período neolítico chegou na Europa central no e em partes da Europa Setentrional no 5º e A civilização Tripiliana (-) foi a primeira grande civilização da Europa e uma das primeiras do mundo; era localizada na Ucrânia moderna e também na Moldávia e Roménia. Foi provavelmente mais antiga que os Sumérios no Oriente Próximo, e tinha cidades com habitantes que cobriam 450 hectares.
Começando no Neolítico, tem-se a civilização dos Camunos no Val Camonica, Itália, que deixou mais de petróglifos, o maior sítio arqueológico da Europa.
Também conhecido como Idade do Cobre, o Calcolítico europeu foi um tempo de mudanças e confusão. O fato mais relevante foi a infiltração e invasão de imensas partes do território por povos originários da Ásia Central, considerado pelos principais historiadores como sendo os originais indo-europeus, mas há ainda diversas teorias em debate. Outro fenómeno foi a expansão do Megalitismo e o aparecimento da primeira significante estratificação económica e, relacionado a isso, as primeiras monarquias conhecidas da região dos Balcãs. A primeira civilização bem conhecida da Europa foi as dos Minoicos da ilha de Creta e depois os Micenas em adjacentes partes da Grécia, no começo do 
Embora o uso do ferro fosse de conhecimento dos povos egeus por volta de , não chegou à Europa Central antes de , levando ao início da Cultura de Hallstatt, uma evolução da Idade do Ferro (que até então se encontrava na Cultura dos Campos de Urnas). Provavelmente como subproduto desta superioridade tecnológica, pouco depois os indo-europeus consolidam claramente suas posições na Itália e na Península Ibérica, penetrando profundamente naquelas penínsulas (Roma foi fundada em 
Os gregos e romanos deixaram um legado na Europa que é evidente nos pensamentos, leis, mentes e línguas actuais. A Grécia Antiga foi uma união de cidades-estado, na qual uma primitiva forma de democracia se desenvolveu. Atenas foi sua cidade mais poderosa e desenvolvida, e um berço de ensinamento nos tempos de Péricles. Fóruns de cidadãos aconteciam e o policiamento do estado deu ordem ao aparecimento dos mais notáveis filósofos clássicos, como Sócrates, Platão e Aristóteles. Como rei do Reino Grego da Macedónia, as campanhas militares de Alexandre o Grande espalharam a cultura helénica até às nascentes do rio Indo.
Mas a República Romana, alicerçada pela vitória sobre Cartago nas Guerras Púnicas, estava crescendo na região. A sabedoria grega passada às instituições romanas, assim como a própria Atenas foi absorvida sob a bandeira do senado e do povo de Roma. Os romanos expandiram seu império desde a Arábia até a Bretanha. Em quando atingiu o seu ápice, seu líder, Júlio César foi morto sob suspeitas de estar corrompendo a república para se tornar um ditador. Na sucessão, Otaviano usurpou as raízes do poder e dissolveu o senado romano. Quando proclamou o renascimento da república ele, de facto, transferiu o poder do senado romano quando república para um império, o Império Romano.
Quando o Imperador Constantino reconquistou Roma sob a bandeira da Cruz em 312, ele rapidamente editou o Édito de Milão em 313, declarando legal o cristianismo no Império Romano. Além disso, Constantino mudou oficialmente a capital do império, Roma, para a colónia grega de Bizâncio, que ele renomeou para Constantinopla ("Cidade de Constantino"). Em 395, Teodósio, que tornou o cristianismo religião oficial do Império Romano, iria ser o último imperador a comandar o Império Romano em toda a sua unidade, sendo depois o império dividido em duas partes: O Império Romano do Ocidente, centrado em Ravena, e o Império Romano do Oriente (depois referido como Império Bizantino) centrado em Constantinopla. A parte ocidental foi seguidamente atacada por tribos nómadas germânicas, e em 476 finalmente caiu sob a invasão dos Hérulos comandados por Odoacro.
A autoridade romana no Oeste entrou em colapso e as províncias ocidentais logo tornaram-se pedaços de reinos germânicos. Entretanto, a cidade de Roma, sob o comando da Igreja Católica Romana permaneceu como um centro de ensino, e fez muito para preservar o pensamento clássico romano na Europa Ocidental. Nesse meio-tempo, o imperador romano em Constantinopla, Justiniano I, conseguiu com sucesso, montar toda a lei romana no Corpo do Direito Civil . Por todo o , o Império Romano do Oriente esteve envolvido numa série de conflitos sangrentos, primeiro contra o Império Sassânida, depois contra o Califado Ortodoxo. Em 650, as províncias do Egito, Palestina e Síria foram perdidas para forças muçulmanas.
Na Europa Ocidental, uma estrutura política surgia: no vácuo do poder deixado pelo colapso de Roma, hierarquias locais foram construídas sob a união das pessoas nas terras que eram trabalhadas. Dízimos eram pagos ao senhor da terra e este senhor devia tributos ao príncipe regional. Os dízimos eram usados para financiar o estado e as guerras. Esse foi o sistema feudal, no qual novos príncipes e reis apareceram, no qual o maior deles foi o líder Franco Carlos Magno. Em 800, Carlos Magno, após as suas grandes conquistas territoriais, foi coroado Imperador dos Romanos ("Imperator Romanorum") pelo Papa Leão III, afirmando efectivamente o seu poder na Europa Ocidental. O reinado de Carlos Magno marcou o começo dum novo império germânico no oeste, o Sacro Império Romano. Para além das suas fronteiras novas forças estavam crescendo. O Principado de Kiev estava delimitando o seu território, a Grande Morávia estava crescendo, enquanto os anglos e os saxões estavam confirmando as suas fronteiras.
O Renascimento foi um movimento cultural que afectou profundamente a vida intelectual europeia no seu período pré-moderno. Começando em Itália, e espalhando-se de norte a oeste, o renascimento durou aproximadamente 250 anos e a sua influência afectou a literatura, filosofia, arte, política, ciência, história, religião entre outros aspectos de indagação intelectual.
O italiano Francesco Petrarca ("Francesco di Petracco"), suposto primeiro legítimo humanista, escreveu na década de 1330: "Estou vivo agora, ainda que eu prefira ter nascido noutro tempo". Ele era um entusiasta da antiguidade romana e grega. Nos séculos XV e XVI, o contínuo entusiasmo pela antiguidade clássica foi reforçado pela ideia de que a cultura herdada estava se dissipando e de que havia um conjunto de ideias e atitudes com que seria possível reconstruí-la. Matteo Palmieri escreveu em 1430: "Agora, com certeza, todo espírito pensante deve agradecer a Deus, porque a ele foi permitido nascer numa nova era". O Renascimento fez nascer uma nova era em que aprender era muito importante.
Importantes precedentes políticos aconteceram neste período. O político Nicolau Maquiavel escreveu "O Príncipe" que influenciou o posterior absolutismo e a política pragmática. Também foram importantes os diversos líderes que governaram estados e usaram a arte da Renascença como sinal de seus poderes.
Durante esse período, a corrupção da Igreja Católica levou a uma dura reação, na Reforma Protestante. E ela ganhou muitos seguidores, especialmente entre príncipes e reis buscando um estado forte para acabar com a influência da igreja católica. Figuras como Martinho Lutero começaram a surgir, assim também como João Calvino com o seu Calvinismo que teve influência em muitos países e o rei que rompeu com a igreja católica e fundou a Igreja Anglicana. Essas divisões religiosas trouxeram uma onda de guerras inspiradas e conduzidas religiosamente, mas também pela ambição dos monarcas na Europa Ocidental que se tornavam cada vez mais centralizadas e poderosas.
A reforma protestante também levou a um forte movimento reformista na igreja católica chamado Contra-Reforma, que tinha como objectivo reduzir a corrupção, assim como aumentar e fortalecer o dogma católico. Um importante grupo da igreja católica que surgiu nessa época foram os Jesuítas, que ajudaram a manter a Europa Oriental na linha católica de pensamento. Mesmo assim, a igreja católica foi fortemente enfraquecida pela reforma e, grande parte do continente não estava mais sob sua influência e os reis nos países que continuaram no catolicismo começaram a anexar as terras da igreja para os seus próprios domínios.
As numerosas guerras não impediram que os novos estados explorassem e conquistassem largas porções do mundo, particularmente na Ásia (Sibéria) e a recém-descoberta América. No , Portugal liderou a exploração geográfica, seguido pela Espanha no começo no . Eles foram os primeiros estados a fundar colónias/colônias na América e estações de troca nas costas da África e da Ásia, porém logo foram seguidos pela França, Inglaterra e Holanda. Em 1552, o czar Russo Ivan, o Terrível conquistou os dois maiores canatos tártaros, Cazã e Astracã, e a viagem de Yermak em 1580, que levou a anexação da Sibéria pela Rússia.
A expansão colonial prosseguiu-se nos anos seguintes (mesmo com alguns empecilhos, como a Revolução Americana e as guerras pela independência em muitas colónias americanas). A Espanha controlou parte da América do Norte e grande parte da América Central e do Sul, as Caraíbas/o Caribe e Filipinas.; Portugal teve em suas mãos o Brasil e a maior parte dos territórios costeiros em África e na Ásia (Índia e pequenos territórios na China etc); Os britânicos comandavam a Austrália, Nova Zelândia, maior parte da Índia e grande parte da África e América do Norte; a França comandou partes do Canadá e da Índia (porém quase tudo foi perdido para os britânicos em 1763), a Indochina, grandes terras na África e Caribe; a Holanda ganhou as Índias Orientais (hoje Indonésia) e algumas ilhas nas Caraíbas/no Caribe; países como Alemanha, Bélgica, Itália e Rússia conquistaram colónias posteriormente.
Essa expansão ajudou a economia dos países que a fizeram. O comércio prosperou, por causa da menor estabilidade entre os impérios. No final do , a prata americana era responsável por 1/5 de todo o comércio da Espanha. Os países europeus travaram guerras que foram pagas através do dinheiro conseguido com a exploração das colónias/colônias. No entanto, os lucros com o tráfico de escravos e as plantações das Índias Ocidentais, a mais rentável das colônias britânicas naquele momento, representavam apenas 5% de toda a economia do Império Britânico no final do , tempo da Revolução Industrial.
A partir do início deste período, o capitalismo substituía o feudalismo como principal forma de organização económica, ao menos no oeste da Europa. A expansão das fronteiras coloniais resultou numa Revolução Comercial. Nota-se no período o crescimento da ciência moderna e a aplicação de suas descobertas em melhorias tecnológicas, que culminaram com a revolução Industrial. Descobertas ibéricas do Novo Mundo, que começaram com a jornada de Cristóvão Colombo ao oeste com a busca de uma rota fácil para as Índias Orientais em 1492, foram logo adaptadas por explorações inglesas e francesas na América do Norte. Novas formas de comércio e a expansão dos horizontes fizeram necessária uma mudança no direito internacional.
A reforma protestante produziu efeitos profundos na unidade europeia. Não apenas dividindo as nações uma das outras pela sua orientação religiosa, mas alguns estados foram afectados internamente por lutas religiosas, fortemente encorajadas por seus inimigos externos. A França viveu essa situação no com uma série de conflitos, como as guerras religiosas na França, que culminaram no triunfo da Dinastia Bourbon. A Inglaterra preveniu-se desse facto/fato com a consolidação sob a Rainha Elizabeth do moderado Anglicanismo. Quase toda a parte da atual Alemanha estava dividida em inúmeros estados sob o comando teórico do Sacro Império Romano Germânico, que também estava dividido dentro do próprio governo. A única exceção a isso era a Comunidade Polaco-Lituana, uma união criada pela União de Lublin, expressando uma grande tolerância religiosa. Esse embate religioso aconteceu até à Guerra dos Trinta Anos quando o nacionalismo substituiu a religião como principal motor dos conflitos na europa.
A Guerra dos Trinta Anos aconteceu entre 1618 e 1648, principalmente no território da atual Alemanha, e envolveu as principais potências europeias. Começou como um conflito religioso entre Protestantes e Católicos no Sacro Império Romano Germânico, e gradualmente desenvolveu-se numa guerra geral, envolvendo boa parte da europa, por razões não necessariamente ligadas à religião. O maior impacto da guerra, na qual exércitos de mercenários foram largamente utilizados, foi a devastação de regiões inteiras na busca do exército inimigo. Episódios como a disseminação da fome e das doenças devastaram a população dos estados germânicos e, em menor grau, dos Países Baixos e da Itália, onde levaram à falência muito dos poderes regionais envolvidos. Entre um quarto e um terço da população alemã pereceu por causas diretamente ligadas à guerra ou ainda de doenças e miséria causadas pelo conflito armado. A guerra durou trinta anos, mas os conflitos que ela deu início ainda continuaram sem solução por muito tempo.
Depois da Paz de Vestfália, que permitiu aos países que eles escolhessem a sua orientação religiosa, o Absolutismo tornou-se o padrão do continente, enquanto a Inglaterra caminhava rumo ao liberalismo com a Guerra Civil Inglesa e a Revolução Gloriosa. Os conflitos militares na europa não acabaram, mas tiveram menos impacto na vida dos seus cidadãos. No noroeste, o Iluminismo deu a base filosófica para um novo ponto de vista na sociedade, e a contínua difusão da literatura foi possível com a invenção da prensa, criando novas formas de avanço do pensamento humano. Ainda, nesse segmento, a Comunidade Polaco-Lituana foi uma exceção, com a sua quase democrática "liberdade dourada".
A Europa Oriental era uma arena de conflito disputada pela Suécia, Comunidade Polaco-Lituana e Império Otomano. Nesse período observou-se um gradual declínio destes três poderes que foram eventualmente substituídos pelas novas monarquias absolutistas, Rússia, Prússia e Áustria. Na virada para o , eles tornaram-se as novas potências, dividindo a Polónia entre si, com Suécia e Turquia perdendo territórios substanciais para a Rússia e a Áustria respetivamente/respectivamente. Uma grande parte de judeus polacos/poloneses emigrou para a Europa Ocidental, fundando comunidades judaicas em lugares de onde foram expulsos durante a Idade Média.
A intervenção francesa na Guerra de Independência dos EUA levou o estado francês à falência. Depois de diversas tentativas falhas de uma reforma financeira, foi forçado a reavivar a Assembleia dos Estados Gerais, um corpo representativo do país feito pelas três classes do estado: o clero, os nobres e o povo. Os membros dos Estados-Gerais reuniram-se no Palácio de Versalhes em maio de 1789, mas o debate e a forma de votação que seria usada criaram um impasse. Veio junho, e o terceiro estado, associado a membros dos dois outros estados, declarou-se uma Assembleia Nacional e prometeu não se dissolver até que França tivesse uma constituição e criasse, em julho, uma Assembleia Nacional Constituinte. No mesmo tempo, os parisienses revoltaram-se, celebremente derrubando a prisão da Bastilha em 14 de julho de 1789.
Nesse tempo, a assembleia criou uma monarquia constitucional, e nos dois anos que se passaram várias leis foram criadas como a Declaração dos direitos do Homem e do Cidadão, a abolição do feudalismo e uma mudança fundamental das relações entre a França e Roma. No início, o rei continuou no trono ao longo dessas mudanças e gozou de uma popularidade razoável com o povo, mas a anti-realeza crescia com o perigo de uma invasão estrangeira. Então o rei, sem poderes, decidiu fugir com a sua família, mas ele foi reconhecido de volta a Paris. Em 12 de janeiro de 1793, sendo condenada a sua traição, ele foi executado.
Em 20 de setembro de 1792, a convenção nacional aboliu a monarquia e declarou a França uma república. Devido à iminência das guerras, a convenção nacional criou o Comitê de Salvação Pública controlado por Maximilien Robespierre do Partido dos Jacobinos, para atuar como executivo do país. Sob Robespierre o comitê iniciava o Reino do terror, no qual cerca de pessoas foram executadas em Paris, na maioria nobres, apesar de, frequentemente, faltarem evidências. Por todo o país, insurreições contra-revolução foram brutalmente reprimidas. O regime foi posto abaixo no golpe de 9 Termidor (27 de Julho de 1794) e Robespierre foi executado. O regime que se seguiu acabou com o Terror e afrouxou a maioria das regras extremas de Robespierre.
Napoleão Bonaparte foi o general francês que mais obteve sucesso nas guerras da Revolução, tendo conquistado grandes porções da península Itálica e forçado os austríacos à paz. Em 1799, retornou do Egito e em 18 de Brumário (9 de Novembro) subjugou o governo, substituindo-o pelo seu Consulado, do qual tornou-se o primeiro Cônsul. Em 2 de Dezembro de 1804, depois duma tentativa de assassinato, ele coroou-se imperador. Em 1805, Napoleão planeou invadir a Grã-Bretanha, mas a recém-criada aliança entre britânicos, russos e austríacos (Terceira Coalizão) forçou-o a direcionar a atenção para o continente, quando ao mesmo tempo ele tinha falhado em desviar a Armada Superior Britânica para longe do Canal da Mancha, ocasionando uma decisiva derrota francesa na batalha de Trafalgar em 21 de outubro, e colocando um fim às suas esperanças de invadir a Grã-Bretanha. Em 2 de dezembro de 1805, Napoleão derrotou o exército austro-russo, numericamente superior, em Austerlitz, forçando a Áustria desistir da coalizão e levando à fragmentação do Sacro Império Romano Germânico. Em 1806, a Quarta coalizão foi formada; em 14 de Outubro Napoleão derrotou os prussianos na Batalha de Jena-Auerstedt, marchando através da Alemanha e derrotando os russos em 14 de junho de 1807 em Friedland. Os Tratados de Tilsit dividiram a Europa entre França e Rússia e criaram o Ducado de Varsóvia.
Em 12 de junho de 1812, Napoleão invadiu a Rússia com a sua Grande Armée de aproximadamente soldados. Após as vitórias em Smolensk e Borodino, Napoleão ocupou Moscovo, apenas para encontrá-la queimada pelo exército russo em retirada. Assim, ele foi forçado a bater com seu exército em retirada. Na volta o seu exército foi arrasado pelos cossacos e sofreu de doenças, fome e com o rigoroso inverno russo. Apenas soldados sobreviveram a essa campanha. Em 1813, começou o declínio de Napoleão, sendo derrotado pelo Exército das Sete Nações na Batalha de Leipzig em outubro de 1813. Ele foi forçado a abdicar depois da Campanha dos Seis Dias e a ocupação de Paris. Sob o Tratado de Fontainebleau ele foi exilado na Ilha de Elba. Retornou à França em 1 de março de 1815 e convocou um exército leal, mas foi compreensivelmente derrotado por forças britânicas e prussianas na Batalha de Waterloo em 18 de junho de 1815.
Depois da derrota da revolucionária França, outras grandes forças tentaram restaurar a situação existente antes de 1789. Em 1815, no Congresso de Viena, as maiores forças da Europa organizaram-se para produzir um pacífico equilíbrio de poder entre os impérios depois das Guerrras Napoleónicas (embora estivessem ocorrendo movimentos internos revolucionários) sob o sistema de Matternich. Entretanto, os seus esforços foram incapazes de parar a propagação de movimentos revolucionários: a classe média foi profundamente influenciada pelos ideais de democracia da Revolução Francesa, a revolução Industrial trouxe importantes mudanças sócio-económicas/econômicas, as classes baixas começaram a ser influenciadas pelas ideias socialistas, comunistas e anarquistas (especialmente unidas por Karl Marx no Manifesto Comunista), e a preferência dos novos capitalistas era o liberalismo.
Uma nova onda de instabilidade veio da formação de diversos movimentos nacionalistas (na Alemanha, Itália, Polônia, etc.), buscando uma unidade nacional e/ou liberação do domínio estrangeiro. Como resultado, o período entre 1815 e 1871 foi palco de um grande número de conflitos e guerras de independência. Napoleão III, sobrinho de Napoleão I, retornou do exílio na Inglaterra em 1848 para ser eleito pelo parlamento francês, como o então "Presidente-Príncipe" e num golpe de estado eleger-se imperador, aprovado depois pela grande maioria do eleitorado francês. Ele ajudou na unificação da Itália lutando contra o Império Austríaco e lutou a Guerra da Crimeia com a Inglaterra e o Império Otomano contra a Rússia. Seu império ruiu depois duma infame derrota para a Prússia, na qual ele foi capturado. A França então se tornou uma fraca república que recusava-se a negociar e foi derrotada pela Prússia em poucos meses. Em Versalhes, o Rei Guilherme I da Prússia foi proclamado Imperador da Alemanha e a Alemanha moderna nasceu. Mesmo que a maioria dos revolucionários tenha sido derrotada, muitos estados europeus tornaram-se monarquias constitucionais, e em 1871 Alemanha e Itália se desenvolveram em estados-nação. Foi no também que se observou o Império Britânico emergir como o primeiro poder global do mundo devido, em grande parte, à Revolução Industrial e a vitória nas Guerras Napoleónicas.
A paz iria apenas durar até que o Império Otomano declinasse suficientemente para se tornar alvo de outros. Isso incitou a Guerra da Crimeia em 1854, e começou um tenso período de pequenos conflitos entre as nações dominantes da Europa que deram o primeiro passo para a posterior Primeira Guerra Mundial. Isso mudou uma terceira vez com o fim de várias guerras que transformaram o Reino da Sardenha e o Reino da Prússia nas nações da Itália e da Alemanha, mudando significativamente o balanço do poder na Europa. A partir de 1870, a hegemonia Bismarquiana na Europa pôs a França em uma situação crítica. Ela devagar reconstruiu suas relações internacionais, buscando alianças com a Grã-Bretanha e Rússia, para controlar o crescente poder da Alemanha sobre a Europa. Desse modo, dois lados opostos se formaram na Europa, incrementando suas forças militares e suas alianças ano a ano.
A Revolução Industrial foi um período compreendido entre o fim do e o começo do , no qual ocorreram grandes mudanças na agricultura, manufatura e transporte e foi produzido um profundo efeito socioeconómico/socioeconômico e cultural na Grã-Bretanha, que posteriormente se espalhou por toda a Europa, América do Norte, e depois para todo o mundo, num processo que ainda continua: a Industrialização. Na parte final dos anos de 1700 a economia baseada na força manual no Reino da Grã-Bretanha começou a ser substituída por outra dominada pela indústria e pelas máquinas. Começou com a mecanização das indústrias têxteis, o desenvolvimento de técnicas avançadas de produção de ferro e o aumento do uso de carvão refinado. A expansão do comércio foi possibilitada com a introdução de canais, rodovias e auto-estradas. A introdução das máquinas a vapor (abastecidas primeiramente com carvão) e maquinaria bruta (principalmente na manufatura têxtil) deram a base para grandes aumentos na capacidade produtiva inglesa. O desenvolvimento de máquinas de ferramentas nas duas primeiras décadas do facilitou a produção de mais máquinas para serem utilizadas noutras indústrias. Durante o , a industrialização se alastrou pelo resto da Europa Ocidental e América do Norte, afetando posteriormente grande parte do mundo.
Depois da relativa paz na maior parte do , a rivalidade entre as potências europeias explodiu em 1914, quando a Primeira Guerra Mundial começou. Mais de 60 milhões de soldados europeus foram mobilizados entre 1914 e 1918. De um lado estavam Alemanha, Áustria-Hungria, o Império Otomano e a Bulgária (Poderes Centrais/Tríplice Aliança), enquanto que no outro lado estavam a Sérvia e a Tríplice Entente – a elástica coligação entre França, Reino Unido e Rússia, que ganhou a participação da Itália em 1915 e dos Estados Unidos em 1917. Embora a Rússia tenha sido derrotada em 1917 (a guerra foi uma das maiores causas da Revolução Russa, levando à formação da comunista União Soviética), a Entente finalmente prevaleceu no outono de 1918.
No Tratado de Versalhes (1919) os vencedores impuseram severas condições à Alemanha e aos novos estados reconhecidos (tais como Polónia, Checoslováquia, Hungria, Áustria, Jugoslávia, Finlândia, Estónia, Letónia, Lituânia) criados na Europa Central a partir dos extintos impérios Alemão, Austro-Húngaro e Russo, supostamente na base da auto-definição. A maioria desses países entraria em guerras locais, sendo a maior delas a Guerra Polaco-Soviética . Nas décadas seguintes, o medo do comunismo e a Grande Depressão levaram grupos extremistas nacionalistas — sob a categoria do fascismo — na Itália (1922), Alemanha (1933), Espanha (depois da guerra civil, terminada em 1939) e em outros países como a Hungria.
Depois de aliar-se com a Itália de Mussolini no Pacto de Aço e assinar o pacto de não-agressão com a União Soviética, o ditador alemão Adolf Hitler começou a Segunda Guerra Mundial em 1 de Setembro de 1939 invadindo a Polónia, depois de uma expansão militar ocorrida no final da década de 1930. Após sucessos iniciais (principalmente a conquista do oeste da Polónia/Polônia, grande parte da Escandinávia, França e os Balcãs antes de 1941), as forças do Eixo começaram a enfraquecer-se em 1941. Os principais oponentes ideológicos de Hitler eram os comunistas da União Soviética, mas por causa da falha alemã em derrotar o Reino Unido e das falhas italianas no norte da África e no Mediterrâneo, as forças do Eixo se resumiram à Europa Ocidental, Escandinávia, além de ataques a África. O ataque feito posteriormente à União Soviética (que junto com a Alemanha dividiu a Europa central em 1939-1940) não foi feito com a força necessária. Apesar de um sucesso inicial, o exército alemão foi parado perto de Moscovo em dezembro de 1941.
Apenas no ano seguinte é que o avanço alemão seria parado e eles começariam a sofrer uma série de derrotas, como por exemplo, nas batalhas de Stalingrado e Kursk. Nesse ínterim, o Japão (aliado de Alemanha e Itália desde setembro de 1940) atacou os britânicos no Sudeste Asiático e os Estados Unidos no Havaí em 7 de Dezembro de 1941; a Alemanha e a Itália declararam guerra aos Estados Unidos em união com seu aliado. A guerra aumentou a tensão entre o Eixo (Alemanha, Itália e Japão) e os Aliados (Reino Unido, União Soviética e os Estados Unidos). As forças Aliadas venceram no norte da África e invadiram a Itália em 1943, e a ocupada França em 1944. Na primavera de 1945, a Alemanha foi invadida pelo leste pela União Soviética e pelo oeste pelos Aliados; Hitler cometeu suicídio e a Alemanha se rendeu no começo de maio acabando com a guerra na Europa.
O período foi marcado também por um industrializado e planeado genocídio de mais de 11 milhões de pessoas, incluindo a maioria dos judeus da Europa e ciganos, assim como milhões de polacos e eslavos soviéticos. O sistema soviético de trabalho forçado, as expulsões da população da União Soviética e a grande fome da Ucrânia tiveram semelhante carga de mortes. Durante e depois da guerra, milhões de civis foram afetados pelas forçadas transferências da população.
A Primeira e especialmente a Segunda Guerra Mundial acabaram com a preponderante posição da Europa Ocidental. O mapa do continente foi redesenhado na Conferência de Yalta e dividido se tornou a principal zona de contenção na Guerra Fria entre dois blocos, os países ocidentais e o bloco Oriental. Os Estados Unidos e a Europa Ocidental (Reino Unido, França, Itália, Portugal, Países Baixos, Alemanha Ocidental, Noruega, etc.) estabeleceram a aliança da OTAN como proteção contra uma possível invasão soviética. Depois, a União Soviética e o Leste Europeu (Polónia, Checoslováquia, Hungria, Roménia, Bulgária e Alemanha Oriental) estabeleceram o Pacto de Varsóvia como proteção contra uma possível invasão dos Estados Unidos.
Na mesma época, a Europa Ocidental lentamente começou um processo de integração política e económica/econômica, desejando um continente unido e integrado para prevenir outra guerra. Esse processo resultou naturalmente no desenvolvimento de organizações como a União Europeia e o Conselho da Europa. O movimento Solidarność que aconteceu na década de 1980 enfraqueceu o governo comunista na Polônia, foi o começo do fim do domínio comunista na Europa Oriental e o declínio da União Soviética. O líder soviético Mikhail Gorbachev instituiu a Perestroika e a Glasnost, que enfraqueceram oficialmente a influência soviética na Europa Oriental. Os governos que davam suporte aos soviéticos entraram em colapso e a Alemanha Ocidental anexou a Oriental em 1990. Em 1991, a própria União Soviética ruiu, dividindo-se em 15 estados, com a Rússia tomando o lugar da União Soviética no Conselho de Segurança da ONU. Entretanto, a separação mais violenta aconteceu na Jugoslávia, nos Bálcãs. Quatro (Eslovénia, Croácia, Bósnia e Herzegóvina e Macedónia/Macedônia) das seis repúblicas jugoslavas declararam independência e para a maioria delas uma violenta guerra se seguiu, em algumas partes até 1995. Em 2006, Montenegro se separou e declarou independência, seguido por Kosovo, formalmente uma província autónoma/autônoma da Sérvia, em 2008, e descaracterizando completamente o antigo mapa da Jugoslávia/Iugoslávia. Na era pós-guerra fria, OTAN e a União Europeia foram gradualmente admitindo a maioria dos antigos estados membros do Pacto de Varsóvia.
Em 1992, o Tratado de Maastricht foi assinado pelos então membros da União Europeia. Isso transformou o "Projeto Europeu" de ser uma comunidade económica/econômica com certos aspectos políticos, numa união com uma intensa cooperação e prosperidade baseada numa união de soberanias nacionais. Em 1985, o Acordo de Schengen criou uma área sem fronteiras e sem controle de passaporte entre os estados que o assinaram.
Uma moeda comum para a maioria dos estados membros da União Europeia, o euro, foi estabelecida eletronicamente em 1999, oficialmente partilhando todas as moedas de cada participante com os outros. A nova moeda foi posta em circulação em 2002 e as velhas foram retiradas dos mercados. Apenas três países dos quinze estados membros decidiram não aderir ao euro (Reino Unido, Dinamarca e Suécia). Em 2004, a UE deu ordem à sua maior expansão, admitindo 10 novos membros (oito dos quais antigos estados comunistas). Outros dois ingressaram no grupo em 2007, num total de 27 nações.
Um tratado estabelecendo uma constituição para a UE foi assinado em Roma em 2004, com a intenção de substituir todos os antigos tratados com apenas um só documento. Entretanto, a sua ratificação nunca foi feita devido à rejeição de franceses e holandeses, via referendo. Em 2007, concordou-se em substituir aquela proposta com um novo tratado reformado, o Tratado de Lisboa, que iria entrar como uma emenda em vez de substituir os tratados existentes. Esse tratado foi assinado em 13 de dezembro de 2007 e entraria em vigor em janeiro de 2009, se ratificado até essa data. Isso daria à União Europeia seu primeiro presidente e ministro de relações exteriores.
Os Bálcãs são a parte da Europa que mais deseja aderir à União Europeia, com a Croácia a ser o último país até à data a ser aceite no bloco em 2013.
Fisiograficamente, a Europa é o componente noroeste da maior massa de terra do planeta, conhecida como a Eurásia, ou Eurafrásia: a Ásia ocupa a maior parte leste dessa porção de terra contínua e todos partilham uma plataforma continental comum. A fronteira oriental da Europa agora é comumente definida pelos montes Urais, na Rússia. O geógrafo do Estrabão, considerava o rio Don "Tanais" como o limite para o mar Negro, como diziam as primeiras fontes judaicas.
A fronteira sudeste com a Ásia não é universalmente definida, sendo que o rio Ural, ou, alternativamente, o rio Emba servem mais comummente como limites possíveis. O limite continua até ao mar Cáspio, a crista das montanhas do Cáucaso, ou, alternativamente, o rio Cura no Cáucaso, e o mar Negro, Bósforo, o mar de Mármara, o estreito de Dardanelos, o mar Egeu concluem o limite com a Ásia. O mar Mediterrâneo ao sul separa a Europa da África. A fronteira ocidental é o oceano Atlântico, a Islândia, embora mais perto da Gronelândia (América do Norte) do que da Europa continental, são geralmente incluídos na Europa.
Por causa das diferenças sócio-políticas e culturais, existem várias descrições de fronteira da Europa, sendo que em algumas fontes alguns territórios não estão incluídos na Europa, enquanto outras fontes incluem-nos. Por exemplo, os geógrafos da Rússia e de outros países pós-soviéticos geralmente incluem os Urais na Europa, incluindo o Cáucaso na Ásia. Da mesma forma, o Chipre é mais próximo da Anatólia (ou Ásia Menor), mas é muitas vezes considerado parte da Europa e atualmente é um estado membro da UE. Além disso, Malta já foi considerado uma ilha da África ao longo de vários séculos.
O relevo europeu mostra grande variação dentro de áreas relativamente pequenas. As regiões do sul são mais montanhosas, e enquanto se move a norte o terreno desce dos altos Alpes, Pirenéus e Cárpatos, através de planaltos montanhosos e baixas planícies do norte, que são vastas a leste. Esta planície estendida é conhecida como a Grande Planície Europeia, e em seu coração encontra-se a Planície do Norte da Alemanha. Um arco de terras altas, também existe ao longo da costa norte-ocidental, que começa na parte ocidental da ilha da Grã-Bretanha e da Irlanda, e continua ao longo da montanhosa coluna, com fiordes cortados, da Noruega.
Esta descrição é simplificada. Sub-regiões como a Península Ibérica e a península Itálica contêm suas próprias características complexas, como faz a própria Europa Central continental, onde o relevo contém muitos planaltos, vales de rios e bacias que complicam a tendência geral. Sub-regiões como a Islândia, a Grã-Bretanha e a Irlanda são casos especiais. A primeira é uma terra independente no oceano do norte, que é considerada como parte da Europa, enquanto as outras duas são zonas de montanha que outrora foram parte do continente até o nível do mar cortá-las da massa de terra principal.
O continente apresenta uma complexa rede hidrográfica, com grandes rios como o Volga, na Rússia, e o Danúbio, que atravessa territórios (ou delimita fronteiras) da Alemanha, Áustria, República Checa, Croácia, Hungria, Sérvia, Romênia, Bulgária e Ucrânia. O rio Volga é o maior rio da Europa. Começa no Lago Ládoga e atravessa no sentido norte-sul a região oeste da Rússia até desaguar no mar Cáspio.
Entre os lagos europeus destacam-se o mar Cáspio, localizado na divisa com a Ásia e que possui 371 mil km²; e o lago Ládoga, na Federação Russa, este último o maior localizado totalmente no continente, com 17 700 km² de área. Outros lagos extensos são o Onega, o Vänern, o Saimaa, o Vättern, entre outros.
A Europa encontra-se principalmente nas zonas de clima temperado, sendo submetido a correntes de ventos do oeste.
O clima é mais ameno em comparação com outras áreas da mesma latitude de todo o mundo devido à influência da Corrente do Golfo. A Corrente do Golfo é o apelido de "aquecimento central da Europa", porque torna o clima da Europa mais quente e mais húmido do que seria de outra maneira. A Corrente do Golfo não só leva água quente à costa da Europa, mas também aquece os ventos que sopram de oeste em todo o continente do Oceano Atlântico.
Portanto, a temperatura média durante todo o ano de Nápoles, é de 16 °C (60,8 °F), enquanto ela fica a apenas 12 °C (53,6 °F), em Nova York, que é quase na mesma latitude. Berlim, na Alemanha; Calgary, no Canadá, e Irkutsk, na parte asiática da Rússia, estão em torno da mesma latitude, as temperaturas de janeiro, em Berlim, são em média em torno de 8 °C (15 °F), mais elevadas do que aquelas registradas em Calgary, e são quase 22 °C (40 °F) mais elevadas do que as temperaturas médias em Irkutsk.
Desde o Renascimento, a Europa teve uma grande influência na cultura, economia e movimentos sociais no mundo. As invenções mais significativas tiveram origem no mundo ocidental, principalmente na Europa e nos Estados Unidos. Algumas questões atuais e passadas na demografia europeia incluíram emigração religiosa, relações raciais, imigração econômica, a taxa de natalidade decrescente e o envelhecimento da população.
Em alguns países, como a Irlanda e a Polónia, o acesso ao aborto é atualmente limitado. No passado, tais restrições e também as restrições sobre o controle artificial da natalidade eram comuns em toda a Europa. O aborto continua sendo ilegal na ilha de Malta, onde o catolicismo é a religião do Estado. Além disso, três países europeus (Países Baixos, Bélgica e Suíça) e a Comunidade Autónoma da Andaluzia (Espanha) têm permitido uma forma limitada de eutanásia voluntária para doentes terminais.
Em 2005, a população da Europa era estimada em 731 milhões de acordo com as Nações Unidas, que é um pouco mais do que um nono da população mundial. Um século antes, a Europa tinha quase um quarto da população mundial. A população da Europa cresceu no passado, mas nas outras regiões do mundo (especialmente na África e na Ásia), a população tem crescido muito mais rapidamente. Dentre os continentes, a Europa tem uma densidade populacional relativamente alta, perdendo apenas para a Ásia. O país mais densamente povoado da Europa são os Países Baixos, terceiro no ranking mundial após a Coreia do Sul e Bangladesh. Pan e Pfeil (2004) contam 87 distintos "povos da Europa", dos quais 33 formam a maioria da população em pelo menos um Estado soberano, enquanto os 54 restantes constituem minorias étnicas.
Segundo a projeção de população da ONU, a população da Europa pode cair para cerca de 7% da população mundial até 2050, ou 653 milhões de pessoas (variante média, 556 a 777 milhões em baixa e alta variante, respetivamente/respectivamente). Neste contexto, existem disparidades significativas entre regiões em relação às taxas de fertilidade. O número médio de filhos por mulher em idade reprodutiva é de 1,52. De acordo com algumas fontes, essa taxa é maior entre os europeus muçulmanos. A ONU prevê que o declínio contínuo da população de vastas áreas da Europa Oriental. A população da Rússia está diminuindo em pelo menos 700 mil pessoas a cada ano. O país tem hoje 13 mil aldeias desabitadas.
A Europa é o lar do maior número de migrantes de todas as regiões do mundo, em 70,6 milhões de pessoas, segundo um relatório da OIM. Em 2005, a UE teve um ganho líquido global de imigração de 1,8 milhão de pessoas, apesar de ter uma das maiores densidades populacionais do mundo. Isso representou quase 85% do crescimento populacional total da Europa. A União Europeia pretende abrir centros de emprego para trabalhadores migrantes legais da África.
Emigração da Europa começou com os colonos espanhóis e portugueses no , e com colonos franceses e ingleses no . Mas os números mantiveram-se relativamente pequenas até ondas de emigração em massa no , quando milhões de famílias pobres, deixaram a Europa.
Hoje, uma grande população de ascendência europeia é encontrada em todos os continentes. A ascendência europeia predomina na América do Norte e, em menor grau, na América do Sul (principalmente na Argentina, Chile, Uruguai e Centro-Sul do Brasil). Além disso, a Austrália e a Nova Zelândia têm grandes populações de descendentes europeus. A África não tem países de maioria de descendentes de europeus, mas há minorias significativas, como a dos brancos sul-africanos. Na Ásia, as populações descendentes de europeus (mais especificamente russos) predominam no Ásia Setentrional.
As línguas europeias pertencem principalmente a três grupos de Línguas indo-europeias: as línguas românicas, derivadas do latim do Império Romano, as línguas germânicas, cujos ancestrais vieram de língua do sul da Escandinávia, e as línguas eslavas. Apesar de ter a maioria de seu vocabulário descendente de línguas românicas, o idioma Inglês é classificado como uma língua germânica.
As línguas românicas são faladas principalmente no sudoeste da Europa, bem como na Roménia e na Moldávia. As línguas germânicas são faladas no noroeste da Europa e algumas partes da Europa Central. As línguas eslavas são faladas na Europa Central, Oriental e sudeste da Europa.
Muitas outras línguas fora dos três grupos principais grupos existem na Europa. Outras línguas indo-europeias incluem o grupo do Báltico (ie, Letã e Lituana), o grupo Céltico (ie, Irlandês, Gaélico Escocês, Manês, Galês, Córnico e Bretão), Grego, Albanês, e Arménio. Um grupo diferente de línguas urálicas são o Estónio, Finlandês e Húngaro, falado nos respetivos/respectivos países, bem como em partes da Roménia, Rússia, Sérvia e Eslováquia.
Outras línguas não indo-europeias são o maltês (a única língua oficial semita da UE), o Basco, Geórgio, Azerbaijão, Turco no leste da Trácia Oriental e as línguas das nações minoritárias na Rússia.
O multilinguismo e a proteção das línguas regionais e minoritárias são objetivos políticos reconhecidos na Europa de hoje. A Convenção para a Proteção das Minorias Nacionais e a Carta Europeia das Línguas Regionais ou Minoritárias do Conselho da Europa estabelecem um quadro jurídico para os direitos linguísticos na Europa.
Historicamente, a religião na Europa tem tido uma grande influência na arte, cultura, filosofia e direito europeu. A religião maioritária na Europa é o cristianismo praticado por católicos, ortodoxos orientais e protestantes.
Na sequência, é o Islão, concentrado principalmente no sudeste (Bósnia e Herzegovina, Albânia, Kosovo, Cazaquistão, Chipre do Norte, Turquia e Azerbaijão), e o Budismo Tibetano encontrado em Kalmykia. As outras religiões, incluindo o Judaísmo e o Hinduísmo, são religiões minoritárias.
A Europa é um continente relativamente secular e tem o maior número e proporção de pessoas sem religião, agnósticas e ateias no mundo ocidental, com um número particularmente elevado de pessoas que se autodescrevem como não-religiosas na República Checa, Estónia, Suécia, Alemanha (Oeste) e França.
Uma união constituída por mais de uma dezena de países, que fazem transações comerciais utilizando uma moeda única - Euro - e cujos interesses são representados por instituições comuns. Essa nova Europa começou a ganhar corpo em dezembro de 1991, quando os 12 países-membros da União Europeia concluíram o Tratado de Maastricht, que objetivava a união política, económica/econômica e monetária dos participantes, sem fechar espaço para novas adesões.
Através desse acordo, Alemanha, Bélgica, Dinamarca, Espanha, França, Grécia, Irlanda, Itália, Luxemburgo, Países Baixos, Portugal e Reino Unido iniciaram a caminhada da integração europeia. Áustria, Finlândia e Suécia são uns dos mais novos membros e vários outros países já entraram com seu pedido de adesão.
A reunião na cidade neerlandensa de Maastricht - que, em dezembro de 1991, consolidou a formação da União Europeia - representou um capítulo de várias etapas, cujas iniciativas pioneiras surgiram logo após a Segunda Guerra Mundial.
A Comunidade Económica Europeia (CEE) ou Mercado Comum Europeu (MCE) foi o embrião da atual União Europeia (UE). Seus países membros são: Alemanha, Áustria, Bélgica, Dinamarca, Espanha, Finlândia, França, Grécia, Irlanda, Itália, Luxemburgo, Países Baixos, Portugal, Reino Unido e Suécia.
Quando de sua formação, em 1957, a entidade era constituída apenas por Alemanha, Bélgica, França, Itália, Luxemburgo e Países Baixos. Em 1973, ingressaram a Dinamarca, a Irlanda e o Reino Unido; em 1981, a Grécia, e em 1986, Espanha e Portugal. Em 1995, a chamada Europa dos Doze cresceu ainda mais, ganhando a adesão de Áustria, Finlândia e Suécia.
A partir de 1994, os países-membros da Comunidade Económica Europeia, que adotou então o nome de União Europeia, se integrariam para formar um mercado único, em que seriam abolidos os sistemas alfandegários e as diferentes taxas de impostos, além das restrições ao comércio, serviços e à circulação de capitais. Isso significaria, entre outras coisas, que os habitantes da União Europeia teriam trânsito livre em todos os países-membros, inclusive para trabalho; os impostos seriam aos poucos unificados e haveria livre acesso às mercadorias e serviços de todos os países-membros dentro da comunidade.
Desde 1995, para facilitar a circulação de pessoas por alguns países da União Europeia, entrou em vigor um acordo entre Portugal, Espanha, França, Bélgica, Países Baixos, Luxemburgo e Alemanha para eliminar as barreiras alfandegárias e a obrigação da apresentação do passaporte entre esses países. Essa área recebeu o nome de Espaço Schengen, tirado da cidade luxemburguesa onde o acordo foi assinado.
No sentido da integração económica/econômica, outro passo importante seria a utilização de uma moeda comum. O ECU (European Currency Unity ou Unidade Monetária Europeia) circula, desde 1993, como padrão em operações financeiras e, apesar da discordância de alguns membros, pretendeu-se que, gradualmente, ele fosse adotado nas operações cotidianas até 1999, quando o euro entrou em vigor como moeda escritural e como moeda oficial desde 2002.
Todos os países que integram a União Europeia apresentam economia desenvolvida, ainda que existam diferenças extraordinárias entre eles, como entre Irlanda e Alemanha, por exemplo, ou Grécia e Dinamarca. A meta, no entanto, é reduzir esses contrastes, tornando a comunidade cada vez mais homogénea/homógena/homogênea.
Apesar das metas em comum, há divergências entre os países-membros da União Europeia e são frequentes os atritos e necessários os ajustes para garantir a execução de tais metas. O ano de 1994 foi de provas para a integridade da União Europeia, já que ocorreram, nos países, plebiscitos para ratificar seus objetivos e confirmar ou não a adesão à União.
Na Dinamarca e no Reino Unido, as opiniões estavam muito divididas, mas o apoio à comunidade prevaleceu. Na Noruega, entretanto, sua população decidiu não ingressar na União Europeia, apesar da solicitação de adesão feita anteriormente.
Os países europeus ocidentais estão vinculados a importantes organizações que agregam países de outros continentes, como a OTAN e a OCDE.
A Organização do Tratado do Atlântico Norte (OTAN), criada em 1949, tem caráter militar. Além de países europeus, inclui outros dois banhados pelo oceano Atlântico Norte: Canadá e Estados Unidos. Seu objetivo fundamental é a cooperação militar e a defesa de seus membros, no caso de agressâo internacional.
Com o fim da Guerra Fria, o papel da OTAN tem estado em segundo plano. A aliança assumiu um caráter preponderantemente político em 1990, desenvolvendo o papel de resolver crises localizadas. Vários países do Leste Europeu solicitaram o ingresso à OTAN.
A OCDE (Organização para a Cooperação e Desenvolvimento Económico) foi estabelecida em 1961 para promover bem-estar econômico e social entre seus membros e harmonizar a qualidade de vida nos países em desenvolvimento. Além de 18 países europeus, engloba também Austrália, Canadá, Japão, Nova Zelândia e Estados Unidos.
De acordo com definições diferentes, os territórios podem ser sujeitos a várias categorizações. Os 27 Estados Membros da União Europeia são altamente integrados economicamente e politicamente, a própria União Europeia faz parte da geografia política da Europa. A tabela abaixo mostra o esquema de sub-regiões geográficas utilizado pela Organização das Nações Unidas, ao lado do grupo regional publicado no CIA World Factbook.
Dentro dos referidos Estados existem várias regiões, desfrutando de ampla autonomia, bem como de vários países independentes de facto com reconhecimento internacional limitado ou reconhecido, nenhum deles é membro da ONU:
De acordo com os pontos de vista espacial e económico, podemos dividir o continente em: Europa Ocidental, Europa Setentrional, Europa Centro-Oriental e Europa Meridional. Sendo:
Como um continente, a economia da Europa é atualmente a maior do planeta e é a região mais rica como medido por ativos sob gestão, com mais de 32,7 trilhões de dólares em relação ao 27,1 trilhões de dólares da América do Norte. Tal como acontece com outros continentes, a Europa tem uma grande variação da riqueza entre os seus países. Os países mais ricos tendem a estar no Ocidente, enquanto algumas das economias do Leste ainda estão emergindo do colapso da União Soviética e da Iugoslávia.
A União Europeia, um organismo intergovernamental composto por 27 estados europeus, compreende o maior espaço económico/econômico único no mundo. Atualmente, para 16 países da UE, o euro é a moeda comum. Cinco países europeus classificam-se entre as dez maiores economias nacionais do mundo por PIB (PPC). Isso inclui (classificação de acordo com a CIA): Alemanha (5), Reino Unido (6), Rússia (7), França (8) e Itália (10).
O capitalismo tem sido dominante no mundo ocidental desde o fim do feudalismo. Da Grã-Bretanha, que gradualmente se espalhou pela Europa. A Revolução Industrial começou na Europa, mais concretamente ao Reino Unido no final do , e no impulsionou a industrialização da Europa ocidental. Economias foram interrompidas pela Primeira Guerra Mundial, mas até o início da Segunda Guerra Mundial já tinham se recuperado e estavam tendo que competir com a crescente força económica dos Estados Unidos. A Segunda Guerra Mundial, novamente, danificados muito as indústrias europeias.
Após a Segunda Guerra Mundial, a economia do Reino Unido estava em estado de ruína, e continuou a sofrer um relativo declínio econômico nas décadas seguintes. A Itália também estava em má condição económica/econômica, mas recuperou um elevado nível de crescimento na década de 1950. A Alemanha Ocidental recuperou-se rapidamente e dobrou a produção de níveis pré-guerra na década de 1950. A França também organizou um retorno notável a um crescimento rápido e a modernização e, mais tarde a Espanha, sob a liderança de Franco, também recuperou-se, e a nação obteve um enorme crescimento econômico sem precedentes no início da década de 1960, em que é chamado de milagre espanhol. A maioria dos estados da Europa Oriental ficou sob o controle da URSS e, portanto, eram membros do Conselho para Assistência Econômica Mútua (COMECON).
Os estados que mantiveram um sistema de livre mercado foram agraciados com uma grande quantidade de ajuda dos Estados Unidos ao abrigo do Plano Marshall. Os Estados ocidentais mudaram para ligar as suas economias em conjunto, fornecendo a base para a UE e o aumento do comércio transfronteiriço. Isso ajudou-os a desfrutar de uma rápida melhora de suas economias, enquanto os estados da COMECON estavam lutando em grande parte devido ao custo da Guerra Fria. Até 1990, a Comunidade Europeia foi ampliado de 6 para 12 membros fundadores. A ênfase na ressurreição da economia da Alemanha Ocidental levou a ultrapassagem do Reino Unido como a maior economia da Europa.
Com a queda do comunismo na Europa Oriental, em 1991, os estados do Leste tiveram de se adaptar a um sistema de mercado livre. Havia vários graus de sucesso com os países centro-europeus, como Polónia, Hungria e Eslovénia, que se adaptaram razoavelmente rápido, enquanto estados do Leste como a Ucrânia e a Rússia, estão levando muito mais tempo. A Europa Ocidental ajudou a Europa Oriental, formando laços ao nível da economia.
Após o Leste e o Oeste da Alemanha se reunirem em 1990, a economia da Alemanha Ocidental, apoiou a reconstrução da infra-estrutura da Alemanha Oriental. A Jugoslávia mostrou um atraso maior, sendo devastada pela guerra e em 2003 ainda havia muitas tropas de paz da e da OTAN no Kosovo, na República da Macedónia, na Bósnia e Herzegovina, sendo apenas a Eslovénia que conseguiu fazer algum progresso real.
Na mudança do milênio, a União Europeia dominou a economia da Europa, que inclui os cinco maiores economias europeias da época a Alemanha, Reino Unido, França, Itália e Espanha. Em 1999, 12 dos 15 membros da UE aderiram à Zona Euro substituindo suas antigas moedas nacionais pelo euro comum. Os três que optaram por permanecer fora da zona euro foram Reino Unido Dinamarca e Suécia.
A Zona Euro entrou em sua primeira recessão oficial no terceiro trimestre de 2008, os números oficiais confirmados em janeiro de 2009. A crise econômica do final dos anos 2000, que teve início nos Estados Unidos, propagou-se de forma rápida para a Europa e afetou grande parte da região. A taxa de desemprego oficial nos 16 países que usam o euro subiu para 9,5% em maio de 2009. Os jovens trabalhadores da Europa têm sido especialmente atingidos. No primeiro trimestre de 2009, a taxa de desemprego na UE-27 para pessoas entre 15-24 anos foi de 18,3%.
A cultura europeia pode ser melhor descrita como uma série de culturas sobrepostas e que envolve questões de Ocidente contra Oriente e Cristianismo contra Islão. Existem várias linhas de ruptura culturais através do continente e movimentos culturais inovadores discordam uns dos outros. De acordo com Andreas Kaplan, o continente Europeu pode ser definido como "diversidade cultural máxima a uma distância geográfica mínima". Assim, uma "cultura comum europeia" ou "valores comuns europeus", é algo cuja definição é mais complexa do que parece.
Na Europa pratica-se uma considerável quantidade de modalidades desportivas. O desporto mais popular é o futebol, representado pela UEFA. O torneio mais importante de seleções é o Campeonato Europeu de Futebol, enquanto que o de clubes é a Liga dos Campeões da UEFA. Em relação ao Campeonato do Mundo de Futebol, em dez edições países europeus sediaram o evento, e em dez seleções de países europeus venceram o torneio.

O Espírito Santo é uma das 27 unidades federativas do Brasil. Está localizado na região Sudeste. Faz fronteira com o oceano Atlântico a leste, com a Bahia ao norte, com Minas Gerais a oeste e noroeste e com o estado do Rio de Janeiro ao sul. Sua área é de 46 095,583 km². É o quarto menor estado do Brasil, maior apenas que Sergipe, Alagoas e Rio de Janeiro. Sua capital é o município de Vitória, e sua cidade mais populosa, o município da Serra. O Espírito Santo é, ao lado de Santa Catarina, um dos únicos entre os estados do Brasil no qual a capital não é a maior cidade. Outros importantes municípios são Cariacica, Cachoeiro de Itapemirim, Colatina, Guarapari, Linhares, São Mateus e Vila Velha. O gentílico do estado é capixaba ou espírito-santense.
Em 1535, os colonizadores portugueses chegaram na Capitania do Espírito Santo e desembarcaram na região da Prainha. Naquela época, teve início a construção do primeiro povoado que recebeu o nome de Vila do Espírito Santo. Por causa dos índios terem atacado a Vila do Espírito Santo, o líder Vasco Fernandes Coutinho fundou outra vila, naquela vez em uma das ilhas. Esta vila passou a ser chamada de Vila Nova do Espírito Santo, atual . Enquanto isso, a antiga recebeu o nome de Vila Velha. Houve um tempo, que poucas pessoas conhecem, em que houve a anexação do Espírito Santo à Bahia. Isso ocorreu no ano de 1715. Então, a capital da extinta Capitania do Espírito Santo passou a ser Salvador. A Capitania do Espírito Santo somente recuperou sua autonomia da Capitania da Bahia em 1809. Com a proclamação da Independência do Brasil, em 7 de setembro de 1822, o seu "status" foi alterado para província, permanecendo assim até a Proclamação da República Brasileira, em 15 de novembro de 1889, quando se transformou no atual estado do Espírito Santo.
Atualmente, a capital Vitória é um importante porto exportador de minério de ferro. Na agricultura, merecem destaque os seguintes produtos econômicos: o café, arroz, cacau, cana-de-açúcar, feijão, frutas e milho. Na pecuária, há criação de gado de corte e leiteiro. Na indústria, são fabricados produtos alimentícios, madeira, celulose, têxteis, móveis e siderurgia. O estado também possui festas famosas. Entre elas podemos citar: a Festa da Polenta em Venda Nova do Imigrante, a Festa da Penha em Vila Velha e o Festival de Arte e Música de Alegre. O Vital (carnaval fora de época, em novembro) foi extinto.
O nome do estado é uma denominação dada pelo donatário Vasco Fernandes Coutinho que ali desembarcou em 1535, num domingo dedicado ao Espírito Santo. Como curiosidade dessa etimologia, merece destaque o Convento de Nossa Senhora da Penha, símbolo da religiosidade capixaba que abriga em seu acervo a tela mais antiga da América Latina, a imagem de Nossa Senhora das Alegrias.
Em junho de 1534 foram concedidas cinquenta léguas de litoral entre os rios Mucuri e Itapemirim. A concessão foi feita pelo rei de Portugal Dom João III entregando o lote da capitania ao veterano das Índias. Vasco Fernandes Coutinho, um português, desembarcou no território da capitania, a 23 de maio de 1535, e deu o nome ao futuro estado por ser domingo do Espírito Santo. No mesmo dia foi fundada uma vila, denominada pelo donatário como Vila do Espírito Santo (atual cidade de Vila Velha). Em 1535, a vila deu o nome à capitania, à província em 1822 e ao estado (1889). Tal fato ocorreu 35 anos após o Descobrimento do Brasil, conforme tenha sido explicado que a capitania hereditária foi um dos estados mais antigos do Brasil.
Os habitantes naturais do estado do Espírito Santo são denominados "capixabas" (ou "espírito-santenses"). O gentílico foi dado aos futuros cidadãos do Espírito Santo devido às roças de milho que ficavam na ilha de Vitória. As roças de milho pertenciam aos índios, os primeiros habitantes da região quando os portugueses aí chegaram. Tudo leva a crer que a referida assertiva intelectual ajuda a evitar a confusão do nome da unidade federativa brasileira com o nome da terceira pessoa da Santíssima Trindade.
Inicialmente, a região era habitada por diversas tribos indígenas, todas pertencentes ao tronco Tupi; as tribos do interior eram chamadas de Botocudos, sendo-lhes atribuído comportamento hostil e belicoso, além da prática de antropofagia. No litoral, as tribos também eram hostis, porém de hábitos um pouco diferentes.
Na região Sul do actual estado e na região da serra do Caparaó, as tribos não eram hostis, e o seu nome deriva de seu hábito de levar os visitantes para "ouvir o silêncio" da Serra do Castelo. As demais tribos eram os aimorés e os goitacás.
Em 23 de maio de 1535, o fidalgo português Vasco Fernandes Coutinho, veterano das campanhas da África e da Índia, aportou em terras da capitania, que lhe destinara o rei D. João III. Como era um domingo do Espírito Santo, chamou de vila do Espírito Santo a povoação que mandou construir nas terras que lhe couberam: cinquenta léguas de costa, entre os rios Mucuri e Itapemirim, com outro tanto de largo, sertão adentro, a partir do ponto em que terminava, ao norte, o quinhão concedido a Pero de Campos Tourinho, donatário da capitania de Porto Seguro. A Vila do Espírito Santo é hoje a cidade de Vila Velha. Ainda em 1535, a vila passou à capitania, em 1822 província e em 1889 a estado.
A fixação da vila foi uma história de lutas, pois os índios não entregaram aos portugueses, sem resistência, suas roças e malocas. Recuaram até a floresta, onde se concentraram para iniciar uma luta de guerrilhas que se prolongou, com pequenas tréguas, até meados do . Foi assim das mais duras a empresa cometida a Vasco Fernandes Coutinho. Para o patriarca do Espírito Santo a capitania foi um prêmio que se transformou em castigo; teve de empenhar todos os haveres para conservar sua vila; acabou por morrer pobre e desvalido.
Além da insubmissão dos indígenas, o donatário teve de enfrentar as dissensões entre os portugueses. A seus companheiros Jorge de Meneses e Duarte Lemos concedera extensas sesmarias, usando os poderes que recebera juntamente com a carta de doação. Com isso, criou dois rivais implacáveis.
Duarte de Lemos fundou Vitória — chamada de Vila Nova — na ilha de Santo Antônio, em posição estratégica, mais vantajosa que Vila Velha para a defesa contra os constantes ataques dos silvícolas. Para lá se transferiu a sede da capitania. À mesma época, chegaram os missionários jesuítas, empenhados na catequese, o que provocou choques com os colonos, que preferiam a dominação do gentio pela escravidão. A presença do padre José de Anchieta deu um sentido muito especial à ação dos padres da Companhia de Jesus em terras do Espírito Santo. Desde 1561, Anchieta elegera para seu refúgio a aldeia de Reritiba, de onde teve de se afastar constantemente, em virtude de seus encargos, ora em São Paulo, no Rio de Janeiro ou na Bahia. Dois poemas escreveu ele em Reritiba: "De Beata Virgine dei Marte Maria" ("Da Santa Virgem Maria Mãe de Deus") e "De gestis Mendi de Saa" ("Dos feitos de Mem de Sá"). Neste último, está descrita a epopeia de uma esquadra enviada da Bahia por Mem de Sá, governador-geral do Brasil, em socorro a Vasco Fernandes Coutinho e sua gente, que estavam sob cerco dos tamoios na ilha de Vitória. A maior força dos gentios estava concentrada numa aldeia forrificada junto ao rio Cricaré. Ali ocorreu a batalha decisiva, em 22 de maio de 1558. Os portugueses, embora vitoriosos, sofreram pesadas baixas. Entre os mortos estavam o próprio filho de Mem de Sá, Fernão de Sá, que comandava a esquadra; e dois filhos de Caramuru (Diogo Álvares Correia) com a índia Paraguaçu.
A posição estratégica da capitania, dada a proximidade com o Rio de Janeiro, ocasionou algumas tentativas estrangeiras de invasão. Em 1592, os capixabas rechaçaram uma investida dos ingleses, sob o comando de Thomas Cavendish. Em 1625, o donatário Francisco de Aguiar Coutinho enfrentou a primeira investida dos holandeses, comandados por Pieter Pieterszoon Heyn, luta em que se destacou a heroína capixaba Maria Ortiz. Em 1640, com sete navios, os holandeses atacaram novamente o Espírito Santo, sob o comando do coronel Koin. Conseguiram desembarcar 400 homens, mas foram repelidos pelo capitão-mor João Dias Guedes e não se firmaram em Vitória. Atacaram então Vila Velha, de onde foram também rechaçados. O governo colonial, diante de tão repetidos ataques, resolveu destacar para Vitória quarenta infantes da tropa regular. Nessa oportunidade a capitania progride e Koin captura duas naus carregadas de açúcar que, atingidas pelo fogo de terra, ficam com a carga quase toda avariada.
O esgotamento da população, que nos primeiros tempos, por diversas vezes, ameaçara desertar a capitania, bem como a incapacidade de dar seguimento a sua incipiente agricultura, denunciavam a fraqueza dos alicerces em que se baseava a colonização local. Também aí os recursos particulares revelaram-se insuficientes para manter empresa tão árdua e onerosa.
Em 1627, morreu o donatário Francisco de Aguiar Coutinho, cujo sucessor, Ambrósio de Aguiar Coutinho, não se interessou pelo senhorio e continuou como governador nos Açores. Sucederam-se os capitães-mores, com frequentes e sérias divergências entre eles e os oficiais da câmara. Ao atingir a maioridade, em 1667, Antônio Luís Gonçalves da Câmara Coutinho, último descendente do primeiro donatário, conseguiu a nomeação para capitão-mor de Antônio Mendes de Figueiredo, governante operoso e estimado. Em 1674 efetuou-se a compra do território ao último donatário da família Câmara Coutinho pelo fidalgo baiano Francisco Gil de Araújo, por quarenta mil cruzados, transação confirmada por carta régia de 18 de março de 1675.
No governo do novo donatário, o comércio e a lavoura se desenvolveram, mas foi totalmente frustrado o motivo principal da compra da capitania: o descobrimento das "pedras verdes" — as esmeraldas. Essa busca começara por iniciativa do governo-geral. As expedições iniciais, denominadas por alguns historiadores "ciclo espírito-santense", incluem-se na categoria das entradas. Na verdade, o ciclo limitou-se a poucas expedições relevantes, cuja importância está menos nos resultados obtidos, do que na dinamização do interesse pela área e em um maior conhecimento do interior. Entre as mais destacadas, contam-se as de Diogo Martins Cão (1596), Marcos de Azeredo (1611) e Agostinho Barbalho de Bezerra (1664), que vasculharam as imediações do rio Doce. Francisco Gil de Araújo fundou a vila de Nossa Senhora de Guarapari e construiu os fortes do Monte do Carmo e de São Francisco Xavier; o de São João, encontrado em ruínas, foi reconstruído.
Gil de Araújo promoveu 14 entradas através do rio Doce, dirigidas à serra das Esmeraldas, as quais podem ter travado contato com os paulistas de Fernão Dias Pais. Da grande atividade e do vultoso emprego de capital realizados por Francisco Gil não resultou qualquer descoberta metalífera, embora se tenham produzido alguns frutos na valorização das terras, pelo estabelecimento de povoadores e criação de novos engenhos. Os lucros, de qualquer modo, não compensaram o investimento feito. Seu filho e herdeiro, talvez por esse motivo, preferiu conservar-se ausente do senhorio e, por morte deste, a capitania tornou-se devoluta, sendo vendida à coroa por Cosme Rolim de Moura, primo do último donatário. Em consequência, ficou o Espírito Santo submetido à jurisdição da Bahia, e seu governo sempre a cargo de displicentes capitães-mores.
Durante o ainda perdurou o interesse pela mineração, reanimado pela descoberta de Antônio Rodrigues Arzão de pequena quantidade de ouro no rio Doce, em 1692. Seguiram-se numerosas entradas, dando início à abertura do caminho para as Minas Gerais, enquanto as jazidas do Castelo e outras atraíam moradores de capitanias vizinhas. Assistiu-se a um novo impulso de conquista e ocupação do interior, e as concessões de sesmarias favoreceram a fixação dos colonos mais empreendedores. O movimento despertou a atenção das auroridades baianas, e acabou prejudicado pelos cuidados do monopólio real e receio de invasão estrangeira às Minas Gerais a partir do Espírito Santo. Tomaram-se então medidas para fortificar melhor a capitania, enquanto por ordem do rei ficou proibido o prosseguimento das explorações. Impediu-se a abertura de entradas para as minas. A capitania defendia-se de surpresas marítimas e ficava isolada pelas defesas naturais: florestas cerradas e selvagens inimigos. A colonização, portanto, continuou sem maiores progressos, embora em 1741 fosse criada a comarca de Vitória, que abrangia São Salvador de Campos e São João da Barra. Em 1747 o ouvidor Manuel Nunes Macedo assim descrevia a situação de Vitória: 
É certo que a obstinação dos mineradores e as melhorias efetuadas no sistema de defesa acabaram por diminuir o rigor das proibições e, em 1758, de acordo com ordem régia, abriu-se um caminho para as minas e estabeleceu-se um posto de quitação na vila de Campos.
Em 1797, o regente D. João dirigiu-se ao governador da Bahia nesses termos: 
O novo governador assumiu o cargo em 29 de março de 1800. A obra de recuperação teve como objetivo principal melhores comunicações com a de Minas Gerais. Em 8 de outubro do mesmo ano, Silva Pontes assinou o auto, conjuntamente com o representante do governo de Minas, que regulou a cobrança de impostos entre as duas capitanias. Interessou-se também pela navegação do rio Doce, por abertura de estradas, pela ampliação dos cultivos e pelo povoamento da terra. Em 1810 a capitania tornou-se autônoma em relação à Bahia, e passou a depender diretamente do governo-geral. Governou na época Manuel Vieira de Albuquerque Tovar, que não se afastou do programa de Silva Pontes. Deu o nome de Linhares às antigas ruínas da aldeia de Coutins.
O período colonial encerrou-se sob melhores auspícios, sobretudo em função da diligência de Francisco Alberto Rubim, nomeado governador em 1812. Rubim foi o autor da "Memória estatística da capitania do Espírito Santo", realizada em 1817, na qual afirmou haver na época na capitania 24.587 habitantes, seis vilas, oito povoados e oito freguesias. Consolidara-se a ocupação do território e ampliara-se a base demográfica. Em face das dificuldades enfrentadas, esses dados revelam um progresso nada desprezível.
Em 20 de março de 1820 foi empossado como governador Baltazar de Sousa Botelho de Vasconcelos, a quem coube enfrentar os dias agitados da independência e passar a administração à junta do governo provisório. Antes mesmo de promulgada a constituição do império, foi nomeado presidente da província o ouvidor Inácio Acióli de Vasconcelos.
Durante o movimento de independência, em março e abril de 1821, ocorreram várias comoções políticas no Espírito Santo, enquanto se procedia à escolha de seus representantes às cortes de Lisboa. Após a proclamação da autonomia brasileira, foi dado total apoio à nova realidade política, e em 1 de outubro de 1822, reconhecido imediatamente D. Pedro na condição de imperador do Brasil.
O governo provincial enfrentou séria crise econômica nos primeiros anos da década de 1820, ocasionada pelo estrangulamento da produção agrícola em razão da prolongada estiagem. Mesmo assim, iniciou a cultura cafeeira. Para tanto, incentivou o aproveitamento de terras por colonos estrangeiros, o que se deu simultaneamente à chegada de fazendeiros fluminenses, mineiros e paulistas. A exemplo das demais províncias do sul, no Espírito Santo essa experiência colonizadora baseou-se na pequena propriedade agrícola, que logo se estendeu ao longo da zona serrana central, em contraste com as áreas do sul daquela região, onde predominava a grande propriedade.
Em 1846 fundou-se a colônia de Santa Isabel (Campinho) com imigrantes alemães de Hunsrück e em 1855 uma sociedade particular — depois encampada pelo governo — criou a colônia do Rio Novo com famílias suíças, alemãs, holandesas e portuguesas. Entre 1856 e 1862 houve considerável afluência de imigrantes alemães para a colônia de Santa Leopoldina, que tinha por sede o porto de Cachoeiro de Itapemirim, no rio Itapemirim, a cinquenta quilômetros da foz, no sul do estado. Rapidamente as antigas áreas de pastoreio pontilharam-se de pequenos estabelecimentos agrícolas, que demonstraram grande força expansiva. As colônias de Santa Isabel e Santa Leopoldina,por exemplo, criaram desdobramenros através de todo o planalto, entre os rios Jucu e Santa Maria, e mais tarde atravessaram o rio Doce.
No processo de colonização enfrentaram os imigrantes, a par de outras dificuldades, o sério problema indígena na região do rio Doce. Malgrado os esforços de aldeamento e as tentativas de utilização de sua mão-de-obra, sucediam-se os choques com os colonos, e chegou mesmo a verificar-se grave contenda entre índios e moradores de Cachoeiro de Itapemirim, como elevado número de mortos e feridos, em 1825. Duas décadas depois, o comendador e futuro barão de Itapemirim, Joaquim Marcelino da Silva Lima, ainda tentou organizar um grande aldeamento à base de terras devolutas.
Os canaviais haviam sido substituídos pelos cafeeiros. Ainda não tinha sido fundada nenhuma usina. Os engenhos centrais pouco a pouco desapareciam. Além de fazendeiros capixabas, que passam a cultivar o café, vieram também, com o mesmo propósito, fluminenses, mineiros e até paulistas, como o barão de Itapemirim.
Graças ao trabalho profícuo desses colonos, quando se aboliu a escravidão dos negros — o que derrocou as grandes fazendas, de imediato ou não — a economia do Espírito Santo resistiu e proporcionou aos seus presidentes, depois de proclamada a república, os meios necessários para empreendimentos como a construção de estradas de ferro, expansão do ensino e organização de planos urbanos, com Muniz Freire; instalação de água, luz, esgoto, bondes elétricos, de um parque industrial, de uma usina elétrica e de uma usina de açúcar em Cachoeiro de Itapemirim e na vila de Itapemirim, de uma fazenda-modelo em Cariacica, além de reforma da instrução pública e construção de grupos escolares e de pontes entre Vitória e o litoral e Colatina e o norte do rio Doce. Essas e outras obras foram realizadas com recursos provenientes sobretudo do café produzido pelas colônias de imigrantes europeus organizadas desde a monarquia.
Com a irradiação ferroviária que o café suscitou em meados do , o Espírito Santo beneficiou-se da rede de leitos, cujo centro estava em Campos dos Goitacases e que estabelecia comunicações entre duas importantes áreas cafeeiras: a Zona da Mata, em Minas, e o sul capixaba. Apesar de situada fora da região de cultivo, a cidade de Vitória foi a que mais progrediu sob o surto daquela lavoura, e já em 1879 processaram-se os primeiros estudos destinados à construção do porto, que deveria escoar toda a produção da província. Atendendo às novas exigências, em meados do século começou a funcionar a imprensa capixaba, com a circulação do jornal "O Correio da Vitória", de propriedade de Pedro Antônio de Azeredo, a partir de 1849.
Em 1850 a configuração territorial do Espírito Santo já assinalava a existência de dez municípios: Vitória, Serra, Nova Almeida, Linhares, São Mateus, Espírito Santo, Guarapari, Benevente (hoje Anchieta) e Itapemirim. Pouco antes a província perdera parte de suas terras, em virtude da desanexação de Campos dos Goitacases e São João da Barra, restituídas ao Rio de Janeiro em 1832.
No final do , os capixabas, sobretudo a intelectualidade, aderiram ao movimento abolicionista. A exemplo do que aconteceu nas demais províncias, surgiram associações ligadas à emancipação, como a Sociedade Abolicionista do Espírito Santo (1869) ao lado de acirrada campanha jornalística e parlamentar. No próprio edifício da Câmara Municipal de Vitória fundou-se uma sociedade libertadora (1883). Durante a propaganda, evocava-se a crueldade dos castigos infligidos aos escravos, como sucedera após a insurreição de cerca de 200 negros no distrito de Queimados, em 1849.
A abolição da escravatura, no entanto, conduziu os grandes proprietários à ruína, em virtude da privação da tradicional mão-de-obra. Assim, com o advento da república, o primeiro governador do estado não encontrou condições materiais para levar a efeito os planos preconizados pela propaganda republicana. As finanças da antiga província encontravam-se exauridas.
Ainda no final do , coincidindo com a fixação da constituição estadual (1891 e 1892), o governador eleito recorreu a reformas e incentivos econômicos que deram novo impulso ao estado. A fim de assegurar uma receita mais sólida, levantou empréstimos externos, que favoreceram a lavoura cafeeira e permitiram maiores investimentos agrícolas. O Espírito Santo obteve assim uma arrecadação cinco vezes mais alta que a da antiga província. Efetuou-se o saneamento de Vitória e em 1895 foi inaugurado o primeiro trecho da Estrada de Ferro Sul do Espírito Santo, entre Porto de Argolas e Jabaeté.
A ocupação do norte do Espírito Santo só começou nas primeiras décadas do , e ganhou novo impulso depois da construção da ponte de Colatina sobre o rio Doce, inaugurada em 1928. A economia capixaba contou com a migração de contingentes do sul e do centro do país para aquela área, e assim firmou-se o cultivo do café, que respondeu por 95% da receita em 1903. Durante a primeira guerra mundial, o porto de Vitória figurava como o segundo grande exportador nacional.
Com a Revolução de 1930 assumiu a direção do estado, na qualidade de interventor, João Punaro Bley, mantido pelo Estado Novo até 1943, e sob cuja administração se iniciaram obras para ampliar o porto de Vitória e para construção de cais de minério, este arrendado em 1942 pela Companhia Vale do Rio Doce. No governo de Jones dos Santos Neves, em 1945, foi criada a Universidade Federal do Espírito Santo (UFES), primeira iniciativa referente ao ensino superior no estado. Para ampliar a exportação de minério de ferro oriundo de Minas Gerais, a Companhia Vale do Rio Doce construiu o porto de Tubarão, em Vitória, com capacidade para estocar um milhão de toneladas de minério, receber navios de até cem mil toneladas e carregá-los a um ritmo de seis mil toneladas por hora. As obras foram iniciadas em 1966 e terminadas em tempo recorde. Situado dez quilômetros ao norte da capital, é um dos maiores portos de minério do mundo. Com a transferência para Tubarão da maior parte da exportação de minério de ferro, o porto de Vitória ficou liberado para outras aplicações.
Com a instalação de Tubarão a região foi dotada de uma infraestrutura que propiciou o surgimento de um novo complexo industrial, do qual faz parte uma usina de pelotização de minério de ferro, com capacidade de produção de dois milhões de toneladas anuais. Inaugurada em 1976, entrou em atividade em 29 de novembro de 1983, dez anos depois de iniciadas as obras, a Usina Siderúrgica de Tubarão, que representou um investimento total de três bilhões de dólares. A fase foi marcada por um intenso esforço de industrialização provomido pela Companhia de Desenvolvimento Econômico do Espírito Santo (Codes), mais tarde transformada no Banco de Desenvolvimento do Espírito Santo (Bandes). No início da década de 70 foi criado o FUNDAP (Fundo de Desenvolvimento para Atividades Portuárias) que consistia de um incentivo financeiro para a instalação de empresas importadoras, incentivando as atividades portuárias. Instalaram-se fábricas de café solúvel, massas alimentícias, chocolates, azulejos e conservas de frutas, e aprovaram-se projetos para a implantação de fábricas de laticínios, calçados, material elétrico, óleos comestíveis e sucos cítricos.
Em novembro de 2007, é inaugurada a expansão da siderúrgica Arcelor Mittal Tubarão (ex-Companhia Siderúrgica de Tubarão) para ampliar a produção anual de placas de aço de 5 milhões para 7,5 milhões de toneladas. O estado é o maior produtor de placas de aço do país.
Em abril de 2008, a Polícia Federal realiza a Operação Auxílio-Sufrágio, que desmantela uma quadrilha especializada em fraudes contra a Previdência Social no estado. O deputado estadual Wolmar Campostrini (PDT) é acusado de ser líder do esquema. Por causa de trâmites burocráticos, as investigações ainda não foram concluídas e Campostrini mantém o cargo. Em outubro do mesmo ano, o prefeito da capital, João Coser (PT) é reeleito em primeiro turno. Em 2010, Renato Casagrande (PSB) é eleito governador no primeiro turno, com 82,3% dos votos. Em 2014, Paulo Hartung (PMDB) foi eleito governador do estado e César Colnago (PSDB) eleito vice-governador.
A partir de 2006, a precariedade dos presídios passou a ser noticiada, pois provocou rebeliões, assassinatos e até esquartejamentos (na Casa de Custódia de Viana); em 2009, presos são mantidos em contêineres de aço, sem ventilação adequada, por falta de celas. Em março de 2010, essa situação é discutida em um painel na Comissão de Direitos Humanos das Nações Unidas. Cumprindo parcialmente compromissos assumidos, o governo desativa as celas metálicas e demole a Casa de Custódia de Viana, em maio de 2010. Em outubro, sete penitenciárias foram vistoriadas por uma comissão liderada pelo Conselho de Defesa dos Direitos da Pessoa Humana e da Ordem dos Advogados do Brasil. O relatório, a ser entregue à Procuradoria Geral da República, sugere providências urgentes e intervenção federal no sistema penitenciário do estado.
O estado do Espírito Santo ocupa uma área de no litoral do Brasil, localiza-se a oeste do Meridiano de Greenwich e a sul da Linha do Equador e com fuso horário de menos três horas em relação à hora mundial GMT. No Brasil, o estado faz parte da região Sudeste, fazendo divisa com os estados de Minas Gerais, Bahia e Rio de Janeiro. O estado é banhado pelo oceano Atlântico.
Cerca de 40% do território do estado encontra-se em uma faixa de planície, porém a variação das altitudes é bem grande. O relevo apresenta-se dividido em duas regiões distintas: A Baixada Espírito-Santense e a Serra do Castelo, na qual fica o Pico da Bandeira com 2.892 m, na serra de Caparaó. Seu clima predominante é o tropical de Altitude do tipo Cwb. O bioma (dominío morfoclimático) do estado são os chamados "Mares de Morros" caracterizados pela vegetação tropical, em climas mais amenos, formados por serras fortemente erodidas. Os principais rios capixabas são o Doce, o São Mateus, o Itaúnas, o Itapemirim e o Jucu. Os cinco integram as Bacias Costeiras do Sudeste.
O clima é tropical litorâneo úmido, influenciado pela massa de ar tropical atlântica. As chuvas concentram-se no verão. A temperatura média varia entre 22 °C e 24 °C, e a pluviosidade, entre 1.000 mm e 1.500 mm anuais.
A maior parte do estado caracteriza-se como um planalto, parte do maciço Atlântico. A altitude média é de seiscentos a setecentos metros, com topografia bastante acidentada e terrenos arqueozoicos, onde são comuns os picos isolados, denominados pontões e os pães-de-açúcar. Na região fronteiriça com Minas Gerais, transforma-se em área serrana, com altitudes superiores a mil metros, na região onde se eleva a Serra do Caparaó ou da Chibata. Aí, se ergue um dos pontos culminantes do Brasil, o Pico da Bandeira, com 2 890m.
De forma mais esquemática, pode-se compor um quadro morfológico do relevo em cinco unidades:
Ao contrário do que ocorre nos estados do Rio de Janeiro e de São Paulo, onde constitui um escarpamento quase contínuo, no Espírito Santo o rebordo do planalto apresenta-se como zona montanhosa muito recortada pelo trabalho dos rios, que, nela, abriram profundos vales. A partir do centro do estado para norte, esses terrenos perdem altura e a transição entre as terras baixas do litoral e as terras altas do interior vai se fazendo mais lenta, até alcançar o topo do planalto no estado de Minas Gerais. Dessa forma, ao norte do Rio Doce, a serra é substituída por uma faixa de terrenos acidentados, mas de altura reduzida, em meio aos quais despontam picos que formam alinhamentos impropriamente denominados serras.
Ocorrem no Espírito Santo dois tipos principais de climas, o tropical chuvoso e o mesotérmico úmido. O primeiro domina nas terras baixas e caracterizam-se por temperaturas elevadas durante todo o ano e médias térmicas superiores a 22 °C. O tipo "Am", das florestas pluviais, com mais de 1.250mm anuais de chuvas e com uma estação seca pouco pronunciada, ocorre no litoral norte, no sopé da serra e na região de Vitória; o tipo "Aw", com cerca de 1.000mm de chuva e estação seca bem marcada, ocorre no resto das terras baixas.
O clima mesotérmico úmido, sem estação seca, surge na região serrana do sul do estado. Caracteriza-se por temperaturas baixas no inverno (média do mês mais frio abaixo de 18 °C). Observam-se, entretanto, bruscas alterações climáticas.
O Espírito Santo está incluído em sua totalidade no bioma da Mata Atlântica, apresentando desde fitofisionomias florestais em áreas com altitude menor, até fitofisionomias abertas, em áreas com maior altitude. Entre as fitosionomias florestais destacam-se a floresta ombrófila densa, que ocupava quase 70% do estado, e a floresta estacional semidecidual, que ocupava cerca de 23%. A floresta ombrófila aberta, mais rara, ocupava cerca de 3% do estado, sendo encontrada no sudeste e noroeste. Do ponto de vista geológico, o Espírito Santo é dividido em zona de tabuleiros, zona serrana e planície costeira, com extrema influência na vegetação encontrada nessas zonas.
As floresta úmidas da zona de tabuleiros (abaixo de 300 m de altitude) do norte do Espírito Santo e sul da Bahia frequentemente são chamadas de "mata de tabuleiro", e apresentam pouca vegetação rasteira, muitas epífitas e lianas. As árvores podem ter até 30 m de altura e a primeira vista, essa floresta apresenta semelhanças com a Floresta Amazônica. Hoje em dia, a mata de tabuleiro só é encontrada em bom estado de conservação na Reserva Biológica de Sooretama e na Reserva Natural Vale. No litoral, também observa-se a presença de restingas e mangues, principalmente ao norte do rio Doce. Muitas vezes, as restingas limitam-se apenas às praias, mas podem avançar para o interior, unindo-se com as matas de tabuleiros.
A zona serrana, localizada em terras altas e vales do interior ao sul do rio Doce principalmente, possui desde florestas com muita vegetação rasteira (entre 300 e 2 000 m de altitude), até campos de altitude, acima dos 2 000 m. Alguns autores denominam essa vegetação de "floresta pluvial atlântica". Principalmente na Serra do Caparaó, encontra-se uma vegetação aberta denominada campo rupestre, ainda muito pouco estudada pela ciência e que vem se mostrando ser um ecossistema único.
Atualmente, a vegetação nativa do Espírito Santo está reduzida a menos de 15% da cobertura original: em 2011, calculava-se que havia apenas 5 107,53 km² de florestas, o que totalizava cerca de 11,07%. Por conta de sua semelhança, principalmente na parte norte do estado, com o sul da Bahia, a Mata Atlântica capixaba está incluída em um projeto de corredor ecológico que visa integrar as unidades de conservação desse estado com os do sul baiano, o chamado "Corredor Central da Mata Atlântica".
Os principais rios do estado são, de norte para o sul, o Itaúnas, o São Mateus, o Doce e o Itapemirim, que correm de oeste para leste, isto é, da serra para o litoral. O mais importante deles é o Doce, que nasce em Minas Gerais e divide o território espírito-santense em duas partes quase iguais. Em seu delta formam-se numerosas lagoas, das quais a mais importante é a de Juparanã.
O litoral capixaba é rochoso ao sul, com falésias de arenito, e também na parte central, com grandes morros e afloramentos graníticos a beira mar, o litoral sul-central é muito recortado com muitas enseadas e baias protegidas por rochas e afloramentos rochosos a beira mar, é arenoso ao norte, com praias cobertas por uma vegetação rasteira e extensas dunas, principalmente em Itaúnas e Conceição da Barra.
A 1.140 quilômetros da costa, em pleno Oceano Atlântico, encontram-se a Ilha da Trindade (12,5 km²) e as Ilha de Martim Vaz, situadas a 30 quilômetros de Trindade. Essas ilhas estão sob a administração do Espírito Santo.
O estado possui um litoral mais recortado no centro-sul, e mais mar aberto no norte, o que faz a maior parte das ilhas se concentrarem na parte central do estado, porém o estado possui várias ilhas. Ao todo, são 73 ilhas localizadas na costa do estado, sendo 50 localizadas na capital Vitória.
No Espírito Santo, o Instituto Brasileiro do Meio Ambiente e dos Recursos Naturais Renováveis (IBAMA) administra dezessete unidades de conservação: dois parques nacionais, seis reservas biológicas, três reservas particulares do patrimônio natural, duas áreas de proteção ambiental, uma estação ecológica e três florestas nacionais.
O estado também é conhecido por possuir diversos locais que servem para armazenamento dos ovos de Tartarugas-marinhas ("Cheloniidae"). No estado, o TAMAR, um projeto conservacionista brasileiro dedicado à preservação de espécies de tartarugas-marinhas ameaçadas de extinção, mantém sete bases do projeto no estado: Itaúnas, Guriri, Pontal do Ipiranga, Povoação, Vila de Regência, Ilha da Trindade e Anchieta. Os trabalhos de monitoramento das praias realizados pelas equipes do TAMAR normalmente são realizados entre os meses de setembro e março, no fim do período reprodutivo. As tartarugas marinhas demoram até 20 anos para chegar à idade reprodutiva e de cada mil filhotes que nascem apenas um chega à fase adulta. Ou seja, das 100 mil tartarugas nascidas no último ano, daqui a vinte anos, provavelmente, estima-se que apenas 100 retornem para desovar.
Segundo o censo demográfico de 2010 realizado pelo IBGE, em 2010, o estado do Espírito Santo possuía habitantes, sendo o décimo quarto estado mais populoso do Brasil, representando 1,8% da população brasileira. Segundo o mesmo censo, habitantes eram homens e habitantes eram mulheres. Ainda segundo o mesmo censo, habitantes viviam na zona urbana e na zona rural. Em dez anos, o estado registrou uma taxa de crescimento populacional de 13,59%.
Em relação ao ano de 1991, quando a população era de , esses números mostram uma taxa de crescimento anual de 2% ao ano, inferior a do Brasil como um todo (1,6%) para o mesmo período (1991-2000). Ainda segundo o censo demográfico de 2000, o Espírito Santo é o décimo quarto estado mais populoso do Brasil e concentra 1,82% da população brasileira. Do total da população do estado em 2000, habitantes são mulheres e habitantes são homens. Para 2006, a estimativa é de habitantes.
Nos últimos anos, o crescimento da população urbana intensificou muito, ultrapassando o total da população rural. Segundo a estimativa de 2000, 67,78 dos habitantes viviam em cidades. Dois municípios capixabas mantêm o pomerano como segunda língua oficial (além do português): Vila Pavão e Santa Maria de Jetibá. Também foi aprovada em agosto de 2011 a PEC 11/2009, emenda constitucional que inclui no artigo 182 da Constituição Estadual a língua pomerana, junto com a língua alemã, como patrimônios culturais do Estado.
A densidade demográfica no estado, que é uma divisão entre sua população e sua área, é de habitantes por quilômetro quadrado, sendo a sétima segunda maior do Brasil e com uma densidade comparada à do país asiático Malásia. A distribuição da população estadual é desigual, apresentando maior concentração na região serrana, no interior. Nessa área, a densidade demográfica atinge a média de 50 hab./km² e a ultrapassa no extremo sudoeste. A Baixada Litorânea, faixa que acompanha o litoral, apresenta quase sempre densidades inferiores à média estadual. Apenas nas proximidades de Vitória observa-se uma pequena área com mais de 50 hab./km². A parte norte da baixada litorânea é a menos povoada do estado. Sete municípios (Vila Velha, Cariacica, Cachoeiro de Itapemirim, Colatina, São Mateus e Linhares) concentram mais de 45% da população do Espírito Santo (1975).
O Índice de Desenvolvimento Humano (IDH) do estado, considerado como "elevado" pelo Programa das Nações Unidas para o Desenvolvimento (PNUD), é de , segundo dados do ano de 2010, sendo naquele período, o sétimo mais alto entre as unidades federativas do Brasil. Naquele ano, considerando apenas a educação, o índice era de 0,653, considerado "médio"; o índice de longevidade era de 0,835, considerado "muito alto" e o índice de renda era de 0,743, considerado como "alto". A renda per capita é de reais. Entre 1991 e 2000, o estado registrou uma forte evolução tanto no seu IDH geral quanto na educação, longevidade e renda, critérios utilizados para calcular o índice. A educação foi o critério que mais evoluiu em nove anos, de 0,304 em 1991 para 0,491 em 2000, e em 2010 o valor passou a ser 0,653. Depois da educação, vem a longevidade, que em 1991 tinha um valor de 0,686, passando para 0,777 em 2000 e 0,835 em 2010. E, por último, vem a renda, o critério que menos evoluiu entre 1991, quando era de 0,619, e 2000, ano em que foi calculado como sendo de 0,687, avançando para o valor de 0,743 em 2010. Quanto ao IDH, que é uma média aritmética dos três subíndices, a evolução também foi significativa, passando de 0,505 em 1991 (considerado como "baixo" pela ONU) para 0,64 em 2000 (considerado "médio" pela ONU), e para 0,74 em 2010 (considerado "elevado" pela ONU).
Em 2010, o município com o maior IDH era a capital, Vitória, com um valor de 0,845, considerado como "muito elevado" pelo PNUD no período, posicionado na primeira posição entre os municípios capixabas naquele ano e na quarta posição entre todos os municípios do país, empatado com Balneário Camboriú (SC), e ficando atrás somente de São Caetano do Sul (SP), Águas de São Pedro (SP) e Florianópolis (SC). Já dentre as capitais estaduais do país, Vitória foi posicionada naquele período em segundo lugar, perdendo apenas para Florianópolis, Santa Catarina. Concomitantemente, o município com menor IDH foi Ibitirama, situado na Mesorregião do Sul Espírito-Santense, possuindo o índice no valor de 0,622, que possuindo todos os indicadores sociais abaixo da média estadual no período, estava posicionado na 78° e último lugar entre os municípios do estado e no 3653° lugar entre todos os municípios brasileiros, com um IDHM considerado "médio" pelo PNUD. No ano 2000, o município capixaba mais bem avaliado de acordo com o IDH era mais uma vez a capital, Vitória, com o índice no valor de 0,759, considerado como "elevado" no período, estando ranqueado na sétima posição na época entre todos os municípios do Brasil, ficando atrás apenas de São Caetano do Sul (SP), Águas de São Pedro (SP), Santos (SP), Balneário Camboriú (SC), Niterói (RJ) e Florianópolis (SC). No mesmo período, o município com menor valor de IDH era Santa Leopoldina, situado na Mesorregião Central Espírito-Santense, com um índice de 0,468 no período, considerado como "baixo" à época. Já no ano de 1991, o município com melhor IDH do estado era igualmente a capital, Vitória, com um índice de 0,644, considerado como "médio" pela ONU e sendo posicionado na sexta posição entre todos os municípios do Brasil, ficando atrás somente de São Caetano do Sul (SP), Santos (SP), Florianópolis (SC), Niterói (RJ) e Porto Alegre (RS).
O coeficiente de Gini, que mede a desigualdade social, é de 0,50, sendo que 1,00 é o pior número e 0,00 é o melhor. A incidência da pobreza, medida pelo IBGE, é de %, o limite inferior da incidência de pobreza é de %, o superior é % e a subjetiva é %.
Apesar de tradicionalmente o Catolicismo ser a religião mais professada no Espírito Santo, nas últimas décadas houve grande aumento no número de evangélicos. Segundo o Censo 2010, a Igreja Católica é a religião de 53,4% dos capixabas. Divide-se administrativamente em uma arquidiocese, a Arquidiocese de Vitória, e três dioceses sufragâneas: Cachoeiro de Itapemirim, Colatina e São Mateus. Na Igreja Católica, destaca-se o Convento da Penha, que é um dos principais monumentos históricos do estado e a Basílica de Santo Antônio.
Ainda segundo o Censo IBGE 2010, as Igrejas evangélicas são seguidas por 33,1% dos capixabas, o que faz do Espírito Santo o estado mais evangélico do Brasil. São muitas as igrejas evangélicas, sendo a maior a Assembleia de Deus em suas várias ramificações, seguida da Igreja Cristã Maranata, fundada no estado há 43 anos e da multifacetada Igreja Batista e da Igreja Universal do Reino de Deus. É possível encontrar também praticantes de religiões de origem africana, além de espíritas e outros. O luteranismo também está presente em todo o estado, mas é nas regiões serranas, onde há maior quantidade de descendentes de alemães e pomeranos, que sua presença é mais forte.
É no Espírito Santo que se encontra o Mosteiro Zen Morro da Vargem, primeiro da América Latina, localizado em Ibiraçu e aberto a visitação, no estado também foram construídos o Convento da Penha, 1º convento do Brasil em 1555, e a primeira igreja luterana da América Latina.
De acordo com dados do censo de 2010 realizado pelo Instituto Brasileiro de Geografia e Estatística (IBGE), a população do Espírito Santo está composta por: católicos (53,4%), evangélicos (33,1%), pessoas sem religião (9,61%), espíritas (0,72%), budistas (0,02%), muçulmanos (0,00%), umbandistas (0,14%) e judeus (0,01%).
O censo do IBGE de 2010 revelou os seguintes números: 1,7 milhão brancos (48,6%), 1,5 milhão Pardos (42,2%), 293 mil Negros (8,4%) e 0,8% amarelos (21,9 mil) ou Indígenas (9 mil).
A população do estado, assim como no resto do Brasil, foi formada por elementos indígenas, africanos e europeus. O Espírito Santo, no , contava com uma grande população de origem indígena e africana. Depois da colonização portuguesa, a partir do o estado recebeu levas consideráveis de imigrantes, na maioria italianos, mas também alemães, portugueses e espanhóis.
O desenvolvimento social e econômico do Espírito Santo, a par de transformar o estado em um dos mais ricos do Brasil, acarretou também os seguintes fenômenos:
O Espírito Santo é a segunda unidade federativa mais violenta do Brasil, perdendo apenas para Alagoas, e lidera o maior índice de criminalidade da Região Sudeste do país, superando ainda mais o Rio de Janeiro, Minas Gerais e São Paulo. A taxa de homicídios é de 45,6 a cada mil.
O município mais violento do Espírito Santo e da Região Sudeste do Brasil é Serra, na Região Metropolitana de Vitória; é também o quarto mais violento do Brasil (102,4), registrando, em 2006, taxas médias de homicídio superiores apenas às dos municípios de Vitória, Viana, Cariacica, Linhares e Pedro Canário. O município com a menor taxa média de homicídios é Marechal Floriano, na Mesorregião Central Espírito-Santense, mais precisamente na Microrregião de Afonso Cláudio.
O estado do Espírito Santo é governado por três poderes, o executivo, representado pelo governador, o legislativo, representado pela Assembleia Legislativa do Estado do Espírito Santo, e o judiciário, representado pelo Tribunal de Justiça do Estado do Espírito Santo e outros tribunais e juízes. Também é permitida a participação popular nas decisões do governo através de referendos e plebiscitos.
A atual constituição do estado do Espírito Santo foi promulgada em 1989, acrescida das alterações resultantes de posteriores emendas constitucionais.
O Poder Executivo capixaba está centralizado no governador do estado, que é eleito em sufrágio universal e voto direto e secreto, pela população para mandatos de até quatro anos de duração, e podem ser reeleitos para mais um mandato. Sua sede é o "Palácio Anchieta", que desde o é a sede do governo capixaba. A residência oficial do governador fica na Praia da Costa, localizada no município de Vila Velha.
O Poder Legislativo do Espírito Santo é unicameral, constituído pela Assembleia Legislativa do Estado do Espírito Santo, localizado na Enseada do Suá. Ela é constituída por 30 deputados, que são eleitos a cada 4 anos. No Congresso Nacional, a representação capixaba é de 3 senadores e 10 deputados federais. A maior corte do Poder Judiciário capixaba é o Tribunal de Justiça do Estado do Espírito Santo, localizado na Enseada do Suá. Compõem o poder judiciário os desembargadores e os juízes de direito.
O Espírito Santo está dividido politicamente em 78 municípios. O mais populoso deles é Vila Velha, com 416 mil habitantes, sendo o município mais antigo do estado. Sua região metropolitana possui aproximadamente 1,7 milhão de habitantes.
Uma mesorregião é uma subdivisão dos estados brasileiros que congrega diversos municípios de uma área geográfica com similaridades econômicas e sociais. Foi criada pelo IBGE e é utilizada para fins estatísticos e não constitui, portanto, uma entidade política ou administrativa. Oficialmente, as quatro mesorregiões do estado são:
Além da mesorregião, existe a microrregião, que é, de acordo com a Constituição brasileira de 1988, um agrupamento de municípios limítrofes, com a finalidade de integrar a organização, o planejamento e a execução de funções públicas de interesse comum, definidas por lei complementar estadual. O Espírito Santo é dividido em treze microrregiões. São elas: Vitória, Afonso Cláudio, Guarapari, Santa Teresa, Linhares, Montanha, São Mateus, Barra de São Francisco, Colatina, Nova Venécia, Alegre, Cachoeiro do Itapemirim e Itapemirim.
Por último, existem os municípios (as menores unidades autônomas da federação), que são circunscrições territoriais dotadas de personalidade jurídica e com certa autonomia administrativa. Em geral, o Espírito Santo está dividido em 78 municípios, sendo a vigésima unidade de federação com o maior número de municípios e a quarta e última do Sudeste (atrás de Minas Gerais, São Paulo e Rio de Janeiro).
Durante a década de 2000, por sucessivas leis estaduais, foram criadas e alteradas regiões de gestão e planejamento, estabelecidas com o objetivo de centralizar a atividades das secretarias estaduais. Seus limites nem sempre coincidem com os das mesorregiões e microrregiões do Espírito Santo. As onze regiões administrativas do estado são: Metropolitana (Grande Vitória), Pólo Linhares, Litoral Sul, Pólo Afonso Cláudio (Sudoeste Serrana), Litoral Norte, Extremo Norte, Pólo Colatina, Noroeste 1, Noroeste 2, Pólo Cachoeiro de Itapemirim, Caparaó (Microrregião de Alegre).
Na economia do Espírito Santo, têm destaque a agricultura, a pecuária e a mineração.
Na produção agrícola, destacam-se a cana-de-açúcar (2,5 milhões de toneladas), a laranja (175 milhões de frutos), o coco-da-baía (148 milhões de frutos) e o café (1 milhão de toneladas). O total de galináceos no estado é de aproximadamente 9,2 milhões de aves, e o de gado bovino ultrapassa 1,8 milhão de cabeças. Há reservas importantes de granito e uma incipiente extração de gás natural e petróleo. Areias e mármores também são importantes produtos do extrativismo capixaba. Embora relativamente pequeno, o parque industrial do Espírito Santo abriga indústrias químicas, metalúrgicas, alimentícias e de papel e celulose.
Em 2012, a pauta de exportação do Espírito Santo se baseou em Minério de Ferro (52,49%), Petróleo Cru (10,87%), Pastas Químicas de Madeira Á Soda ou Sulfato (10,01%), Pedras de Cantaria ou Construção (5,58%) e Café (4,42%).
O Espírito Santo é sede de importantes cooperativas agropecuárias, entre as quais se destacam: a Capil, de Itarana; a Ceaq, de São Domingos do Norte; a Cooaprucol de Colatina; a Coop-Forgrande, de Castelo; a Cocaes, de Brejetuba; a Cavil, de Bom Jesus do Norte; e a Coopeves, de Vila Velha.
A atividade turística do estado concentra-se no litoral, onde há belas praias, como a de Itaúnas e a de Guarapari. O pico da Bandeira, terceiro mais alto do país, é outro destino turístico bastante procurado. Ultimamente, tem ganhado destaque um novo tipo de turismo: o gastronômico, em que se aprecia a típica culinária capixaba, herdeira de diversas culturas.
O sistema rodoviário se organiza a partir da BR-101, que corta o Espírito Santo de norte a sul, margeando o litoral. O estado possui 30,1 mil quilômetros de estradas de rodagem, mas apenas 10% são pavimentados.
O produto agrícola tradicional do estado é o café, cultura que orientou a ocupação de praticamente todo o território capixaba. Após uma fase de decadência no estado, o café recuperou uma posição de relativo destaque nacional. Seguem-se a ele, em ordem de importância, as culturas de milho, banana, mandioca, feijão, arroz e cacau.
A criação de bovinos serviu-se de solos virgens no norte do estado, em terrenos desmatados. Nessa área cria-se e engorda-se gado de corte, e ali desenvolveu-se a indústria frigorífica, cuja carne é enviada principalmente para o Rio de Janeiro, além de abastecer a região de Vitória. No sul pratica-se muito a pecuária leiteira, e o leite é comercializado, por meio de cooperativas, nos mercados do Rio de Janeiro e Vitória.
De desenvolvimento mais recente são a silvicultura e a fruticultura, com aproveitamento para conservas de frutas e para a produção de celulose, destacando-se nessa última atividade alguns projetos de reflorestamento, que poderão compensar em parte o desmatamento avassalador sofrido pelo estado.
O subsolo do estado é rico em minerais, inclusive petróleo. Há consideráveis reservas de calcário, mármore, manganês, ilmenita, bauxita, zircônio, monazitas e terras raras, embora nem todas em exploração. No extrativismo mineral, destaca-se a exploração, na área de Cachoeiro de Itapemirim, de reservas de mármores, calcário e dolomita.
Nos centros urbanos da capital e de Cachoeiro de Itapemirim concentram-se praticamente todas as principais unidades da indústria de transformação capixaba. Na grande Vitória localizam-se as indústrias siderúrgicas: Companhia Ferro e Aço de Vitória, usina de pelotização de minério de ferro da Companhia Vale do Rio Doce; madeireira, têxtil, de louças, de café solúvel, de chocolates e frigorífica. No vale do rio Itapemirim, desenvolvem-se indústrias de cimento, de açúcar e álcool e de conservas de frutas.
As 10 maiores empresas industriais do Espírito Santo são a Companhia Vale do Rio Doce, ArcelorMittal, Samarco Mineração, Aracruz Celulose, Fertilizantes Heringer, ArcelorMittal Brasil, Escelsa, Garoto (a maior fábrica de chocolates da América Latina e a mais importante empresa industrial de alimentos do estado) e Sol Coqueria.
É deficitário o comércio do estado com as demais unidades federativas do Brasil. O valor da exportação por cabotagem, em junho de 2010, foi da ordem de US$ 1.075.429 e o da importação de US$ 642.997. Quanto ao seu comércio exterior, devido à exportação de minério, a situação é completamente inversa do comércio por cabotagem. O valor total da exportação para o exterior, em 2009, foi de US$ 6.510.241 e a da importação, de US$ 5.484.252.
O setor terciário é pouco desenvolvido em todo o Estado. No entanto, a atividade comercial adquire certa importância com as exportações de minério de ferro proveniente de Minas Gerais, através da Estrada de Ferro Vitória a Minas e é embarcado nos portos de Atalaia e ponta do Tubarão. Por outro lado, a ligação de Cachoeiro de Itapemirim à cidade do Rio de Janeiro, por rodovia pavimentada, permitiu a incorporação da região à bacia leiteira fluminense e facilitou a exportação de produtos agrícolas, como café, milho, mandioca, arroz e hortigranjeiros.
Nos últimos anos, o Espírito Santo vem se destacando na produção de petróleo e gás natural. Com várias descobertas realizadas, principalmente pela Petrobras, o Estado saiu da quinta posição no ranking brasileiro de reservas, em 2002, para se tornar a segunda maior província petrolífera do País, com reservas totais de 2,5 bilhões de barris. São cerca de 140 mil barris diários. Os campos petrolíferos se localizam tanto em terra quanto em mar, em águas rasas, profundas e ultraprofundas, contendo óleo leve e pesado e gás não associado.
Dentre os destaques da produção está o campo de Golfinho, localizado a norte do estado, com reserva de 450 milhões de barris de óleo leve, considerado o mais nobre. O primeiro módulo de produção do local já está em operação, com o FPSO Capixaba, e o segundo deve iniciar a operação até o final deste ano, com o FPSO Cidade de Vitória.
Há ainda os campos de Jubarte, Cachalote, Baleia Franca, Baleia Azul, Baleia Anã, Caxaréu, Mangangá e Pirambu, que fazem parte do denominado Parque das Baleias, no Sul, que somam uma reserva de 1,5 bilhão de barris. O Espírito Santo é atualmente responsável por 40% das notificações de petróleo e gás natural brasileiras, conforme levantamento da Agência Nacional do Petróleo, Gás Natural e Biocombustível (ANP) desde sua criação, em janeiro de 1998.
A indústria de petróleo no Espírito Santo possibilita o pagamento de royalties relacionados à exploração de petróleo e gás natural aos municípios nos quais estão localizados os campos produtores e as instalações das empresas. Para beneficiar os 68 municípios capixabas que não recebem royalties petrolíferos, o Governo do Estado criou o Fundo para Redução das Desigualdades Regionais, o primeiro projeto desta natureza aprovado no país. Os recursos são provenientes do repasse de 30% dos royalties creditados no cofre público estadual. Em vigor desde junho de 2006, a distribuição do dinheiro do fundo leva em consideração a população, o percentual de repasses do ICMS e a condição de não ser grande recebedor de royalties. As cidades que têm participação acima de 10% no ICMS e mais de 2% dos royalties não têm acesso aos recursos do Fundo.
Em 2005, existiam, no Estado, 1.755 estabelecimentos hospitalares, com 7.684 leitos e 378 médicos, 35 enfermeiros diplomados e 210 auxiliares de enfermagem. Em 2010, dos 1.755 hospitais existentes, 125 eram de adultos e crianças, 88 eram exclusivamente de crianças, sendo 98 gerais e 22 especializados. Em 2005, da população, 84,4% dos capixabas tinham acesso à rede de água, enquanto 75,7% se beneficiam da rede de esgoto sanitário.
Atualmente a situação energética do Estado do Espírito Santo é de confiabilidade, por se conectar ao Sistema Interligado Sul/Sudeste/Centro-oeste através de um anel de transmissão. O estado produz 33% de suas necessidades, importando, consequentemente, 67% da energia requerida de FURNAS Centrais Elétricas S.A. As concessionárias de distribuição de energia elétrica operando no Espírito Santo são a Espírito Santo Centrais Elétricas S/A (Escelsa), atualmente uma empresa do grupo EDP, e Empresa Luz e Força Santa Maria (ELFSM).
Com seu franco desenvolvimento, expansão e a crescente demanda por fontes energéticas que sustentem de maneira consistente este processo, o Espírito Santo vem utilizando como principal energia alternativa a energia eólica. O processo consiste na conversão do vento em energia elétrica através de aerogeradores - gigantes turbinas em forma de cata-vento colocadas em pontos estratégicos onde a ação do vento é intensa.
O Estado dispunha em 2008 de uma rede de de 2.733 escolas de ensino fundamental, das quais 482 estaduais, 1.986 municipais, 1.157 particulares e 6 federais. O corpo docente era constituído de 29.282 professores, sendo que 6.777 trabalhavam nas escolas públicas estaduais, 18.146 nas escolas públicas municipais e 4.359 nas escolas particulares. Estudavam nestas escolas 553.396 alunos, dos quais 491.342 nas escolas públicas e 62.054 nas escolas particulares. O ensino médio foi ministrado em 438 estabelecimentos, com a matrícula de 139.984 alunos. Dos 139.984 discentes, 119.478 estavam nas escolas públicas e 20.506 nas particulares. Quanto ao ensino superior, em 2008, o estado possuía 91 estabelecimentos, com 6.490 professores e 89.610 discentes.
Em 2004 a taxa de analfabetismo no estado era de 9,5%, uma das mais baixas do Brasil. Da população, 21,0% dos capixabas são analfabetos funcionais. O Espírito Santo é a 12ª melhor educação do Brasil, com um Índice de Desenvolvimento Humano de 0,887.
As principais universidades do Espírito Santo são a Escola Agrotécnica Federal de Alegre, o Instituto Federal do Espírito Santo, a Universidade Federal do Espírito Santo e o Centro Universitário Norte do Espírito Santo.
Os principais jornais diários editados em Vitória são a "Gazeta", o mais antigo e de instalações mais modernas; o "Diário", "Diário Oficial do Estado" e "A Tribuna". Em Cachoeiro de Itapemirim, circula o Correio do Sul; em Colatina, a "Folha do Norte". As principais emissoras de radiodifusão da capital são a Rádio Espírito Santo, que emite em ondas médias, tropicais e de frequência modulada, a Rádio Vitória e a Rádio Capixaba, ambas em ondas médias e curtas. Os municípios de Cariacica, Colatina, Mimoso do Sul e Santa Teresa também possuem emissoras de rádio. Na capital, funcionam a TVE Espírito Santo, a TV Gazeta, a TV Vitória, a TV Tribuna, a TV Capixaba e a RedeTV! ES. Há torres repetidoras de emissoras do Rio de Janeiro.
No estado existe apenas um aeroporto administrado pela Infraero, o Aeroporto Eurico de Aguiar Salles (Vitória), além dos aeroportos como o de Baixo Guandu/Aimorés, o de Cachoeiro de Itapemirim, o de Guarapari, o de Linhares e o Tancredo de Almeida Neves (São Mateus), que são de responsabilidade das suas respectivas administrações municipais.
A Estrada de Ferro Vitória a Minas escoa minério de ferro de Itabira (MG) até o porto de Tubarão, e volta com carvão para siderurgia. Também faz transporte de passageiros e carga geral no vale do rio Doce. A Ferrovia Centro-Atlântica serve ao sul do estado e comunica Vitória com o estado do Rio de Janeiro. As principais rodovias são a BR-101, que corta o estado de norte a sul, pelo litoral, e a BR-262, que liga Vitória a Belo Horizonte (MG) e ao extremo oeste do país. Outras rodovias importantes são a BR-482, que atravessa Alegre e Jerônimo Monteiro e entronca com a BR-101 no distrito de Safra; a BR-342, que liga Ecoporanga a Nova Venécia, no norte do estado; e a BR-381, que liga o município de São Mateus ao município de São Paulo, passando por Nova Venécia e Barra de São Francisco. O estado possui dois portos, ambos na capital: o cais comercial de Vitória e o porto de exportação de minério de ferro de Tubarão.
As principais unidades das Forças Armadas com sede no Espírito Santo são: no Exército Brasileiro, o Espírito Santo integra a 1ª Região Militar (juntamente com o estado do Rio de Janeiro) destacando aí o 38º Batalhão de Infantaria; na Marinha do Brasil, o Espírito Santo faz parte do 1º Distrito Naval (com sede no Rio de Janeiro), destacando-se no Estado a Escola de Aprendizes-Marinheiros; e na Força Aérea Brasileira, o Espírito Santo integra o III Comando Aéreo Regional, com sede na cidade do Rio de Janeiro, destacando-se o Estado como parte integrante do Cindacta I, que forma o quadrilátero com as cidades do Rio de Janeiro, São Paulo, Belo Horizonte e Brasília.
A Polícia Militar do Estado do Espírito Santo (PMES) é uma das forças de polícia militar do Brasil, sendo responsável pelo policiamento ostensivo no Estado do Espírito Santo. Seu Quartel do Comando Geral (QCG) é situado na Avenida Maruípe, na cidade de Vitória, capital do Estado.
O Corpo de Bombeiros Militar do Estado do Espírito Santo (CBMES) é uma Corporação cuja missão primordial consiste na execução de atividades de defesa civil, prevenção e combate a incêndios, buscas, salvamentos e socorros públicos no âmbito do estado do Espírito Santo. Ele é Força Auxiliar e Reserva do Exército Brasileiro, e integra o Sistema de Segurança Pública e Defesa Social do Brasil. Seus integrantes são denominados Militares dos Estados pela Constituição Federal de 1988, assim como os membros da Polícia Militar do Estado do Espírito Santo.
A Polícia Civil do Estado do Espírito Santo é uma das polícias do Espírito Santo, Brasil, órgão do sistema de segurança pública ao qual compete, nos termos do artigo 144, § 4º, da Constituição Federal e ressalvada competência específica da União, as funções de polícia judiciária e de apuração das infrações penais, exceto as de natureza militar. As principais instituições penitenciárias do estado são o Instituto de Readaptação Social (em Vila Velha) e Colônia Penal (em Viana).
A Superintendência do Departamento de Polícia Federal no Espírito Santo está localizada no bairro vilavelhense do São Torquato e é responsável pelo cadastro de passaportes brasileiros de capixabas e outras pessoas residentes no Estado, controles de passageiros nacionais e estrangeiros no aeroportos internacionais e defesa mútua e obrigatória das fronteiras do Brasil como outros países sul-americanos ao lado do Exército Brasileiro, da Marinha do Brasil e da Força Aérea Brasileira.
As principais entidades culturais do estado encontram-se na capital: a Universidade Federal do Espírito Santo (UFES), o Instituto Histórico e Geográfico, a Associação Espírito-Santense de Imprensa, a Academia Espírito-Santense de Letras, a Associação Espírito-Santense de Juristas, a Arcádia Espírito-Santense, a Associação Médica do Espírito Santo, a Academia Feminina de Letras, o Instituto dos Advogados, o Centro Capixaba de Folclore e o Instituto Espírito-Santense de História, Geografia e Arte Religiosa. Em Cachoeiro de Itapemirim há a Academia Cachoeirense de Letras.
A capital conta com as bibliotecas Estadual, Municipal, do Tribunal de Justiça, dos Comerciários, Embaixador Macedo Soares (da delegacia da Fundação IBGE), Central da Universidade Federal do Espírito Santo e da Companhia Vale do Rio Doce, entre outras. Em Cachoeiro de Itapemirim destacam-se as Bibliotecas Municipal, do Centro Espírita Fraternidade e Luz, do Colégio Estadual Muniz Freire e da Casa dos Braga — pequeno museu dedicado aos irmãos escritores Newton e Rubem Braga, na casa onde nasceram. Muitos outros municípios do interior possuem também pequenas bibliotecas.
O teatro mais relevante da capital é o Theatro Carlos Gomes, inaugurado em 1927 e inovado em 1970, sob a responsabilidade da Fundação Cultural do Espírito Santo, com 311 poltronas e 40 camarotes.
Na capital, o museu histórico mais relevante é o Museu Solar Monjardim, antigo Museu de Arte e História e Museu Capixaba, anteriormente vinculado à Universidade Federal do Espírito Santo e na atualidade, administrado pelo Instituto Brasileiro de Museus (Ibram). O museu encontra-se instalado no Solar Monjardim, tombado pelo Instituto do Patrimônio Histórico e Artístico Nacional e antiga Casa-Grande da Fazenda, hoje bairro, de Jucutuquara. No centro histórico da capital encontram-se o Museu de Arte do Espírito Santo Dionísio del Santo (Maes) e o Museu Capixaba do Negro Verônica da Paz (Mucane). No município vizinho de Vila Velha, o Museu Ferroviário da Vale, na antiga sede da Estação Pedro Nolasco, oferece vista para o centro de Vitória.
Em Santa Teresa, há o Museu de Biologia Professor Mello Leitão, instituição criada pelo ilustre naturalista capixaba Augusto Ruschi em sua própria residência, onde também existe uma das melhores bibliotecas do mundo especializadas na fauna e na flora do país.
São tombados pelo Instituto do Patrimônio Histórico e Artístico Nacional os seguintes monumentos: a igreja de Nossa Senhora da Assunção (1587) e residência contígua, em Anchieta, onde morou o clérigo José de Anchieta; a igreja de Nossa Senhora da Ajuda, em Viana; a igreja dos Reis Magos (1558) e residência contígua, em Nova Almeida, município da Serra. Em Vitória, está localizados o Solar de Monjardim, a igreja de São Gonçalo Garcia (1766), a igreja de Nossa Senhora do Rosário (1765) e a igreja de Santa Luzia (1547). Em Vila Velha, o célebre convento e igreja de Nossa Senhora da Penha, localizado a 135m de altura sobre a entrada da baía de Vitória, e a igreja matriz de Nossa Senhora do Santo Rosário, todos do .
Em Vitória, as festas populares tradicionais mais distintas são as de Nossa Senhora da Penha, as comemorações católicas de Santo Antônio, em 13 de junho, de São Pedro dos Pescadores, na praia do Suá, em 29 de junho, e de Nossa Senhora da Vitória, em 8 de setembro. Em Guarapari e Conceição da Barra, realizam-se as festas de Nossa Senhora da Conceição, em 8 de outubro, e o alardo, realizada no ciclo de Natal ou nos dias 19 e 20 de janeiro. Em Cachoeiro de Itapemirim, o Dia de Cachoeiro, 29 de junho, é celebrado com uma semana de eventos em que ocorrem exposição agropecuária, bailes, shows populares, desfiles e caxambu da ilha da Luz. Em diversas cidades e aldeias litorâneas, como Guarapari, Marataízes, Anchieta, Piúma e Conceição da Barra, o dia de São Pedro, 29 de junho, padroeiro dos pescadores, é festejado também com procissões marítimas. Em Conceição da Barra, acontece a festa do Reis de Bois, no ciclo natalino.
As praias de areia monazítica de Guarapari, aconselhadas para a cura de reumatismo e artrose, e o convento de Nossa Senhora da Penha, em Vila Velha, são os maiores pontos turísticos do estado. Em Vitória, são locais importantes o palácio Anchieta, prédio onde funciona o governo estadual; as igrejas tombadas de Santa Luzia, do Rosário e de São Gonçalo Garcia; o Parque Moscoso, com concha acústica com capacidade para atrair 400 espectadores sentados; o porto, com seu terminal de exportação de minério; as praias: Comprida, Suá, Camburi e do Canto;
A costa capixaba é margeada de belas praias, que recebem muitos turistas — principalmente mineiros que aproveitam o sol e a água do mar e que são trajados de sunga e biquíni — no verão, sobressaindo-se Guriri, em São Mateus, Marataízes, Guarapari, Piúma, Iriri, Anchieta e Conceição da Barra, onde se situam as célebres dunas da barra do rio Itaúnas.
Nas serras capixabas também são encontrados pontos de grande atração turística, sobressaindo-se Domingos Martins, Santa Teresa, Rio Novo e Venda Nova do Imigrante.No interior, junto à divisa com Minas Gerais, localiza-se o Parque Nacional do Caparaó. O pico do Itabira e as pedras do Frade e da Freira (310m), em Cachoeiro de Itapemirim, são o símbolo maior da cidade, onde se pode visitar também a tradicional fábrica de pios de pássaros em madeira.
O prato típico mais lembrado do estado é a torta capixaba, feita tradicionalmente nas casas de Vitória durante a semana santa, mas também oferecida durante todo o ano aos turistas nos melhores restaurantes da capital. Sobressai-se ainda a moqueca capixaba, de peixes e frutos do mar cozidos em panelas de barro artesanais, ao molho de urucum.
A cultura do estado sofre forte influência de alemães, italianos e afro-descendentes, o que gera diversas manifestações culturais e festas singulares. Os principais eventos no estado, são de entretenimento, culturais e musicais, o maior evento do estado é a Vitória Stone Fair, maior exposição de Rochas Ornamentais do mundo, porém existem vários outros de importância quase igual, voltados ao setor agropecuário e ao setor alimentício. A maioria dos eventos, de pequeno, médio e grande porte, ocorre no Pavilhão de Carapina, espaço construído pelo governo do estado, para sediar eventos, no município de Serra.
Existe em Itapemirim a Tradicional Festa do Atum e do Dourado, sendo uma das principais festas da cultura pesqueira do Brasil, onde há anexado a festa o Festival de Frutos do Mar Capixaba, no distrito de Itaipava. Reúne mais de 50 mil pessoas por dia, onde tem a oportunidade de experimentar tradicionais pratos em frente ao mar, além da tradicional volta dos barcos, em que pecorrem a ilha dos Franceses e o preparo do Peixe no Rolete. Há também a tradicional festa de Corpus Christi, realizada por volta dos meses de maio e junho, onde em Castelo são confeccionados tapetes artesanais em um perímetro aproximado de um quilômetro pelo entorno do centro da cidade. Esse tapetes com vários quadro e passadeiras de desenho e muito colorido são de inspiração religiosa e feitos basicamente de flores, serragem colorida e grãos. Outro importante evento é a Festa do Cafona, em Colatina, evento que reúne pessoas de todo o Brasil, que se vestem de forma inusitada e propositalmente ridícula para ouvir músicas com letras provocativas e também ridículas e fazerem coisas bizarras e obscenas. Também há o Festival de Alegre, na cidade de Alegre, importante evento do cenário musical nacional, reúne as maiores e mais populares bandas brasileiras e as vezes, até bandas estrangeiras. Há também a tradicional e italiana festa da polenta realizada em Venda Nova do Imigrante. O maior rodeio do estado é o de Ibiraçu, onde a um encontro de música Sertaneja. O Festival de Inverno de Domingos Martins e a Festa do Vinho, são os maiores eventos da região serrana do estado.
Há também várias manifestações culturais importantes, como a festa de Exposição Municipal Afonso-Claudense e a festa do Afonso-Claudense Ausente e Presente, que comemora o aniversário do município de Afonso Cláudio; o Boi Pintadinho, em Muqui; a Sömmerfest em Domingos Martins; a Festa do Imigrante em Santa Teresa; a Festa do Morango em Domingos Martins; a Festa de São Benedito, na cidade de Serra; e a Festa da Penha, maior festa religiosa do estado que reúne cerca de 900 mil fiéis durante a Semana Santa, no Convento da Penha em Vila Velha, durante o período são celebradas muitas missas e romarias.
Na capital acontece o desfile das escolas de samba capixabas, que reúne no Sambão do Povo, como é conhecido o Sambódromo Capixaba, mais de cinquenta mil pessoas, fora os que desfilam, prestigiam as 14 escolas da Grande Vitória que desfilam em três dias de muita festa e animação. O desfile das escolas de samba capixabas acontece sempre uma semana antes do carnaval oficial e tem como atual campeã a Independentes de Boa Vista. A Liga Espírito-santense de Escolas de Samba (LIESES) é o órgão organizador dos desfiles em parceria com a prefeitura. Depois de dois anos em grupo único, os desfiles voltarão, em 2011, a serem divididos em dois grupos que desfilarão em 3 dias distintos.
No setor esportivo, a secretaria responsável por atuar nessa área é a "Secretaria de Esportes e Lazer", que tem como secretário Vanderson Alonso Leite, apelidado de Vandinho, natural de Baixo Guandu e formado em administração com ênfase em análise de sistemas. O estado é sede de diversos clubes de futebol conhecidos nacionalmente, como, por exemplo, o Rio Branco Atlético Clube, a Desportiva Ferroviária, Sociedade Desportiva Serra Futebol Clube e o Vitória Futebol Clube. O Campeonato Capixaba de Futebol é organizado pela Federação de Futebol do Estado do Espírito Santo e realizado ininterruptamente desde 1917, sendo um dos mais antigos torneios de futebol organizados no Brasil. O estado possui diversos estádios de futebol, como o Salvador Venâncio da Costa, o Governador Bley (todos em Vitória), o Mário Monteiro (em Cachoeiro do Itapemirim), o Engenheiro Alencar de Araripe (em Cariacica), o Municipal Justiniano de Mello e Silva (em Colatina), entre muitos outros. Em 2010, segundo a Confederação Brasileira de Futebol, o estado aparece na décima-quinta colocação no ranking nacional das federações estaduais.
Outros esportes também têm popularidade no estado. No vôlei, o órgão responsável pela atuação no esporte é a Federação Espírito-Santense de Voleibol, que possui diversos clubes filiados e organiza todos os torneios oficiais que envolvam as equipes do estado. No basquete, a federação responsável é a Federação Capixaba de Basquetebol. No skate, existe a Associação Capixaba de Skate (ACSK) responsável pela organização de eventos e afins relacionados ao esporte. Todos os anos, o estado realiza os "Jogos Escolares do Espírito Santo", evento da secretaria de esportes do governo estadual, que reúne diversas modalidades esportivas.
No Espírito Santo há dois feriados estaduais que são eles o dia da Colonização do solo espírito-santense, no dia 23 de maio, e o Dia do Servidor Público, no dia 28 de outubro.

Estatística é a ciência que utiliza-se das teorias probabilísticas para explicar a frequência da ocorrência de eventos, tanto em estudos observacionais quanto em experimentos para modelar a aleatoriedade e a incerteza de forma a estimar ou possibilitar a previsão de fenômenos futuros, conforme o caso.
Algumas práticas estatísticas incluem, por exemplo, o planejamento, a sumarização e a interpretação de observações. Dado que o objetivo da estatística é a produção da melhor informação possível a partir dos dados disponíveis, alguns autores sugerem que a estatística é um ramo da teoria da decisão.
Devido às suas raízes empíricas e seu foco em aplicações, a estatística geralmente é considerada uma disciplina distinta da matemática, e não um ramo dela.
A estatística é uma ciência que se dedica à coleta, análise e interpretação de dados. Preocupa-se com os métodos de recolha, organização, resumo, apresentação e interpretação dos dados, assim como tirar conclusões sobre as características das fontes donde estes foram retirados, para melhor compreender as situações.
O termo "estatística" surge da expressão em latim "statisticum collegium" palestra sobre os assuntos do Estado, de onde surgiu a palavra em língua italiana "statista", que significa "homem de estado", ou político, e a palavra alemã "Statistik", designando a análise de dados sobre o Estado. A palavra foi proposta pela primeira vez no século XVII, em latim, por Schmeitzel na Universidade de Jena e adotada pelo acadêmico alemão Godofredo Achenwall. Aparece como vocabulário na Enciclopédia Britânica em 1797, e adquiriu um significado de coleta e classificação de dados, no início do século XIX.
De acordo com a Revista do Instituto Internacional de Estatística, "Cinco homens, Hermann Conring, Gottfried Achenwall, Johann Peter Süssmilch, John Graunt e William Petty já receberam a honra de serem chamados de fundadores da estatística por diferentes autores."
Alguns autores dizem que é comum encontrar como marco inicial da estatística a publicação do "Observations on the Bills of Mortality" (Observações sobre os Censos de Mortalidade, 1662) de John Graunt. As primeiras aplicações do pensamento estatístico estavam voltadas para as necessidades de Estado, na formulação de políticas públicas, fornecendo dados demográficos e econômicos. A abrangência da estatística aumentou no começo do século XIX para incluir a acumulação e análise de dados de maneira geral. Hoje, a estatística é largamente aplicada nas ciências naturais, e sociais, inclusive na administração pública e privada.
Seus fundamentos matemáticos foram postos no século XVII com o desenvolvimento da teoria das probabilidades por Pascal e Fermat, que surgiu com o estudo dos jogos de azar. O método dos mínimos quadrados foi descrito pela primeira vez por Carl Friedrich Gauss cerca de 1794. O uso de computadores modernos tem permitido a computação de dados estatísticos em larga escala e também tornaram possível novos métodos antes impraticáveis.
Ligações para estatística observacional fenômeno são coletados pelos "fenômenos estatísticos".
A estatística não é uma ferramenta matemática que nos informa sobre o quanto de erro nossas observações apresentam sobre a realidade pesquisada. A estatística baseia-se na medição do erro que existe entre a estimativa de quanto uma amostra representa adequadamente a população da qual foi extraída. Assim o conhecimento de teoria de conjuntos, análise combinatória e cálculo são indispensáveis para compreender como o erro se comporta e a magnitude do mesmo. É o erro (erro amostral) que define a qualidade da observação e do delineamento experimental.
A faceta dessa ferramenta mais palpável é a "estatística descritiva". A descrição dos dados coletados é comumente apresentado em gráficos ou relatórios e serve tanto a prospecção de uma ou mais variáveis para posterior aplicação ou não de testes estatísticos bem como a apresentação de resultados de delineamentos experimentais.
Nós descrevemos o nosso conhecimento de forma matemática e tentamos aprender mais sobre aquilo que podemos observar. Isto requer:
Em algumas formas de estatística descritiva, nomeadamente mineração de dados ("data mining"), os segundo e terceiro passos tornam-se normalmente mais importantes que o primeiro.
A probabilidade de um evento é definida como um número entre zero e um.
Normalmente aproximamos a probabilidade de alguma coisa para cima ou para baixo porque elas são tão prováveis ou improváveis de ocorrer, que é fácil de reconhecê-las como probabilidade de um ou zero. Entretanto, isso pode levar a desentendimentos e comportamentos perigosos, porque é difícil distinguir entre, uma probabilidade de 10 e uma de 10, a despeito da grande diferença numérica entre elas. Por exemplo, se você espera atravessar uma estrada 10 ou 10 vezes na sua vida, definir o risco de atravessá-la em 10 significa que você está bem seguro pelo resto da sua vida. Entretanto, um risco de 10 significa que é bem provável que você tenha um acidente, mesmo que intuitivamente um risco de 0,01% pareça muito baixo.
O crescimento rápido e sustentados no poder de processamento dos computadores a partir da segunda metade do século XX teve um forte impacto na prática da estatística. Os modelos estatísticos mais antigos eram quase sempre lineares, mas os computadores modernos, junto com algoritmos numéricos apropriados, causaram um aumento do interesse nos modelos não-lineares (especialmente redes neurais e árvores de decisão) assim como na criação de novos tipos, como o modelo linear generalizado e o modelo multi-nível.
O aumento na capacidade de computação também tem levado à popularização de métodos que demandam muitos cálculos baseados em reamostragem (em inglês e no jargão do meio "resampling"), como testes de permutação e bootstrap, enquanto técnicas como a amostragem de Gibbs tem feito com que os métodos de Bayes fiquem mais fáceis. A revolução informática também tem levado a um aumento na ênfase na estatística "experimental" e "empírica". Um grande número de softwares estatísticos, de uso tanto geral como específico estão disponíveis no mercado.
Algumas ciências usam a estatística aplicada tão extensivamente que elas têm uma terminologia especializada. Estas disciplinas incluem:
Estatística forma uma ferramenta chave nos negócios e na industrialização como um todo. É utilizada a fim de entender sistemas variáveis, controle de processos (chamado de "controle estatístico de processo" ou CEP), custos financeiros (contábil) e de qualidade e para sumarização de dados e também tomada de decisão baseada em dados. Em nessas funções ela é uma ferramenta chave, e é a única ferramenta segura.

Escultura é uma arte que representa ou ilustra imagens plásticas em relevo total ou parcial. Existem várias técnicas de trabalhar os materiais, como a cinzelação, a fundição, a moldagem ou a aglomeração de partículas para a criação de um objeto.
Vários materiais se prestam a esta arte, uns mais perenes como o bronze ou o mármore, outros mais fáceis de trabalhar, como a argila, a cera ou a madeira.
Embora possam ser utilizadas para representar qualquer coisa, ou até coisa nenhuma, tradicionalmente o objetivo maior foi sempre representar o corpo humano, ou a divindade numa forma antropomórfica.
É considerada a quarta das artes clássicas.
Através da maior parte da história, permaneceram as obras dos artistas que utilizaram-se dos materiais mais perenes e duráveis possíveis como a pedra (mármore, pedra calcária, granito) ou metais (bronze, ouro, prata). Ou que usavam técnicas para melhorar a durabilidade de certos materiais (argila, terracota) ou que empregaram os materiais de origem orgânica mais nobres possíveis (madeiras duráveis como ébano, jacarandá, materiais como marfim ou âmbar). Mas de um modo geral, embora se possa esculpir em quase tudo que consiga manter por pelo menos algumas horas a forma idealizada (manteiga, gelo, cera, gesso, areia molhada), essas obras efêmeras não podem ser apreciadas por um público que não seja coevo.
A escolha de um material normalmente implica a técnica a se utilizar. A cinzelação, quando de um bloco de material se retira o que excede a figura utilizando ferramentas de corte próprias, para pedra ou madeira; a modelagem, quando se agrega material plástico até conseguir o efeito desejado, para cera ou argila; a fundição, quando se verte metal quente em um molde feito com outros materiais.
Modernamente, novas técnicas, como dobra e solda de chapas metálicas, moldagens com resinas, betão armado ou plásticos, ou mesmo a utilização da luz coerente para dar uma sensação de tridimensionalidade, tem sido tentadas e só o tempo dirá quais serão perenes.
Através do tempo, algumas formas especificas de esculturas foram mais utilizadas que outras: O busto, espécie de retrato do poderoso da época; a estátua eqüestre, tipicamente mostrando um poderoso senhor em seu cavalo; Fontes de água, especialmente em Roma, para coroar seus fabulosos aquedutos e onde a água corrente tinha um papel a representar; estátua, representando uma pessoa ou um deus em forma antropomórfica; Alto ou Baixo-relevo, o modo de ilustrar uma história em pedra ou metal ; mobiliário, normalmente utilizado em jardins.
As primeiras esculturas na Índia são atribuídas à civilização do vale do Indo, onde trabalhos em pedra e bronze foram descobertos, sendo uma das mais antigas esculturas do mundo. Mais tarde, com o desenvolvimento do hinduismo, do budismo, e do jansenismo, esta região produziu alguns dos mais intricados e elaborados bronzes. Alguns santuários, como o de Ellora, apresentam grandes estátuas esculpidas diretamente na rocha. Durante o século II a.C. no noroeste da Índia, onde hoje é o Paquistão e o Afeganistão, as esculturas começaram a representar passagens da vida e os ensinamentos de Buda. Embora a Índia tivesse uma longa tradição de esculturas religiosas, Buda nunca tinha sido representado na forma humana antes, apenas por símbolos. Este fato reflete já uma influencia artística persa e grega na região. A Índia influenciou ainda, através do budismo, boa parte da Ásia, como as existentes na localidade de Angkor, no Camboja.
Artefactos chineses datam do século X a.C., mas alguns períodos selecionados tiveram destaque: Dinastia Zhou (1050-771 a.C.) produziu alguns intrincados vasos em bronze fundido; Dinastia Han (206-220 a.C.) apresentou o espectacular "Exército de terracota" de Xian, em tamanho natural, defendendo a tumba do imperador; As primeiras esculturas de influencia budista aparecem no período dos "Três reinos" (século III) ; Dinastia Wei (séculos 5 e 6 ) nos da a escultura dos "Gigantes grotescos", reconhecidas por suas qualidades e elegância. O período considerado a idade de ouro da China é a Dinastia Tang, com suas esculturas budistas, algumas monumentais, considerados tesouros da arte mundial.
Após este período a qualidade da escultura chinesa caiu muito. É interessante notar que a arte chinesa não tem nus, como é comum na arte ocidental, à exceção de pequenas estátuas para uso dos médicos tradicionais. Também tem poucos retratos, exceto nos mosteiros, onde eram mais comuns. E nada do que se produziu após a Dinastia Ming ( após século XVII) foi reconhecido como bom pelos museus e colecionadores de arte. No século passado, a influencia do realismo socialista de origem soviética arruinou o que restava da arte chinesa. Espera-se que o ressurgimento e abertura para o mundo ocidental traga a arte chinesa ao seu lugar de mérito.
Os japoneses faziam muitas estátuas associadas a religião, a maioria sob patrocínio do governo. Notáveis foram as chamadas ‘’haniva’’, esculturas em argila colocadas sobre tumbas, no período ‘’Kofun’’. A imagem em madeira do século IX de ‘’Shakyamuni’’, um Buda histórico é a típica escultura da era ‘’Heian’’, com seu corpo curvado, coberto com um denso drapeado e com uma austera expressão facial. A escola Key criou um novo estilo, mais realista.
Existem poucos exemplares de esculturas pré-colombianas no continente americano, entre elas as famosas estátuas da Ilha de Páscoa, algumas esculturas, principalmente em alto-relevo, decorando edificações Maia e Asteca do Peru ao México e algumas peças primitivas em madeira ou argila, geralmente com significado religioso, dos povos nativos de toda América.
No restante, só se começou a produzir arte a partir do século XVI, já sob influência do Barroco, com destaque para imagens religiosas em madeira, terracota e pedra macia nos locais de influência católica. Nos países de religião protestante, por sua maior resistência ao uso religioso de imagens, foi mais tardio o aparecimento de artistas, entrando diretamente no Neoclássico por influência da cultura européia. A partir daí, com a facilidade de transporte e comunicações, a arte nas Américas ficou muito semelhante à desenvolvida na Europa.
A escultura popular em argila do Nordeste brasileiro, as obras em madeira e argila dos povos da Amazônia, figuras religiosas em todas as regiões católicas da América também possuem sua relevância no contexto atual.
A arte da África tem uma ênfase especial pela escultura, especialmente em ébano e outras madeiras nobres. Além das divindades antropomórficas, tem especial interesse as máscaras rituais. As esculturas mais antigas são da cultura Nok (cerca de 500 a. C.), no território onde atualmente se encontra a Nigéria.
A escultura no antigo Egito visava dar uma forma física aos deuses e seus representantes na terra, os faraós. Regras rígidas deviam ser seguidas: homens eram mais escuros que mulheres; as mãos de figuras sentadas deveriam estar nos joelhos; e cada deus tinha suas regras especificas de representação. Por esse motivo, poucas modificações ocorreram em mais de três mil anos, embora tivessem resultado em peças maravilhosas como a cabeça de Nefertiti ou a máscara mortuária de Tutancâmon.
A Grécia clássica é com certeza o berço ocidental da arte de esculpir, desde seus primeiros artefatos a partir do século X a.C., em mármore ou bronze, até o apogeu da era de Péricles (século V a.C.), com as esculturas da Acrópole de Atenas. Foi também quando alguns escultores começaram a receber reconhecimento individual, como Fídias. Produziu obras impares,como a Vitória de Samotrácia, os mármores de Elgin ou a Vénus de Milo.
A partir dos gregos, os romanos, depois de um começo na tradição etrusca, abraçaram a cultura clássica e continuaram a produzir esculturas até o fim do império, numa escala monumental e numa quantidade impressionante, espalhando principalmente o trabalho em mármore por todo o império.
Após o fim do império e a idade média, onde pouco se fez, tivemos algumas esculturas góticas (séculos 12 e13), basicamente como decoração de igrejas, como a porta da catedral de Chartres, arte fúnebre com suas tumbas elaboradas e as famosas gárgulas.
Tudo pareceu culminar no Renascimento, com mestres como Donatello e seu "Davi" em bronze, a estátua eqüestre do "Gattamelata" ou suas inúmeras esculturas em mármore, abrindo caminho para a obra maior de Michelangelo, com seu magnífico "David" em mármore, a Pietá, ou Moisés. Provavelmente o "David" de Florença seja a escultura mais famosa do mundo desde que foi revelada em 8 de setembro de 1504. É um exemplo do contrapposto, estilo de posicionar figuras humanas.
Quando Benvenuto Cellini criou um saleiro em ouro e ébano em 1540, mostrando Netuno e Anfitrite em formas alongadas e posições desconfortáveis, transformou o Naturalismo e criou a obra maior do Maneirismo que em sua forma mais exagerada virou o Barroco, que acrescenta elementos exteriores, como efeitos de iluminação. Bernini foi sem duvida o mais importante escultor desse período, com obras como O Êxtase de Santa Teresa.
Após os excessos do Barroco, o Neoclassicismo é uma volta ao modelo helenista clássico, antes dos anos confusos do Modernismo, que teve a magnífica obra em bronze do francês Auguste Rodin e seu "O Pensador", e depois enterrou a tradição clássica com o Cubismo, o Futurismo, o Minimalismo, as Instalações e a Pop Art.
Algumas das obras de escultura mais famosas são:


Euclides de Alexandria ( "Eukleidēs"; "fl." "c." 300 AC) foi um professor, matemático platónico e escritor possivelmente grego, muitas vezes referido como o "Pai da Geometria". Além de sua principal obra, Os Elementos, Euclides também escreveu sobre perspectivas, seções cônicas, geometria esférica, teoria dos números e rigor.
A geometria euclidiana é caracterizada pelo espaço euclidiano, imutável, simétrico e geométrico, metáfora do saber na antiguidade clássica e que se manteve incólume no pensamento matemático medieval e renascentista, pois somente nos tempos modernos puderam ser construídos modelos de geometrias não-euclidianas.
Euclides é a versão portuguesa da palavra grega Εὐκλείδης, que significa "Boa Glória".
Pouco se sabe sobre a vida de Euclides pois há apenas poucas referências fundamentais a ele, tendo sido escritas séculos depois que ele viveu, por Proclo e Pappus de Alexandria. Proclo apresenta Euclides apenas brevemente no seu "Comentário sobre os Elementos", escrito no século V, onde escreve que Euclides foi o autor de "Os Elementos", que foi mencionado por Arquimedes e que, quando Ptolomeu I perguntou a Euclides se não havia caminho mais curto para a geometria que "Os Elementos", ele respondeu: "não há estrada real para a geometria". Embora a suposta citação de Euclides por Arquimedes foi considerada uma interpolação por editores posteriores de suas obras, ainda se acredita que Euclides escreveu suas obras antes das de Arquimedes. Além disso, a anedota sobre a "estrada real" é questionável, uma vez que é semelhante a uma história contada sobre Menecmo e Alexandre, o Grande. Na outra única referência fundamental sobre Euclides, Pappus mencionou brevemente no século IV que Apolônio "passou muito tempo com os alunos de Euclides em Alexandria, e foi assim que ele adquiriu um hábito de pensamento tão científico". Também se acredita que Euclides pode ter estudado na Academia de Platão, na Grécia.
As datas de nascimento (inclusive o local) e morte (inclusive suas circunstâncias) de Euclides são desconhecidas e estimadas pela comparação com as figuras contemporâneas mencionadas nas referências. Nenhuma imagem ou descrição da aparência física de Euclides foi feita durante sua vida portanto as representações de Euclides em obras de arte são o produtos da imaginação artística.
Convidado por Ptolomeu I para compor o quadro de professores da recém fundada Academia, que tornaria Alexandria o centro do saber da época, tornou-se o mais importante autor de matemática da Antiguidade greco-romana e talvez de todos os tempos, com seu monumental "Stoichia" ("Os elementos", "c." 300 a.C.).
Depois da queda do Império Romano, os seus livros foram recuperados para a sociedade européia pelos estudiosos muçulmanos da Península Ibérica. Escreveu ainda "Optica" (295 a.C.), sobre a óptica da visão e sobre astrologia, astronomia, música e mecânica, além de outros livros sobre matemática. Entre eles citam-se "Lugares de superfície", "Pseudaria", "Porismas" e mais algumas outras.
Algumas das suas obras como "Os elementos", "Os dados" (uma espécie de manual de tabelas de uso interno na Academia e complemento dos seis primeiros volumes de Os Elementos), "Divisão de figuras" (sobre a divisão geométrica de figuras planas), "Os Fenômenos" (sobre astronomia), e "Óptica" (sobre a visão), sobreviveram parcialmente e hoje são, depois de "A Esfera" de Autólico, os mais antigos tratados científicos gregos existentes. Pela sua maneira de expor nos escritos deduz-se que tenha sido um habilíssimo professor.
A obra Os Elementos, atribuída a Euclides, é uma das mais influentes na história da matemática, servindo como o principal livro para o ensino de matemática (especialmente geometria) desde a data da sua publicação até o fim do século XIX ou início do século XX. Nessa obra, os princípios do que é hoje chamado de geometria euclidiana foram deduzidos a partir de um pequeno conjunto de axiomas.
A obra composta por treze volumes, sendo:
Escrita em grego, a obra cobre toda a aritmética, a álgebra e a geometria conhecidas até então no mundo grego, reunindo o trabalho de predecessores de Euclides, como Hipócrates e Eudóxio. Sistematizou todo o conhecimento geométrico dos antigos, intercalando os teoremas já então conhecidos com a demonstração de muitos outros, que completavam lacunas e davam coerência e encadeamento lógico ao sistema por ele criado. Após sua primeira edição foi copiado e recopiado inúmeras vezes, tendo sido traduzido para o árabe em (774). A obra possui mais de mil edições desde o advento da imprensa, sendo a sua primeira versão impressa datada de 1482 (Veneza, Itália). Essa edição foi uma tradução do árabe para o latim. Tem sido − segundo George Simmons − “considerado como responsável por uma influência sobre a mente humana maior que qualquer outro livro, com exceção da Bíblia".
Embora muitos dos resultados descritos em "Os Elementos" originarem-se em matemáticos anteriores, uma das reconhecidas habilidades de Euclides foi apresentá-los em uma única estrutura logicamente coerente, tornando-a de fácil uso e referência, incluindo um sistema rigoroso de provas matemáticas que continua a ser a base da matemática 23 séculos mais tarde.
Não há menção de Euclides nas primeiras cópias ainda remanescentes de "Os Elementos", e a maioria das cópias dizem que são "a partir da edição de Teão" ou as "palestras de Teão", enquanto o texto considerado primário, guardado pelo Vaticano, não menciona qualquer autor. A única referência que os historiadores se baseiam para Euclides ter escrito "Os Elementos" veio de Proclo, que brevemente em seu "Comentário sobre Os Elementos" atribui Euclides como o seu autor. Euclides foi a peça chave em toda a história da Geometria.
Os estudos de Euclides sobre a geometria da visão foi a primeira elaboração em torno da atualmente denominada óptica geométrica.
Diferentemente das análises filosóficas e de suas suposições físicas sobre a natureza da visão, as quais eram isentas de qualquer consideração geométrica, a óptica de Euclides fundamentou-se na análise geométrica da visão e, à primeira vista, parece desprovida de qualquer consideração física acerca da operação da visão. Noções como a cor, a luz ou o transparente, a forma sensível, a luz solar, a natureza do olho e a estrutura física dos órgãos sensoriais envolvidos na visão estão excluídas da óptica de Euclides, uma vez que essas entidades não poderiam ser geometricamente analisáveis ou melhor não poderiam ser tratadas pela sua geometria.
A análise geométrica da visão elaborada por Euclides supõe uma teoria física mínima acerca da operação da visão e funda-se na redução da visão a um modelo geométrico, no qual o campo visual é tomado como uma coleção, ou agregado, de “raios visuais” concebidos como linhas retas geométricas discretas e divergentes, as quais aparecem como o último termo da análise. Essa coleção de linhas retas “visuais” divergentes, em cuja origem encontra-se o olho, assume a forma de um cone geométrico, conhecido na tradição como “cone visual”, em cuja base encontra-se a figura daquilo que é visto, isto é, a superfície interceptada pelo feixe divergente de linhas retas visuais – entidades estas que possuem uma natureza híbrida, geométrico-sensível.
O que aparece ao olho é determinado como uma função das propriedades e relações geométricas que são derivadas dessa construção, a qual, ao reduzir o cone visual a uma projeção plana que resulta em triângulos definidos por um vértice situado no olho e por dois raios visuais que unem as extremidades daquilo que é visto, permite calcular a aparência do tamanho, da figura e do movimento daquilo que é visto. Essa construção da estrutura geométrica do “cone visual” é delineada por Euclides quando postula que o aspecto retilíneo dos raios visuais, o cone visual constituído pela divergência desses raios visuais discretos e a condição geral da visibilidade ou seja, que para ser visto, um objeto deve ser interceptado pela radiação ocular.
 

Eusebiozinho é uma personagem do romance "Os Maias", de Eça de Queirós. Eça faz a caricatura do pequeno Eusébio através do uso expressivo do adjectivo, do verbo, de figura de estilo. E usa o diminutivo para minorar (com ironia) o personagem.
Representa a educação retrógrada portuguesa, habitualmente conhecido por Silveirinha, devido a ser o primogénito de uma das Silveiras, Eugénia Silveira, senhoras ricas e beatas. Amigo de infância de Carlos da Maia com quem brincava em Santa Olávia, levando pancada continuamente, e com quem contrastava na educação. Desde cedo se interessou pelos algarismos e letras, mas quando cresceu, rapidamente os esqueceu. Para além disso, também cresceu tísico, molengão, tristonho e corrupto. Casou-se na Régua, mas enviuvou cedo, por isso procurava, para se distrair, bordéis ou aventureiras de ocasião pagas à hora. 

Edwin O’Neill Willis (Russellville, — Rio Claro, ) foi um ornitólogo estadunidense. Estudou e pesquisou aves nos Estados Unidos, Panamá, Colômbia, Peru, na Amazônia e em todo o Brasil. Ele foi um dos mais destacados cientistas da ornitologia brasileira.
Edwin Willis se graduou em biologia no Instituto Politécnico da Virgínia em 1956 e em 1958 concluiu mestrado em zoologia na Universidade do Estado da Louisiana. Seu doutorado em zoologia na Universidade da Califórnia de Berkeley foi obtido em 1964. Depois ele fez pós-doutorado no Museu Americano de História Natural, em 1966.
Passou a residir no Brasil, onde lecionou na Unicamp e casou-se com a também ornitóloga Yoshika Oniki, com quem ele publicou em 2003 o livro "Aves do estado de São Paulo", em que descrevem todas as espécies de aves do estado de São Paulo e apresentam pranchas coloridas de cada ave feitas por Tomas Sigrist. Também foi co-autor junto com sua esposa, do livro "Bibliography of Brazilian Birds": "1500-2002", em relacionam todas as obras sobre aves do Brasil publicadas ao longo de cinco séculos.
Willis era professor titular da Universidade Estadual Paulista Júlio de Mesquita Filho e se aposentou em 2005. Tinha grande experiência na área de zoologia, especialmente comportamento animal. Ele atuava principalmente nos temas thamnophilidae, dendrocolaptidae, comportamento, ecologia e formigas de correição. Sua extensa obra expandiu o conhecimento científico sobre a ecologia de inúmeras aves dos neotrópicos.
"Willisornis" é um gênero de ave da família Thamnophilidae que homenageia Edwin Willis.

A conjunção é uma operação na lógica matemática, que pode ser ligada à operação de interseção de conjuntos. A conjunção é representada pelo conectivo lógico ∧, e em programação por AND ou &&.
A conjunção lógica pode ainda ser representada pelo símbolo do produto.
Em lógica binária, ocorrem apenas dois estados:
A conjunção é uma operação que verifica a seguinte tabela de verdade: 
ou de forma equivalente
Portanto pode ainda ser representada pela multiplicação, que dá o mesmo resultado, se a e b forem 0 ou 1.
Outra interpretação é a da lógica fuzzy, que generaliza pela equivalência com o mínimo(a,b).
A operação de conjunção lógica está ainda relacionada com a interseção de conjuntos. 
Um elemento está na intersecção dos conjuntos apenas se for verdade que está em ambos.
Segue a representação dessa operação no diagrama de Venn.
A operação lógica da conjunção funciona da mesma forma que a conjunção semântica e. 
Suponham-se duas frases quaisquer:
A conjunção só é verdadeira se ambas as frases forem. Se não estiver chovendo, a conjunção é falsa (se não estiver dentro de casa, também).
Convém notar que na linguagem vulgar a conjunção "e" pode ter um significado aditivo, não relacionado com o significado lógico.
A conjunção relaciona dois valores, mas usando o seu resultado podem ser feitas operações com mais valores.
Com uma tabela de verdade pode demonstrar-se a propriedade associativa 
e portanto neste caso basta escrever 
sem necessidade de parentesis, já que o resultado é o mesmo.
A conjunção lógica tem diversas propriedades. Destacam-se:

Na biologia, Evolução (também conhecida como evolução biológica, genética ou orgânica) é a mudança das características hereditárias de uma população de seres vivos de uma geração para outra. Este processo faz com que as populações de organismos mudem e se diversifiquem ao longo do tempo. O termo "evolução" pode referir-se à evidência observacional que constitui o fato científico intrínseco à teoria da evolução biológica, ou, em acepção completa, à teoria em sua completude. Uma teoria científica é por definição um conjunto indissociável de todas as evidências verificáveis conhecidas e das ideias testáveis e testadas àquelas atreladas.
Do ponto de vista genético, a evolução pode ser definida como qualquer alteração no número de genes ou na frequência dos alelos de um ou um conjunto de genes em uma população e ao longo das gerações. Mutações em genes podem produzir características novas ou alterar as que já existiam, resultando no aparecimento de diferenças hereditárias entre organismos. Estas novas características também podem surgir pela transferência de genes entre populações, como resultado de migração, ou entre espécies, resultante de transferência horizontal de genes. A evolução ocorre quando estas diferenças hereditárias tornam-se mais comuns ou raras numa população, quer de maneira não-aleatória, através de seleção natural, ou aleatoriamente, através de deriva genética.
A seleção natural é um processo pelo qual características hereditárias que contribuem para a sobrevivência e a reprodução se tornam mais comuns numa população, enquanto que características prejudiciais tornam-se mais raras. Isto ocorre porque indivíduos com características vantajosas tem mais sucesso na reprodução, de modo que mais indivíduos na próxima geração herdem tais características. Ao longo de muitas gerações, adaptações ocorrem através de uma combinação de mudanças sucessivas, pequenas e aleatórias nas características, mas significativas em conjunto, em virtude da seleção natural dos variantes mais adequados - adaptados - ao seu ambiente. Em contraste, a deriva genética produz mudanças aleatórias na frequência das características numa população. A deriva genética reflete o papel que o acaso desempenha na probabilidade de um determinado indivíduo sobreviver e reproduzir-se. Na década de 1930, a seleção natural darwiniana foi combinada com a hereditariedade mendeliana em uma síntese moderna, onde foi feita a ligação entre as "unidades" de evolução - os genes - e o "mecanismo" central de evolução - fundado na deriva genética e seleção natural. Tal teoria, denominada Síntese Evolutiva Moderna e detentora de um grande poder preditivo e explanatório, por oferecer uma unificadora e inigualável explicação natural para toda a diversidade da vida na Terra, tornou-se o pilar central da biologia moderna .
Uma espécie pode ser definida como o agrupamento dos espécimes capazes de compartilhar material genético - usualmente por via sexuada - a fim de reproduzirem-se gerando descendência fértil. No entanto, quando uma espécie é separada em várias populações que por algum motivo não mais se possam cruzar, mecanismos como mutações, deriva genética e a selecção de características novas provocam a acumulação de diferenças ao longo de gerações, diferenças que, acumuladas, podem implicar desde curiosidades biológicas como os denominados anéis de espécies até a emergência de espécies novas e distintas. As semelhanças entre organismos sugere que todas as espécies conhecidas descenderam de um ancestral comum (ou "pool" genético ancestral) através deste processo de divergência gradual.
Estudos do registro fóssil permitem reconstruir de forma satisfatória e precisa o processo de evolução da vida na Terra, desde os primeiros registros de sua presença no planeta - que datam de 3,4 mil milhões de anos atrás - até hoje . Tais fósseis, juntamente com o reconhecimento da fabulosa diversidade de seres vivos atrelada - a grande maioria hoje extinta - já em meados do século dezenove mostravam aos cientistas que as espécies encontram-se cronologicamente relacionadas, e que essas mudam ao longo do tempo. Contudo, os mecanismos que levaram a estas mudanças permaneceram pouco claros até o reconhecimento científico de que o próprio planeta tem uma história geológica muito rica - implicando mudanças ambientais constantes - e até a publicação do livro de Charles Darwin - "A Origem das Espécies" - detalhando a teoria de evolução por selecção natural. O trabalho de Darwin levou rapidamente à aceitação da evolução pela comunidade científica.
A herança em organismos ocorre por meio de caracteres discretos – características particulares de um organismo. Em seres humanos, por exemplo, a cor dos olhos é uma característica herdada dos pais. As características herdadas são controladas por genes e o conjunto de todos os genes no genoma de um organismo é o seu genótipo.
O conjunto das características observáveis que compõem a estrutura e o comportamento de um organismo é denominado o seu fenótipo. Estas características surgem da interação do genótipo com o ambiente. Desta forma, não são todos os aspectos de um organismo que são herdados. O bronzeamento da pele resulta da interação entre o genótipo de uma pessoa e a luz do sol; assim, um bronzeado não é hereditário. No entanto, as pessoas têm diferentes respostas à radiação solar, resultantes de diferenças no seu genótipo; um exemplo extremo são os indivíduos com a característica hereditária do albinismo, que não se bronzeiam e são altamente sensíveis a queimaduras de sol, devido à inexistência do pigmento melanina na pele.
Os genes são regiões nas moléculas de ácido desoxirribonucleico (DNA) que contêm informação genética. O DNA é uma molécula comprida com quatro tipos de bases ligadas umas às outras. Genes diferentes apresentam uma sequência diferente de bases; é a sequência destas bases que codifica a informação genética. Dentro das células, as longas cadeias de DNA estão associadas com proteínas formando estruturas chamadas cromossomas. Um local específico dentro de um cromossoma é conhecido como locus. Uma vez que normalmente existem duas cópias do mesmo cromossoma no genoma, os locus correspondentes em cada um destes (cuja sequência de DNA pode ser igual ou diferente) são denominados alelos. As sequências de DNA podem mudar através de mutações, produzindo novos alelos. Se uma mutação ocorrer dentro de um gene, o novo alelo pode afectar a característica que o gene controla, alterando o fenótipo de um organismo. No entanto, enquanto que esta simples correspondência entre alelo e uma característica funciona em alguns casos, a maioria das características são mais complexas e são controladas por múltiplos genes que interagem uns com os outros.
Como o fenótipo de um indivíduo resulta da interação de seu genótipo com o ambiente, a variação nos fenótipos de uma população reflete, em certa medida, a variação nos genótipos dos indivíduos. A síntese evolutiva moderna define evolução como a mudança nas frequências gênicas ao longo do tempo, ou seja, a flutuação na frequência de um ou mais alelos, se tornando mais ou menos prevalecente relativamente a outras formas do mesmo gene. Forças evolutivas atuam direcionando essa mudança de diferentes formas. A variação em determinado locus desaparece quando algum alelo se fixa na população, ou seja, quando um mesmo alelo passa a estar presente em todos os indivíduos.
A origem de toda a variação genética são mutações no material genético. Essa variação pode ser reorganizada por meio da reprodução sexuada, e distribuída entre populações por meio de migração. A variação também pode vir de trocas de genes entre espécies diferentes, como por exemplo na transferência horizontal de genes em bactérias, e hibridização, principalmente em plantas. Apesar da constante introdução de variação por meio desses processos, a maior parte do genoma de uma espécie é idêntica em todos os indivíduos. No entanto, até mesmo relativamente poucas mudanças no genótipo podem levar a mudanças dramáticas no fenótipo: chimpanzés e humanos possuem apenas cerca de 5% de diferença em seu genoma.
A variação genética se origina de mutações aleatórias que ocorrem no genoma dos organismos. Mutações são mudanças na sequência dos nucleotídeos do genoma de uma célula, sendo causadas por radiação, vírus, transposons e substâncias químicas mutagênicas, assim como erros que ocorrem durante a meiose ou replicação do DNA. Esses agentes produzem diversos tipos de mudança nas sequências de DNA, que podem ser sem efeito, podem alterar o produto de um gene, ou alterar o quanto um gene é produzido. Estudos com a mosca-das-frutas, "Drosophila melanogaster", apontam que cerca de 70% das mutações são deletérias (prejudiciais), sendo as restantes neutras (sem efeito) ou com pequeno efeito benéfico. Devido aos efeitos danosos das mutações sobre o funcionamento das células, os organismos desenvolveram ao longo do tempo evolutivo mecanismos responsáveis pelo reparo do DNA para remover mutações. Assim, a taxa ótima de mutação é resultado do balanço entre as demandas conflitantes de reduzir danos a curto prazo, como risco de câncer, e aumentar os benefícios a longo prazo de mutações vantajosas.
Grandes porções de DNA também podem ser duplicadas, fenômeno que funciona como fonte de material para a evolução de novos genes, sendo estimado que dezenas a centenas de genes são duplicados nos genomas de animais a cada milhão de anos. A grande maioria dos genes pertence a famílias de genes homólogos, que partilham um ancestral comum, de forma semelhante ao que ocorre com linhagens de espécies. Novos genes podem ser produzidos tanto por duplicação e mutação de um gene ancestral como por recombinação de partes de genes diferentes para formar novas combinações com funções distintas. Por exemplo, quatro dos genes utilizados no olho humano para a produção de estruturas responsáveis pela percepção de luz, derivam de um ancestral comum, sendo que três desses genes atuam na visão em cores e um na visão noturna. Uma vantagem na duplicação de genes (ou mesmo de genomas inteiros por poliploidia) é que sobreposição ou redundância funcional em vários genes pode permitir que alelos que seriam deletérios sem essa redundância sejam mantidos na população, aumentando assim a diversidade genética.
Mudanças em número de cromossomos também podem envolver a quebra e rearranjo de DNA entre cromossomos. Por exemplo, no gênero "Homo", dois cromossomos se fundiram, formando o cromossomo 2 humano. Essa fusão não ocorreu na linhagem dos outros grandes primatas (orangotango, chimpanzé, e gorila), e eles mantêm esses cromossomos separados. O papel mais importante desse tipo de rearranjo dos cromossomos na evolução pode ser o de acelerar a divergência de uma população em novas espécies, por meio de uma redução na chance de cruzamento entre as populações, preservando as diferenças genéticas entre elas.
Sequências de DNA que têm a capacidade de se mover pelo genoma, como transposons, constituem uma fração significativa do material genético de plantas e animais, e podem ter sido importantes na evolução de genomas. Por exemplo, mais de um milhão de cópias de um padrão denominado sequência Alu estão presentes no genoma humano, e tem sido demonstrado que essas sequências podem desempenhar um papel da regulação da expressão gênica. Outro efeito dessas sequências de DNA é que, ao se moverem dentro do genoma, elas podem mudar ou deletar genes existentes, gerando assim diversidade genética.
Em organismos de reprodução assexuada, os genes são herdados todos juntos, ou ligados, dado que eles não podem se misturar com genes de outros organismos durante a reprodução. Por outro lado, a prole de organismos sexuados contêm uma mistura aleatória dos cromossomos de seus pais, produzida por meio da segregação independente durante a meiose. No processo relacionado de recombinação gênica, organismos sexuados também podem trocar DNA entre cromossomos homólogos. Esses processos de embaralhamento podem permitir que mesmo alelos próximos numa cadeia de DNA segreguem independentemente. No entanto, como ocorre cerca de um evento de recombinação para cada milhão de pares de bases em humanos, genes próximos num cromossomo geralmente não são separados, e tendem a ser herdados juntos. Essa tendência é medida encontrando-se com qual frequência dois alelos ocorrem juntos, medida chamada de desequilíbrio de ligação. Um conjunto de alelos que geralmente é herdado em grupo é chamado de haplótipo, e essa co-herança pode indicar que o locus está sob seleção positiva (veja abaixo).
A recombinação em organismos sexuados ajuda a remover mutações deletérias e manter mutações benéficas. Consequentemente, quando alelos não podem ser separados por recombinação - como no cromossomo Y humano, que passa intacto de pais para filhos - mutações deletérias se acumulam. Além disso, a recombinação pode produzir indivíduos com combinações de genes novas e vantajosas. Esses efeitos positivos da recombinação são balanceados pelo fato de que esse processo pode causar mutações e separar combinações benéficas de genes. A taxa ótima de recombinação para uma espécie é, portanto, o resultado do balanço entre essas demandas conflitantes.
A transferência horizontal de genes é um processo pelo qual um organismo transfere material genético para outra célula que não a sua prole, em contraste à transferência vertical em que um organismo recebe material genético de seu ancestral. A maior parte do pensamento em genética tem se focado na transferência vertical, mas recentemente a transferência horizontal tem recebido maior atenção.
De um ponto de vista genético, evolução é uma "mudança de uma geração para a outra nas frequências de alelos de uma população que compartilha um conjunto de genes". Uma população é um grupo de indivíduos pertencentes a determinada espécie e que ocupa um espaço delimitado. Por exemplo, todas as mariposas da mesma espécie que vivem numa floresta isolada representam uma população. Um determinado gene nessa população pode ter diversas formas alternativas, que respondem por variações entre os fenótipos dos organismos. Um exemplo pode ser um gene para coloração em mariposas que tenha dois alelos: preto e branco. O conjunto de todos os genes presentes em todos os organismos de uma determinada população é conhecido como fundo genético, onde cada alelo ocorre várias vezes. A fração de genes dentro desse conjunto que é um alelo em particular é uma quantidade denominada frequência alélica, ou frequência genética. A evolução ocorre quando há mudanças nas frequências de alelos de uma população de organismos intercruzantes. Por exemplo, quando o alelo para a cor preta se torna mais comum numa população de mariposas.
Para entender os mecanismos que fazem com que uma população evolua, é útil considerar quais as condições necessárias para que a população não evolua. Segundo o princípio de "Hardy-Weinberg", as frequências de alelos numa população suficientemente grande irá se manter constante apenas se as únicas forças atuando na população forem a recombinação aleatória dos alelos na formação dos gametas e a combinação aleatória dos alelos nessas células sexuais durante a fecundação. Uma população em que as frequências dos alelos é constante "não" está evoluindo: a população está em "Equilíbrio de Hardy-Weinberg".
Há três mecanismos básicos de mudanças evolutivas: selecção natural, deriva genética e fluxo génico. A selecção natural favorece genes que melhoram a capacidade para a sobrevivência e reprodução. A deriva genética é mudança aleatória na frequência de alelos, causada pela amostragem aleatória dos genes de uma geração durante a reprodução, e o fluxo génico é a transferência de genes entre (e dentro de) populações. A importância relativa da selecção natural e deriva genética numa população varia conforme a intensidade da selecção e do efectivo populacional, que é o número de indivíduos capazes de se reproduzir. A seleção natural costuma predominar em grandes populações. A predominância de derivação genética em pequenas populações é capaz até mesmo de levar a fixação de suaves mutações deletérias. Como resultado, mudanças no tamanho da população podem influenciar dramaticamente o rumo da evolução. Os efeitos de gargalo, onde a população encolhe temporariamente e portanto perde variação genética, resultam numa população mais uniforme. Efeitos de gargalo surgem também de alterações no fluxo génico tais como uma diminuição da migração, expansões para outros habitats ou subdivisão populacional.
Selecção natural é o processo pelo qual mutações genéticas que melhoram a reprodução tornam-se, ou permanecem, mais comuns em gerações sucessivas de uma população. Este mecanismo tem sido muitas vezes chamado de "autoevidente" porque segue forçosamente a partir de três simples factos:
Estas condições geram competição entre organismos para a sua sobrevivência e reprodução. Por isso, organismos com características que lhes trazem alguma vantagem sobre os seus competidores transmitem estas características vantajosas, enquanto que características que não conferem nenhuma vantagem não são passadas para a geração seguinte.
O conceito central da selecção natural é a aptidão evolutiva de um organismo. Isto mede a contribuição genética de um organismo para a geração seguinte. Contudo, não é o mesmo que o número total de descendentes: a aptidão mede a proporção de gerações subsequentes que carregam os genes de um organismo. Por consequência, se um alelo aumenta a aptidão mais do que outros alelos do mesmo gene, então em cada geração esse alelo tornar-se-á mais comum dentro da população. Diz-se que estas características são "seleccionadas "a favor"" ou "positivamente". Exemplos de características que podem aumentar a aptidão são sobrevivência melhorada e aumento da fecundidade. Pelo contrário, aptidão mais baixa causada por ter um alelo menos beneficial resulta na diminuição da frequência deste alelo; são "seleccionados "contra"" ou "negativamente". É importante notar que a aptidão de um alelo não é uma característica fixa. Se o ambiente muda, características que previamente eram neutras ou prejudiciais podem tornar-se benéficas ou vice-versa.
Selecção natural dentro de uma população, de uma característica que pode variar dentro de uma gama de valores, tal como a altura, pode ser categorizada em três tipos diferentes. A primeira é selecção direccional, que é um desvio do valor médio de uma característica ao longo do tempo - por exemplo, certos organismos que vão lentamente ficando mais altos de geração para geração. A segunda é selecção disruptiva, que é a selecção a favor de valores extremos das características e resulta frequentemente em que dois valores diferentes se tornem mais comuns, com selecção contra valores médios. Isto aconteceria quando quer indivíduos altos ou baixos têm certa vantagem, mas não os que têm altura média. Por último, existe selecção estabilizadora em que há selecção contra valores extremos das características em ambos os lados do espectro, o que causa uma diminuição da variância à volta do valor médio. Isto provocaria, usando o mesmo exemplo, que os organismos se fossem tornando todos da mesma altura.
Um caso especial de selecção natural é selecção sexual, que é selecção sobre qualquer característica que aumente o sucesso reprodutor, incrementando a capacidade de atracção de um organismo a potenciais parceiros. As características que evoluíram através de selecção sexual são particularmente proeminentes em machos de algumas espécies animais, apesar de algumas características como hastes muito elaboradas, chamamentos ou cores vivas poderem atrair predadores, diminuindo por isso a sobrevivência desses machos. Esta desvantagem é compensada pelo maior sucesso reprodutivo em machos que apresentam estas características seleccionadas sexualmente.
Uma área de pesquisa activa actualmente refere-se à unidade de selecção, com propostas de que a selecção natural actua no nível dos genes, células, indivíduos, populações ou mesmo espécies. Nenhum destes modelos são mutuamente exclusivos e a selecção pode actuar em vários níveis simultaneamente. Abaixo do nível do indivíduo, genes chamados transposões tentam copiar-se a si próprios ao longo do genoma. Selecção acima do nível do indivíduo, tal como selecção de grupo, pode permitir a evolução de cooperação, como discutido mais abaixo.
Deriva genética é a mudança na frequência alélica de uma geração para a outra que acontece porque os alelos nos descendentes são amostras aleatórias dos presentes nos progenitores. Em termos matemáticos, os alelos estão sujeitos a erros de amostragem. Como resultado disto, quando forças selectivas estão ausentes ou são relativamente fracas, frequências alélicas tendem a "andar à deriva" para cima ou para baixo ao acaso (numa caminhada aleatória). Esta deriva termina quando um alelo eventualmente fique fixado, quer por desaparecer da população, ou por substituir completamente todos os outros alelos. A deriva genética pode assim eliminar alguns alelos de uma população meramente devido ao acaso, e duas populações separadas que começaram com a mesma estrutura genética podem divergir para duas populações com um conjunto diferente de alelos.
O tempo necessário para que um alelo se fixe por deriva genética depende do tamanho da população, com a fixação acontecendo mais rapidamente em populações mais pequenas. A medida mais importante para este caso é o efectivo populacional, que foi definido por Sewall Wright como o número teórico que representa o número de indivíduos reprodutores que exibem o mesmo grau de consanguinidade.
Apesar da selecção natural ser responsável pela adaptação, a importância relativas das duas forças, selecção natural e deriva genética, como motores de mudança evolutiva em geral, é uma área de pesquisa actual em biologia evolutiva. Estas investigações foram despoletadas pela teoria neutral da evolução molecular, que propôs que a maioria das mudanças evolutivas resultam da fixação de mutações neutrais que não têm efeitos imediatos na aptidão de um organismo. Daí que, neste modelo, a maioria das mudanças genética resulte da constante pressão mutacional e deriva genética.
Fluxo génico é a troca de genes entre populações, que são normalmente da mesma espécie. Exemplos de fluxo génico entre espécies incluem a migração seguido de cruzamento de organismos, ou a troca de pólen. A transferência de genes entre espécies inclui a formação de híbridos e transferência lateral de genes.
Migração para dentro ou para fora de uma população pode mudar as frequências alélicas. Imigração pode adicionar material genético novo para o pool genético já estabelecido de uma população. Por outro lado, emigração pode remover material genético. Barreiras à reprodução são necessárias para que as populações se tornem em novas espécies, sendo que o fluxo génico pode travar este processo, espalhando as diferenças genéticas entre as populações. Fluxo génico é impedido por barreiras como cadeias montanhosas, oceanos ou desertos ou mesmo por estruturas artificiais como a Grande Muralha da China, que tem prejudicado o fluxo de genes de plantas.
Dependendo de quanto é que duas espécies divergiram desde o seu ancestral comum mais recente, pode ainda ser possível que produzam descendência, tais como é exemplificado pelo cruzamento entre cavalos e burros, produzindo mulas. Tais híbridos são geralmente inférteis, devido à impossibilidade dos dois conjuntos de cromossomas se emparelharem durante a meiose. Neste caso, espécies próximas são capazes de se cruzar regularmente, mas os híbridos serão seleccionados contra e as espécies permanecerão separadas. Contudo, híbridos viáveis podem formar-se ocasionalmente e mesmo formar novas espécies. Estas novas espécies podem ter propriedades intermédias entre as espécies parentais ou possuir fenótipos totalmente novos. A importância da hibridização no processo de criação de novas espécies de animais não é clara, apesar de haver alguns casos conhecidos em muitos tipos de animais, sendo a espécie "Hyla versicolor" um exemplo particularmente bem estudado.
No entanto, a hibridação é um importante meio de especiação em plantas, uma vez que a poliploidia (ter mais do que duas cópias de cada cromossoma) é tolerada em plantas mais prontamente do que em animais. A poliploidia é importante em híbridos porque permite a reprodução, com cada um dos conjuntos de cromossomas capaz de emparelhar com um par idêntico durante a meiose. Os poliplóides também têm mais diversidade genética, o que permite que evitem depressão de consanguinidade em populações pequenas.
A transferência génica horizontal é a transferência de material genético de um organismo para outro que não é seu descendente. Isto é mais comum em bactérias. Em medicina, isto contribui para a disseminação de resistência a antibióticos, porque assim que uma bactéria adquire genes de resistência eles podem-se transferir rapidamente para outras espécies. Também é possível que tenha ocorrido transferência horizontal de genes de bactérias para eucariontes como a levedura "Saccharomyces cerevisiae" e para o escaravelho "Callosobruchus chinensis", por exemplo. Os vírus também podem transportar DNA entre organismos, permitindo a transferência de genes mesmo entre domínios. A transferência de genes também ocorreu entre os ancestrais das células eucarióticas e procariontes, durante a aquisição do cloroplasto e da mitocôndria.
A evolução influencia cada aspecto da estrutura e comportamento dos organismos. O mais proeminente é o conjunto de adaptações físicas e comportamentais que resultam do processo de seleção natural. Essas adaptações aumentam a aptidão por contribuírem com atividades como busca por alimento, defesa contra predadores ou atração de parceiros sexuais. Outro resultado possível da seleção é o surgimento de cooperação entre organismos, evidenciada geralmente no auxílio a organismos aparentados, ou em interações mutualísticas ou simbióticas. A longo prazo, a evolução produz novas espécies, por meio da divisão de populações ancestrais entre novos grupos que se tornam incapazes de intercruzarem.
Essas consequências da evolução são comummente divididas entre macroevolução, que é a evolução que ocorre acima do nível de espécies, e trata de fenómenos como a especiação, e microevolução, que trata das mudanças evolutivas que ocorrem dentro de uma espécie, como a adaptação a um ambiente específico por determinada população. Em geral, macroevolução é o resultado de longos períodos de microevolução. Assim, a distinção entre micro e macroevolução não é absoluta, havendo apenas uma diferença de tempo entre os dois processos. No entanto, na macroevolução, as características de toda a espécie é que são consideradas. Por exemplo, uma grande quantidade de variação entre indivíduos permite que uma espécie se adapte rapidamente a novos habitats, diminuindo as possibilidade de se tornar extinta, enquanto que uma grande área de distribuição aumenta a possibilidade de especiação, por fazer com que seja mais provável que parte da população fique isolada. Neste sentido, microevolução e macroevolução podem por vezes estar separadas.
Um problema conceptual muito comum é acreditar-se que a evolução é progressiva, mas a seleção natural não tem um objetivo final, e não produz necessariamente organismos mais complexos. Apesar de espécies complexas terem evoluído, isso ocorre como consequência indireta do aumento no número total de organismos, e formas de vida simples continuam sendo mais comuns. Por exemplo, a esmagadora maioria das espécies constitui-se de procariotos microscópicos, que são responsáveis por cerca de metade da biomassa do planeta, apesar de seu pequeno tamanho, e compõem uma grande parte da biodiversidade na Terra. Assim, organismos simples continuam sendo a forma de vida dominante no planeta, sendo que a formas de vida mais complexas parecem mais diversas apenas porque são mais evidentes para nós.
Adaptações são estruturas ou comportamentos que melhoram uma função específica dos organismos, aumentando sua chance de sobreviver e reproduzir. Elas são produzidas por uma combinação da produção contínua de pequenas mudanças aleatórias nas características (mutações), e da selecção natural das variantes melhor ajustadas ao seu ambiente. Esse processo pode causar tanto o ganho de uma nova propriedade, como a perda de uma propriedade ancestral. Um exemplo que demonstra esses dois tipos de mudança é a adaptação bacteriana a antibióticos. Mutações que causam resistência a antibióticos podem modificar o alvo da droga ou remover os transportadores que permitem que a droga entre na célula. Outros exemplos notáveis são a capacidade adquirida pela bactéria "Escherichia coli" em utilizar o ácido cítrico como nutriente em experiências de laboratório de evolução a longo prazo, a aquisição de novas enzimas pela "Flavobacterium" que permitem que estas bactérias cresçam nos produtos da manufactura do náilon, ou a evolução na bactéria do solo "Sphingobium" de um via metabólica completamente nova que degrada o pesticida sintético pentaclorofenol. Uma interessante mas ainda controversa ideia é que algumas adaptações poderiam aumentar a capacidade dos organismos em gerar diversidade genética e adaptarem-se por seleção natural (aumentando a "evolucionabilidade" do organismo).
No entanto, muitas características que parecem ser simples adaptações podem ser exaptações: estruturas que originalmente surgiram como adaptações para desempenhar determinada função, mas que durante o processo evolutivo, coincidentemente se tornaram úteis no desempenho de uma outra função. Um exemplo é o lagarto africano "Holaspis guentheri", que desenvolveu uma cabeça extremamente fina para se esconder em pequenas cavidades, como pode ser percebido ao olhar-se para espécies aparentadas. No entanto, nessa espécie a cabeça se tornou tão fina que auxilia o animal a planar quando saltando entre árvores - uma exaptação.
Uma adaptação ocorre pela modificação gradual de estruturas existentes. Estruturas com organização interna semelhante podem ter funções muito diferentes em organismos aparentados. Isso é resultado de uma única estrutura ancestral que se adaptou para funcionar de formas diferentes em cada linhagem. Os ossos nas asas de morcegos, por exemplo, são estruturalmente similares tanto com as mãos humanas como com as barbatanas de focas, devido à descendência dessas estruturas de uma ancestral comum que também tinha cinco dedos na extremidade de cada membro anterior. Outras características anatômicas únicas, como ossos no pulso do panda, que formam um falso "polegar", indicam que a linhagem evolutiva de um organismo pode limitar que tipo de adaptação é possível.
Durante a adaptação, algumas estruturas podem perder a sua função e se tornarem estruturas vestigiais. Essas estruturas podem ter pouca ou nenhuma função numa espécie, apesar de terem uma função clara em espécies ancestrais ou relacionadas. Exemplos incluem os remanescentes não funcionais de olhos em alguns peixes de cavernas, asas em aves incapazes de voar e a presença de ossos do quadril em baleias e cobras. Exemplos de estruturas vestigiais em humanos incluem o dente do siso, o cóccix e o apêndice vermiforme.
Uma área de pesquisa atual em biologia do desenvolvimento evolutiva é a base desenvolvimental de adaptações e exaptações. Essa linha de pesquisa busca compreender a origem e evolução de desenvolvimento embrionário e como modificações nos processos do desenvolvimento produzem novas características de forma gradualista, onde as mudanças ocorrem com a presença de intermédiarios, ou ainda pelo modelo de saltos evolutivos, onde uma mudança "abrupta" pode correr de uma geração para outra e com um passar do tempo aquela nova estrutura pode ser torna-se vantajosa para a população da espécies. Esses estudos têm demonstrado que a evolução pode alterar o desenvolvimento para criar novas estruturas, como as estruturas embrionárias que formam ossos da mandíbula em outros animais formando parte do ouvido médio em mamíferos. É também possível que estruturas perdidas ao longo da evolução reapareçam devido a mudanças em genes do desenvolvimento, como uma mutação em galinhas que faz com que os embriões produzam dentes similares aos de crocodilos.
Interações entre organismos podem produzir tanto conflito como cooperação. Quando a interação ocorre entre pares de espécies, como um patógeno e um hospedeiro, ou um predador e uma presa, essas espécies podem desenvolver séries de adaptações combinadas. Nesses casos, a evolução de uma espécie causa adaptações numa outra. Essas mudanças na segunda espécie, por sua vez, causam novas adaptações na primeira. Esse ciclo de seleção e resposta é chamado de co-evolução. Um exemplo é a produção de tetrodotoxina numa espécie de salamandra "(Taricha granulosa)" e a evolução de resistência à tetrodotoxina em seu predador, uma serpente "(Thamnophis sirtalis)". Nesse par de presa e predador, uma corrida armamentista evolutiva produziu altos níveis de toxina na salamandra e correspendentemente altos níveis de resistência na cobra.
No entanto, nem todas as interações entre espécies envolvem conflito. Muitos casos de interações mutuamente benéficas evoluiram. Por exemplo, existe uma cooperação extrema entre plantas e micorrizas que crescem sobre as raízes, auxiliando na absorção de nutrientes do solo. Essa é uma interação recíproca, já que as plantas provêm à micorriza açúcares da fotossíntese. Nesse caso o fungo geralmente cresce dentro das células da planta, permitindo a troca de nutrientes, enquanto envia sinais que reprimem o sistema imunitário da planta.
A cooperação também evoluiu entre organismos da mesma espécie. Um caso extremo é a eussocialidade, que pode ser observada em insetos sociais, como abelhas, cupins e formigas, onde insetos estéreis alimentam e defendem um pequeno número de organismos da colônia que são capazes de se reproduzir. Numa escala ainda menor, as células somáticas que formam o corpo de um animal são limitadas em sua capacidade de se reproduzir para que se mantenha a estabilidade no organismo e permita que um pequeno número de células germinativas produza prole. Nesse caso, células somáticas respondem a sinais específicos que as instruem a crescer ou destruir a si próprias. Se as células ignoram esses sinais e tentam se multiplicar de forma desordenada, seu crescimento descontrolado causa câncer.
Imagina-se que esses exemplos de cooperação dentro de uma espécie evoluíram pelo processo de seleção de parentesco, que consiste em um organismo agir de forma a aumentar a probabilidade de parentes produzirem prole. Essa atividade é selecionada porque se o indivíduo que ajuda possui alelos que promovem a atividade de ajudar, é provável que seus parentes também possuam esses alelos e, assim, esses alelos são passados adiante. Outros processos que podem promover a cooperação incluem seleção de grupo, onde a cooperação fornece benefícios para um grupo de organismos.
Especiação é o processo pelo qual uma espécie diverge, produzindo duas ou mais espécies descendentes. Eventos de especiação foram observados diversas vezes, tanto em condições controladas de laboratório como na natureza. Em organismos de reprodução sexuada, a especiação resulta do isolamento reprodutivo seguido por divergência entre as linhagens. Há quatro tipos de mecanismos de especiação, sendo a especiação alopátrica considerada a mais comum em animais. Esse tipo de especiação ocorre quando populações são isoladas geograficamente, por fragmentação de habitat ou migração, por exemplo. Como as forças evolutivas passam a atuar independentemente nas populações isoladas, a separação vai, eventualmente, produzir organismos incapazes de se intercruzarem.
O segundo mecanismo de especiação a ser considerado é a especiação peripátrica, que ocorre quando pequenas populações de organismos são isoladas num novo ambiente. Ela difere da especiação alopátrica pelo fato de as populações isoladas serem muito menores do que a população parental. Nesse caso, o efeito fundador causa uma especiação rápida tanto pela deriva genética oriunda do efeito fundador como pela rápida ação da seleção natural sobre um conjunto de genes pequeno.
O terceiro mecanismo de especiação é a especiação parapátrica. Ela é similar à especiação peripátrica na medida em que uma população pequena ocupa um novo habitat, mas difere porque não há separação física entre essas populações. O que ocorre é que a especiação resulta da evolução de mecanismos que reduzem o fluxo gênico entre as duas populações. Geralmente isso ocorre quando há alguma mudança drástica no ambiente da espécie parental. Um exemplo é a gramínea "Anthoxanthum odoratum", que pode passar por especiação parapátrica em resposta a poluição localizada de metais de minas. Neste caso, plantas com resistência a altos níveis de metais no solo evoluem. A seleção contra cruzamentos com a população parental sensível a metais produz uma mudança no tempo de floração das plantas resistentes, causando isolamento reprodutivo. A seleção contra híbridos entre as duas populações pode causar o que é chamado de "reforço", que é a evolução de características que promovem o cruzamento dentro de determinada espécie, assim como deslocamento de caráter, que ocorre quando duas espécies se tornam mais distintas em aparência.
Finalmente, quando há especiação simpátrica, espécies divergem sem uma barreira geográfica entre elas ou mudanças drásticas no ambiente. Esse tipo de especiação é considerado raro, já que uma pequena quantidade de fluxo gênico pode remover as diferenças genéticas entre partes de uma população. Em geral, a especiação simpátrica em animais exige a evolução tanto de diferenças genéticas como de acasalamento preferencial, para permitir que o isolamento reprodutivo evolua.
Um tipo de evolução simpátrica envolve o cruzamento entre duas espécies aparentadas, produzindo uma nova espécie híbrida. Esse tipo de especiação não é comum em animais, já que híbridos são comumente inviáveis ou estéreis, porque não há pareamento entre os cromossomos homólogos de cada progenitor durante a meiose. Ela é mais comum em plantas, porque plantas frequentemente dobram o número de cromossomos, formando poliplóides. Isso permite o pareamento de cada cromossomo com seu homólogo durante a meiose, já que os cromossomos de cada progenitor já se apresentam em pares. Um exemplo desse tipo de especiação ocorreu quando as espécies "Arabidopsis thaliana" e "Arabidopsis arenosa" se hibridizaram para formar a nova espécie "Arabidopsis suecica". Isso ocorreu há cerca de 20.000 anos atrás e o processo de especiação foi reproduzido em laboratório, permitindo o estudo dos mecanismos genéticos envolvidos no processo. De fato, eventos de poliploidização numa espécie podem ser uma causa comum de isolamento reprodutivo, já que metade dos cromossomos duplicados não irá parear quando ocorrer cruzamento com organismos sem essa duplicação.
Eventos de especiação são importantes na teoria do equilíbrio pontuado, que explica a existência do padrão observado no registro fóssil de "explosões" de evolução entre longos períodos de estase, em que as espécies se mantém relativamente sem mudanças. Nessa teoria, a especiação e a rápida evolução são relacionadas, com seleção natural e deriva genética atuando mais fortemente em organismos especiando em novos habitats ou com pequeno tamanho populacional. Como resultado, os períodos de estase no registro fóssil correspondem à população parental, e os organismos passando por especiação e rápida evolução são encontrados em pequenas populações geograficamente restritas., sendo raramente preservados como fósseis.
Barreiras reprodutivas ao cruzamento podem ser classificadas em "pré-zigóticas" ou "pós-zigóticas". A distinção entre as duas é definida se a barreira previne a formação de prole antes ou depois da fertilização do óvulo.
Barreiras pré-zigóticas são aquelas que impedem a cópula entre as espécies, ou então impedem a fertilização do óvulo caso a espécie tente cruzar.
Alguns exemplos são:
Barreiras pós-zigóticas são aquelas que ocorrem após a fertilização, geralmente resultando na formação de um zigoto híbrido que é infértil ou inviável. Isso geralmente é resultado de incompatibilidade nos cromossomos do zigoto. Um zigoto é um óvulo fertilizado antes de se dividir, ou o organismo que se origina desse óvulo fertilizado. Inviável significa incapaz de chegar à idade adulta.
Exemplos incluem:
Extinção é o desaparecimento de toda uma espécie. A extinção não é um evento incomum, já que espécies normalmente surgem por especiação e desaparecem por extinção. De fato, quase todas as espécies de planta e animal que já existiram hoje estão extintas. Essas extinções aconteceram continuamente durante toda a história da vida, apesar de haver picos nas taxas de extermínio em eventos de extinção em massa. A extinção entre o Cretáceo e o Terciário (Extinção K-T), na qual os dinossauros desapareceram, é a mais conhecida. No entanto, um evento anterior, a extinção do Permiano-Triássico, foi ainda mais severa, levando cerca de 96% das espécies então existentes ao extermínio. A extinção do Holoceno é um processo de desaparecimento de espécies em massa ocorrendo atualmente, em decorrência da expansão da espécie humana pelo globo nos últimos milhares de anos. Taxas de extinção atuais são de 100 a 1000 vezes maiores do que as taxas normais, e até 30% das espécies pode estar extinta até o meio deste século. Atividades humanas são hoje a principal causa da extinção em massa atual e o aquecimento global pode acelerar ainda mais essa extinção no futuro.
O papel da extinção na evolução depende do tipo de extinção que é considerada. As causas das baixas taxas de evolução, que atuam continuamente e são responsáveis pela maior parte das extinções, não são bem conhecidas, e podem ser o resultado da competição entre as espécies por recursos compartilhados. Se a competição de outras espécies pode alterar a chance de determinada espécie sobreviver, isso poderia produzir seleção natural no nível de espécies, em contraposição à que ocorre no nível de organismos. As extinções em massa intermitentes também são importantes, mas ao invés de agir como força seletiva, elas reduzem drasticamente a diversidade, de forma não específica, promovendo picos de radiação adaptativa e especiação nas espécies sobreviventes.
A origem da vida é o precursor necessário para a evolução biológica, mas perceber que a evolução ocorreu depois de os organismos aparecerem pela primeira vez, e investigar como isto acontece, não depende na compreensão exacta de como a vida começou. O consenso científico actual é de que a bioquímica complexa que constitui a vida provém de reacções químicas mais simples, mas que não é claro como ocorreu esta transição. Não há muitas certezas sobre os primeiros desenvolvimentos da vida, a estrutura dos primeiros seres vivos, ou a identidade ou natureza do último ancestral comum ou do pool genético ancestral. Como consequência, não há consenso científico sobre como a vida surgiu. Algumas propostas incluem moléculas capazes de auto-replicação, como o RNA e a construção de células simples.
Todos os seres vivos da Terra descendem de um ancestral comum ou de um pool genético ancestral. E as espécies actuais são um estádio no processo de evolução, e a sua diversidade resulta de uma longa série de eventos de especiação e extinção. A origem comum dos seres vivos foi inicialmente deduzida a partir de quatro simples factos sobre seres vivos: Primeiro, eles têm distribuições geográficas que não podem ser explicadas por adaptações locais. Segundo, a diversidade da vida não é uma série de organismos completamente únicos, mas os seres vivos têm semelhanças morfológicas. Terceiro, características vestigiais com nenhuma utilidade evidente são parecidas com características ancestrais funcionais e finalmente, que organismos podem ser classificados usando estas semelhanças numa hierarquia de grupos aninhados uns nos outros.
Espécies passadas também deixaram registos da sua história evolutiva. Fósseis, juntamente com a anatomia comparada de seres vivos existentes actualmente, constituem o registo morfológico ou anatómico. Comparando as anatomias de espécies modernas e extintas, paleontólogos podem inferir as linhagens dessas espécies. Contudo, esta metodologia tem maior sucesso em organismos com partes duras, tais como conchas, ossos ou dentes. Além disso, como os procariontes como bactérias e archaea partilham uma série limitada de morfologias comuns, os seus fósseis não fornecem informação sobre a sua ascendência.
Mais recentemente, evidências de origem comum provieram do estudo de semelhanças bioquímicas entre organismos. Por exemplo, todas as células vivas usam os mesmos ácidos nucleicos e aminoácidos. O desenvolvimento da genética molecular revelou o registo da evolução deixado nos genomas dos seres vivos: datando quando as espécies divergiram através do relógio molecular produzido pelas mutações. Por exemplo, comparações entre sequências de DNA revelaram a estreita semelhança genética entre humanos e chimpanzés e revelou quando existiu um ancestral comum às duas espécies.
Apesar da incerteza sobre como a vida começou, é claro que os procariontes foram os primeiros seres vivos a habitar a Terra, há aproximadamente 3-4 mil milhões de anos. Não ocorreram nenhumas mudanças óbvias em morfologia ou organização celular nestes organismos durante os próximos milhares de milhão de anos.
A próxima grande inovação na evolução foram os eucariontes. Estes surgiram a partir de bactérias antigas terem sido rodeadas por antecessores de células eucarióticas, numa associação cooperativa chamada de endossimbiose. A bactéria encapsulada e a célula hospedeira sofreram evolução, com a bactéria a evoluir em mitocôndrias ou em hidrogenossomas. Uma segunda captura de seres semelhantes a cianobactérias levou à formação de cloroplastos em algas e plantas.
A história da vida foi a história de procariontes, archae e eucariontes unicelulares até há cerca de um milhar de milhão de anos atrás quando seres multicelulares começaram a aparecer nos oceanos durante o período Ediacarano. A evolução de organismos multicelulares ocorreu múltiplas vezes, de forma independente, em organismos tão diversos como esponjas, algas castanhas, cianobactérias, mycetozoa e mixobactérias.
Depois do aparecimento dos primeiros seres multicelulares, ocorreu um notável diversificação biológica num período de 10 milhões de anos, num evento chamado explosão cambriana quando a maioria dos grupos de animais modernos apareceram entre 540 e 520 milhões de anos atrás. Durante este evento, evoluiram a maior parte dos tipos de animais modernos, assim como linhagens únicas que se extinguiram entretanto. Têm sido propostos vários "detonadores" para esta explosão, incluindo a acumulação de oxigénio na atmosfera resultante da fotossíntese. Um estudo conduzido por pesquisadores em 2013 estimou, pela primeira vez, as taxas de evolução durante a "explosão cambriana". Os resultados, solucionam o "dilema de Darwin": o súbito aparecimento de um grande número de grupos de animais modernos no registro de fóssil durante o início do período Cambriano.. Há cerca de 500 milhões de anos, plantas e fungos colonizaram a terra, e foram logo seguidos por artrópodes e outros animais. Os anfíbios apareceram pela primeira vez há cerca de 300 milhões de anos, seguidos pelos primeiros amniotas, os mamíferos há volta de 200 milhões de anos e as aves há cerca de 100 milhões de anos (ambos a partir de linhagens semelhantes a répteis. Contudo, apesar da evolução destes grandes animais, seres vivos mais pequenos semelhantes aos que evoluíram cedo no processo, continuam a ser bem sucedidos e a dominar a Terra, formando a maioria da biomassa e das espécies procariontes.
Na natureza existem exemplos de espécies que mesmo sem ter ancestral comum quando comparado com a outra, desenvolveram tamanha similaridade quando se diz respeito a forma e comportamento, essas espécies similares irão apresentar estruturas análogas quando estas apresentam similaridade na forma superficial ou na função, o que difere de estruturas homólogas que se originam estruturas de um ancestral em comum com as espécies comparadas. Um exemplo desse tipo de evolução no reino animal é encontrado quando comparado as asas dos morcegos e das aves.
Certa forma de evolução foi acrescentada na história, através de isolamentos entre indivíduos de um grupo. Um exemplo de evolução paralela se apresenta nos mamíferos, em que se diferem entre placentários e marsupiais, sendo que geralmente, alguns pares de animais tais como: Canis (Placentário) e Thylacinus (marsupial), Felis (placentário) e Dasyurus (marsupial), Glaucomys (placentário) e Petaurus (marsupial), Marmota (placentário) e Vombatus (marsupial), Myrmecophaga (placentário) e Myrmecabius (marsupial), Talpa (placentário) e Notoryctes (marsupial), apresentam similaridades tanto na aparência quanto em hábitos. Ao contrário da evolução convergente, a evolução paralela ocorre conforme uma mesma linhagem ancestral evolui. 
Ideias evolutivas como origem comum e de transmutação de espécies existiram pelo menos desde o século VI a.C., quando foram examinadas pelo filósofo grego Anaximandro de Mileto. Outros que consideraram estas ideias incluem o filósofo grego Empédocles, o filósofo-poeta romano Lucrécio, o biólogo árabe Al-Jahiz, o filósofo persa Ibn Miskawayh, e o filósofo oriental Zhuang Zi.
À medida que o conhecimento biológico aumentou no século XVIII, ideias evolutivas foram propostas por alguns filósofos como Pierre Louis Maupertuis em 1745, Erasmus Darwin em 1796, e Georges-Louis Leclerc (conde de Buffon) entre 1749 e 1778. As ideias do biólogo Jean-Baptiste Lamarck acerca da transmutação das espécies teve grande influência. Charles Darwin formulou a sua ideia de selecção natural em 1838 e ainda estava desenvolvendo a sua teoria em 1858 quando Alfred Russel Wallace lhe enviou uma teoria semelhante, e ambas foram apresentadas na Linnean Society of London em dois artigos separados. No final de 1859, a publicação de "A Origem das Espécies" por Charles Darwin, explicava a selecção natural em detalhe e apresentava provas que levaram a uma aceitação cada vez mais geral da ocorrência da evolução.
O debate sobre os mecanismos da evolução continuaram, e Darwin não foi capaz de explicar a fonte das variações hereditárias sobre as quais a selecção natural actuaria. Tal como Lamarck, ele pensava que os progenitores passavam à descendência as adaptações adquiridas durante a sua vida, uma teoria subsequentemente nomeada de Lamarckismo. Na década de 1880, as experiências de August Weismann indicaram que as mudanças pelo uso e desuso não eram hereditárias, e o Lamarckismo entrou gradualmente em descrédito. Mais importante do que isso, Darwin não consegui explicar como características passam de geração para geração. Em 1865, Gregor Mendel descobriu que as características eram herdadas de uma maneira previsível. Quando o trabalho de Mendel foi redescoberto em 1900, a discórdia sobre a taxa de evolução prevista pelos primeiros geneticistas e biometristas levou a uma ruptura entre os modelos de evolução de Mendel e de Darwin.
Esta contradição só foi reconciliada nos anos 1930 por biólogos como Ronald Fisher. O resultado final foi a combinação da evolução por selecção natural e hereditariedade mendeliana, a síntese evolutiva moderna. Na década de 1940, a identificação do DNA como o material genético por Oswald Avery e colegas, e a subsequente publicação da estrutura do DNA por James Watson e Francis Crick em 1953, demonstraram o fundamento físico da hereditariedade. Desde então, a genética e biologia molecular tornaram-se partes integrais da biologia evolutiva e revolucionaram o campo da filogenia.
Na sua história inicial, a biologia evolutiva atraiu primariamente cientistas vindos de campos tradicionais de disciplinas orientadas para a taxonomia, cujo treino em organismos particulares os levava a estudar questões gerais em evolução. Assim que a biologia evolutiva se expandiu como disciplina académica, particularmente depois do desenvolvimento da síntese evolutiva moderna, começou a atrair cientistas de um leque mais alargado das ciências biológicas. Actualmente, o estudo da biologia evolutiva envolve cientistas de campos tão diversos como bioquímica, ecologia, genética e fisiologia, e conceitos evolutivos são usados em disciplinas ainda mais distantes como psicologia, medicina, filosofia e ciência dos computadores.
Mesmo antes da publicação d"'A Origem das Espécies", a ideia que a vida evolui era fonte de debate. A evolução ainda é um conceito contencioso em algumas secções da sociedade fora da comunidade científica. O debate tem-se centrado nas implicações filosóficas, sociais e religiosas da evolução, não na ciência em si; a proposta de que a evolução biológica ocorre através do mecanismo de selecção natural é padrão na literatura científica.
Apesar de muitas religiões terem reconciliado as suas crenças com a evolução através de vários conceitos de evolução teísta, há muitos criacionistas que acreditam que a evolução é contraditória com as histórias de criação encontradas nas respectivas religiões. Tal como Darwin reconheceu desde cedo, o aspecto mais controverso do pensamento evolutivo é a sua implicação para a origem dos seres humanos. Em alguns países, notavelmente os Estados Unidos, as tensões entre os ensinamentos científicos e religiosos têm alimentado a controvérsia da criação vs. evolução, um conflito religioso que foca na política do criacionismo e no ensino da evolução nas escolas públicas. Apesar de outros campos da ciência como cosmologia e ciências da Terra também entrarem em conflito com a interpretação literal de muitos textos religiosos, muitos crentes religiosos opõem-se à biologia evolutiva.
A evolução tem sido usada para posições filosóficas que propõe discriminação e o racismo. Por exemplo, as ideias eugénicas de Francis Galton foram desenvolvidas para argumentar que o pool genético humano podia ser melhorado através de políticas de cruzamentos selectivos, incluindo incentivos para aqueles considerados como "bom stock" para se reproduzirem, e esterilização compulsória, testes pré-natais, controlo da natalidade e inclusive homicídio dos considerados "mau stock". Um outro exemplo de uma extensão da teoria evolutiva que é reconhecida actualmente como indevida é o "Darwinismo social", um termo dado à teoria Malthusiana dos Whig, desenvolvida por Herbert Spencer em ideias de "sobrevivência do mais apto" no comércio e nas sociedades humanas em geral, e por outros que reclamavam que a desigualdade social, racismo e imperialismo eram justificados. Contudo, cientistas e filósofos contemporâneos consideram que estas ideias não são nem mandatadas pela teoria evolutiva nem sustentadas por quaisquer dados.
Uma grande aplicação tecnológica da evolução é a selecção artificial, que é a selecção intencional de certas características em populações de seres vivos. Os seres humanos têm usado a selecção artificial há milhares de anos na domesticação de plantas e animais. Mais recentemente, tal selecção tornou-se uma parte vital da engenharia genética, com o uso de marcadores selecionáveis tais com a resistência a antibióticos para manipular DNA na biologia molecular.
Como a evolução é capaz de produzir processos e redes altamente optimizados, tem muitas aplicações em ciência dos computadores. Aqui, simulações de evolução usando algoritmos genéticos e vida artificial foram iniciadas com o trabalho de Nils Aall Barricelli na década de 1960, e depois estendidas por Alex Fraser, que publicou uma série de artigos sobre simulação de evolução artificial. A evolução artificial tornou-se um método de optimização largamente reconhecido como resultado do trabalho de Ingo Rechenberg na década de 1960 e 70, que usou estratégias evolutivas para resolver problemas de engenharia complexos. Algoritmos genéticos em particular tornaram-se populares pelos escritos de John Holland. À medida que o interesse académico cresceu, o aumento dramático no poder computacional permitiu aplicações práticas. Algoritmos evolutivos são agora usados para resolver problemas multi-dimensionais mais eficientemente do que por software produzido por programadores humanos, e também para optimizar o desenho de sistemas.

O etileno ou eteno é o hidrocarboneto alceno mais simples da família das olefinas, constituído por dois átomos de carbono e quatro de hidrogênio (CH). Existe uma ligação dupla entre os dois carbonos. A existência de uma ligação dupla significa que o etileno é um "hidrocarboneto insaturado". Pela nomenclatura IUPAC recebe a denominação de eteno.
A molécula não pode rodar em torno da ligação dupla, e os seis átomos dispõem-se no mesmo plano. O ângulo das duas ligações carbono-hidrogênio é de 117º, muito próximo dos 120º preditos pela hibridização sp² ideal.
É um gás incolor, odor etéreo, levemente adocicado que liquefaz a -103°C e solidifica a -169°C, sendo o composto químico de maior utilização no setor químico industrial. 
A hulha é aquecida a uma temperatura de 1000°C/1300°C em presença de uma corrente de ar. Obtém-se uma fração gasosa que contém entre 3% a 5% de etileno.
Industrialmente o etileno é preparado pela desidrogenação do etano (retirada de hidrogênio). A desidrogenação ocorre entre 500°C e 750°C, utilizando catalisadores como óxido de crômio, de molibdênio, de vanádio e de urânio suspensos em alumina.
Várias indústrias propõem a fabricação de plástico verde ou ecológico a partir do álcool etílico produzido a partir da cana de açúcar. O método é antigo e semelhante a fabricação de éter etílico (antigamente chamado sulfúrico):
O método é catalisado por ácido sulfúrico ou alumina. A baixa temperatura favorece a produção do éter etílico e alta temperatura favorece o etileno.
Quando moléculas grandes constituintes do petróleo (geralmente alcanos) são quebradas (inglês "to crack" = quebrar) através de um processo simples de aquecimento utilizando catalisadores (pode ser silica, alumina Al2O3), forma-se uma fração gasosa que contém na sua composição etileno. Esse processo é um dos mais simples que ocorrem com a transformação do petróleo.
O etileno é usado como:
A maior aplicação do etileno é através do emprego de derivados obtidos a partir dele:
Biossíntese
A rota completa de síntese do etileno é um ciclo (ciclo de Yang).O primeiro precursor do etileno nesta via é o aminoácido metionina, o qual é adenilado pela AdoMet sintetase, formando a S-adenosilmetionina. O precursor imediato do etileno é o ácido 1-aminociclopropano-1-carboxílico (ACC) que é sintetizado a partir da AdoMet pela enzima ACCsintase, nesta reação, a adenina é liberada da AdoMet e é ligada à outra molécula de metionina através do ciclo de Yang. A última etapa de síntese do etileno é a conversão do ACC em etileno catalisada pela enzima ACC oxidase. 
A etapa limitante para a produção do etileno é a síntese do ACC a partir de AdoMet, que é catalisada pela ACCsintase. Esta enzima tem seus níveis regulados por fatores ambientais e internos, como ferimentos, inundação, estresse hídrico e presença de auxina e é codificada por uma família multigênica divergente, na qual os genes são regulados de formas distintas por indutores diferentes.
Inicialmente, o Etileno liga-se a um receptor proteico na membrana do Retículo Endoplasmático. Em seguida, esse receptor deixa de ativar uma proteína, a CTR1, que atua como reguladora negativa da cadeia de sinais químicos que produz a resposta biológica do etileno. Em outras palavras, a presença do etileno inativa uma proteína que atua como inibidora, fazendo então com que a resposta ocorra. Na ausência do etileno, a CTR1 inibe a formação dos fatores de transcrição que irão regular a expressão de genes de resposta ao etileno na planta.
Vem sendo demonstrado que o Etileno regula diversas respostas nos vegetais. O etileno é conhecido como “hormônio do amadurecimento”, pois promove o amadurecimento de frutos. Outros efeitos biológicos promovidos pelo etileno são: germinação de sementes; epinastia (curvatura para baixo)de folhas; abscisão (queda) de frutos maduros, órgãos senescentes ou danificados e folhas; expansão celular horizontal e crescimento lateral do caule; quebra de dormência de gemas e sementes em algumas espécies; alongamento do caule de espécies vegetais aquáticas submersas; formação de raízes e pêlos absorventes; indução floral e expressão sexual, como por exemplo em Cucurbitaceae (família das abóboras), o etileno induz a preferência de flores femininas. Embora o etileno iniba o florescimento na maioria das espécies, em plantas de abacaxi ele induz o florescimento.

Espanha (; ), também conhecido como Reino de Espanha ou Reino da Espanha, é um país situado na Europa meridional, na Península Ibérica. Seu território principal é delimitado a sul e a leste pelo mar Mediterrâneo, com exceção a uma pequena fronteira com o território britânico ultramarino de Gibraltar; ao norte pela França, Andorra e pelo golfo da Biscaia e ao noroeste e oeste pelo oceano Atlântico e por Portugal.
O território espanhol inclui ainda as ilhas Baleares, no Mediterrâneo, as ilhas Canárias, no oceano Atlântico, próximas da costa Africana e duas cidades autônomas no norte de África, Ceuta e Melilla, que fazem fronteira com o Marrocos. Com uma área de , a Espanha é, depois da França, o segundo maior país da Europa Ocidental e da União Europeia.
Devido à sua localização, o território da Espanha foi sujeito a muitas influências externas, muitas vezes simultaneamente, desde os tempos pré-históricos até quando a Espanha se tornou um país. Por outro lado, o próprio país foi uma importante fonte de influência para outras regiões, principalmente durante a Era Moderna, quando se tornou um império mundial que deixou como legado mais de 400 milhões de falantes do espanhol espalhados pelo mundo.
A Espanha é uma democracia organizada sob a forma de um governo parlamentar sob uma monarquia constitucional. É um país desenvolvido com o nono PIB nominal mais elevado do mundo e elevado padrão de vida (a Espanha possui o 23.º melhor Índice de Desenvolvimento Humano (IDH) do mundo). É um membro das Organização das Nações Unidas (ONU), da União Europeia (UE), da Organização do Tratado do Atlântico Norte (OTAN), da Organização para a Cooperação e Desenvolvimento Econômico (OCDE) e da Organização Mundial do Comércio (OMC).
O nome Espanha deriva de Hispânia, nome com o qual os romanos designavam geograficamente a Península Ibérica. O nome "Ibéria" era o que os gregos davam à Península embora houvesse outras designações dadas pelos povos antigos. O facto do termo "Hispânia" não ter uma raiz latina resultou na formulação de diversas teorias sobre a sua origem, algumas controversas. A opção mais consensual seria a de que o nome Hispânia provém do fenício "i-spn-ea". Os romanos tomaram essa denominação dos vencidos cartaginenses, interpretando o prefixo "i" como "costa", "ilha" ou "terra", e o sufixo "ea" com o significado de "região". O lexema "spn" foi traduzido como "coelhos" (na realidade dassies, animais comuns no norte da África).
O nome de Espanha, evolução da designação do Império Romano Hispânia era, até ao , apenas descritivo da Península Ibérica, não se referindo a um país ou Estado específico, mas sim ao conjunto de todo o território ibérico e dos países que nele se incluíam. A Espanha é unificada durante o Iluminismo, até então era um conjunto de reinos juridicamente e politicamente independentes governados pela mesma monarquia. Até à data da unificação a monarquia era formada por um conjunto de reinos associados por herança e união dinástica ou por conquista. A forma de governo era conhecida como "aeque principaliter", os reinos eram governados cada um de forma independente, como se tivesse cada reino o seu próprio rei, cada reino mantinha o seu próprio sistema legal, a sua língua, os seus foros e os seus privilégios.
As "Leyes de extranjeria" determinavam que o natural de qualquer um dos reinos era estrangeiro em todos os outros reinos ibéricos.
A constituição de 1812 adota o nome "As Espanhas" para a nova nação.
A constituição de 1876 adota pela primeira vez o nome "Espanha".
Os termos "as Espanhas" e "Espanha" não eram equivalentes, e eram usados com muita precisão. O termo "As Espanhas" referia-se a um conjunto de unidades jurídico-políticas, ou seja, referia-se a um conjunto de reinos independentes, primeiramente apenas aos reinos cristãos da Península Ibérica, depois apenas aos reinos unidos sobre a mesma monarquia. O termo "Espanha" referia-se a um espaço geográfico e cultural que englobava diversos reinos independentes. A partir de Carlos V o uso do título "Rei das Espanhas", referia-se à parte da Espanha que não incluía Portugal, mas esta designação era apenas uma forma de designar coletivamente um extenso número de reinos, uma abreviação, que não tinha validade jurídica, para uma longa lista de títulos reais cuja forma oficial era rei de Castela, de Leão, de Aragão, de Navarra, de Granada, de Toledo, de Valência, da Galiza, de Maiorca, de Menorca, de Sevilha, etc. (da mesma forma utilizava-se o título Sua Majestade Lusitana para o rei de Portugal, ou rei Lusitano)
O uso do da designação de "reis de Espanha" pelos reis Fernando e Isabel foi considerado uma ofensa pelo rei de Portugal que considerava que o nome designava a Península. A última vez que Portugal protestou oficialmente o uso do termo "coroa de Espanha" ou "monarquia de Espanha" pelo governo de Madrid foi, supõe-se, durante o Tratado de Utrecht em 1714.
Atualmente o nome "Península Hispânica" não é aceite pelos portugueses, sendo que a designação usada é a de Península Ibérica.
A partir de 1640, com a Restauração da Independência de Portugal, a designação "Rei da Espanha" manteve-se, apesar de a união dinástica já não englobar toda a Península.
A "História de Espanha" é a própria de uma nação europeia, que compreende o período entre a pré-história e a época atual, passando pela formação e queda do primeiro Império espanhol.
Os primeiros humanos modernos chegaram à Península Ibérica no território da atual Espanha há 35 mil anos. No período histórico o território foi invadido e colonizado por celtas, fenícios, cartagineses, gregos e cerca de , a maior parte da Península Ibérica começou a formar parte do Império Romano, sendo o rio Ebro a fronteira entre a Espanha romana e cartaginesa.
Durante a Segunda Guerra Púnica, uma expansão do Império Romano capturou colônias comerciais cartaginesas ao longo da costa do Mediterrâneo, cerca de Os romanos levaram quase dois séculos para completar a conquista da Península Ibérica, apesar de terem o controle de boa parte dela há mais de 600 anos. O domínio romano era unido pela lei, idioma e as estradas romanas.
As culturas das populações celtas e ibéricas foram gradualmente romanizadas (latinizadas) em diferentes níveis e em diferentes partes da Hispânia (o nome romano para a Península). Os líderes locais foram admitidos na classe aristocrática romana. A Hispânia serviu como um celeiro para o mercado romano e seus portos exportavam ouro, lã, azeite e vinho. A produção agrícola aumentou com a introdução de projetos de irrigação, alguns dos quais permanecem em uso. Os imperadores Trajano e e o filósofo Sêneca nasceram na Hispânia. O cristianismo foi introduzido na província no e tornou-se popular nas cidades no O termo "Espanha", as línguas, a religião e a base das leis atuais da Espanha se originaram a partir deste período.
O enfraquecimento da jurisdição do Império Romano do Ocidente em Hispânia começou em 409, quando os povos germânicos suevos e vândalos, juntamente com os alanos sármatas, cruzaram o Reno e devastaram a Gália e a Península Ibérica. Os visigodos atacaram a Ibéria no mesmo ano. Os suevos estabeleceram um reino no que hoje é a moderna Galiza e o Norte de Portugal. O império romano ocidental se desintegrava, mas a sua base social e econômica continuou, ainda que de forma modificada. Os seus regimes sucessores mantiveram muitas das instituições e das leis do Império, incluindo o cristianismo.
Os aliados dos alanos, os vândalos asdingos, estabeleceram um reino na Galécia, ocupando grande parte da região, mas indo mais ao sul do rio Douro. Os vândalos silingos ocuparam a região que ainda tem o seu nome - Vandalúsia, a moderna Andaluzia, na Espanha. Os bizantinos estabeleceram um enclave, Espânia, no sul, com a intenção de reviver o Império Romano ao longo da Península Ibérica. Eventualmente, entretanto, Hispânia foi reunida sob o domínio visigótico.
No , quase toda a Península Ibérica foi conquistada por exércitos de mouros muçulmanos provenientes principalmente do Norte de África. Essas conquistas fizeram parte da expansão do Califado Omíada. Apenas uma pequena área montanhosa no noroeste da Península conseguiu resistir à invasão inicial muçulmana.
Sob a lei islâmica, os cristãos e os judeus receberam o estatuto subordinado de "dhimmi". Esse estatuto permitia que cristãos e judeus praticassem suas religiões como "povos do livro", mas eles eram obrigados a pagar um imposto especial e eram sujeitos a certas discriminações. A conversão ao islamismo prosseguiu a um ritmo cada vez maior. Acredita-se que os "muladi" (muçulmanos de origem étnica ibérica) compreendiam a maioria da população de "Al-Andalus" até o final do .
A comunidade muçulmana na Península Ibérica era diversificada e atormentado por tensões sociais. Os povos berberes do Norte de África, que tinham fornecido a maior parte dos exércitos invasores, entraram em choque com a liderança árabe do Oriente Médio. Ao longo do tempo, grandes populações árabes se estabeleceram, especialmente no vale do rio Guadalquivir, na planície costeira de Valência, no vale do rio Ebro (no final deste período) e na região montanhosa de Granada.
Córdova, a capital do califado, era a maior, mais rica e sofisticada cidade na Europa Ocidental na época. O comércio e o intercâmbio cultural no Mediterrâneo floresceram. Os muçulmanos importaram uma rica tradição intelectual do Oriente Médio e do Norte da África. Estudiosos muçulmanos e judeus desempenharam um papel importante na renovação e ampliação da aprendizagem clássica grega na Europa Ocidental. As culturas romanizados da Península Ibérica interagiram com as culturas muçulmanas e judaicas de forma complexa, dando, à região, uma cultura distinta.
No , os territórios muçulmanos fragmentaram-se em reinos rivais (as chamadas taifas), permitindo, aos pequenos Estados cristãos, a oportunidade de ampliar enormemente seus territórios.
A chegada das seitas islâmicas dominantes dos Almorávidas e Almóadas, do Norte da África, restaurou a unidade na Península Ibérica muçulmana, com uma aplicação mais rigorosa e menos tolerante do islã, provocando uma recuperação das fortunas muçulmanas. Este Estado islâmico reunido experimentou mais de um século de sucessos que reverteram parcialmente as vitórias cristãs.
As contínuas disputas entre muçulmanos e cristãos tiveram, como consequência, a Reconquista Cristã, começando no com a resistência cristã no norte da Espanha e através dos séculos seguintes com o avanço dos reinos cristãos ao sul, culminando com a conquista de Granada e com a expulsão dos últimos mouros em 1492.
Durante este período, os reinos e principados cristãos se desenvolveram notavelmente, incluídos os mais importantes: a Coroa de Castela e o Reino de Aragão. A união destes dois reinos através do casamento em 1469 da rainha Isabel I de Castela com o rei Fernando II de Aragão levou à criação do Reino da Espanha.
A unificação das coroas de Aragão e Castela lançou as bases para a Espanha moderna e para o Império Espanhol. A Espanha era a maior potência da Europa durante o e a maior parte do , uma posição reforçada pelo comércio e pela riqueza de suas possessões coloniais. Ela atingiu o seu apogeu durante os reinados dos dois primeiros habsburgos espanhóis - Carlos I (1516-1556) e Filipe II (1556-1598). Este período foi marcado pelas Guerras Italianas, Revolta dos Comuneiros, Revolta Holandesa, Rebelião das Alpujarras, conflitos com os otomanos, a Guerra Anglo-Espanhola e as guerras com a França.
O Império Espanhol se expandiu até incluir grande parte da América, ilhas na região Ásia-Pacífico, áreas da Itália, cidades do Norte de África, bem como partes do que hoje são parte de França, Alemanha, Bélgica, Luxemburgo e Países Baixos. Foi o primeiro império do qual se dizia que "o Sol nunca se punha".
A chamada "Era dos Descobrimentos" foi marcada por explorações ousadas por mar e por terra, a abertura de novas rotas comerciais pelos oceanos, conquistas e os primórdios do colonialismo europeu. Junto com a chegada dos metais preciosos, especiarias, luxos e novas plantas agrícolas, exploradores espanhóis trouxeram o conhecimento do Novo Mundo e desempenharam um papel de liderança na transformação da compreensão europeia do mundo. O florescimento cultural testemunhado é agora referido como o "Século de Ouro Espanhol". A ascensão do humanismo, da Reforma Protestante e de novas descobertas geográficas levantaram questões abordadas pelo movimento influente intelectual agora conhecida como a Escola de Salamanca.
Com a morte de Carlos II, a dinastia de Habsburgo se extinguiu, para deixar lugar aos Borbões, após a Guerra de Sucessão. Como consequência dessa guerra, a Espanha perdeu sua preponderância militar e, após sucessivas bancarrotas, o país foi reduzindo paulatinamente seu poder, convertendo-se, no final do , em uma potência menor.
O foi testemunha de grandes mudanças na Europa, acompanhadas pela Espanha. Na primeira parte desse século, a Espanha sofreu a independência da maioria de suas colônias no Novo Mundo. O século também esteve marcado pelas intervenções estrangeiras e os conflitos internos. Napoleão chegou a colocar seu irmão José Bonaparte no governo da Espanha. Após a expulsão dos franceses, a Espanha entrou em um extenso período de instabilidade: se sucederam continuas lutas entre liberais, republicanos e partidários do Antigo Regime.
A chegada da Revolução Industrial nas últimas décadas do século, levou algo de riqueza a uma classe média que se ampliava em alguns centros principais, porém a Guerra Hispano-Americana, em 1898 levou à perda de quase todas as colônias restantes, restando apenas os territórios na África.
Apesar de um nível de vida crescente e uma integração maior com o resto de Europa, no primeiro terço do , seguiu a instabilidade política. Espanha permaneceu neutral durante a Primeira Guerra Mundial.
O trouxe um pouco de paz; a Espanha desempenhou um papel menor na partilha da África, colonizando o Sahara Ocidental, Marrocos Espanhol e a Guiné Equatorial. As pesadas perdas sofridas durante a guerra do Rif, no Marrocos, ajudaram a minar a monarquia. Um período de governo autoritário do general Miguel Primo de Rivera (1923-1931) terminou com o estabelecimento da Segunda República Espanhola. A República ofereceu autonomia política ao País Basco, Catalunha e à Galiza e deu direito de voto às mulheres.
Então, em 1936, a Guerra Civil Espanhola (1936-39) iniciou-se. Três anos mais tarde, as forças nacionalistas, lideradas pelo general Francisco Franco, saíram vitoriosos com o apoio da Alemanha nazista e da Itália fascista. A Frente Popular governista foi apoiada pela União Soviética, o México e pelas Brigadas Internacionais, mas não foi apoiada oficialmente pelas potências ocidentais, devido à política britânica, liderada pelos Estados Unidos, de não intervencionismo.
A Guerra Civil tirou a vida de mais de 500.000 pessoas e causou a fuga de cerca de meio milhão de cidadãos espanhóis. A maioria de seus descendentes vivem agora em países da América Latina, com cerca de 300.000 apenas na Argentina.
O Estado espanhol estabelecido por Francisco Franco após a Guerra Civil foi nominalmente neutro na Segunda Guerra Mundial, embora fosse simpático às Potências do Eixo. O único partido legal sob o regime pós-guerra civil de Franco era o "Falange Española Tradicionalista y de las JONS", formado em 1937. O partido enfatizava o anti-comunismo, o catolicismo e o nacionalismo. Dada a oposição à Franco de partidos políticos concorrentes, o partido passou a se chamar Movimento Nacional ("Movimiento Nacional") em 1949.
Após a Segunda Guerra Mundial, a Espanha ficou isolada politicamente e economicamente e foi mantida fora das Nações Unidas. Isso mudou em 1955, durante o período da Guerra Fria, quando o país se tornou estrategicamente importante para os Estados Unidos para estabelecer sua presença militar na Península Ibérica como base para qualquer possível transferência pela União Soviética para a bacia do Mediterrâneo. Na década de 1960, a Espanha registrou uma taxa sem precedentes de crescimento econômico no que ficou conhecido como o milagre espanhol, que retomou a transição, bastante interrompida, para uma economia moderna.
Com a morte de Franco, em novembro de 1975, Juan Carlos assumiu o cargo de Rei de Espanha e de chefe de Estado, em conformidade com a lei. Com a aprovação da nova Constituição espanhola de 1978 e a restauração da democracia, o Estado descentralizou muito da sua autoridade para as regiões com governo local e criou uma organização interna baseada em comunidades autónomas.
No País Basco, o nacionalismo moderado tem coexistido com um movimento radical nacionalista liderado pela organização armada "Euskadi Ta Askatasuna" (ETA). O grupo foi formado em 1959 durante o governo de Franco, mas continuou a travar a sua violenta campanha mesmo após a restauração da democracia e do retorno de um elevado grau de autonomia regional.
Em 23 de fevereiro de 1981, elementos rebeldes entre as forças de segurança apreenderam Cortes em uma tentativa de impor um governo militar apoiado pelos Estados Unidos. O Rei Juan Carlos assumiu o comando pessoal dos militares e, com êxito, ordenou que os golpistas, através da televisão nacional, se rendessem.
Em 30 de maio de 1982 a Espanha aderiu à Organização do Tratado do Atlântico Norte (OTAN), após um referendo. Nesse ano, o Partido Socialista Operário Espanhol (PSOE) chegou ao poder, o primeiro governo de esquerda em 43 anos. Em 1986 a Espanha aderiu à Comunidade Europeia, que posteriormente tornou-se a União Europeia (UE). O PSOE foi substituído no governo pelo Partido Popular (PP) em 1996.
Em 1 de janeiro de 2002, a Espanha deixou de usar a peseta como moeda e substituíu-a pelo euro, que compartilha com outros 15 países da zona euro. O país experimentou um forte crescimento econômico, bem acima da média da UE, mas as preocupações divulgadas e emitidas por muitos comentaristas econômicos no auge do "boom" dos preços imobiliários e dos elevados défices de comércio exterior de que o país estava susceptível a passar por um doloroso colapso econômico foram confirmadas por uma grave recessão que assola o país desde 2008.
Em 11 de março de 2004, uma série de bombas explodiram em trens de Madrid. Depois de um julgamento de cinco meses em 2007, concluiu-se que os atentados foram perpetrados por um grupo islâmico militante local inspirado pela organização Al-Qaeda. As explosões mataram 191 pessoas e feriram mais de 1800, e a intenção dos autores do atentado terrorista pode ter sido influenciar o resultado da eleição geral espanhola, realizada três dias depois.
Embora as suspeitas iniciais tenham se focado no grupo basco ETA, logo surgiram evidências indicando um possível envolvimento de grupos extremistas islâmicos. Devido à proximidade da eleição, a questão da responsabilidade rapidamente se tornou uma controvérsia política, com os principais partidos concorrentes, PP e PSOE, trocando de acusações sobre a manipulação do resultado. Em 14 de março de eleições, o PSOE, liderado por José Luis Rodríguez Zapatero, obteve uma pluralidade suficiente para formar um novo gabinete, portanto, suceder a administração anterior do PP.
Nas eleições de 20 de novembro de 2011 o partido liderado por Mariano Rajoy obteve mais de votos e elegeu 186 deputados, conquistando a maioria absoluta e o melhor resultado de sempre do Partido Popular, que voltou ao poder.
Situada na Europa Ocidental, a Espanha ocupa a maior parte da Península Ibérica e, fora dela, dois arquipélagos principais (ilhas Canárias no oceano Atlântico e as ilhas Baleares no mar Mediterrâneo), duas cidades (Ceuta e Melilla, no Norte da África), a ilha de Alborão e uma série de ilha e ilhotas que se encontram frente às costas peninsulares, como as ilhas Columbretes. Ademais, consta de possessões menores continentais, como as ilhas Chafarinas, o ilhote de Vélez de la Gomera e o ilhote de Alhucemas, todas elas frente à costa africana.
Em extensão territorial, é o quarto maior país da Europa, atrás apenas da Rússia (que é o maior país do mundo, tendo em conta apenas a parte europeia), Ucrânia e França, e o segundo maior da União Europeia, atrás apenas da França.
Os limites físicos da Espanha são os seguintes: Portugal e o oceano Atlântico a oeste; o mar Mediterrâneo a leste, o Estreito de Gibraltar, mar Mediterrâneo e oceano Atlântico a sul; os Pirenéus a nordeste e o golfo da Biscaia e o mar Cantábrico a norte.
A Espanha tem um clima variado ao longo do seu território. Predomina o tipo mediterrânico em quase toda a sua geografia. As costas mediterrânicas do sul e o vale do Rio Guadalquivir têm um clima denominado mediterrânico costeiro: temperaturas e precipitações suaves quase todo o ano, exceto no verão.
À medida que se avança para o interior, o clima é mais extremo, passando o clima a ser do tipo clima mediterrânico continental, predominante em quase toda a Península: temperaturas altas no verão, baixas no inverno e precipitações irregulares (dependendo da posição geográfica).
Desde 1996 o índice de emissões de CO subiu notavelmente na Espanha, descumprindo os objetivos do Protocolo de Quioto sobre emissões geradoras do efeito estufa e contribuintes da mudança climática. Ban Ki-moon, secretário geral da ONU, pediu à Espanha uma ‘‘liderança mais ativa’‘ na luta contra a mudança climática.
A Espanha é um país especialmente afetado pelo fenômeno da seca: durante o período 1880-2000, mais da metade dos anos foram classificados como secos ou muito secos. Sete anos da década dos 80 e cinco da década de 90 foram considerados secos ou muito secos. A mudança climática prevê para a Espanha gravíssimos problemas meio ambientais, agravando as características mais extremas.
Segundo Al Gore, a Espanha é o país europeu mais vulnerável ao efeito estufa.
Em 2012, a população de Espanha oficialmente alcançou os 47 milhões de pessoas, conforme registrado pelo "Padrón municipal". A densidade populacional do país, em , é menor do que a da maioria dos países da Europa Ocidental e sua distribuição através do país é bastante desigual. Com exceção da região do entorno da capital, Madrid, as áreas mais povoadas ficam em torno da costa. A população da Espanha mais que dobrou desde 1900, quando se situava em 18,6 milhões, principalmente devido ao espetacular crescimento demográfico vivido pelo país na década de 1960 e início de 1970.
Os espanhóis nativos compõem 88% da população total da Espanha. Depois da taxa de natalidade ter caído na década de 1980, a taxa de crescimento populacional da Espanha diminuiu, mas a população novamente cresceu baseada inicialmente no regresso de muitos espanhóis que emigraram para outros países europeus durante os anos 1970 e, mais recentemente, alimentada por um grande número de imigrantes que constituem 12% da população. Os imigrantes são originários principalmente na América Latina (39%), Norte da África (16%), Europa Oriental (15%) e África subsaariana (4%). Em 2005, a Espanha instituiu um programa de anistia de três meses através do qual foi concedida residência legal à imigrantes ilegais.
Em 2008, o país concedeu a cidadania a pessoas, principalmente para pessoas vindas do Equador, Colômbia e Marrocos. Uma parte considerável dos residentes estrangeiros na Espanha também vêm de outros países da Europa Ocidental e Central. Estes são em sua maioria britânicos, franceses, alemães, holandeses e noruegueses. Eles residem principalmente na costa do Mediterrâneo e nas ilhas Baleares, onde muitos escolhem para viver sua aposentadoria.
Populações substanciais descendentes de colonos espanhóis e imigrantes existem em outras partes do mundo, com destaque para a América Latina. Começando no final do , um grande número de colonos ibéricos estabeleceram-se no que se tornou a América Latina e no momento a maior parte dos latino-americanos brancos (que representam cerca de um terço da população da América Latina) são de origem espanhola ou portuguesa. No , estima-se que espanhóis emigraram, principalmente para Peru e México. A eles se juntaram 450.000 que emigraram no século seguinte. Entre 1846 e 1932 estima-se que cerca de 5 milhões de espanhóis emigraram para a América, especialmente para Argentina, Brasil e Cuba. Cerca de dois milhões de espanhóis migraram para outros países da Europa Ocidental entre 1960 e 1975. Durante o mesmo período, cerca de foram para a América Latina.
A Espanha é o país mais tolerante em relação à homossexualidade em todo o mundo. Apenas 6% dos espanhóis dizem que a homossexualidade é "moralmente inaceitável", ao passo que 55% a consideram "moralmente aceitável" e 38% dizem que a homossexualidade "não é uma questão moral". Desde 2004 o casamento entre pessoas do mesmo sexo na Espanha é legal.
Os movimentos migratórios, tanto internos quanto externos, foram determinantes na composição demográfica moderna da Espanha. Entre o final do e início do , houve uma significativa corrente imigratória da Espanha para países ibero-americanos. Entre os principais destinos estavam Cuba, Argentina e Brasil. A densidade populacional da Espanha é menor que a da maioria dos países europeus. As populações rurais estão se movendo para as cidades. Nos últimos anos a Espanha apresenta uma considerável diminuição na taxa de imigração neta, deixando de possuir a maior taxa de imigração de Europa (em 2005 de 1,5% anual somente superado na UE pelo Chipre) atualmente sua taxa de imigração neta chega a 0,99%, ocupando a 15ª posição na União Europeia. além disso, o 9° país com maior porcentagem de imigrantes dentro da UE, abaixo de países como Luxemburgo, Irlanda, Áustria e Alemanha.
Em 2005 a Espanha recebeu 38,6% da migração para a União Europeia, principalmente de cidadãos de origem latino-americana, de outros países da Europa Ocidental, da Europa Oriental e do Magrebe. A população estrangeira na Espanha em 2007 cifrava-se em 4 144 166, um incremento de 11,1% em reação ao ano anterior. Este valor representa 9,3% dos 44 708 964 habitantes na Espanha. A comunidade marroquina, com 563 mil residentes, é a mais numerosa, seguindo-se os equatorianos (461 mil), romenos (407 mil) e britânicos (274 mil).
A Espanha é abertamente um país multilingue. O idioma oficial e o mais falado no conjunto da Espanha, por 98,9% da população, é o castelhano, língua materna de 89% dos espanhóis, que pode receber a denominação alternativa de espanhol. A estimativa do seu número de falantes em todo o mundo vai desde os 450 aos 500 milhões de pessoas, sendo a segunda língua materna mais falada depois do Chinês. Há previsões que se torne a segunda língua de comunicação internacional depois do inglês no futuro, e, após este, é a segunda língua mais estudada.
A Constituição Espanhola reconhece a riqueza linguística de Espanha como património cultural sujeito a especial respeito e proteção, e declara que o "resto de línguas espanholas" são oficiais nas comunidades autónomas segundo os seus estatutos de autonomia, apesar de ser apenas um dever e obrigação o conhecimento do castelhano.
A Espanha ratificou em 9 de abril de 2001 a Carta Europeia das Línguas Regionais ou Minoritárias. do Conselho Europeu.
O artigo 16.3 da Constituição Espanhola vigente define o país como um Estado sem confissão: ‘‘"Nenhuma confissão terá caráter estatal"‘‘. Porém, é garantida a liberdade religiosa e de culto dos indivíduos e é assegurada uma relação de cooperação entre os poderes públicos e todas as confissões religiosas.
De acordo com um estudo de 2015, cerca de 68% dos espanhóis classificaram-se como católicos romanos, 3,8% como aderentes de outras religiões (incluindo islamismo, protestantismo, budismo etc.), e cerca de 25% como ateus ou não religiosos.
De acordo com pesquisa de 2010 do "Eurobarometer", 59% da população espanhola acredita na existência de algum deus. 20% dos espanhóis acreditam na existência de algum tipo de espírito ou força vital, ao passo que 19% não acredita que exista qualquer tipo de espírito, deus, ou força vital.
A maioria dos espanhóis não frequentam templos religiosos regularmente. O estudo apontou que, dos espanhóis que se dizem religiosos, 61% raramente frequenta a missa, 14% frequenta a missa algumas vezes ao ano, 10% algumas vezes ao mês e 14% todos os domingos ou várias vezes na semana. Embora uma maioria dos espanhóis seja católica, a maior parte, especialmente os jovens, ignora as doutrinas morais conservadoras em assuntos como sexo antes do casamento, orientação sexual e métodos contraceptivos.
A segunda religião em número de membros é a muçulmana. Calcula-se que há cerca de fiéis, vindos fundamentalmente das recentes ondas de imigração. Há também um número crescente de igrejas protestantes, que somam cerca de fiéis (a estatística própria dos protestantes em Espanha indica , dos quais são espanhóis e o resto são estrangeiros que residem na Espanha durante pelo menos seis meses ao ano). Em terceiro lugar vêm as Testemunhas de Jeová com 103 784 fiéis e logo após, com cerca de fiéis, o mormonismo. A comunidade judia na Espanha não supera os fiéis.
A Espanha é uma monarquia parlamentarista, com um monarca hereditário que exerce como Chefe de Estado – o Rei da Espanha, e um parlamento bi-cameral, as "Cortes Generales".
O poder executivo é formado por um Conselho de Ministros presidido pelo Presidente do Governo, que exerce como Chefe de Governo, e o poder judicial está formado pelo conjunto de Juizados e Tribunais, integrado por Juízes e Magistrados, que têm a potestade de administrar justiça em nome do Rei. O poder legislativo se estabelece nas Cortes Gerais, que é o órgão supremo de representação do povo espanhol. As Cortes Gerais são compostas de uma câmara baixa, o Congresso dos Deputados, e uma câmara alta, o Senado.
O Congresso dos Deputados é formado por 350 membros eleitos por votação popular, em listas fechadas e através de representação proporcional mediante circunscrições provinciais, para servir em legislaturas de quatro anos. O sistema não é absolutamente proporcional, já que existe um número mínimo de cadeiras por circunscrição (3) e se usa um sistema proporcional levemente corrigido para favorecer as listas majoritárias (o Sistema d'Hondt).
O Senado possui 259 membros, dos quais 208 são eleitos diretamente mediante voto popular, por circunscrições provinciais, em cada uma das quais se elegem 4 senadores, seguindo um sistema majoritário (3 para a lista majoritária, 1 para a seguinte), exceto nas ilhas Baleares e nas ilhas Canárias, onde cada circunscrição é uma ilha. Os outros 51 são designados pelos órgãos regionais para servir, também, por períodos de quatro anos.
No dia 2 de junho de 2014, o rei Juan Carlos I renunciou a favor do seu filho, Felipe de Bourbon, foi a primeira vez em mais de 50 anos que um rei abdica do trono na Espanha.
Após o retorno da democracia após a morte de Francisco Franco em 1975, as prioridades da política externa da Espanha foram sair do isolamento diplomático, entrar na Comunidade Europeia e definir relações de segurança com o mundo ocidental. Como membro da OTAN desde 1982, a Espanha se estabeleceu como participante nas atividades multilaterais de segurança internacional. A adesão da Espanha à União Europeia representa uma parte importante da sua política externa, visto que o país prefere coordenar seus esforços com seus parceiros da UE através dos mecanismos de cooperação política europeia. A Espanha manteve suas relações especiais com a América hispânica e as Filipinas. Sua política enfatiza o conceito de uma comunidade ibero-americana, essencialmente a renovação do conceito historicamente liberal de "Hispanismo", que busca ligar a Península Ibérica com a América hispânica através de idioma, comércio, história e cultura.
A Espanha reivindica Gibraltar, um território britânico ultramarino de 6 quilômetros quadrados, na parte mais meridional da Península Ibérica. Então uma cidade espanhola, foi conquistado por uma força anglo-holandesa em 1704 durante a Guerra da Sucessão Espanhola em nome do Arquiduque Carlos, pretendente do trono espanhol. A situação jurídica relativa a Gibraltar foi resolvida em 1713 pelo Tratado de Utrecht, no qual a Espanha cedeu o território perpetuamente à Coroa britânica, afirmando que, se os britânicos abandonassem o local, ele seria oferecido à Espanha em primeiro lugar. Desde a década de 1940, a Espanha pediu o retorno de Gibraltar. A esmagadora maioria dos gibraltânicos se opõe fortemente a isso, assim como rejeitam qualquer proposta de soberania compartilhada. As resoluções da ONU apelam ao Reino Unido e à Espanha para chegarem a um acordo sobre o estatuto de Gibraltar.
Outra reivindicação da Espanha é sobre as Ilhas Selvagens, uma reivindicação não reconhecida por Portugal. A Espanha afirma que são rochas e não ilhas, alegando que não há águas territoriais portuguesas em torno das ilhas em disputa. Em 5 de julho de 2013, a Espanha enviou uma carta à ONU que expressava esses pontos de vista.
As forças armadas da Espanha são conhecidas como as Forças Armadas Espanholas (). Seu comandante-em-chefe é o rei da Espanha, Felipe VI.
As Forças Armadas espanholas estão divididas em três ramos:
Desde a Constituição de 1978 que a Espanha está dividida em 17 comunidades autônomas e as duas cidades autônomas de Ceuta e Melilla, gozando estas de estatuto intermediário entre o município e a Comunidade. Das 17 comunidades autônomas, quatro delas (Galiza, País Basco, Andaluzia e Catalunha) possuem condição de "Nacionalidades Históricas" reconhecidas na Constituição, juntamente com um "Estatuto de autonomia", o que reverte num maior poder e capacidade de decisão e soberania com respeito às outras comunidades.
As comunidades dividem-se ainda em cinquenta províncias.
Lista das comunidades e cidades autônomas:
A Espanha é na atualidade o que se denomina um "Estado de Autonomias", um país formalmente unitário, mas que funciona como uma federação descentralizada de comunidades autônomas, cada uma delas com diferentes níveis de autonomia. As diferenças dentro deste sistema são provocadas pelo processo de transferência de responsabilidades do governo central para as regiões foi pensado em um princípio como um processo, que garantisse um maior grau de autonomia somente àquelas comunidades que buscavam um tipo de relação mais federalista com o resto da Espanha (as chamadas "comunidades autônomas de regime especial": Andaluzia, Catalunha, Galiza, Navarra e País Basco). Por outro lado, o resto de comunidades autônomas ("comunidades autônomas de regime comum") teria uma menor autonomia. Porém, estava previsto que ao longo dos anos, estas comunidades fossem adquirindo gradativamente maior autonomia.
Hoje em dia, a Espanha está considerada como um dos países europeus mais descentralizados, pois todos os seus diferentes territórios administram de forma local seus sistemas de saúde e educativos, assim como alguns aspetos do orçamento público; alguns deles, como o País Basco e Navarra, administram seu orçamento sem praticamente contar, excetuado em alguns aspetos, com a supervisão do governo central espanhol. Catalunha, Navarra e o País Basco possuem suas próprias polícias totalmente operativas e completamente autônomas. Excetuando Navarra (cuja polícia se chama "Policía Foral de Navarra"), tanto a polícia da Catalunha ("Mossos d'Esquadra") como a polícia do País Basco ("Ertzaintza") substituem as funções da Polícia Nacional da Espanha em seus respetivos territórios. Navarra ainda está em processo de transferência de funções.
Existem na Espanha diversos movimentos políticos de posição separatista, ligados a nacionalismos periféricos, como o nacionalismo basco, o nacionalismo galego, o nacionalismo catalão, que reclamam a independência da Espanha dos territórios em que são ativos. Estes movimentos acontecem na Catalunha, Galiza, Navarra e no País Basco, onde existem partidos explicitamente separatistas como a "União do Povo Galego" (UPG), "Esquerda Republicana da Catalunha", "Aralar", o "Eusko Alkartasuna", assim como os seguidores da chamada "esquerda abertzale" que não se desvinculam do ETA (sua última denominação formal é Batasuna, partido ilegalizado em Espanha, mas legal em França). Por outro lado, partidos como o "Bloco Nacionalista Galego" (BNG), "Partido Nacionalista Basco" (PNV) e "Convergència i Unió" (CiU) oscilam entre posturas autonomistas e abertamente separatistas.
A economia mista capitalista da Espanha é a décima segunda maior economia do mundo em PIB (PPC), a nona maior por PIB nominal e a quinta maior na União Europeia, bem como a quarta maior da Zona Euro. O país é também o terceiro maior investidor do mundo.
O governo de centro-direita do ex-primeiro-ministro José María Aznar teve sucesso para ser admitido no grupo de países que lançaram o euro em 1999. A taxa de desemprego situava-se em 7,6% em outubro de 2006, uma taxa que comparavelmente favorável a de muitos outros países europeus e especialmente com o início dos anos 1990 quando se situava em mais de 20%. Os pontos fracos perenes da economia espanhola incluem alta inflação, uma grande economia informal e um sistema educativo que os relatórios da OCDE classificam entre os piores entre os países desenvolvidos, em conjunto com os Estados Unidos e o Reino Unido.
No entanto, a bolha imobiliária que começou a se formar a partir de 1997, alimentada por taxas de juros historicamente baixas e uma onda imensa de imigração, implodiu em 2008 e levou a economia a um rápido enfraquecimento e a um aumento do desemprego. Até o final de maio de 2009, o desemprego atingiu 18,7% (37% para os jovens).
Antes da atual crise, a economia espanhola era creditada por ter evitado uma taxa de crescimento virtual zero como alguns de seus maiores parceiros na União Europeia apresentaram. Na verdade, a economia do país criou mais de metade de todos os novos postos de trabalho na União Europeia durante cinco anos até 2005, um processo que está sendo rapidamente revertido. A economia espanhola, até há pouco tempo, era considerada uma das mais dinâmicos da União Europeia, atraindo uma quantidade significativa de investimentos estrangeiros.
O crescimento econômico mais recente foi grandemente beneficiado pelo "boom" imobiliário mundial, com o setor de construção civil representando surpreendentes 16% do PIB do país e 12% dos empregos no seu último ano.
Segundo cálculos do jornal alemão "Die Welt", a Espanha estava a caminho de ultrapassar países como a Alemanha em renda per capita até 2011. No entanto, o PIB per capita da Espanha ainda era inferior à média da União Europeia, que era de US$ 29.875 dólares em 2010, tornando-se o segundo mais baixo da Europa Ocidental, depois do de Portugal. O lado negativo do agora extinto "boom" imobiliário é também um correspondente aumento nos níveis de endividamento pessoal: o nível médio de endividamento das famílias triplicou em menos de uma década. Isto pôs grande pressão em cima de uma renda mais baixa para os grupos de renda média; até 2005, o nível médio de endividamento em relação a renda havia crescido para 125%, devido principalmente ao "boom" de hipotecas caras, que hoje muitas vezes excedem o valor da propriedade.
De 1869 a 2002, a moeda da Espanha foi a peseta. O país é um dos membros fundadores do euro, que entrou em circulação em 2002. As moedas de euro espanholas designadas para circulação mostram a efígie do Rei Juan Carlos.
Em 2008/2009, o arrocho do crédito e a recessão mundial manifestaram-se na Espanha através de uma enorme recessão no setor imobiliário. Contudo, os bancos da Espanha e os serviços financeiros evitaram os problemas mais graves dos seus congéneres nos Estados Unidos e no Reino Unido, devido principalmente a um regime financeiro conservador e regulamentado rigorosamente respeitado. Na verdade, o maior banco da Espanha, o Banco Santander, participou da ajuda do governo do Reino Unido ao setor bancário britânico.
A Comissão Europeia previu que a Espanha iria entrar em recessão econômica até o final de 2008. Segundo o Ministro das Finanças da Espanha, "a Espanha enfrenta a sua pior recessão em meio século".
Durante as últimas quatro décadas, a indústria turística espanhola cresceu e se tornou a segunda maior do mundo, alcançando o valor de cerca de 40 bilhões de euros, cerca de 5% do PIB do país, em 2006. Hoje, o clima da Espanha, a história e os monumentos culturais e sua posição geográfica, juntamente com as suas instalações, fazem do turismo uma das principais indústrias nacionais da Espanha e uma grande fonte de emprego estável e de desenvolvimento.
A educação estatal na Espanha é gratuita e obrigatória dos 6 aos 16 anos de idade. O sistema educacional atual foi estabelecido pela lei educacional de 2006, a LOE ("Ley Orgánica de Educación") ou Lei Orgânica de Educação. Em 2014, a LOE foi parcialmente modificada pela lei LOMCE mais nova e controversa ("Ley Orgánica para la Mejora de la Calidad Educativa"), ou Lei Orgânicapara a Melhoria do Sistema Educacional, comumente chamada "Ley Wert". Desde 1970 a 2014, a Espanha teve sete leis educacionais diferentes (LGE, LOECE, LODE, LOGSE, LOPEG, LOE e LOMCE).
A Institución Libre de Enseñanza foi um projeto educacional que se desenvolveu em Espanha por meio século, de 1876 até 1936, por Francisco Giner de los Ríos e Gumersindo de Azcárate. O instituto inspirou-se na filosofia do krausismo. Concepción Arenal no feminismo e Santiago Ramón y Cajal na neurociência estavam no movimento.
O território espanhol carece de petróleo, o que faz das fontes alternativas de energia um fator estratégico para o país, sendo registrados importantes recordes pela Espanha. Em 2010, os espanhóis superaram os Estados Unidos como líderes mundiais em energia solar, com uma planta de grande potência na estação chamada La Florida, perto de Alvarado, Badajoz. Em 2009, mais de 50% da energia produzida em Espanha foi gerada por moinhos de vento e o registro de maior produção total de energia eólica foi alcançado com megawatts.
O sistema rodoviário espanhol é principalmente centralizado, com seis rodovias que ligam Madrid ao País Basco, Catalunha, Valência, Andaluzia Ocidental, Extremadura e Galícia. Além disso, existem rodovias ao longo das costas do Atlântico (Ferrol a Vigo), Cantabria (Oviedo a São Sebastião) e Mediterrâneo (Girona a Cádiz). A Espanha estabeleceu a meta de colocar um milhão de carros elétricos nas estradas até 2014 como parte do plano do governo para economizar energia e aumentar a eficiência energética. O ex-ministro da Indústria, Miguel Sebastián, disse que "o veículo elétrico é o futuro e o motor de uma revolução industrial".
A Espanha possui a mais extensa rede ferroviária de alta velocidade na Europa e a segunda mais extensa do mundo, depois da China. Em outubro de 2010, a o país possuía um total de 3.500 km de trilhos de alta velocidade ligando Málaga, Sevilha, Madrid, Barcelona, Valência e Valladolid, com trens com velocidades até 300 km/h. Em média, o trem de alta velocidade espanhol é o mais rápido do mundo, seguido do trem-bala japonês e do TGV francês. Em relação à pontualidade, é o segundo lugar no mundo (98,54% de chegada no horário) após o japonês Shinkansen (99%). Caso os objetivos do ambicioso programa AVE (trens de alta velocidade espanhóis) sejam atendidos, até 2020, a Espanha terá 7.000 km de trens-bala que ligam quase todas as cidades provinciais a Madrid em menos de três horas e a Barcelona em quatro horas.
Existem 47 aeroportos públicos na Espanha. O mais movimentado é o aeroporto de Madrid (Barajas), com 50 milhões de passageiros em 2016, sendo o 25º aeroporto mais movimentado do mundo, bem como o quarto mais ocupado da União Europeia. O aeroporto de Barcelona (El Prat) também é importante, com 44 milhões de passageiros em 2016, sendo o 33º aeroporto mais movimentado do mundo. Outros principais aeroportos estão localizados em Maiorca (23 milhões de passageiros), Málaga (13 milhões de passageiros), Las Palmas (11 milhões de passageiros), Alicante (10 milhões de passageiros) e menores, com número de passageiros entre 4 e 10 Milhões, como o aeroporto de Tenerife (dois aeroportos), Valência, Sevilha, Bilbao, Ibiza, Lanzarote e Fuerteventura. Além disso, mais de 30 aeroportos com o número de passageiros abaixo de 4 milhões.
Os portos e portos mais importantes são Algeciras, Barcelona, Valência e Bilbao outros: Cádiz, Cartagena, Ceuta, Huelva, La Coruña, Las Palmas, Málaga, Melilla, Gijón, Palma de Maiorca, Sagunto, Santa Cruz de Tenerife, Los Cristianos (Tenerife), Santander, Tarragona, Vigo, Motril, Almería, Sevilha, Castellón de la Plana, Alicante, Pasaia, Avilés e Ferrol.
O sistema de saúde da Espanha ("Sistema Nacional de Saúde") é considerado um dos melhores do mundo, na 7ª posição no ranking elaborado pela Organização Mundial da Saúde (OMS). A assistência médica é pública, universal e gratuita para qualquer cidadão espanhol. O gasto total em saúde é de 9,4% do PIB, um pouco acima da média de 9,3% da OCDE.
A Espanha é conhecida pelo seu patrimônio cultural diversificado, tendo sido influenciado por muitas nações e povos ao longo de sua história. A cultura espanhola tem suas origens nas culturas ibérica, celta, celtibera, latina, visigótica, católica romana, e islâmica.
A definição de uma cultura nacional espanhola tem sido caracterizada pela tensão entre o estado centralizado, dominado nos últimos séculos por Castela, e muitas regiões e povos minoritários. Além disso, a história da nação e de seu ambiente mediterrânico e atlântico desempenharam papéis importantes na formação de sua cultura. Depois da Itália, a Espanha é o país com o maior número de Patrimônios da Humanidade da UNESCO no mundo, com um total de 40.
Devido à diversidade histórica, geográfica e de gerações, a literatura espanhola tem passado por um grande número de influências e é muito diversificada. Alguns grandes movimentos literários podem ser identificados dentro dela.
Miguel de Cervantes é provavelmente o autor mais famoso da Espanha, e sua obra "Dom Quixote" é considerado a obra mais emblemática no cânone da literatura espanhola e um clássico fundador da literatura ocidental.
A música espanhola é muitas vezes considerada exterior como sinônimo de flamenco, um gênero musical do oeste da Andaluzia que, ao contrário da crença popular, não é muito comum fora dessa região. Vários estilos regionais de música folclórica abundam em Aragão, Catalunha, Valência, Castela, País Basco, Galiza e Astúrias. Pop, rock, hip hop e heavy metal também são populares.
No campo da música clássica, a Espanha produziu uma série de compositores notáveis como Isaac Albéniz, Manuel de Falla e Enrique Granados e cantores e artistas como Plácido Domingo, José Carreras, Montserrat Caballé, Alicia de Larrocha, Alfredo Kraus, Pablo Casals, Ricardo Viñes, José Iturbi, Pablo de Sarasate, Jordi Savall e Teresa Berganza. Na Espanha, existem mais de 40 orquestras profissionais, incluindo o Orquestra Sinfônica de Barcelona e Nacional da Catalunha, Orquestra Nacional de Espanha e a Orquestra Sinfônica de Madrid. As casas de ópera mais importantes incluem o Teatro Real, o "Gran Teatre del Liceu", o Teatro Arriaga, o Palácio Euskalduna e o Palácio das Artes Rainha Sofia.
Milhares de fãs de música também viajam para a Espanha a cada ano para o festival de música reconhecido internacionalmente "Sónar" que muitas vezes apresenta os próximos artistas pop e techno, e "Benicàssim", que tende a característica de rock alternativo e atos de dança. Ambos os festivais marcam uma presença internacional de música e refletir o gosto dos jovens no país.
O mais popular instrumento musical tradicional, a guitarra, tem origem na Espanha. Típicos do norte são os "gaiteros", principalmente nas Astúrias e Galiza.
Artistas da Espanha têm sido altamente influentes no desenvolvimento de vários movimentos artísticos europeus. Devido à diversidade histórica, geográfica e de gerações, a arte espanhola tem conhecido um grande número de influências.
A herança mourisca na Espanha, especialmente na Andaluzia, é ainda hoje evidente em cidades como Córdova, Sevilha e Granada. Influências europeias incluem Itália, Alemanha e França, especialmente durante os períodos barroco e neoclássico.
Devido à sua diversidade histórica e geográfica, a arquitetura espanhola tem atraído a partir de uma série de influências. Uma cidade importante da província fundada pelos romanos e com uma infraestrutura extensa da era romana, Córdova se tornou a capital cultural, incluindo uma arquitetura em estilo árabe, feita durante a época do Califado Omíada. A arquitetura de estilo árabe mais tarde continuou a ser desenvolvida sob as sucessivas dinastias islâmicas, terminando com os Nasridas, que construíram seu famoso complexo do palácio em Granada.
Simultaneamente, os reinos cristãos gradualmente surgiram e desenvolveram seus próprios estilos, desenvolvendo um estilo pré-românico, quando por um tempo isolado das principais influências arquitetônicas contemporâneas europeias durante o início da Idade Média, que mais tarde integraram os fluxos românico e gótico.
Houve então um extraordinário florescimento do estilo gótico, que resultou em inúmeras construções que forma sendo construídas em todo o território. O estilo mudéjar, a partir dos séculos XII a XVII, foi desenvolvido através da introdução de motivos de estilo árabe, padrões e elementos em arquitetura europeia.
A chegada do modernismo na área acadêmica produziu grande parte da arquitetura do . Um estilo influente no centro de Barcelona, conhecido como modernismo catalão, produziu uma série de importantes arquitetos, dos quais Gaudí é um deles. O estilo internacional foi liderado por grupos como GATEPAC. A Espanha está atualmente a viver uma revolução na arquitetura contemporânea e arquitetos espanhóis como Rafael Moneo, Santiago Calatrava, Ricardo Bofill, entre outros, ganharam renome mundial.
A Volta a Espanha ("Vuelta a España" ou simplesmente "Vuelta") é um dos principais eventos esportivos do país, que junto ao Giro d’Italia e o Tour de France, é uma das três "Grandes Voltas" do ciclismo mundial. A "Vuelta" teve sua primeira edição em 1935, porém não houve edições durante a Segunda Guerra Mundial. Teve seu retorno em 1955 até atualmente. Até 2009 foram realizadas 63 edições da "Vuelta a España".
Os esportes na Espanha são dominados, principalmente, pelo ciclismo, o futebol (desde o ), o basquete, o ténis, o andebol, e pelos esportes de motor, principalmente o Motociclismo. A partir dos Jogos Olímpicos de 1992, disputados na cidade de Barcelona, o país entrou na elite mundial em diversos esportes. Tem como maior ídolo no esporte Alberto Contador, da equipe Astana Pro Cycling Team. Contador é vencedor do Tour de France 2007 e 2009, além do Giro d'Italia 2008 e Volta a Espanha também em 2008, entre outras vitórias em voltas. É considerado o melhor ciclista da atualidade, e um dos grandes nomes do esporte de todos os tempos. Em 2010 a Espanha consagrou-se campeã de futebol mundial, tendo vencido a Copa do Mundo na África do Sul e tornou-se a única seleção de futebol a ser campeã do mundo e bicampeã da Europa, tendo vencido os campeonatos europeus de 2008, realizado na Suíça e na Áustria, e 2012, na Polónia e Ucrânia.
Na Espanha se conserva a tradição de realizar diversos espetáculos taurinos, tais como os "encierros" (corridas nas quais as pessoas correm junto aos touros pelas ruas) e as ‘‘corridas de toros’‘ (touradas), que fazem parte da identidade de numerosas festas populares. As praças de touros com maior relevância na temporada taurina são a de "Las Ventas" em Madrid, a "Monumental" em Pamplona, a "Maestranza" em Sevilha e a de Valência.
A televisão é o principal meio de comunicação audiovisual do país, com emissoras nacionais, regionais e locais. As principais emissoras são a , , , Cuatro, Telecinco e .
Na imprensa, os principais jornais de circulação nacional são "El País", ', "ABC", "La Razón" e '. Na imprensa esportiva, destacam-se os jornais "Marca" e "As".

"Rutherford é redirecionado para esta página. Se procura outros significados de Rutherford, consulte Rutherford (desambiguação)."
Ernest Rutherford, o 1º Barão Rutherford de Nelson, (Brightwater, Nova Zelândia, — Cambridge, ), foi um físico e químico neozelandês naturalizado britânico, que se tornou conhecido como o pai da física nuclear. Num trabalho no começo da carreira, descobriu o conceito de meia-vida radioativa, provou que a radioatividade causa a transmutação de um elemento químico em outro, e também distinguiu e nomeou as radiações alfa e beta. Foi premiado com o Nobel de Química em 1908 "por suas investigações sobre a desintegração dos elementos e a química das substâncias radioativas".
Rutherford realizou sua obra mais famosa após ter recebido esse prêmio. Em 1911, ele defendeu que os átomos têm sua carga positiva concentrada em um pequeno núcleo, e, desse modo, criou o modelo atômico de Rutherford, ou modelo planetário do átomo, através de sua descoberta e interpretação da dispersão de Rutherford em seu experimento da folha de ouro. A ele é amplamente creditada a primeira divisão do átomo, em 1917, liderando a primeira experiência de "dividir o núcleo" de uma forma controlada por dois alunos sob sua direção, John Cockcroft e Ernest Walton.
Dedicada à sua memória, a Medalha e Prêmio Rutherford foi instituída pelo Conselho da Sociedade de Física em 1939. A primeira palestra ocorreu em 1942. A palestra foi convertida em uma medalha e prêmio em 1965, sendo a primeira Medalha e Prêmio Rutherford concedida no ano seguinte.
Ernest Rutherford nasceu em Spring Grove (atual Brightwater), cidade portuária da ilha sul da Nova Zelândia, o quarto filho e segundo homem de uma família de sete filhos e cinco filhas. Seu pai, James Rutherford, um mecânico escocês, emigrou para a Nova Zelândia com toda a família em 1842. Sua mãe, nascida Martha Thompson, uma professora de inglês, com sua mãe viúva, também se mudou em 1855.
Ernest recebeu a sua educação em escolas públicas. Aos 16 anos entrou em Nelson Collegiate School. Graduou-se em 1893 em Matemática e Ciências Físicas na Universidade da Nova Zelândia. Após ter concluído os estudos, ingressou no Trinity College, Cambridge, como um estudante na investigação do Laboratório Cavendish sob a coordenação de J. J. Thomson. Foi na Inglaterra que Rutherford estudou as radiações de Urânio em pesquisas feitas em colaboração com o Frederick Soddy. Em 1902, ambos distinguem os raios alfa e beta e desenvolvem a teoria das desintegrações radioativas espontâneas. Uma oportunidade surgiu quando o lugar de professor de Física na Universidade McGill, em Montreal ficou vago. Em 1898 partiu para o Canadá, para assumir o posto. No mesmo ano, foi nomeado professor de Física da Universidade McGill, em Montreal, e em 1907 na Universidade Victoria em Manchester. Nessa época, Ernest formulou a hipótese de que a radiatividade não se tratava de um fenômeno comum a todos os átomos, mas somente de uma certa categoria. Esses estudos resultaram o livro Radiatividade, verdadeiro marco na história do progresso científico.
Apesar de ser um físico, recebeu o Nobel de Química de 1908, por suas investigações sobre a desintegração dos elementos e a química das substâncias radioativas.
Ainda em Manchester, trabalhando em conjunto com Hans Geiger e Thomas Royds, Rutherford elucidou a natureza da chamada radiação alfa. Após comprovar que esta é formada por partículas com o dobro da carga elétrica de um elétron, em 1907 Rutherford e seus colegas elaboraram um experimento engenhoso no qual partículas alfa foram acumuladas em um tubo de vidro evacuado. Ao passar uma corrente elétrica pelo tubo, puderam observar claramente o espectro do gás hélio, provando assim que as partículas alfa eram na verdade átomos de hélio ionizados, mais tarde identificados como núcleos de hélio.
Rutherford realizou seus trabalhos mais famosos depois de receber o prêmio Nobel de 1908. Sob sua direção, em 1909 Hans Geiger e Ernest Marsden realizaram o famoso experimento (muitas vezes chamado no Brasil de "Experimento de Rutherford"), o qual demonstrou a natureza nuclear dos átomos através da deflexão de partículas alfa atravessando uma fina folha de ouro. Nesse experimento, Rutherford pediu a Geiger e Marsden que procurassem por partículas alfa defletidas por ângulos muito grandes, algo que não seria esperado dadas as teorias atômicas da época. Embora raras, tais deflexões foram de fato observadas, algo que Rutherford mais tarde descreveu como "... o evento mais incrível que aconteceu comigo em toda a minha vida. Foi quase tão incrível quanto se você atirasse um projétil de 15 polegadas num lenço de papel e ele ricocheteasse de volta e o atingisse". Para conseguir explicar a forma precisa com que as deflexões dependiam do ângulo, Rutherford foi levado em 1911 a formular o modelo atômico que leva seu nome - no qual concebeu o átomo como constituído de um núcleo minúsculo de carga positiva, contendo quase toda a massa do átomo, e orbitado por elétrons. Baseado na concepção de Rutherford, o físico dinamarquês Niels Bohr idealizaria mais tarde um novo modelo atômico.
Em 1919, antes de deixar Manchester para assumir a direção do Laboratório Cavendish em Cambridge, Rutherford se tornou a primeira pessoa a deliberadamente transmutar um elemento em outro. Bombardeando nitrogênio puro com radiação alfa, ele foi capaz de converter núcleos de nitrogênio em oxigênio. Nos produtos dessa reação nuclear, identificou partículas idênticas a núcleos de hidrogênio, demonstrando que estes eram partes constituintes do núcleo de nitrogênio - e, por inferência, provavelmente de outros núcleos também. Tal construção já havia sido suspeitada há tempos devido ao fato de a massa atômica de todos os elementos serem aproximadamente um múltiplo da do hidrogênio (Hipótese de Prout). Por conta dessas considerações, em 1920 Rutherford postulou então que o núcleo de hidrogênio deveria ser uma partícula fundamental, que ele denominou próton, a qual seria o elemento constituinte de todos os demais núcleos. Tais fatos levaram a que Rutherford fosse considerado como o fundador da Física Nuclear.
Rutherford dirigiu o Laboratório Cavendish desde 1919 até à sua morte, período em que foi Professor Cavendish de Física. Sua liderança e trabalho inspiraram duas gerações de cientistas.
Foi presidente da Royal Society de 1925 a 1930.
Recebeu a Ordem de Mérito em 1925 e em 1931 foi condecorado Baron Rutherford de Nelson, Cambridge, um título que foi extinto depois da sua inesperada morte, enquanto aguardava uma cirurgia de hérnia umbilical. Após tornar-se um Lord, ele só poderia ser operado por um médico também nobre (uma exigência do protocolo britânico) e essa demora custou-lhe a vida. Morreu em 19 de outubro de 1937 em Cambridge, e suas cinzas foram enterradas na Abadia de Westminster, perto das tumbas de Isaac Newton e outros grandes cientistas.
Participou da 1ª, 2ª, 3ª, 4ª e 7ª Conferência de Solvay.

Enrico Fermi (Roma, — Chicago, ) foi um físico italiano naturalizado estadunidense.
Destacou-se pelo seu trabalho sobre o desenvolvimento do primeiro reator nuclear, e pela sua contribuição ao desenvolvimento da teoria quântica, física nuclear e de partículas, e mecânica estatística. Doutorou-se na Universidade de Pisa e recebeu o Prémio Nobel de Física em 1938.
Foi um dos poucos físicos da era moderna a combinar a teoria com a experiência. Após alguns anos na Alemanha, regressou à Universidade de Roma, onde, em 1926, dedicou-se à mecânica estatística de partículas que obedecem ao princípio de exclusão de Pauli, como os electrões. O resultado é a chamada estatística de Fermi-Dirac, uma vez que Dirac chegou independentemente às mesmas conclusões. Em 1933 Fermi introduziu o conceito de interação fraca, que em conjunto com o recém postulado neutrino, entrariam na teoria do decaimento beta. Juntamente com um grupo de colaboradores, Fermi começou uma série de experiências nas quais foram produzidos artificialmente núcleos radioativos, pelo bombardeamento com neutrões de vários elementos. Alguns dos seus resultados sugeriram a formação de elementos transuranianos. De facto, o que eles observaram, e que mais tarde foi comprovado por Otto Hahn, foi a fissão nuclear, feito que, em 1938, lhe rendeu o Prêmio Nobel de Física. Foi então para os Estados Unidos, onde viria a participar no projeto Manhattan. Dirigiu o projecto de construção do primeiro reator nuclear na Universidade de Chicago. Depois da Segunda Guerra Mundial, Fermi dedicou-se à Física de partículas, a que deu contribuições importantes. O elemento químico de número atômico 100, criado sinteticamente em 1952, recebeu o nome de Férmio em sua honra.
Enrico Fermi nasceu em Roma, Itália. Ele era o terceiro filho de Alberto Fermi, inspetor-chefe do Ministério das Comunicações da Itália, e sua mãe era Ida de Gattis, professora de uma escola primária. Sua irmã, Maria, era dois anos mais velha que ele, enquanto seu irmão, Giulio, era um ano mais velho. Desde jovem Fermi gostava de estudar física e matemática, interesses também de seu irmão mais velho. Sua família nunca foi muito religiosa, e Fermi foi um agnóstico sua vida inteira. Quando Giulio morreu inesperadamente de um abcesso na garganta em 1915, Enrico ficou emocionalmente arrasado, e refugiou-se em estudos científicos para se distrair. De acordo com ele mesmo, todos os dias caminhava em frente ao hospital onde Giulio morreu, até se acostumar com a dor. Numa banca do Campo de' Fiori, Fermi comprou e leu o livro intitulado "Elementorum physicae mathematicae" (900 páginas), escrito em latim pelo padre Andrea Caraffa, professor do Collegio Romano, que abordava matemática, mecânica clássica, astronomia, óptica e acústica. Mais tarde, Fermi e seu melhor amigo, outro estudante inclinado para a ciência, chamado Enrico Persico, empenharam-se em projetos científicos, tais como construir giroscópios e medir o campo magnético da Terra. O interesse de Fermi pela física foi ainda mais incentivado quando um amigo de seu pai, o engenheiro Adolfo Amidei, lhe deu vários livros sobre física e matemática, que Fermi leu e assimilou rapidamente.
Em 1918 Fermi matriculou-se na "Escola Normal Superior" em Pisa, onde mais tarde recebeu o seu diploma de graduação e de doutorado. Para entrar na prestigiada instituição, havia um exame para os candidatos, que incluía um ensaio. Pelo seu ensaio sobre o tema dado, "Características do som", Fermi, com 17 anos de idade, escolheu derivar e resolver a transformada de Fourier baseada na equação diferencial parcial das ondas numa corda. O examinador, professor Giulio Pittato, entrevistou Fermi e concluiu que o seu ensaio teria sido digno de louvor mesmo para um doutorado. Enrico Fermi ficou com o primeiro lugar na classificação do exame de entrada. Durante os anos na Scuola Normale Superiore, Fermi formou equipe com um colega estudante Franco Rasetti, que mais tarde, se tornou o mais próximo amigo e colaborador de Fermi.
Além de frequentar as aulas, Enrico Fermi encontrou tempo para trabalhar nas suas atividades extracurriculares, particularmente com a ajuda de seu amigo Enrico Persico, que permaneceu em Roma para estudar numa universidade. Entre 1919 e 1923 Fermi estudou, por si mesmo, relatividade geral, mecânica quântica e física atômica.
Os seus conhecimentos de física quântica atingiram um nível tão elevado que o chefe do Instituto de Física, professor Luigi Puccianti, pediu-lhe para organizar seminários sobre o assunto. Durante esse tempo ele aprendeu cálculo tensorial, um instrumento matemático inventado por Gregorio Ricci-Curbastro e Tullio Levi-Civita, e necessário para demonstrar os princípios da relatividade geral.
Em setembro de 1920, Fermi ingressou no Instituto de Física. Como só havia, além de Fermi, mais dois estudantes nesse departamento, Puccianti deixava-os usar o laboratório livremente para os fins que desejassem. Fermi decidiu então que deviam começar a pesquisar a cristalografia de raios-X. Os três estudantes trabalharam para produzir uma Fotografia de Laue - uma fotografia de um cristal feita por raios-X.
Em 1921, seu terceiro ano na universidade, publicou os seus primeiros trabalhos científicos no periódico italiano "Il Nuovo Cimento". O primeiro foi intitulado: "Sobre a dinâmica de um rígido sistema de cargas elétricas em condições transientes"; o segundo: "Sobre a eletrostática de um campo gravitacional uniforme de cargas eletromagnéticas e sobre o peso de cargas eletromagnéticas". Um sinal de que as concepções na Física estavam mudando foi que a massa começou, então, a ser expressa como um tensor, uma ferramenta matemática usada, geralmente, para descrever algo que se move e varia no espaço tridimensional. Na mecânica clássica, a massa é uma grandeza escalar, mas na relatividade ela muda com a velocidade. Usando a relatividade, Fermi provou que uma carga possui um peso igual a U/c², sendo U a energia do sistema e c a velocidade da luz. Porém, à primeira vista, a primeira publicação parecia apontar para uma contradição entre a teoria eletrodinâmica e a relativística em relação ao cálculo das massas eletromagnéticas, visto que o valor anteriormente previsto era de 4/3 U/c². Um ano depois, com um trabalho intitulado "Correção da discrepância entre a teoria eletrodinâmica e um relativista de cargas eletromagnéticas, Enrico Fermi mostrou que essa discrepância era consequência da relatividade. Esta publicação teve tanto sucesso que foi traduzida para o alemão e publicada no famoso periódico científico alemão "Physikalische Zeitschrift".
Em 1922 publicou o seu importante trabalho científico no periódico italiano "I Rendiconti dell'Accademia dei Lincei" intitulado "Sobre os fenômenos que ocorrem nas proximidades de uma linha de mundo" ). Nesse artigo, Fermi examinou o Princípio da Equivalência e introduziu as chamadas Coordenadas de Fermi. Ele provou que, para uma linha de mundo próxima a uma linha do tempo, o espaço comporta-se como um Espaço Euclidiano. Finalmente, em 1922, Fermi recebeu o seu diploma de graduação na Scuola Normale Superiore ao apresentar a sua tese chamada "Um teorema de probabilidade e suas aplicações", obtendo laurea com impressionantes 21 anos. Nessa época, a física teórica ainda não era considerada uma disciplina na Itália, portanto a única tese aceita seria de física experimental. Por isso, Fermi usou imagens de difração de raios-X para enriquecer seu trabalho. Os físicos italianos também levaram algum tempo para assimilar as ideias da relatividade geral vindas da Alemanha.
Enquanto escrevia um apêndice para a versão italiana do livro "The Mathematical Theory of Relativity, "de August Kopff em 1923, Fermi descobriu um enorme potencial energético nuclear escondido na famosa equação de Einstein (E=mc²), e que podia ser explorado. "Não parece possível, pelo menos num futuro próximo", ele escreveu, "achar uma maneira de liberar essas enormes quantidades de energia - o que é algo bom, pois a primeira consequência desse fenômeno seria reduzir a pó o físico que tivesse o azar de realizá-lo."
O orientador de doutorado de Fermi foi Luigi Puccianti. Em 1924, Fermi passou um semestre em Göttingen estudando com Max Born, onde também conheceu Werner Heisenberg e Pascual Jordan. Fermi então foi para Leiden para estudar com Paul Ehrenfest de setembro a dezembro de 1924, conhecendo Albert Einstein, Hendrik Lorentz e também Samuel Goudsmit e Jan Tinbergen, que se tornaram seus bons amigos. Do início de 1925 ao final de 1926, Fermi lecionou física matemática e mecânica teórica na Universidade de Florença, onde se juntou com Rasetti para conduzir uma série de experimentos sobre os efeitos do campo magnético no vapor de mercúrio. Fermi também participou de seminários na Sapienza University of Rome, dando palestras sobre mecânica quântica e física dos estados sólidos.
Depois que Wolfgang Pauli anunciou seu princípio da exclusão, em 1925, Fermi respondeu-o com um artigo "Sobre a quantização do gás perfeito monoatômico", no qual ele aplicou o princípio de Pauli a um gás ideal. O mesmo raciocínio desse artigo foi desenvolvido independentemente por outro físico chamado Paul Dirac. Juntos e, ao mesmo tempo, separados, os dois cientistas formaram a famosa estatística de Fermi-Dirac. De acordo com Dirac, as partículas que obedecem o princípio da exclusão são chamadas de "férmions" e as que não obedecem são denominadas "bósons".
Os cargos de professores, na Itália, eram concedidos via concurso, sendo as publicações dos candidatos avaliadas por um comitê de professores. Fermi se inscreveu para a cadeira de física matemática na Universidade de Cagliari, na Sardenha, mas foi dispensado em favor de Giovanni Giorgi.
Com 24 anos, Fermi tornou-se professor da Universidade de Roma em uma nova cadeira de física teórica criada pelo Ministério da Educação a pedido do professor Orso Mario Corbino, que era professor de física experimental, diretor do Instituto de Física e membro do gabinete de Benito Mussolini. Corbino esperava que a nova cadeira conferisse um maior prestígio à física na Itália. Ele também ajudou Fermi a selecionar sua equipe, que logo foi ingressada por mentes notáveis como Edoardo Amaldi, Bruno Pontecorvo, Franco Rasetti e Emilio Segrè. Para os estudos teóricos apenas, Ettore Majorana também participou do que logo foi apelidado de "o Grupo da rua Panisperna" (em relação ao nome da rua em que o instituto tinha seus laboratórios).
Fermi se casou com Laura Capon, uma estudante de ciência da Universidade, em 19 de julho de 1928. Eles tiveram dois filhos: Nella, nascida em janeiro de 1931 e Giulio, nascido em fevereiro de 1936. Em 18 de março de 1929, Fermi se tornou membro da Academia Real da Itália, indicado por Mussolini, e se tornou membro do Partido Fascista em 27 de abril, embora tenha se oposto à ideologia em 1938 quando Mussolini criou as leis raciais de forma a aproximar mais o fascismo do nazismo de Hitler. Essas leis ameaçavam Laura, esposa do cientista, que era judia, e tiraram o trabalho de muitos de seus assistentes de laboratório.
O grupo continuou com os experimentos que vieram a ficar famosos, no entanto, o grupo se desmantelou, em 1933 Rasetti deixou a Itália e foi para o Canadá, Pontecorvo foi para a França, e Segrè partiu para lecionar em Palermo.
Durante seu tempo em Roma, Fermi e seu grupo fizeram importantes contribuições a muitos aspectos práticos e teóricos da física. Essas incluem a teoria do decaimento beta, com a inclusão do postulado do neutrino em 1930 por Wolfgang Pauli, e a descoberta dos nêutrons lentos, que foi fundamental para o funcionamento dos reatores nucleares. Em 1928, ele publicou um trabalho chamado Introdução à Física Atômica, que apresentava uma abordagem mais acessível e atualizada para os estudantes. Fermi também produziu palestras e artigos públicos para professores e cientistas para promover e divulgar a nova física tanto quanto possível. Parte do seu método de ensino era se reunir com estudantes de graduação e professores ao final do dia para trabalhar num problema, geralmente sobre uma pesquisa do grupo. Um sinal de que o trabalho de divulgação estava dando resultado era que estudantes estrangeiros estavam indo à Itália. Um deles foi Hans Bethe, que colaborou com Fermi num artigo de 1932 sobre a interação entre dois elétrons.
Os físicos, na época, ainda possuíam muitas dúvidas acerca do decaimento beta, no qual um elétron é emitido de um núcleo atômico. Para satisfazer a lei da conservação da energia, Pauli postulou a existência de uma partícula invisível com carga zero e uma massa muito pequena que era emitida ao mesmo tempo que o elétron. Fermi pegou essa ideia e, em 1934, escreveu um artigo que decretava a existência do neutrino. Essa teoria, que também pode ser chamada de interação de Fermi ou fraca interação, descrevia uma das quatro forças fundamentais da natureza. O neutrino só foi detectado após a morte de Fermi, pois é uma partícula extremamente difícil de detectar. Quando o cientista submeteu seu artigo à renomada revista britânica "Nature", o editor a rejeitou pois achava que suas especulações eram "muito afastadas da realidade para serem interessantes aos leitores". Fermi então viu a teoria ser publicada em italiano e alemão antes de ser publicada em inglês.
Em janeiro de 1934, Irène Joliot-Curie e Frédéric Joliot anunciaram que eles haviam bombardeado elementos com partículas alfa e, com isso, induzido radioatividade. Em março, Gian-Carlo Wick (integrante do Grupo da rua Panisperna) formulou uma explicação teórica para isso usando a teoria do decaimento beta. Fermi, então, recorreu à física experimental e usou o nêutron, descoberto em 1932. A partícula escolhida não possuía carga e, portanto, não seria defletida pelo núcleo. Isso causou uma grande redução nos custos do experimento (caso contrário ele seria inviável) pois eliminou a necessidade de se ter um acelerador de partículas, o que era (e ainda é) muito custoso. Para criar uma forte fonte de nêutrons, Fermi encheu um bulbo de vidro com pó de berílio, evacuando todo o ar, e então adicionando 50mCi de radônio gasoso. Porém, a eficiência da fonte decaía com a meia-vida do radônio (3,8 dias). Era sabido também que a fonte iria emitir raios-gama, mas isso não iria afetar muito os resultados do experimento. O que Fermi fez foi bombardear diferentes elementos (ao todo 22) e, em todos eles, conseguiu induzir radioatividade. A descoberta foi rapidamente reportada para a revista italiana "La Ricerca Scientifica "em 25 de março de 1934.
A radioatividade natural de elementos como tório e urânio tornou difícil a determinação do que estava acontecendo durante o bombardeamento desses elementos. Porém, após ter removido corretamente a presença de elementos mais leves que urânio e mais pesados que chumbo, Fermi concluiu que eles haviam criado novos elementos, e os denominou espério e ausônio. Seu trabalho, no entanto, foi criticado pela química Ida Noddack, que sugeriu que esses experimentos poderiam ter criado elementos mais leves ao invés de elementos novos mais pesados, mas Fermi e sua equipe não levaram a sério a crítica, pois a equipe da química ainda não havia feito nenhum experimento com urânio. Naqueles anos, a fissão nuclear era tomada como improvável (senão impossível) nos campos teóricos, e ninguém esperava que nêutrons tivessem energia o suficiente para quebrar um núcleo em dois fragmentos mais leves da maneira que Noddack havia sugerido.
O Grupo da Via Panisperna também descobriu outras coisas interessantes. Fazendo o experimento em diferentes superfícies, eles notaram que a colisão com átomos de hidrogênio atrasava os nêutrons. Quanto menor o número atômico do núcleo que a partícula colide, mais energia ela perde por colisão, e portanto menos colisões são necessárias para desacelerá-la. Fermi descobriu que isso produzia uma maior indução de radioatividade, visto que nêutrons com baixa velocidade são mais facilmente capturados. Ele, então, desenvolveu uma equação de difusão para descrever isso.
Fermi era bem conhecido por sua simplicidade na solução de problemas. Suas aptidões de formidável cientista, combinando física nuclear teórica e aplicada, foram amplamente reconhecidas. Ele influenciou muitos físicos que trabalharam com ele, como Hans Bethe, que passou dois semestres trabalhando com Fermi no início da década de 1930.
Fermi permaneceu em Roma até 1938.
Em 1938, com 37 anos, Fermi foi laureado com o Nobel de Física, por suas "demonstrações da existência de novos elementos radioativos produzidos pela irradiação de nêutrons, e por sua descoberta relacionada de reações nucleares provocadas por nêutrons lentos".
Depois que Fermi recebeu o Prêmio Nobel em Estocolmo, ele, sua mulher Laura e seus filhos emigraram para Nova Iorque. Isso foi principalmente por causa das leis anti-semitas promulgadas pelo regime fascista de Benito Mussolini que ameaçavam Laura, que era judia. Além disso, as novas leis colocaram a maior parte dos assistentes de pesquisa de Fermi fora de trabalho.
Logo após sua chegada em Nova Iorque, Fermi começou a trabalhar na Universidade de Columbia.
Fermi se mudou para o Laboratório Nacional de Los Alamos, em etapas posteriores do Projeto Manhattan, para servir de consultor geral.
Durante a explosão da primeira bomba atômica, realizada em Alamogordo, Fermi estava presente. Na ocasião, como se era esperado, havia muitos equipamento de ponta para mensurar a energia liberada pela bomba na atmosfera. Haviam cálculos para isso, porém a bomba real teria perdas consideráveis de rendimento. Entretanto, como esta foi a primeira bomba atômica testada na história, não era certo que os equipamentos de medição funcionariam. Pensando nisso Fermi fez um pequeno experimento para medir a energia liberada: no momento da explosão jogou no chão alguns pedaços de papel. "...no ar parado, os pedacinhos de papel cairiam aos seus pés, mas quando a onda de choque chegou (alguns segundos após o clarão), foram transportados por alguns centímetros na direção da onda. " Como era conhecido a distancia entre o centro da explosão e onde ele estava, Fermi poderia calculara energia.
Tornou-se cidadão naturalizado dos Estados Unidos em 1944.
Em seus últimos anos, Fermi fez trabalhos importantes em física de partículas, especialmente a relacionada com mésons pi, e múons. Ele também era conhecido por ser um professor inspirador na Universidade de Chicago (embora não tenha deixado o Laboratório de Los Alamos até dezembro de 1945), e era conhecido por sua atenção aos detalhes, simplicidade e preparação cuidadosa das aulas. A curta distância entre Argonne e Chicago permitia a participação ativa do cientista tanto nas aulas da universidade quanto na física experimental em Argonne, estudando dispersão de nêutrons com Leona Marshall. Mais tarde, suas notas de aula, especialmente as de mecânica quântica, física nuclear, e termodinâmica, foram transcritas em livros que ainda são impressos. Enrico Fermi também discutiu aspectos em física teórica com Maria Mayer, ajudando-a em seu trabalho sobre a interação spin-órbita, o que a levaria ao Prêmio Nobel.
O Projeto Manhattan foi substituído pela Comissão de Energia Atômica (CAE) no primeiro dia de janeiro de 1947. Fermi fez parte de uma importante subdivisão científica da CAE encabeçada por Robert Oppenheimer. Ele também gostava de passar algumas semanas de cada ano no Laboratório de Los Alamos, onde ajudou Nicholas Metropolis e John von Neumann na instabilidade de Rayleigh-Taylor, a ciência do que ocorre na fronteira entre dois fluidos de diferentes densidades.
Logo após a detonação da primeira bomba nuclear soviética em agosto de 1949, Fermi, junto com Isidor Rabi, escreveu um forte manifesto ao comitê, se opondo fortemente ao desenvolvimento de uma bomba de hidrogênio tanto em aspectos morais quanto técnicos. Mesmo assim, continuou trabalhando no desenvolvimento dessa bomba como consultor.
Nos anos que se seguiram, Fermi continuou lecionando na Universidade de Chicago. Seus alunos de PhD no período pós-guerra incluíam Owen Chamberlain, Geoffrey Chew, Jerome Friedman, Marvin Goldberger, Tsung-Dao Lee, Arthur Rosenfeld e Sam Treiman. Jack Steinberger era seu aluno de graduação. Fermi conduziu importantes experimentos na física de partículas, especialmente os relacionados a píons e múons. Ele fez as primeiras predições da ressonância píon-núcleon, se baseando em métodos estatísticos, pois achava que resultados exatos não eram necessários para uma teoria que não estava completamente correta. Em um artigo com a co-autoria de Chen Ning Yang, ele especulou que píons poderiam ser partículas compostas, uma ideia anteriormente formulada por Shoichi Sakata. Foi então postulado, após anos de estudo, que os píons eram feitos de quarks, que completava o modelo de Fermi e criava o modelo quark.
Fermi também escreveu um artigo "Sobre a origem da Radiação Cósmica" no qual ele propôs que os raios cósmicos provinham de um material acelerado por campos magnéticos no espaço interestelar, o que levou a uma divergência de opiniões entre ele e Teller. O cientista italiano também examinou assuntos relacionados a campos magnéticos nos braços de uma galáxia espiral. Ele também criou o paradoxo de Fermi, um raciocínio muito interessante sobre civilizações extraterrestres.
Perto de sua morte, Fermi questionou sua fé na sociedade e também a capacidade de tomarmos uma decisão prudente em relação às armas nucleares. Ele disse:
Fermi morreu prematuramente, aos 53 anos de idade, vítima de câncer no estômago, provavelmente causado pela exposição a materiais radioativos. Foi sepultado no "Oak Woods Cemetery", Chicago, Illinois, Estados Unidos.

O efeito fotoelétrico é a emissão de elétrons por um material, geralmente metálico, quando exposto a uma radiação eletromagnética (como a luz) de frequência suficientemente alta, que depende do material, como por exemplo a radiação ultravioleta. Ele pode ser observado quando a luz incide numa placa de metal, arrancando elétrons da placa. Os elétrons ejetados são denominados fotoelétrons. Observado pela primeira vez por A. E. Becquerel em 1839 e confirmado por Heinrich Hertz em 1887, o fenômeno é também conhecido por "efeito Hertz", não sendo porém este termo de uso comum.
De acordo com o modelo ondulatório da luz, as expectativas eram:
Qualquer superfície metálica deveria ejetar elétrons quando excitada com uma radiação eletromagnética, de qualquer frequência, desde que essa radiação demorasse um tempo suficiente para o átomo armazenar energia e liberar, posteriormente, esse elétron;
Os elétrons que giram à volta do núcleo atômico são aí mantidos por forças de atração. Se a estes for fornecida energia suficiente, eles abandonarão as suas órbitas. O efeito fotoelétrico implica que, normalmente sobre metais, se faça incidir um feixe de radiação com energia superior à energia de remoção dos elétrons do metal, provocando a sua saída das órbitas: sem energia cinética (se a energia da radiação for igual à energia de remoção) ou com energia cinética, se a energia da radiação exceder a energia de remoção do elétrons. 
Para testar essas ideias, os cientistas montaram um experimento.
A grande dúvida que se tinha a respeito do efeito fotoelétrico era que quando se aumentava a intensidade da luz, ao contrário do esperado, a luz não arrancava os elétrons do metal com maior energia cinética. O que acontecia era que uma maior quantidade de elétrons era ejetado.
Por exemplo, a luz vermelha de baixa frequência estimula os elétrons para fora de uma peça de metal. Na visão clássica, a luz é uma onda contínua cuja energia está espalhada sobre a onda. Todavia, quando a luz fica mais intensa, mais elétrons são ejetados, contradizendo, assim a visão da física clássica que sugere que os mesmos deveriam se mover mais rápido (energia cinética) do que as ondas.
Quando a luz incidente é de cor azul, essa mudança resulta em elétrons muito mais rápidos. A razão é que a luz pode se comportar não apenas como ondas contínuas, mas também como feixes discretos de energia chamados de fótons. Um fóton azul, por exemplo, contém mais energia do que um fóton vermelho. Assim, o fóton azul age essencialmente como uma "bola de bilhar" com mais energia, desta forma transmitindo maior movimento a um elétron. Esta interpretação corpuscular da luz também explica por que a maior intensidade aumenta o número de elétrons ejetados - com mais fótons colidindo no metal, mais elétrons têm probabilidade de serem atingidos.
Aumentar a intensidade de radiação que provoca o efeito fotoelétrico não aumenta a velocidade dos fotoelétrons, mas aumenta o número de fotoelétrons. Para se aumentar a velocidade dos fotoelétrons, é necessário excitar a placa com radiações de frequências maiores e, portanto, energias mais elevadas.
A explicação satisfatória para esse efeito foi dada em 1905, por Albert Einstein, e em 1921 deu ao cientista alemão o prêmio Nobel de Física.
Analisando o efeito fotoelétrico quantitativamente usando o método de Einstein, as seguintes equações equivalentes são usadas:
Energia do fóton = Energia necessária para remover um elétron + Energia cinética do elétron emitido
Algebricamente:
Onde:
"Nota"s:

Os Estados Unidos da América (; ), ou simplesmente Estados Unidos (), são uma república constitucional federal composta por 50 estados e um distrito federal. A maior parte do país situa-se na região central da América do Norte, formada por 48 estados e Washington, D.C., o distrito federal da capital. Banhado pelos oceanos Pacífico e Atlântico, faz fronteira com o Canadá ao norte e com o México ao sul. O estado do Alasca está no noroeste do continente, fazendo fronteira com o Canadá no leste e com a Rússia a oeste, através do estreito de Bering. O estado do Havaí é um arquipélago no Pacífico Central. O país também possui vários outros territórios no Caribe e no Oceano Pacífico. Com 9,37 milhões de km² de área e uma população de mais de 300 milhões de habitantes, o país é o quarto maior em área total, o quinto maior em área contígua e o terceiro em população. Os Estados Unidos são uma das nações mais multiculturais e etnicamente diversas do mundo, produto da forte imigração vinda de muitos países. Sua geografia e sistemas climáticos também são extremamente diversificados, com desertos, planícies, florestas e montanhas que abrigam uma grande variedade de espécies.
Os paleoindígenas que migraram da Ásia há quinze mil anos, habitam o que é hoje o território dos Estados Unidos até os dias atuais. Esta população nativa foi muito reduzida após o contato com os europeus devido a doenças e guerras. Os Estados Unidos foram fundados pelas treze colônias do Império Britânico localizadas ao longo da sua costa atlântica. Em 4 de julho de 1776, foi emitida a Declaração de Independência, que proclamou o seu direito à autodeterminação e a criação de uma união cooperativa. Os estados rebeldes derrotaram a Grã-Bretanha na Guerra Revolucionária Americana, a primeira guerra colonial bem sucedida da Idade Contemporânea. A Convenção de Filadélfia aprovou a atual Constituição dos Estados Unidos em 17 de setembro de 1787; sua ratificação no ano seguinte tornou os estados parte de uma única república com um forte governo central. A Carta dos Direitos, composta por dez emendas constitucionais que garantem vários direitos civis e liberdades fundamentais, foi ratificada em 1791.
Guiados pela doutrina do destino manifesto, os Estados Unidos embarcaram em uma vigorosa expansão territorial pela América do Norte durante o século XIX que resultou no deslocamento de tribos indígenas, aquisição de territórios e na anexação de novos Estados. Os conflitos entre o sul agrário e o norte industrializado do país sobre os direitos dos estados e a expansão da instituição da escravatura provocaram a Guerra de Secessão, que decorreu entre 1861 e 1865. A vitória do Norte impediu a separação do país e levou ao fim da escravatura nos Estados Unidos. No final do século XIX, sua economia tornou-se a maior do mundo e o país expandiu-se para o Pacífico. A Guerra Hispano-Americana e a Primeira Guerra Mundial confirmaram o estatuto do país como uma potência militar. A nação emergiu da Segunda Guerra Mundial como o primeiro país com armas nucleares e como membro permanente do Conselho de Segurança das Nações Unidas. O fim da Guerra Fria e a dissolução da União Soviética deixaram-no como a única superpotência restante.
Os Estados Unidos são um país desenvolvido e formam a maior economia nacional do mundo, com um produto interno bruto que em 2012 foi de de dólares, equivalente a 19% do PIB mundial por paridade do poder de compra (PPC) de 2011. Sua renda "per capita" era a sexta maior do mundo em 2010, no entanto o país é o mais desigual dos membros da Organização para a Cooperação e Desenvolvimento Econômico (OCDE), conforme calculado pelo Banco Mundial. Sua economia é alimentada pela abundância de recursos naturais, por uma infraestrutura bem desenvolvida e pela alta produtividade; e, apesar de ser considerado uma economia pós-industrial, o país continua a ser um dos maiores fabricantes do mundo. Os Estados Unidos respondem por 39% dos gastos militares do planeta e são um forte líder econômico, político e cultural.
Em 1510, o cartógrafo alemão Martin Waldseemüller elaborou um planisfério, onde denominou as terras do hemisfério ocidental de "América", em honra ao cartógrafo italiano Américo Vespúcio. As antigas colônias britânicas usaram pela primeira vez o nome do país moderno na Declaração de Independência — "unânime declaração de independência dos Estados Unidos da América", adotada pelos "representantes dos Estados Unidos da América", em 4 de julho de 1776. Seu nome atual foi formalmente adotado em 15 de novembro de 1777, quando o Segundo Congresso Continental aprovou os Artigos da Confederação, que estipulavam "O nome desta confederação será "Estados Unidos da América"". A forma "Estados Unidos" também é padronizada; outra forma comum é EUA. "Colúmbia", derivado do nome de Cristóvão Colombo, em tempos um nome popular para os Estados Unidos, ainda permanece no nome distrito de Colúmbia. Ocasionalmente o país é referido de forma incorreta como "Estados Unidos da América do Norte". Na escrita, também é comum o uso das abreviaturas EUA, US ou USA.
As formas padrão para se referir a um cidadão dos Estados Unidos são "americano" (mais usual), "estadunidense" (ou "estado-unidense") ou "norte-americano". Também é utilizado o adjetivo "ianque" (do inglês "yankee"). Originalmente e em sentido estrito, "yankee" é um habitantes da região de Nova Inglaterra, mas o uso generalizou-se, passando a designar todos os nativos dos estados do Norte; pode ainda designar especificamente os soldados nortistas durante a Guerra da Secessão ou, mais genericamente, qualquer nativo dos Estados Unidos.
Acredita-se que os povos indígenas dos Estados Unidos continentais, incluindo os nativos do Alasca, emigraram da Ásia. Eles começaram a chegar há doze ou quarenta milênios, se não antes. Alguns, como a cultura mississippiana pré-colombiana, desenvolveram agricultura avançada, arquitetura grandiosa e sociedades estaduais. Mais tarde os europeus começaram a colonização das Américas, muitos milhões de indígenas americanos morreram de epidemias de doenças importadas, como a varíola.
Em 1492, o explorador Cristóvão Colombo sob contrato com a coroa espanhola chegou a várias ilhas do Caribe, fazendo o primeiro contato com os povos indígenas. Em 2 de abril de 1513, o conquistador espanhol Juan Ponce de León desembarcou no local em que ele chamou de "La Florida" — a primeira visita europeia documentada no que viria a ser os Estados Unidos Continentais. Às colônias espanholas na Flórida seguiram-se outras no que é hoje o sudoeste dos Estados Unidos, que atraíram milhares de colonos através do México. Os comerciantes de peles franceses estabeleceram postos da Nova França em torno dos Grandes Lagos; a França acabou por reivindicar a maior parte do interior da América do Norte até o Golfo do México. O primeiro assentamento inglês bem sucedido foi a Colônia da Virgínia em Jamestown, em 1607, e a Colônia de Plymouth, dos chamados "Peregrinos" (em inglês: "Pilgrim Fathers" [pais peregrinos] ou simplesmente "Pilgrims"), em 1620. O fretamento de 1628 da Colônia da Baía de Massachusetts resultou em uma onda de migração; por volta de 1634, a Nova Inglaterra tinha sido povoada por cerca de puritanos. Entre o final dos anos 1610 e a Revolução Americana, cerca de prisioneiros foram enviados para as colônias americanas da Grã-Bretanha. A partir de 1614, os holandeses se estabeleceram ao longo do rio Hudson, nomeadamente na colônia de Nova Amsterdã na ilha de Manhattan.
Em 1674, os holandeses cederam seu território norte-americano à Inglaterra; a província da Nova Holanda foi renomeada para Nova Iorque. Muitos dos novos imigrantes, especialmente do Sul (cerca de dois terços de todos os imigrantes da Virgínia) foram contratados como trabalhadores temporários entre 1630 e 1680. A partir do final do , os escravos africanos foram se tornando a principal fonte de trabalho forçado. Com a divisão das Carolinas em 1729 e a colonização da Geórgia em 1732, foram estabelecidas as treze colônias britânicas que se tornariam os Estados Unidos. Todas contavam com um governo local eleito, estimulando o apoio ao republicanismo. Todas as colônias legalizaram o comércio de escravos africanos. Com taxas de natalidade altas, taxas de mortalidade baixas e imigração constante, a população colonial cresceu rapidamente. O movimento cristão revivalista das décadas de 1730 e 1740, conhecido como o Grande Despertar, incentivou o interesse na religião e na liberdade religiosa. Durante a Guerra Franco-Indígena, as forças britânicas tomaram o Canadá dos franceses, mas a população francófona permaneceu isolada política e geograficamente das colônias do sul. À exceção dos nativos americanos (popularmente conhecidos como "índios americanos"), que estavam sendo deslocados, as treze colônias tinham uma população de 2,6 milhões de habitantes em 1770, cerca de um terço da Grã-Bretanha; cerca de um em cada cinco norte-americanos eram escravos negros. Embora sujeitos aos impostos britânicos, os colonos americanos não tinham representação no Parlamento da Grã-Bretanha.
As tensões entre colonos americanos e os britânicos durante o período revolucionário dos anos 1770 e início dos anos 1780 levaram à Guerra Revolucionária Americana, travada de 1775 até 1781. Em 14 de junho de 1775, o Congresso Continental, em convocação na Filadélfia, criou um Exército Continental sob o comando de George Washington. Proclamando que "todos os homens são criados iguais e dotados de certos direitos inalienáveis", em 4 de julho de 1776 o Congresso aprovou a Declaração de Independência, redigida em grande parte por Thomas Jefferson. Essa data é hoje comemorada como o Dia da Independência dos Estados Unidos. Em 1777, os Artigos da Confederação estabeleceram um fraco governo confederado que operou até 1789.
Após a derrota britânica por forças americanas apoiadas pelos franceses, na Batalha de Yorktown, a Grã-Bretanha reconheceu a independência dos Estados Unidos e a soberania dos estados sobre o território americano a oeste do rio Mississippi. Uma convenção constitucional foi organizada em 1787 por aqueles que desejavam estabelecer um governo nacional forte, com poderes de tributação. A Constituição dos Estados Unidos foi ratificada em 1788. Em 1789 tomaram posse o primeiro Senado e o primeiro presidente (George Washington) da Nova República. Em 1791 foi adotada a "Bill of Rights" (Declaração dos Direitos dos Cidadãos), que proíbe restrições federais das liberdades pessoais e garante uma série de proteções legais.
As atitudes em relação à escravidão foram sendo alteradas; uma cláusula na Constituição protegia o comércio de escravos africanos apenas até 1808. Os estados do Norte aboliram a escravidão entre 1780 e 1804, deixando os estados escravistas do Sul como defensores dessa "instituição peculiar". O Segundo Grande Despertar, iniciado por volta de 1800, fez do evangelicalismo uma força por detrás de vários movimentos de reforma social, entre as quais o abolicionismo.
A ânsia americana de expansão para o oeste levou a uma longa série de Guerras Indígenas e ao genocídio dos indígenas. A compra da Louisiana, o território francês a sul, sob a presidência de Thomas Jefferson em 1803, quase duplicou o tamanho da nação. A Guerra de 1812, travada contra a Grã-Bretanha acabou num empate, reforçando o nacionalismo americano. Uma série de incursões militares americanas na Flórida levaram a Espanha a ceder esse e outros territórios na Costa do Golfo do México em 1819. A Trilha das Lágrimas em 1830 exemplificou a política de remoção dos índios, que retirava os povos indígenas de suas terras nativas. Os Estados Unidos anexaram a República do Texas em 1845. O conceito de "Destino Manifesto" foi popularizado durante essa época. O Tratado de Oregon, assinado com a Grã-Bretanha em 1846, levou ao controle norte-americano do atual Noroeste dos Estados Unidos. A vitória americana na Guerra Mexicano-Americana resultou na cessão da Califórnia e de grande parte do atual Sudoeste dos Estados Unidos em 1848. A corrida do ouro na Califórnia de 1848-1849 estimulou a migração ocidental. As ferrovias construídas, no entanto, tornaram a deslocalização mais fácil para os colonos e provocaram o aumento dos conflitos com os nativos americanos. Depois de meio século, até 40 milhões de bisões americanos foram abatidos para peles e carne e para facilitar a disseminação do transporte ferroviário. A perda do bisão, um recurso fundamental para os Índios das Planícies, constituiu rude golpe para a subsistência de muitas culturas nativas.
As tensões entre os estados ditos livres e os estados escravistas tiveram origem sobretudo em discussões sobre a relação entre os governos estadual e federal e em conflitos violentos acerca da propagação da escravidão em novos estados. Abraham Lincoln, candidato do Partido Republicano, em grande parte abolicionista, foi eleito presidente em 1860. Antes da sua tomada de posse, sete estados escravistas declararam sua secessão, o que o governo federal sempre considerou ilegal, e formaram os Estados Confederados da América.
Com o ataque confederado em Fort Sumter, a Guerra de Secessão começou, e mais quatro estados escravistas aderiram à Confederação. A Proclamação da Emancipação de Lincoln, em 1863, declarou livres os escravos da Confederação. Após a vitória da União em 1865, três emendas à Constituição americana garantiam a liberdade para quase quatro milhões de afro-americanos que tinham sido escravos, fizeram-nos cidadãos e lhes deram direito ao voto. A guerra e a sua resolução levaram a um aumento substancial do poder federal.
Após a guerra, o assassinato de Lincoln radicalizou as políticas republicanas da Reconstrução na reinserção e reconstrução dos estados do sul, assegurando os direitos dos escravos recém-libertos. A resolução da disputada eleição presidencial de 1876 pelo compromisso de 1877 terminou com a Era da Reconstrução; as Leis de Jim Crow iniciaram um período de perseguição aos afro-americanos.
No Norte, a urbanização e um afluxo de imigrantes sem precedentes da Europa meridional e oriental apressou a industrialização do país. A onda de imigração, que durou até 1929, proveu trabalho e transformou a cultura americana. O desenvolvimento da infraestrutura nacional estimulou o crescimento econômico.
A compra do Alasca do Império Russo em 1867 completou a expansão continental do país. O massacre de Wounded Knee, em 1890, foi o último grande conflito armado das Guerras Indígenas. Em 1893, a monarquia indígena do Reino do Havaí, no Pacífico, foi derrubada em um golpe de Estado liderado por residentes norte-americanos; os Estados Unidos anexaram o arquipélago em 1898. A vitória no mesmo ano da Guerra Hispano-Americana demonstrou que os Estados Unidos eram uma grande potência mundial e levou à anexação de Porto Rico, Guam e as Filipinas. As Filipinas conquistaram a independência meio século depois, Porto Rico e Guam permanecem como territórios americanos.
Durante os primeiros anos da Primeira Guerra Mundial, que eclodiu em 1914, os Estados Unidos mantiveram-se neutros. Apesar da maioria dos americanos simpatizarem com os britânicos e com os franceses, muitos eram contra uma intervenção. Em 1917, os Estados Unidos se juntaram aos Aliados, ajudando a virar a maré contra as Potências Centrais. Após a guerra, o Senado não ratificou o Tratado de Versalhes, que estabelecia a Liga das Nações. O país seguiu uma política de unilateralismo, beirando o isolacionismo.
Em 1920, o movimento pelos direitos das mulheres conseguiu a aprovação de uma emenda constitucional que concedia o sufrágio feminino. A prosperidade dos "Roaring Twenties" ("anos 20 florescentes, alegres, ruidosos ou vívidos") terminou com a quebra da Bolsa de Valores de Nova Iorque em 1929, que desencadeou a Grande Depressão. Após sua eleição como presidente em 1932, Franklin Delano Roosevelt respondeu à crise social e econômica com o "New Deal" ("novo acordo"), uma série de políticas de crescente intervenção governamental na economia. O "Dust Bowl" de meados da década de 1930 empobreceu muitas comunidades agrícolas e estimulou uma nova onda de imigração ocidental.
Os Estados Unidos, neutros durante as fases iniciais da Segunda Guerra Mundial, iniciada com a invasão da Polônia pela Alemanha Nazista em setembro de 1939, começaram a fornecer material para os Aliados em março de 1941 através do programa "Lend-Lease" ("Lend-Lease Act"; "Lei de empréstimo e arrendamento"). Em 7 de dezembro de 1941, o Império do Japão lançou um ataque surpresa a Pearl Harbor, o que levou os Estados Unidos a se juntar aos Aliados contra as potências do Eixo e ao internamento compulsivo de milhares de americanos de origem japonesa. A participação na guerra estimulou o investimento de capital e a capacidade industrial do país. Entre os principais combatentes, os Estados Unidos foram o único país a se tornar muito mais rico, ao contrário dos restantes aliados, que empobreceram por causa da guerra.
As conferências dos aliados em Bretton Woods e Yalta delinearam um novo sistema de organizações internacionais que colocou os Estados Unidos e a União Soviética no centro da política geoestratégica mundial. Como a vitória foi conquistada na Europa, uma conferência internacional realizada em 1945 em São Francisco produziu a Carta das Nações Unidas, que se tornou ativa depois da guerra. Tendo desenvolvido as primeiras armas nucleares, os Estados Unidos, usaram-as sobre as cidades japonesas de Hiroshima e Nagasaki, em agosto de 1945. O Japão se rendeu em 2 de setembro do mesmo ano, marcando o fim da guerra.
Os Estados Unidos e a União Soviética disputaram a supremacia mundial após a Segunda Guerra Mundial, durante o período chamado de Guerra Fria, cujos principais atores a nível militar na Europa foram Organização do Tratado do Atlântico Norte (OTAN) e o Pacto de Varsóvia. Os Estados Unidos promoviam a democracia liberal e o capitalismo, enquanto a União Soviética promovia o comunismo e uma economia planificada. Ambos apoiavam ditaduras e estavam envolvidos em guerras por procuração. As tropas americanas combateram as forças comunistas chinesas na Guerra da Coreia de 1950-53. O Comitê de Atividades Antiamericanas seguiu uma série de investigações sobre suspeitas de subversões de esquerda, enquanto o senador Joseph McCarthy tornou-se a figura emblemática do sentimento anticomunista.
O lançamento soviético de 1961 do primeiro voo tripulado fez com que o presidente John F. Kennedy lançasse o repto dos Estados Unidos serem o primeiro país a aterrissar um homem na lua, o que foi realizado em 1969. Kennedy também enfrentou uma tensa crise motivado pela presença de forças soviéticas em Cuba que por pouco não provocou um confronto nuclear. Entretanto, os Estados Unidos experimentaram uma expansão econômica sustentada. Ao mesmo tempo, cresceu o movimento dos direitos civis, simbolizado e liderado por afro-americanos, como Rosa Parks e Martin Luther King Jr, usando a não violência para enfrentar a segregação e a discriminação. Após o assassinato de Kennedy em 1963, as leis de direitos civis (1964) e direito ao voto (1965) foram sancionadas pelo presidente Lyndon B. Johnson. Johnson e seu sucessor, Richard Nixon, expandiram uma guerra por procuração no sudeste da Ásia para a mal sucedida Guerra do Vietnã. Um amplo movimento de contracultura cresceu, alimentado pela oposição à guerra, o nacionalismo negro e a revolução sexual. Betty Friedan, Gloria Steinem e outros levaram uma nova onda de feminismo que buscava a igualdade política, social e econômica das mulheres.
Como consequência do escândalo de Watergate, em 1974 Nixon se tornou o primeiro presidente americano a renunciar, para evitar sofrer um "impeachment" (impugnação do mandato) sob as acusações de obstrução da justiça e abuso de poder, sendo sucedido pelo vice-presidente Gerald Ford. A administração de Jimmy Carter da década de 1970 foi marcada pela estagflação e a crise dos reféns do Irã. A eleição de Ronald Reagan como presidente em 1980 anunciou uma virada à direita na política norte-americana, refletida em grandes mudanças na tributação e nas prioridades dos gastos. Seu segundo mandato foi marcado pelo escândalo Irã-Contras e pelo significativo progresso diplomático com a União Soviética. O posterior colapso soviético pôs fim à Guerra Fria.
Sob a presidência de George H. W. Bush, os Estados Unidos assumiram um papel de liderança na ONU sancionando a Guerra do Golfo. A maior expansão econômica da história moderna americana ocorreu de março de 1991 a março de 2001, abrangendo a administração de Bill Clinton e a "Bolha da Internet". Uma ação judicial civil e um escândalo sexual levaram ao "impeachment" de Clinton em 1998, mas ele permaneceu no cargo.
A eleição presidencial de 2000, uma das mais acirradas e controversas da história dos Estados Unidos, que chegou a envolver suspeitas de fraude e outras dúvidas na contagem de votos, foi resolvida por uma decisão da Suprema Corte dos Estados Unidos, que declarou George W. Bush, filho de George H. W. Bush, presidente. Na manhã de 11 de setembro de 2001, terroristas da organização fundamentalista islâmica al-Qaeda atacaram o complexo do World Trade Center, em Nova Iorque, e o prédio do Pentágono, nos arredores de Washington, D.C., causando a morte de cerca de três mil pessoas. Em resposta aos atentados, o governo Bush lançou a chamada Guerra ao Terror e, no final de 2001, forças norte-americanas lideraram uma invasão ao Afeganistão, removendo o governo Taliban e acabando com campos de treinamento da al-Qaeda. Insurgentes do Taliban, no entanto, continuam (2011) a travar uma guerra de guerrilha no país. Em 2002, a administração Bush começou a pressionar uma mudança de regime no Iraque por motivos controversos. Sem o apoio da OTAN ou da ONU para uma intervenção militar, o governo Bush organizou e liderou uma coalizão de forças militares para invadir preventivamente o Iraque em 2003, removendo o ditador Saddam Hussein do poder. Em 2005, o furacão Katrina causou profundos danos ao longo da Costa do Golfo, devastando a cidade de Nova Orleans, na Louisiana.
Em 2008, em meio a uma recessão econômica global, o primeiro presidente afro-americano, Barack Obama, foi eleito. Dois anos depois, grandes reformas nos sistemas de saúde e financeiro do país foram decretadas. Em 2011, um ataque de SEALs da marinha norte-americana matou o líder da rede al-Qaeda, Osama bin Laden, na cidade de Abbottabad, no Paquistão. A Guerra do Iraque acabou oficialmente com a retirada das tropas norte-americanas restantes do país em dezembro de 2011. No 11º aniversário dos ataques de 11 de setembro, e menos de um ano após os Estados Unidos colaborarem com a queda do ditador líbio Muammar Gaddafi, duas instalações norte-americanas foram atacadas na Líbia, o que resultou na primeira morte de um embaixador estadunidense desde 1979. Em outubro de 2012, o furacão Sandy causou vasta destruição no litoral das regiões Nordeste e do Médio Atlântico dos Estados Unidos. Em abril de 2013, um ataque terrorista aconteceu durante a Maratona de Boston; foi o primeiro atentado terrorista reconhecido no país desde o 11 de setembro de 2001.
A área dos Estados Unidos contíguos é de aproximadamente sendo que são terra emersa. O Alasca, separado dos Estados Unidos contíguos pelo Canadá, é o maior estado com . O Havaí, um arquipélago no Pacífico central, a sudoeste da América do Norte, tem cerca de A seguir à Rússia e ao Canadá, os Estados Unidos são a quarta maior nação do mundo em área total (terra e água), posição abaixo da China. A classificação varia conforme a estimativa da área total dos Estados Unidos utilize as águas territoriais marítimas, porém, pelo padrão de agrimensura, que considera apenas terra e águas internas a posição é a quarta. Assim, segundo o "CIA World Factbook", que contabiliza as águas costeiras e territoriais, segundo Divisão de Estatísticas das Nações Unidas, que considera as águas costeiras e territoriais dos grandes lagos. e segundo a Encyclopædia Britannica, que considera as águas territoriais dos grandes lagos. Incluindo apenas a área terrestre, os Estados Unidos são o terceiro maior país do mundo em superfície, atrás da Rússia e da China e à frente do Canadá.
O território nacional conta com múltiplas formas de acidentes geográficos e é comum dividir-se a parte dos Estados Unidos na América do Norte excluindo o Alasca em três grandes regiões orográficas: a ocidental, a central e a oriental. À medida que se avança para o interior, a planícies costeiras do litoral Atlântico dão lugar a bosques caducifólios e à meseta de Piedmont. Os Apalaches separam a costa oriental dos Grandes Lagos das pradarias do centro-oeste. As montanhas de Serra Nevada e a Cordilheira das Cascatas ("Cascade Range") se encontram próximas à costa do Pacífico. 
O Monte McKinley, no Alasca, com metros de altitude, é o ponto mais alto do país e de todo o continente. Os vulcões ativos são comuns ao longo do Alasca e nas Ilhas Aleutas e no estado do Havaí só existem ilhas vulcânicas. O supervulcão localizado no Parque Nacional de Yellowstone, nas Montanhas Rochosas, é a maior vulcão do continente.
O principal sistema hidrográfico do país, formado pelos rios Mississipi e Missouri e o terceiro maior sistema fluvial do mundo, percorre o centro dos Estados Unidos de norte a sul. A pradaria plana e fértil das Grandes Planícies se estende até ao oeste, até ser interrompida por uma região de terras altas no sudoeste. As Montanhas Rochosas, na borda ocidental das Grandes Planícies, atravessam a nação do norte até o sul, chegando a altitudes superiores a metros. Ainda na região oeste encontram-se a Grande Bacia do Nevada ("Great Basin") e desertos, como o de Mojave, Sonora e Chihuahua.
Sua grande extensão e variedade geográfica, inclui a maioria dos tipos de clima. A leste do meridiano 100 oeste, o clima varia de continental úmido no norte, a subtropical úmido no sul. A ponta sul da Flórida é tropical, assim como o Havaí. As Grandes Planícies a oeste do meridiano 100 são semiáridas. 
Grande parte das montanhas ocidentais são alpinas. O clima é árido na Grande Bacia, desértico no sudoeste, mediterrânico na costa da Califórnia e oceânico nas costas do Oregon e de Washington e sul do Alasca. A maior parte do Alasca é subártico ou polar. Climas extremos não são incomuns; os países do Golfo do México são propensos a furacões e a maioria dos tornados do mundo ocorrem no interior do país, principalmente na "Tornado Alley" ("Alameda dos Tornados"), no Centro-Oeste.
Os Estados Unidos são considerados um "país megadiverso": cerca de espécies de plantas vasculares ocorrem nos Estados Unidos Continentais e no Alasca, e mais de espécies de plantas são encontradas no Havaí, algumas das quais ocorrem no continente. Os Estados Unidos são o lar de mais de 400 espécies de mamíferos, 750 de aves e 500 de répteis e anfíbios. Cerca de espécies de insetos têm sido registradas.
A "Endangered Species Act" de 1973 protege espécies ameaçadas e seus "habitats", que são monitorados pelo "United States Fish and Wildlife Service". Há 58 parques nacionais e centenas de outros parques, florestas e áreas naturais geridas pelo governo federal, sendo que a porcentagem de área florestal é de 33,1% (2005). 
No total, o governo detém 28,8% da área terrestre do país. A maior parte desta área está protegida, apesar de algumas serem alugadas para perfuração de poços de petróleo e gás natural, mineração, exploração madeireira ou pecuária; 2,4% é usado para fins militares.
A população dos Estados Unidos foi estimada pelo "United States Census Bureau" em novembro de 2010 em habitantes, incluindo 11,2 milhões de imigrantes ilegais. Os Estados Unidos são a terceira nação mais populosa do mundo, a seguir à China e a Índia, e são o único país industrializado em que há perspetivas de aumento em grande parte da população. Com uma taxa de natalidade de 13,82 por mil, 30% abaixo da média mundial, a sua taxa de crescimento populacional é de 0,98%, significativamente superior às da Europa Ocidental, Japão e Coreia do Sul. No ano fiscal de 2009, foi concedida residência legal a 1,1 milhões de imigrantes. O México foi a principal fonte de novos residentes por mais de duas décadas; desde 1998, China, Índia e as Filipinas foram os quatro principais países de origem de imigrantes a cada ano.
Os Estados Unidos têm uma população muito diversificada: trinta e um grupos étnicos têm mais de um milhão de membros. Os estadunidenses brancos são o maior grupo racial; descendentes de alemães, irlandeses e ingleses constituem três dos quatro principais grupos étnicos do país. Os afro-americanos são a maior minoria racial da nação e o terceiro maior grupo étnico.
Os asiático-americanos são a segunda maior minoria racial do país; os dois maiores grupos étnicos asiático-americanos são chineses americanos e filipinos americanos. Em 2008, a população americana incluía um número estimado de 4,9 milhões de pessoas com alguma ascendência de nativos americanos ou nativos do Alasca (3,1 milhões exclusivamente de tal ascendência) e 1,1 milhões com alguma ascendência de nativos do Havaí ou das ilhas do Pacífico (0,6 milhões exclusivamente). De acordo com o censo de 2010, os hispânicos já são mais de 50 milhões nos Estados Unidos.
O crescimento populacional dos hispânicos e latino-americanos é uma grande tendência demográfica. Os 46,9 milhões de americanos de ascendência hispânica são identificados como uma etnia "distinta" pelo "Census Bureau"; 64% dos hispano-americanos são de origem mexicana. Entre 2000 e 2008, a população hispânica do país aumentou 32%, enquanto a população não hispânica cresceu apenas 4,3%. Grande parte deste crescimento populacional vem da imigração. Em 2007, 12,6% da população era era constituída por indivíduos nascidos em outros países, 54% deles na América Latina. A fertilidade é também um fator importante; o número médio de filho por mulher latino-americana (taxa de fecundidade é de três, de 2,2 para as mulheres não hispânicas negras e 1,8 para as mulheres não hispânicas brancas (abaixo da taxa de substituição populacional, que é de 2,1). Minorias (conforme definido pelo "Census Bureau", ao lado de todos os não hispânicos, não multirraciais brancos) constituem 34% da população. Estima-se que os não brancos constituirão a maioria da população em 2042.
Cerca de 82% dos americanos vivem em áreas urbanas; cerca de metade são residentes de cidades com populações superiores a . Em 2008, 273 cidades tinham populações superiores a habitantes, nove cidades tinham mais de um milhão de habitantes e quatro cidades globais tinham mais de 2 milhões de habitantes (Nova Iorque, Los Angeles, Chicago e Houston).
O inglês é a língua nacional "de facto". Embora não haja nenhuma língua oficial em nível federal, algumas leis, como os requisitos para naturalização, padronizam o inglês. Em 2006, cerca de 224 milhões de pessoas, ou 80% da população com idades entre cinco anos ou mais, falava apenas inglês em casa. O espanhol, falado em casa por 12% da população, é o segundo idioma mais comum e a segunda língua estrangeira mais ensinada. Alguns americanos defendem o inglês como a língua oficial do país, como é em, pelo menos, vinte e oito estados do país. Tanto o havaiano quanto o inglês são as línguas oficiais no Havaí por lei estadual.
Enquanto não tenha uma língua oficial, o Novo México tem leis que preveem a utilização dos idiomas inglês e espanhol, a Louisiana tem leis para o inglês e o francês. Outros estados, como a Califórnia, obrigam a publicação de versões em espanhol de alguns documentos do governo, incluindo de tribunais. Vários territórios insulares concedem o reconhecimento oficial para suas línguas nativas, juntamente com o inglês: samoano e chamorro são reconhecidas pela Samoa Americana e Guam, respectivamente; caroliniano e o chamorro são reconhecidos pelas Ilhas Marianas do Norte, assim como o espanhol é uma língua oficial de Porto Rico.
Os Estados Unidos são oficialmente uma nação secular; a Primeira Emenda da Constituição do país garante o livre exercício da religião e proíbe a criação de um governo religioso.
Em um estudo de 2002, 59% dos americanos disseram que a religião teve um papel "muito importante em suas vidas", um número muito maior do que qualquer outra nação desenvolvida. O nível de religiosidade do povo varia bastante regionalmente: segundo pesquisa de 2009, 63% dos habitantes do Mississippi frequentavam a igreja semanalmente, ao passo que em Vermont esse número cai para 23%.
O perfil religioso dos Estados Unidos vem mudando consideravelmente nos últimos anos. De acordo com uma pesquisa de 2014, 70,6% dos adultos se identificaram como cristãos, sendo que em 2007 esse número era de 78,4% e em 1990, de 86,4%. Na década de 2010, pela primeira vez na História, os evangélicos deixaram de ser a maioria da população norte-americana: em 2007, os protestantes representavam 51,3%, porém em 2014 reduziram-se a 46,5%. O grupo que mais cresce nos Estados Unidos são as pessoas sem religião (22,8%), que ultrapassaram os católicos romanos (20,8%) no início da década. Em 2007, o estudo classifica os protestantes brancos, 26,3% da população, como o maior grupo religioso do país; outro estudo estima protestantes de todas as raças em 30-35%.
O total de religiões não cristãs em 2007 foi de 4,7%, acima dos 3,3% em 1990. Os maiores credos não cristãos foram o judaísmo (1,7%), budismo (0,7%), islamismo (0,6%), hinduísmo (0,4%) e o Unitário-Universalismo (0,3%). 8,2% da população em 1990, contra 16,1% em 2007 e 22,8% em 2014, descreveu-se como agnóstico, ateu, ou simplesmente sem-religião.
Os Estados Unidos são a federação mais antiga do mundo. O país é uma república constitucional e uma democracia representativa, "em que a regra da maioria é temperada por direitos das minorias protegidos por lei". O governo é regulado por um sistema de separação de poderes definido pela Constituição, que serve como documento legal supremo do país. No sistema federalista estado-unidense, os cidadãos são geralmente sujeitos a três níveis de governo: federal, estadual e local; funções de governo local são geralmente divididas entre os condados e os governos municipais. Em quase todos os casos, funcionários do executivo e do legislativo são eleitos pelo voto da maioria dos cidadãos do distrito. Não há representação proporcional no nível federal e isso é muito raro em níveis inferiores.
O governo federal é composto de três ramos:
A Câmara dos Representantes tem 435 membros votantes, cada um representando um distrito do Congresso para um mandato de dois anos. Cadeiras na Câmara são distribuídas entre os estados pela população a cada dez anos. De acordo com o censo de 2000, sete estados têm um mínimo de um representante, enquanto a Califórnia, o estado mais populoso, tem cinquenta e três. O Senado tem 100 membros com cada estado tendo dois senadores, eleitos para mandatos de seis anos, um terço das cadeiras do Senado estão acima para a eleição a cada ano.
O presidente não é eleito pelo voto direto, mas por um sistema de colégio eleitoral indireto em que os votos são distribuídos de forma determinada por estado, para um mandato de quatro anos, podendo ser reeleito uma vez, consecutiva ou não. Cada estado recebe uma determinada quantidade de votos de acordo com o número de congressistas dentro do poder legislativo: senadores (dois por cada estado) e representantes (que variam de acordo com a população de cada estado); dando um total de 538 membros. O sistema bipartidarista permite que um dos candidatos à presidência, seja do Partido Republicano ou do Democrata, precise de apenas duzentos e setenta votos para assegurar a vitória. A Suprema Corte, liderada pelo Chefe de Justiça dos Estados Unidos, tem nove membros.
Os governos estaduais estão estruturados de forma mais ou menos semelhante. O estado de Nebraska, excepcionalmente, tem uma legislatura unicameral. O governador (chefe executivo) de cada estado é eleito por sufrágio direto. Alguns juízes estaduais e agentes do gabinete são nomeados pelos governadores dos respectivos estados, enquanto outros são eleitos pelo voto popular.
Todas as leis e procedimentos governamentais são passíveis de recurso judicial e a que foi julgada em desacordo com a Constituição é anulada. O texto original da Constituição estabelece a estrutura e as responsabilidades do governo federal e sua relação com os estados. O artigo primeiro protege o direito ao "grandes decreto" do "habeas corpus" e o Artigo Terceiro garante o direito a um julgamento com júri em todos os casos criminais. Emendas à Constituição exigem a aprovação de três quartos dos estados. A Constituição foi alterada vinte e sete vezes; as dez primeiras emendas, que constituem a Carta dos Direitos, e a décima quarta emenda formam a base central dos direitos individuais dos americanos.
O presidente detém o título de comandante-em-chefe das forças armadas do país e nomeia seus dirigentes, o secretário de defesa e o Chefe do Estado-Maior Conjunto. O Departamento de Defesa dos Estados Unidos administra as forças armadas, incluindo o Exército, Marinha, Corpo de Fuzileiros Navais e da Força Aérea. A Guarda Costeira é executada pelo Departamento de Segurança Interna em tempos de paz e pelo Departamento da Marinha em tempos de guerra. Em 2008, as forças armadas tinham 1,4 milhões de pessoas na ativa. As Reservas da Guarda Nacional elevam o número total de tropas para 2,3 milhões. O Departamento de Defesa também empregou cerca de 700.000 civis, não incluindo empreiteiros.
O serviço militar é voluntário, embora a conscrição possa ocorrer em tempos de guerra através do chamado Sistema de Serviço Seletivo. As forças estado-unidenses podem ser rapidamente implantadas pela grande frota de aviões de transporte da Força Aérea, onze aviões ativos da Marinha e "Marine Expeditionary Unit" no mar com frotas da Marinha no Atlântico e no Pacífico. O país mantém 865 bases e instalações militares ao redor do mundo, com pessoal destacado para mais de 150 países.
A extensão da presença militar global tem levado alguns estudiosos a descrever os Estados Unidos como a manutenção de um "império de bases".
O total de gastos militares dos Estados Unidos em 2008 foi de mais de 600 bilhões de dólares, superior a 41% da despesa militar mundial e maior do que todos os próximos quatorze maiores gastos militares nacionais somados. O gasto per capita de 1.967 dólares foi cerca de nove vezes superior à média mundial; com 4% do PIB, a taxa foi a segunda mais alta entre os quinze maiores gastadores militares, depois da Arábia Saudita.
A base proposta pelo Departamento de Defesa para o orçamento de 2010, 533,8 bilhões de dólares, foi um aumento de 4% em relação a 2009 e 80% maior que em 2001, um adicional de 130 bilhões de dólares foi proposto para as campanhas militares no Iraque e no Afeganistão. Em setembro de 2009, havia cerca de 130 mil soldados americanos enviados ao Iraque e 62 mil mobilizados para o Afeganistão. Até 9 de outubro de 2009, os Estados Unidos haviam sofrido com militares mortos durante a Guerra do Iraque e 869 durante a Guerra no Afeganistão. Entre os anos de 1890 e 2012, o país invadiu ou bombardeou outras 149 nações ao redor do planeta.
Os Estados Unidos exercem uma forte influência econômica, política e militar em todo o mundo. O país é um membro permanente do Conselho de Segurança das Nações Unidas e Nova Iorque hospeda a sede das Nações Unidas. Quase todos os países têm embaixadas em Washington D.C. e muitos consulados em todo o país. Da mesma forma, quase todas as nações acolhem missões diplomáticas americanas. No mundo, apenas Butão, Coreia do Norte e Irã não têm relações diplomáticas com os Estados Unidos.
Os Estados Unidos mantêm laços fortes com o Reino Unido, Canadá, Austrália, Nova Zelândia, Japão, Coreia do Sul e Israel. Trabalha em estreita colaboração com outros membros da Organização do Tratado do Atlântico Norte (OTAN) sobre questões militares e de segurança e com seus vizinhos por meio da Organização dos Estados Americanos (OEA) e tem acordos de livre comércio trilateral, como o Tratado Norte-Americano de Livre Comércio com o Canadá e o México. Em 2008, os Estados Unidos gastaram 25,4 bilhões de dólares líquidos em assistência oficial ao desenvolvimento em grande parte do mundo. Em percentagem do produto nacional bruto (PNB), no entanto, a contribuição americana de 0,18% ficou em último lugar entre os vinte e dois Estados doadores. Em contraste, as doações particulares ao exterior dos americanas são relativamente generosas, particularmente com Israel.
A aplicação da lei nos Estados Unidos é sobretudo da responsabilidade da polícia local e dos departamentos de xerifes, com polícias estaduais que prestam serviços mais amplos. As agências federais, como o Escritório Federal de Investigação (FBI) e os "U.S. Marshals Service", têm funções especializadas. No nível federal e em quase todos os estados, a jurisprudência opera em um sistema de "common law". Tribunais estaduais julgam a maioria dos crimes; tribunais federais julgam certos crimes designados, bem como apelos de alguns sistemas estaduais.
Entre os países desenvolvidos, os Estados Unidos têm níveis acima da média de crimes violentos e níveis particularmente altos de violência armada e de homicídio. Em 2007, havia 5,6 homicídios por 100 mil pessoas, três vezes a taxa do vizinho Canadá. A taxa de homicídios do país, que diminuiu 42% entre 1991 e 1999, permaneceu aproximadamente constante desde então. O direito de civis possuírem armas é objeto de um controverso debate político.
Os Estados Unidos têm a maior taxa registrada de encarceramento e a maior população carcerária total do mundo. No início de 2008, mais de 2,3 milhões de pessoas foram presas, mais de um em cada 100 adultos. A taxa é de cerca de sete vezes o valor de 1980. As prisões de afro-americanos são em cerca de seis vezes maior que a taxa de prisão de homens brancos e três vezes a taxa de homens latinos. Em 2015, o país concentrava 5% da população mundial, mas 25% da população carcerária do planeta. E 60% dos presidiários eram de origem hispânica e africana.
Em 2006, a taxa de encarceramento americano foi mais de três vezes o valor da taxa da Polônia, país da Organização para a Cooperação e Desenvolvimento Econômico (OCDE) com a segunda taxa mais alta. A elevada taxa de encarceramento do país deve-se, em grande parte, à condenação e às políticas de drogas.
Embora tenha sido abolida na maioria das nações ocidentais, a pena capital é sancionada nos Estados Unidos para certos crimes federais e militares, e em trinta e seis estados. Desde 1976, quando a Suprema Corte dos Estados Unidos restabeleceu a pena de morte depois de uma moratória de quatro anos, houve mais mais de mil execuções. Em 2006, o país teve o sexto maior número de execuções no mundo, na sequência de China, Irã, Paquistão, Iraque e Sudão. Em 2007, Nova Jérsei se tornou o primeiro estado a abolir legislativamente a pena de morte desde a decisão de 1976 da Suprema Corte, seguida do Novo México em 2009.
Os Estados Unidos são uma união federal de cinquenta estados. Os originais treze estados foram os sucessores das treze colônias que se rebelaram contra o domínio britânico. No início da história do país, três novos estados foram organizados em território separados das reivindicações dos estados existentes: Kentucky da Virgínia; Tennessee da Carolina do Norte e Maine de Massachusetts. A maioria dos outros estados foi esculpida a partir de territórios obtidos através de guerras ou por aquisições do governo americano. Um conjunto de exceções compreende Vermont, Texas e Havaí: cada um era uma república independente antes de ingressar na união. Durante a Guerra Civil Americana, a Virgínia Ocidental se separou da Virgínia. O Havaí, o mais recente estado do país, foi anexado em 1898 e foi elevado à categoria de estado em 21 de agosto de 1959. Os estados não têm o direito de se separar da união.
Os estados compõem a maior parte da massa terrestre americana, as duas outras áreas consideradas partes integrantes do país são o Distrito de Colúmbia, o distrito federal, onde a capital, Washington, está localizada, e o Atol Palmyra, um território integrado, mas desabitado no Oceano Pacífico. Os Estados Unidos também possuem cinco grandes territórios ultramarinos: Porto Rico e Ilhas Virgens Americanas, no Caribe, e Samoa Americana, Guam e as Ilhas Marianas do Norte, no Pacífico. As pessoas nascidas nos territórios (exceto na Samoa Americana) possuem cidadania americana. Cidadãos americanos residentes nos territórios têm muitos dos mesmos direitos e responsabilidades dos cidadãos residentes nos estados, no entanto, eles geralmente são isentos do imposto de renda federal, não podem votar para presidente e têm apenas uma representação sem direito a voto no Congresso.
Os Estados Unidos têm uma economia mista capitalista, que é abastecida por recursos naturais abundantes, uma infraestrutura bem desenvolvida e pela alta produtividade. Entre as décadas de 1830 e 1860, período conhecido com "free banking era", o país permitia a emissão de moeda privada e possuía um sistema bancário livre de regulamentações. De acordo com o Fundo Monetário Internacional, o PIB dos Estados Unidos de 14,4 trilhões de dólares representa 24% do produto interno bruto mundial no mercado de câmbio e quase 21% do produto interno bruto mundial em paridade do poder de compra (PPC). O maior PIB nacional do mundo era cerca de 5% menor do que o PIB combinado da União Europeia em PPC, em 2008. O país ocupa a décima sétima posição no mundo em termos de PIB nominal per capita e a sexta posição em PIB per capita PPC.
Os Estados Unidos são o maior importador e terceiro maior exportador de bens, embora as exportações per capita sejam relativamente baixas. Em 2008, o déficit comercial total do país foi de 696 bilhões de dólares. Canadá, China, México, Japão e Alemanha são os seus principais parceiros comerciais. A China é o maior detentor da dívida externa pública dos EUA. Depois de uma expansão que durou pouco mais de seis anos, a economia americana entrou em recessão desde dezembro de 2007, recuperando-se em 2010. Os Estados Unidos ocupam o segundo lugar no "Global Competitiveness Report".
Em 2009, estimou-se que o setor privado constituía 55,3% da economia do país; a atividade do governo federal, 24,1%; e as atividades dos estados e de administrações locais (incluindo as transferências federais), os restantes 20,6%. A economia é pós-industrial, com o setor de serviços contribuindo com 67,8% do PIB, embora os Estados Unidos continuem a ser uma potência industrial.
Os Estados Unidos são o terceiro maior produtor de petróleo do mundo, bem como o seu maior importador. É o maior produtor do mundo de energia elétrica e nuclear, assim como de gás natural liquefeito, enxofre, fosfatos e sal. Enquanto a agricultura representa menos de 1% do PIB, os Estados Unidos são o maior produtor mundial de milho e soja. A Bolsa de Valores de Nova Iorque é a maior do mundo em volume de dólares. Coca-Cola e McDonald's são as duas marcas do país mais reconhecidas no mundo.
No terceiro bimestre de 2009, a força de trabalho do país era composta por 154,4 milhões de pessoas. Desses trabalhadores, 81% tinham emprego no setor de serviços. Com 22,4 milhões de pessoas, o governo é o principal campo de trabalho. Cerca de 12% dos trabalhadores são sindicalizados, contra 30% na Europa Ocidental. O Banco Mundial classifica os Estados Unidos em primeiro lugar na facilidade de contratação e demissão trabalhadores. Entre 1973 e 2003, um ano de trabalho para o norte-americano médio cresceu 199 horas.
Em parte como resultado disto, os Estados Unidos mantém a maior produtividade do trabalho no mundo. Em 2008, ele também levou a produtividade por hora do mundo, ultrapassando a Noruega, França, Bélgica e Luxemburgo, que havia superado os Estados Unidos durante a maior parte da década anterior. Em relação à Europa, a propriedade e as taxas de imposto de renda americanas são geralmente mais elevadas, enquanto trabalho e, particularmente, as taxas de imposto sobre o consumo são menores.
Os Estados Unidos têm sido um líder em pesquisa científica e em inovação tecnológica desde o . Em 1876, Alexander Graham Bell registou a primeira patente americana para o telefone. O laboratório de Thomas Edison desenvolveu o primeiro fonógrafo, a primeira lâmpada incandescente, a primeira câmera de vídeo viável. Nikola Tesla foi o pioneiro da corrente alternada, do motor AC e do rádio. No início do , as empresas de automóveis de Ransom E. Olds e Henry Ford promoveram a linha de montagem. Os irmãos Wright, em 1903, fizeram o primeiro objeto sustentado e controlado mais pesado que o ar voar.
A ascensão do nazismo na década de 1930 levou muitos cientistas europeus, incluindo Albert Einstein e Enrico Fermi, a imigrar para os Estados Unidos. Durante a Segunda Guerra Mundial, o Projeto Manhattan desenvolveu armas nucleares, dando início à Era Atômica. A Corrida Espacial produziu rápidos avanços no desenvolvimento de foguetes, da ciência dos materiais e de computadores. Os Estados Unidos também tiveram grande contribuição no desenvolvimento da ARPANET e de sua sucessora, a Internet. Hoje, a maior parte do financiamento para pesquisa e desenvolvimento, 64%, vem do setor privado. Os Estados Unidos lideram no mundo em trabalhos de pesquisa científica e fator de impacto. Os americanos possuem níveis de consumo tecnologicamente avançados, e quase metade dos lares têm acesso à banda larga. O país é o principal desenvolvedor e produtor de alimentos geneticamente modificados. Mais da metade das terras cultivadas com culturas transgênicas do mundo está nos Estados Unidos.
A educação pública americana é operada por governos estaduais e municipais, sendo regulada pelos Departamento de Educação dos Estados Unidos através de restrições sobre as subvenções federais. Crianças são obrigadas na maioria dos estados a frequentar a escola desde os seis ou sete anos (em geral, pré-escola ou primeira série) até os dezoito (geralmente até o décimo segundo grau, ao final do ensino médio); alguns estados permitem que os estudantes deixem a escola aos dezesseis ou dezessete anos. Cerca de 12% das crianças estão matriculadas em escolas paroquiais ou escolas privadas não sectárias. Pouco mais de 2% das crianças fazem ensino doméstico.
Os Estados Unidos têm muitas instituições públicas e privadas de ensino superior competitivas, bem como faculdades de comunidades locais com políticas abertas de admissão. Dos americanos com 25 anos ou mais, 84,6% concluíram o ensino superior, 52,6% frequentavam alguma faculdade, 27,2% recebiam um diploma de bacharel e 9,6% frequentavam uma pós-graduação. A taxa de alfabetização é de cerca de 99% da população. A Organização das Nações Unidas atribui aos Estados Unidos um índice de educação de 0,97, classificando-o na 12ª posição no mundo.
De acordo com a Unesco, os Estados Unidos são o segundo país com o maior número de instituições de educação superior no mundo, com um total de , com um ponto médio de quinze por cada estado. O país conta com o maior número de estudantes universitários do mundo, ascendendo a , correspondente a 4.5% da população total. Lá encontram-se algumas das universidades mais prestigiosas e de maior fama no mundo. Harvard, Berkeley, Stanford e o Instituto de Tecnologia de Massachusetts são consideradas como as melhores universidades por muitas de suas publicações.
Sendo um país desenvolvido, os Estados Unidos contam com uma avançada infraestrutura de transportes: quilômetros de autoestradas, quilômetros de vias férreas e quilômetros de vias fluviais. A maior parte dos seus habitantes utiliza o automóvel como o principal meio de transporte. Em 2003, havia 759 automóveis para cada 1.000 americanos, em comparação com os 472 automóveis para cada 1.000 habitantes da União Europeia no ano seguinte. Cerca de 40% dos veículos pessoais são vans, utilitários esportivos ou caminhões leves. O americano adulto médio (contabilização de todos os que dirigem e não dirigem) gasta 55 minutos dirigindo por dia, viajando 47 km.
A indústria da aviação civil é totalmente privada, enquanto a maioria dos grandes aeroportos são de propriedade pública. As quatro maiores companhias aéreas do mundo em passageiros transportados são americanos; "Southwest Airlines" é a número um. Dos trinta aeroportos mais movimentados por passageiros do mundo, dezesseis estão nos Estados Unidos, sendo o mais movimentado deles o Aeroporto Internacional de Atlanta Hartsfield-Jackson, o maior do mundo. Enquanto o transporte ferroviário de mercadorias é extenso, relativamente poucas pessoas usam transporte ferroviário em viagens, dentro ou entre as cidades. O transporte de massa contabiliza 9% do total de viagens de trabalho dos Estados Unidos, comparado aos 38,8% na Europa. O uso de bicicletas é mínimo, bem abaixo dos níveis europeus.
O consumo energético total do país é de 3,873 bilhões lWh anuais, equivalente a um consumo per capita de 7,8 toneladas de petróleo ao ano. Em 2005, 40% da energia provinha do petróleo, 23% do carvão e 22% de gás natural; o resto provinha de centrais nucleares e de fontes de energia renovável. Os Estados Unidos são o maior consumidor de petróleo e gás natural: anualmente são utilizados 19,15 milhões de barris de petróleo/dia e 683,3 mil milhões de metros cúbicos/dia de gás natural (2010). Por outro lado, no país são encontradas 27% das reservas mundiais de carvão. Durante décadas, a energia nuclear teve um papel julgado na produção de energia, em comparação à maioria dos países desenvolvidos, devido em parte à reação após o acidente de Three Mile Island. Em 2007, o governo recebeu múltiplas petições para a construção de novas centrais nucleares, o que poderia significar uma diminuição considerável no consumo de combustíveis fósseis e mudanças na política energética.
A expectativa de vida dos Estados Unidos é de 77,8 anos ao nascer, um ano menor do que o valor global da Europa Ocidental, e de três a quatro anos menor do que as taxas da Noruega, Suíça e Canadá. Ao longo das últimas duas décadas, a classificação do país em expectativa de vida caiu de 11ª posição para a 42ª no mundo. A taxa de mortalidade infantil é de 6,37 por mil, colocando o país também na 42ª posição entre 221 países, atrás de toda a Europa Ocidental. Aproximadamente um terço da população adulta do país é obesa e um terço adicional tem excesso de peso; a taxa de obesidade, a mais alta do mundo industrializado, mais do que duplicou no último quarto de século. A obesidade relacionada com o diabetes tipo 2 é considerada uma epidemia pelos profissionais de saúde.
A taxa de gravidez na adolescência no país é de 53 por 1.000 mulheres, seis vezes superior à da França e quatro vezes superior à da Alemanha. A legalização do aborto é altamente controversa. Muitos estados proíbem o financiamento público do processo e restringem o aborto, exigem a notificação parental para os menores de idade e o mandato de um período de espera. Apesar de a taxa de aborto estar caindo, a taxa de aborto de 241 por 1.000 nascidos vivos e taxa de abortamento de 15 por mil mulheres com idade entre 15-44 anos permanecem superiores aos da maioria das nações ocidentais.
O sistema de saúde americano gasta muito mais que qualquer sistema de saúde de outra nação, seja em gastos "per capita" ou em percentagem do PIB. A Organização Mundial de Saúde classificou o sistema de saúde americano, em 2000, como o primeiro em capacidade de resposta, mas o 37º em desempenho global. Os Estados Unidos são um líder em inovação médica. Em 2004, o setor não industrial gastou três vezes mais "per capita" do que a Europa em pesquisa biomédica.
Os Estados Unidos são sede dos melhores hospitais do mundo. Grande parte das instalações médicas são de propriedade privada que contam com alguns subsídios do governo local. Apesar de serem associações sem fins lucrativos, muitos dos hospitais mais importantes estão afiliados a grandes corporações ou faculdades de medicina, que têm feito o possível para albergarem 70% de todos os pacientes médicos do país. O Hospital Johns Hopkins, a Mayo Clinic e o Massachusetts General Hospital se encontram entre os melhores hospitais do país e do mundo.
No entanto, ao contrário de todos os outros países desenvolvidos, os Estados Unidos são o único país do mundo ocidental que não tem um sistema de saúde pública universal e estima-se que cerca de 125 cidadãos norte-americanos morram todos os dias por não poderem pagar um plano de saúde, além de seus indicadores de saúde serem considerados os piores entre os países mais industrializados. Em 2004, os seguros privados de saúde pagaram por 36% dos gastos pessoais de saúde, os pagamentos privados corriqueiros por 15%, e os pagamentos federais, estaduais e de governos locais por 44%. Em 2005, 46,6 milhões de americanos, ou 15,9% da população, eram não segurados, 5,4 milhões a mais que em 2001. A principal causa deste aumento é a queda no número de americanos com seguro de saúde patrocinado por empregadores. A questão de americanos não segurados é uma importante questão política. Um estudo de 2009 estimou que a falta de seguro está associada com cerca de 45.000 mortes por ano. Em 2006, Massachusetts se tornou o primeiro estado do país a ter um mandato de seguro de saúde universal. Uma legislação federal aprovada no início de 2010 (o chamado "Patient Protection and Affordable Care Act"), que entrou em vigor em 2014, determinou a criação de um sistema de seguro de saúde quase universal no país.
Os Estados Unidos são uma nação multicultural, lar de uma grande variedade de grupos étnicos, tradições e valores. Além das já pequenas populações nativas americanas e nativas do Havaí, quase todos os americanos ou os seus antepassados emigraram nos últimos cinco séculos. A cultura em comum pela maioria dos americanos é a cultura ocidental em grande parte derivada das tradições de imigrantes europeus, com influências de muitas outras fontes, tais como as tradições trazidas pelos escravos da África. A imigração mais recente da Ásia e especialmente da América Latina adicionou uma mistura cultural que tem sido descrita tanto como homogeneizada quanto heterogênea, já que os imigrantes e seus descendentes mantêm especificidades culturais.
De acordo com a análise de dimensões culturais de Geert Hofstede, os Estados Unidos têm maior pontuação de individualismo do que qualquer país estudado. Apesar da cultura dominante de que os Estados Unidos sejam uma sociedade sem classes, estudiosos identificam diferenças significativas entre as classes sociais do país, que afetam a socialização, linguagem e valores. A classe média e profissional americana iniciou muitas tendências sociais contemporâneas como o feminismo moderno, o ambientalismo e o multiculturalismo. A autoimagem dos americanos, dos pontos de vista social e de expectativas culturais, é relacionada com as suas profissões em um grau de proximidade incomum. Embora os americanos tendam a valorizar muito a realização sócio-econômica, ser parte da classe média ou normal é geralmente visto como um atributo positivo. Embora o sonho americano, ou a percepção de que os americanos gozam de uma elevada mobilidade social, desempenhe um papel fundamental na atração de imigrantes, alguns analistas acreditam que os Estados Unidos têm menos mobilidade social que a Europa Ocidental e o Canadá.
As mulheres na sua maioria trabalham fora de casa e recebem a maioria dos diplomas de bacharel. Em 2007, 58% dos americanos com dezoito anos ou mais eram casados, 6% eram viúvos, 10% eram divorciados e 25% nunca haviam sido casados. O casamento entre pessoas do mesmo sexo é permitido em todos os estados desde 26 de junho de 2015, quando, ao final do caso "Obergefell v. Hodges", decidiu-se que era inconstitucional a proibição da união homoafetiva.
Desde finais do , o beisebol é considerado como o esporte nacional, enquanto o futebol americano, o hóquei no gelo e o basquete são outros três grandes esportes de equipe profissionais. As ligas universitárias também atraem grandes audiências. O futebol americano é o esporte mais popular no país. O boxe e a corrida de cavalo foram uma vez os esportes individuais mais vistos, mas foram substituídos pelo golfe e o automobilismo. O futebol vem crescendo de popularidade desde a criação da MLS.
A maioria dos esportes mais importantes do país evoluíram de práticas europeias, como o basquete, o voleibol, a animação e o snowboarding são esportes criados dentro do território nacional. O lacrosse e o surfe surgiram de povos ameríndios e nativos do Havaí. O Comitê Olímpico dos Estados Unidos organizou, em 1904, os Jogos Olímpicos de Verão, em St. Louis, Missouri; os Jogos de Los Angeles em 1932 e 1984 e mais recentemente os Jogos de Atlanta em 1996. Em 2004, os Estados Unidos conseguiram um total de 103 medalhas, das quais 35 eram de ouro. O país conquistou, ao total, 2 301 medalhas em Jogos Olímpicos de Verão, onde é o país que mais venceu, e 216 nos Jogos Olímpicos de Inverno, onde é o segundo país no ranking total, atrás apenas da Noruega.
As principais artes culinárias americanas são semelhantes às de outros países ocidentais. O trigo é o principal cereal. A cozinha tradicional americana utiliza ingredientes como peru, veado, carne de cervo de rabo branco, batata, batata doce, milho, abóbora e xarope de bordo, alimentos utilizados pelos povos nativos americanos e pelos colonizadores europeus. Carne de porco lentamente cozida e churrasco de carne, "crabcakes", batata frita e "cookies" de chocolate são pratos distintamente americanos. A "soul food", desenvolvida por escravos africanos, é popular em todo o Sul e entre muitos afro-americanos em todo o país. O sincretismo, como o presente nas culinárias crioula da Louisiana, Cajun e Tex-Mex, é regionalmente importante.
Pratos característicos como a torta de maçã, frango frito, pizza, hambúrgueres e cachorros-quentes decorrem das receitas de diversos imigrantes. Batatas fritas, pratos mexicanos como tacos e burritos e pratos de massas livremente adotados a partir de fontes italianas são amplamente consumidos. Americanos geralmente preferem café a chá. O "marketing" feito por indústrias do país é largamente responsável pela onipresença de suco de laranja e leite no café da manhã. Durante os anos 1980 e 1990, a ingestão calórica dos americanos aumentou 24%; as frequentes refeições de "fast-food" estão associadas com o que as autoridades de saúde chamam a "epidemia de obesidade" nos Estados Unidos. Refrigerantes adoçados são amplamente populares; bebidas adoçadas são responsáveis por 9% da ingestão calórica do americano médio.
A primeira exposição comercial de filme do mundo foi feita em Nova Iorque em 1894, usando o cinetoscópio de Thomas Edison. No ano seguinte foi feita a primeira exibição comercial de um filme projetado, também em Nova Iorque, e os Estados Unidos estavam na vanguarda do desenvolvimento do cinema sonoro nas décadas seguintes. Desde o início do , a indústria cinematográfica americana tem sido largamente sediada nos arredores de Hollywood, na Califórnia. O diretor D. W. Griffith foi central para o desenvolvimento da gramática cinematográfica, e o filme "Cidadão Kane" (1941) de Orson Welles é frequentemente citado como o melhor filme de todos os tempos. Atores cinematográficos americanos como John Wayne e Marilyn Monroe se tornaram figuras icónicas, enquanto o produtor/empresário Walt Disney foi um líder em filmes animados e de "merchandising". Os grandes estúdios cinematográficos de Hollywood têm produzido os filmes de maior sucesso comercial da história, como "Star Wars" (1977) e "Titanic" (1997), e os produtos de Hollywood hoje dominam a indústria cinematográfica mundial.
Os americanos são os maiores espectadores de televisão do mundo, e o tempo médio de visualização continua a aumentar, chegando a cinco horas por dia em 2006. As quatro grandes redes de televisão do país são todas entidades comerciais. Americanos ouvem programas de rádio, também largamente comercializado, em média, pouco mais de duas horas e meia por dia. Além de portais e motores de busca, os sites mais populares no país são o Facebook, YouTube, Wikipédia, Blogger, eBay, Google e Craigslist.
Os estilos rítmicos e vocais da música negra americano influenciaram profundamente a música americana em geral, distinguindo-a das tradições europeias. Elementos da música folclórica, como o "blues" e o que é agora conhecido como "old-time music", foram aprovadas e transformadas em gêneros populares com público global. O "jazz" foi desenvolvido por artistas inovadores, tais como Louis Armstrong e Duke Ellington no início do . A música country foi desenvolvida na década de 1920, e o "rhythm and blues" na década de 1940. Elvis Presley e Chuck Berry foram um dos pioneiros do "rock and roll" em meados dos anos 1950. Em 1960, Bob Dylan surgiu a partir do "american folk music revival" para se tornar um dos compositores mais célebres do país e James Brown liderou o desenvolvimento do "funk". Mais recentes criações musicais americanas incluem o "rap" e a "house music". Astros "pop" americanos como Elvis Presley, Michael Jackson e Madonna tornaram-se celebridades globais.
No e início do , a arte e a literatura americana tinham a maioria das suas influências da Europa. Escritores como Nathaniel Hawthorne, Edgar Allan Poe e Henry David Thoreau estabeleceram uma voz literária americana distinta em meados do . Mark Twain e o poeta Walt Whitman foram figuras importantes na segunda metade do século; Emily Dickinson, praticamente desconhecida durante sua vida, é agora reconhecida como uma poetisa americana fundamental. Algumas obras são consideradas sínteses dos aspectos fundamentais da experiência nacionais e caráter, como "Moby Dick" (1851) de Herman Melville, "As Aventuras de Huckleberry Finn" (1885) de Mark Twain e "The Great Gatsby" (1925) de F. Scott Fitzgerald, obra apelidada de "Great American Novel".
Doze cidadãos americanos ganharam o Prêmio Nobel de Literatura, os mais recentes deles Toni Morrison, em 1993, e Bob Dylan, em 2016. Ernest Hemingway, Prêmio Nobel de 1954, é muitas vezes apontado como um dos escritores mais influentes do . Gêneros literários populares, como a ficção ocidental e a "Hard Boiled" foram desenvolvidas nos Estados Unidos. Os escritores da Geração Beat abriram novas abordagens literárias, assim como os autores pós-modernos, tais como John Barth, Thomas Pynchon e Don DeLillo.
Os transcendentalistas, liderados por Thoreau e Ralph Waldo Emerson, estabeleceram o primeiro grande movimento filosófico americano. Após a Guerra Civil, Charles Sanders Peirce e William James e John Dewey foram os líderes no desenvolvimento do pragmatismo. No , o trabalho de W. V. O. Quine e Richard Rorty, construído em cima de Noam Chomsky, trouxe a filosofia analítica à frente dos acadêmicos americanos. John Rawls e Robert Nozick levaram o renascimento da filosofia política.
Nas artes visuais, a Escola do Rio Hudson foi um movimento de meados do , na tradição do naturalismo europeu. O "Armory Show" de 1913, em Nova Iorque, uma exposição de arte moderna europeia, chocou o público e transformou a cena artística americana. Georgia O'Keeffe, Marsden Hartley e outras experiências com novos estilos, exibindo uma sensibilidade muito individualista. Importantes movimentos artísticos como o expressionismo abstrato de Jackson Pollock e Willem de Kooning e da arte pop de Andy Warhol e Roy Lichtenstein foram desenvolvidos em grande parte nos Estados Unidos. A maré do modernismo e pós-modernismo trouxe fama para arquitetos estado-unidenses, como Frank Lloyd Wright, Philip Johnson e Frank Gehry.
Um dos primeiros promotores principais do teatro americano foi o empresário P. T. Barnum, que começou um complexo de entretenimento em Manhattan em 1841. A equipe de Harrigan e Hart produziu uma série de comédias musicais populares em Nova Iorque no final dos anos 1870. No , a forma moderna de musicais surgiu na Broadway, as canções de compositores de teatro musical, como Irving Berlin, Cole Porter e Stephen Sondheim, tornaram-se padrões pop. O dramaturgo Eugene O'Neill ganhou o Prêmio Nobel de literatura em 1936. Outros dramaturgos americanos aclamados incluem vários vencedores do Prêmio Pulitzer como Tennessee Williams, Edward Albee e August Wilson.
Apesar de largamente ignorado na época, o trabalho de Charles Ives na década de 1910 estabeleceu-o como o primeiro grande compositor americano na tradição clássica; outros experimentalistas, tais como Henry Cowell e John Cage, criaram uma abordagem americana de composição clássica. Aaron Copland e George Gershwin desenvolveram uma síntese única de música popular e clássica. As coreógrafas Isadora Duncan e Martha Graham ajudaram a criar a dança moderna, enquanto George Balanchine e Jerome Robbins eram líderes no balé do . Os americanos têm sido importantes no meio artístico da fotografia moderna, com grandes fotógrafos, incluindo Alfred Stieglitz, Edward Steichen e Ansel Adams. As tirinhas de jornais e os "comics" são inovações americanas. Superman, o super-herói dos quadrinhos por excelência, tornou-se um ícone americano.

A EXPO'98, Exposição Mundial de 1998, ou, oficialmente, Exposição Internacional de Lisboa de 1998, cujo tema foi "Os oceanos: um património para o futuro", realizou-se em Lisboa, Portugal de 22 de maio a 30 de setembro de 1998. Teve o propósito de comemorar os 500 anos dos Descobrimentos Portugueses.
A zona escolhida para albergar o recinto foi o limite oriental da cidade junto ao rio Tejo. Foram construídos diversos pavilhões, alguns dos quais ainda permanecem ao serviço dos habitantes e visitantes, integrados no agora designado "Parque das Nações", destacando-se o Oceanário (o maior aquário do Mundo com a reprodução de 5 oceanos distintos e numerosas espécies de mamíferos e peixes, do arquiteto Peter Chermayeff) um pavilhão de múltiplas utilizações (Pavilhão Atlântico, arquiteto Regino Cruz) e um complexo de transportes com metropolitano e ligações ferroviárias (Estação do Oriente, do arquiteto Santiago Calatrava).
A EXPO'98 atraiu cerca de 11 milhões de visitantes, apesar de previsões iniciais apontarem para cerca de 15 milhões, o que veio a justificar algumas opções de gestão de carácter duvidoso, e, acima de tudo, ruinosas para a empresa e seus acionistas. Parte do seu sucesso ficou a dever-se à vitalidade cultural que demonstrou - por exemplo, os seus cerca de 5000 eventos musicais constituíram um dos maiores festivais musicais da história da humanidade. Arquitetonicamente, a Expo revolucionou esta parte da cidade e influenciou as estratégias de requalificação urbana do panorama português - pode dizer-se que o Parque das Nações é um exemplo de requalificação bem-sucedida dum espaço urbano.
A utilização pioneira de ferramentas de design para grandes projetos de arquitetura, engenharia e construção transformou a EXPO'98 num caso de estudo internacional na área do desenho assistido por computador (CAD). O exemplo pegou e outras obras seguiram também a mesma metodologia desta experiência transformada já em «case study».
O pioneirismo da EXPO foi, aliás, ressaltado por um trabalho de reportagem intitulado 'A Tale of Two Cities' publicado na edição de Junho de 1999, da Computer Graphics World (volume 22, nº6), a revista de referência internacional do sector.
«Os clássicos estiradores foram substituídos por estações de trabalho. Estávamos em 1993, o que provocou uma verdadeira revolução no modo de trabalhar típico deste sector e representou uma situação ímpar na história de grandes projetos no nosso país». O homem no centro desta operação foi José da Conceição Silva, um especialista de Informática da área de CAD/AEC, do Laboratório Nacional de Engenharia Civil (LNEC), de Lisboa, requisitado para a Parque Expo para responsável pelo Departamento de CAD, SIG, Web e Multimédia.
A ideia de organizar uma Exposição Internacional em Portugal surgiu em 1989 da parte de António Mega Ferreira e Vasco Graça Moura. Ambos estavam à frente da comissão para as comemorações dos 500 anos dos Descobrimentos portugueses liderada Por Francisco Faria Paulino, director do Pavilhão de Portugal na Exposição de Sevilha, tendo também desempenhado as funções de Secretário-Executivo e Comissário-Geral Adjunto da Comissão Nacional para as Comemorações dos Descobrimentos Portugueses entre 1988 e 1996. Assumiu funções de diretor do Pavilhão de Portugal na Exposição Universal de Sevilha e de Comissário-Geral Adjunto do Pavilhão de Portugal na Exposição Internacional de Génova em 1992. Em 2008, foi também Comissário Executivo das Comemorações dos 500 anos da Cidade do Funchal.
Uma vez obtido o apoio do Governo, Mega Ferreira apresentou o projecto ao Bureau International d'Expositions. A candidatura de Lisboa ganhou à de Toronto. Criou-se uma empresa, ParqueExpo' 98, com vista a criar um evento auto-sustentável que obtivesse receitas de bilhetes vendidos e pela venda de terrenos adjacentes à exposição.
O primeiro comissário da EXPO'98 foi António Cardoso e Cunha. Foi substituído em 1997 por José de Melo Torres Campos, já sob o governo do Partido Socialista.
Decidiu-se construir a exposição na zona oriental de Lisboa, que vira através dos anos uma degradação crescente. A antiga Doca dos Olivais fora nos anos 40 um contacto privilegiado com o rio onde atracavam hidroaviões, tendo sido denominada de Aeroporto de Cabo Ruivo. Quando os aviões a jacto de longo curso tornaram os hidroaviões obsoletos, a zona passou a ser um terreno industrial que conheceu uma degradação constante ao longo das décadas seguintes. A zona de 50 hectares onde hoje está o recinto era, no fim dos anos oitenta, um campo de contentores, matadouros e indústrias poluentes. Toda a exposição foi construída do zero. A torre da refinaria da Petrogal, única estrutura conservada, ficou como lembrança do espaço antes da intervenção. Houve um grande cuidado para que quase todos os equipamentos do recinto tivessem utilização posterior, evitando assim o seu abandono e a degradação, como aconteceu em Sevilha em 1992.
Em paralelo, lançaram-se grandes obras públicas. Entre as maiores estão a Ponte Vasco da Gama (a maior da Europa à data), uma nova linha de metro com sete estações e um interface rodo-ferroviário, a Gare do Oriente.
Foram emitidos bilhetes de um dia (5.000$00–25 euros), três dias (12.500$00–62,35 euros), e bilhetes diários apenas para a parte da noite (2500$00–12,50 euros). Existia também um passe livre com acesso ilimitado à exposição durante três meses (50.000$00–250 euros).
A Swatch lançou alguns meses antes da exposição o modelo Adamastor, que continha um chip carregado com um bilhete de um dia. Para entrar, bastava encostar o relógio ao sensor presente em todos os molinetes de entrada.
O tema musical da exposição foi composto em 1996 por Nuno Rebelo. A peça, de seu nome "Pangea" (o nome do super-continente pré-histórico de onde derivaram os actuais), misturava sobre guitarras portuguesas e uma base sinfónica de cariz épico muitas e díspares sonoridades, reminiscentes dos quatro cantos do mundo.
O logótipo da EXPO'98, representando o mar e o sol, foi concebido por Augusto Tavares Dias, diretor criativo de publicidade.
A mascote foi concebida pelo pintor António Modesto e pelo escultor Artur Moreira. Foi selecionada entre 309 propostas e batizada de Gil (em homenagem a Gil Eanes) por José Luís Coelho, um estudante do ciclo, num concurso que envolveu escolas de todo o país.
Durante a EXPO'98 houve dois tipos de pavilhões; os temáticos da responsabilidade da Parque EXPO (Departamento de Conteúdos), e os pavilhões das Regiões Autónomas, entidades convidadas e patrocinadores.
Pavilhões temáticos:
Outros pavilhões:
África do Sul; Angola; Argélia; Benim; Botsuana; Cabo Verde; Comores; Congo; Costa do Marfim; Djibuti; Egito; Eritreia; Guiné-Bissau; Lesoto; Madagáscar; Malawi; Mali; Marrocos; Maurícia; Mauritânia; Moçambique; Namíbia; Nigéria; Quénia; República Democrática do Congo; São Tomé e Príncipe; Senegal; Seychelles; Suazilândia; Sudão; Tanzânia; Tunísia; Uganda; Zâmbia; Zimbabwe.
Antígua e Barbuda; Argentina; Bahamas; Barbados; Belize; Bolívia; Brasil; Canadá; Chile; Colômbia; Cuba; Dominica; El Salvador; Equador; Estados Unidos; Granada; Guatemala; Guiana; Honduras; Jamaica; México; Nicarágua; Panamá; Paraguai; Peru; República Dominicana; Santa Lúcia; São Vicente e Granadinas; São Cristóvão e Névis; Suriname; Trinidad e Tobago; Uruguai; Venezuela.
Arábia Saudita; Arménia; Bangladesh; Cazaquistão; China; Chipre; Coreia do Sul; Emirados Árabes Unidos; Filipinas; Iémen; Índia; Irão; Israel; Japão; Jordânia; Kuwait; Líbano; Mongólia; Nepal; Palestina; Paquistão;Quirguistão; Sri Lanka; Turquia; Vietname.
Albânia; Alemanha; Andorra; Áustria; Bélgica; Bielorrússia; Bósnia e Herzegovina; Bulgária; Croácia; Dinamarca; Eslováquia; Eslovénia; Espanha; Estónia; Finlândia; França; Grécia; Holanda; Hungria; Islândia; Itália; Jugoslávia; Letónia; Lituânia; Luxemburgo; Macedónia; Mónaco; Noruega; Ordem de Malta; Polónia; Portugal; Reino Unido; Roménia; Rússia; Santa Sé; São Marino; Suécia; Suíça; Ucrânia.
Estados Federados da Micronésia; Ilhas Cook; Ilhas Salomão; Kiribati; Papua-Nova Guiné; Samoa Ocidental; Tonga; Tuvalu.
A exposição fechou as portas já ao nascer do dia 1 de Outubro de 1998. A última noite viu a maior enchente da sua história, tendo entrado no recinto depois das 20 horas cerca de 215 mil pessoas. A certo ponto da noite, e por razões de segurança, tiveram de ser destrancados os molinetes de acesso, o que faz com que nunca tenha havido um número certo para a quantidade de gente que se concentrou para ver o fogo-de-artifício de encerramento, o maior alguma vez realizado em Portugal.
De 1 a 15 de Outubro de 1998, o recinto esteve fechado ao público. Reabriu, já como Parque das Nações, recebendo nesse primeiro fim-de-semana mais de 100 mil visitantes. O Oceanário, o Pavilhão do Futuro, do Conhecimento dos Mares, permaneceram com as exposições que exibiram durante a EXPO'98 até ao dia 31 de Dezembro de 1998. 
Em Fevereiro de 1999 já era possível encontrar algumas alterações no Parque das Nações, tais como:
Muitas zonas do Parque das Nações foram sendo gradualmente vendidas para habitação e escritórios. No fim do processo de venda de terrenos, as receitas tinham superado o custo da exposição em oito vezes.
A zona oriental de Lisboa é hoje o bairro mais moderno da cidade, concentrando áreas comerciais, culturais e de lazer com uma vista privilegiada do rio Tejo. A zona atraiu uma série de instituições e empresas de grande nome, que aí basearam as suas sedes ou representações (Vodafone, Microsoft, Sonaecom SGPS, Sony etc.). Cerca de 28 mil pessoas habitam nas suas áreas residenciais Norte e Sul, integrando a freguesia do Parque das Nações.

Euro (símbolo: €; código: EUR) é a moeda oficial da zona Euro, a qual é constituída por 19 dos 28 estados-membro da União Europeia: Alemanha, Áustria, Bélgica, Chipre, Eslováquia, Eslovénia, Espanha, Estónia, Finlândia, França, Grécia, Irlanda, Itália, Letónia, Lituânia, Luxemburgo, Malta, Países Baixos e Portugal. A moeda é também usada de forma oficial pelas instituições da União Europeia e por quatro outros países europeus e, de forma unilateral, por outros dois. Em 2013, a moeda era usada diariamente por cerca de 334 milhões de europeus. A moeda é também usada oficialmente em diversos territórios ultramarinos da UE.
A moeda é ainda usada por mais 210 milhões de pessoas em todo o mundo, das quais 182 milhões em África, que usam moedas de câmbio fixo em relação ao euro. O euro é a segunda maior moeda de reserva e a segunda moeda mais transaccionada no mundo a seguir ao dólar dos Estados Unidos. Com mais de 995 mil milhões de euros em circulação em 2014, o euro tem o maior valor combinado de notas e moedas em circulação no mundo, tendo ultrapassado o dólar norte-americano. Com base em estimativas do Fundo Monetário Internacional do PIB e da paridade do poder de compra, a zona euro é a segunda maior economia do mundo.
O nome "euro" foi oficialmente adotado em 16 de dezembro de 1995. O euro foi introduzido nos mercados financeiros mundiais enquanto unidade de conta a 1 de janeiro de 1999, em substituição da antiga Unidade Monetária Europeia (ECU), a um câmbio de 1:1 (1,1743 USD). As moedas e notas físicas de euro entraram em circulação a 1 de janeiro de 2002, tornando-a a moeda de uso corrente entre os membros originais. Embora nos primeiros dois anos a cotação do euro tenha descido para 0,8252 USD (26 de outubro de 2000), a partir do fim de 2002 começou a ser transacionada a valores superiores ao dólar, atingindo um máximo de 1,6038 USD em 18 de julho de 2008. A partir do fim de 2009, a crise da dívida pública da Zona Euro levou à criação do Fundo Europeu de Estabilização Financeira e à adoção de várias reformas de estabilização monetária.
A ideia do estabelecimento da moeda única na CEE nasceu já na década de 70. Teve como principais defensores os Economistas Fred Arditti, Neil Dowling, Wim Duisenberg, Robert Mundell, Tommaso Padoa-Schioppa e Robert Tollison. No entanto, só pelo Tratado de Maastricht, de 1992 esta ideia passou da teoria para o Direito. Este tratado foi celebrado pelos doze países que à data faziam parte da Comunidade Económica Europeia. O Reino Unido e a Dinamarca optaram neste tratado por ficar de fora da moeda única. Na teoria os países que aderissem posteriormente à União teriam que aderir à moeda única. A Suécia aderiu à União em 1995 mas negociou entrar numa fase posterior. Os critérios para adesão à nova moeda única foram estabelecidos pelo Pacto de Estabilidade e Crescimento de 1997.
O primeiro nome para o sistema de conversão entre as moedas que se uniriam foi o ECU (European Currency Unit em Inglês). O nome de Euro é atribuído ao Belga German Pirloit que assim o sugeriu a Jacques Santer em 1995. O valor da nova moeda foi ancorado ao do ECU por resolução do Conselho da União Europeia de 31 de dezembro de 1998. Esta entrou em vigor a 1 de janeiro de 1999 em forma não material (transferências, cheques, etc.) e a 1 de janeiro de 2002 em notas e moedas.
A Zona Euro é composta pelos seguintes países da União Europeia, que adotaram a moeda comum: Alemanha, Áustria, Bélgica, Chipre, Eslováquia, Eslovénia, Espanha, Estónia, Finlândia, França, Grécia, Irlanda, Itália, Letónia, Lituânia, Luxemburgo, Malta, Países Baixos e Portugal, prevendo-se que com a expansão da União Europeia alguns dos aderentes mais recentes possam nos próximos anos partilhar também o euro como moeda oficial.
O governo dinamarquês anunciou no seu programa de 22 de novembro de 2007 a sua intenção de organizar um referendo sobre a entrada do país na Zona Euro
Alguns países pequenos que não praticam políticas de moeda própria usam também o euro: Andorra, Mónaco, São Marino e Vaticano. Montenegro também utiliza o euro como sua moeda oficial. Também no Kosovo, o euro passou a circular mesmo antes da sua declaração de independência.
Outros países tinham a sua moeda fixada a uma antiga moeda europeia. Este era o caso do escudo cabo-verdiano, que estava ligado ao escudo português, e do franco CFA, que era indexado ao franco francês, em circulação em diversos países africanos, e o Franco CFP, dos territórios franceses no Pacífico.
O banco que controla as emissões do euro e executa a política cambial da União Europeia é o Banco Central Europeu, com sede em Frankfurt am Main, na Alemanha.
Acumulação internacional de moedas de reserva
Com a implementação da nova moeda no quotidiano, decidiu-se que as regras para a formação do plural da palavra (p.ex. "euro", "euros", "euri", "eurok"), o género, o uso da vírgula ou ponto para separação das casas decimais, e da posição do símbolo da unidade monetária manter-se-iam segundo as convenções nacionais de cada país.
Convenções para Portugal e para a língua portuguesa (e para a generalidade das línguas que não o inglês):
Em finais de 2011, foi enunciado em vários parlamentos europeus, mais notavelmente no Parlamento da França e no próprio Parlamento Europeu, a possibilidade de extinção do euro como moeda. Foi referido por François Fillon, primeiro-ministro francês, que o fim da moeda única seria catastrófico para o continente europeu, ao desvalorizar em 25% as economias mais fortes e em 50% as mais frágeis. Várias empresas, como a Autoeuropa, que tem um peso importante na economia portuguesa, avaliam já o cenário próximo de fim do Euro. Embora seja garantido por vários governantes um contínuo esforço de manutenção da moeda, as pressões de "rating" por parte dos mercados financeiros, têm credibilizado a possibilidade de tal acontecer.
Para adoptar o euro os Estados-membros terão de verificar os critérios de convergência, que impõem limites ao valor percentual do défice público e da taxa de inflação, entre outras condições.

A engenharia ambiental ou engenharia do ambiente é o ramo da engenharia que atua nas áreas da avaliação ambiental, gestão ambiental, abastecimento e tratamento de água, drenagem e tratamento de águas pluviais e residuais, gestão de resíduos, gestão de ecossistemas, gestão de recursos hídricos, clima e qualidade do ar, acústica e vibrações, plano e ordenamento do território, energia, saúde ambiental e segurança e saúde no trabalho e gestão de solos e subsolos.
A engenharia do ambiente estuda os problemas ambientais de forma integrada nas suas dimensões ecológica, social, econômica e tecnológica, com vista a promover o desenvolvimento sustentável. O engenheiro ambiental deverá saber reconhecer, interpretar e diagnosticar impactos ambientais negativos e positivos, avaliar o nível de danos ocorridos no meio ambiente e propor soluções integradas de acordo com o direito do ambiente vigente. 
O Engenheiro Ambiental tem por função resolver problemas concretos de prevenção e remediação (atividade corretiva) diante das ações antrópicas mediante aplicações da tecnologia disponível, pontual e localmente apropriada. De modo geral, tanto no âmbito público como privado, sua atuação deve atender às preocupações ambientais mais amplas, consideradas em tratados internacionais como exigências relativas ao clima da Terra, entre outros.
São exemplos as determinações das Cartas de Estocolmo (1972), do Rio de Janeiro (ECO-92), a Convenção de Viena (1985), o Protocolo de Montreal (1987), relativo à camada de Ozônio, o Protocolo de Quioto (1997), o Protocolo de Annapolis e a Conferência promovida pela ONU em Bali (2007) quanto às mudanças climáticas.
De modo geral, sua atuação tem em vista condições de contorno ambientais próprias do entorno circundante. Deve também preocupar-se com o efeito abrangente por sobre a extensão territorial afetada - exemplificada pela bacia hidrográfica quanto às águas e, o potencial da emissão atmosférica potencialmente carregada pelos ventos para local distante. Evidentemente também prevenir sobre possibilidade de outros vetores capazes de provocar alterações de natureza diversa.
De outra parte, o planejamento e a antevisão dos impactos ambientais expandem a responsabilidade da análise prospectiva (atividade preventiva) por sobre o "vir a ser" das coisas. E torna-se agente do próprio desenvolvimento econômico em termos da ética vinculada ao progresso e bem estar da coletividade. Por este motivo, o seu mercado de trabalho é bastante heterogêneo e distribuí-se por: administração central, seus serviços descentralizados a nível regional, administração local, empresas industriais, empresas de consultoria, empresas de serviços, ONGs, instituições de investigação e ensino superior.
Uma das aptidões que devem ser desenvolvidas pelo engenheiro ambiental é a avaliação da duração, magnitude e reversibilidade das alterações causadas pela atividade humana no meio ambiente, independentemente de sua natureza adversa ou benéfica.
Algumas das áreas de atuação do engenheiro ambiental são¹:
Estudo de Impacto Ambiental - EIA
Geoprocessamento e Sensoriamento Remoto 
Outorgas Superficias e Subterrânea 
Planejamento Urbano 
Relatório de Impacto Ambiental - RIMA
Zoneamento Ecológico 

Fases ou estados da matéria são conjuntos de configurações que objetos macroscópicos podem apresentar. O estado físico tem relação com a velocidade do movimento das partículas de uma determinada substância. Canonicamente e segundo o meio em que foram estudados, são quatro os estados ou fases considerados:
Outros tipos de fases da matéria, como o condensado de bose-einstein ou o supersólido são estudados em níveis mais avançados de física. As características de estado físico são diferentes em cada substância e dependem da temperatura e pressão em que ela se encontra.
Há muitas discussões sobre quantos estados da matéria existem, porém as versões mais populares atualmente são de que a matéria somente tem três estados: sólido, líquido e gasoso. Mas há também outros que, ou são intermediários ou pouco conhecidos. Por exemplo: os vapores, que nada mais são uma passagem do estado líquido para o gasoso na mesma fase em que o gás, porém quando está em estado gasoso, não há mais possibilidade de voltar diretamente ao estado líquido; já quando em forma de vapor, pode ir ao estado líquido, desde que exista as trocas de energia necessárias para tal fato. Por isto que diz comumente "vapor d´água".
Se colocarmos os estados físicos da matéria em ordem crescente, conforme a quantidade de energia que cada um possui, teremos:
Condensado de Bose-Einstein → Sólido → Líquido → Gasoso → Plasma
Em 1924, Albert Einstein e Satyendra Nath Bose previram o "condensado de Bose-Einstein", por vezes referido como o quinto estado da matéria. Trata-se de uma coleção de milhares de partículas ultrafrias ocupando um único estado quântico, ou seja, todos os átomos se comportam como um único e gigantesco átomo.possui características, de ambos, estado sólido e estado líquido, como supercondutividade e super-fluidez, porém, é encontrado em temperaturas extremamente baixas (próximas ao zero absoluto), o que faz com que suas moléculas entrem em colapso. É particularmente estudado na área da mecânica quântica.
Na fase gasosa, o condensado de Bose-Einstein manteve uma previsão teórica não verificada durante muitos anos. Em 1995, os grupos de pesquisa de Eric Cornell e Carl Wieman, de JILA na Universidade do Colorado em Boulder, produziram pela primeira vez esse condensado experimentalmente. Um condensado Bose-Einstein é "mais frio" do que um sólido. Pode ocorrer quando os átomos têm níveis quânticos muito semelhantes (ou o mesmo), em temperaturas muito perto do zero absoluto (-273,15 °C).
Perto do zero absoluto, alguns líquidos formam um segundo estado líquido descrito como superfluido porque tem viscosidade zero ou fluidez infinita. Isso foi descoberto em 1937 para o hélio, que constitui um superfluido abaixo da temperatura lambda de 2,17 K. Neste estado, ele vai tentar "subir" para fora do recipiente. Também tem condutividade térmica infinita, de modo que nenhum gradiente de temperatura pode se formar em um superfluido.
Essas propriedades são explicadas pela teoria de que o isótopo comum hélio-4 faz um condensado de Bose-Einstein (ver próxima seção), no estado superfluido. Mais recentemente, superfluidos de condensado fermiônico tem sido formados a temperaturas ainda mais baixas pelo raro isótopo hélio 3 e lítio-6. 
Dois tipos conhecidos são:
Existem outros possíveis estados da matéria; alguns destes só existem sob condições extremas, como no interior de estrelas mortas, ou no começo do universo depois do Big Bang:
Como a cada uma destas fases de uma substância corresponde determinado tipo de estrutura corpuscular, há vários tipos de mudanças de estruturas dos corpos quando muda a fase, ou de estado de aglomeração, da substância que são feitos. A mudança de fases ocorre conforme o diagrama de fases da substância. Mudando a pressão ou a temperatura do ambiente onde um objeto se encontra, esse objeto pode sofrer mudança de fase.

Engenharia de "software" é uma área da computação voltada à especificação, desenvolvimento, manutenção e criação de sistemas de "software", com a aplicação de tecnologias e práticas de gerência de projetos e outras disciplinas, visando organização, produtividade e qualidade. Atualmente, essas tecnologias e práticas englobam linguagens de programação, banco de dados, ferramentas, plataformas, bibliotecas, padrões de projeto de software, processo de software e qualidade de software. Além disso, a engenharia de software deve oferecer mecanismos para se planejar e gerenciar o processo de desenvolvimento de um sistema computacional de qualidade e que atenda as necessidades de um requisitante de software.
Os fundamentos científicos para a engenharia de software envolvem o uso de modelos abstratos e precisos que permitem ao engenheiro especificar, projetar, implementar e manter sistemas de software, avaliando e garantindo suas qualidades. A área que estuda e avalia os processos de engenharia de software, propondo a evolução dos processos, ferramentas e métodos de suporte a engenharia de software é a Engenharia de Software Experiemental.
Friedrich Ludwig Bauer definiu-a como: "Engenharia de "Software" é a criação e a utilização de sólidos princípios de engenharia a fim de obter software de maneira econômica, que seja confiável e que trabalhe em máquinas reais". Margaret Hamilton é creditada por ter criado o termo "engenharia de software". O próprio significado de engenharia já traz os conceitos de criação, construção, análise, desenvolvimento e manutenção.
A Engenharia de "Software" se concentra nos aspectos práticos da produção de um sistema de "software", enquanto a ciência da computação estuda os fundamentos teóricos dos aspectos computacionais.
O termo foi criado na década de 1960 e utilizado oficialmente em 1968 na "NATO Science Committee". Sua criação surgiu numa tentativa de contornar a crise do software e dar um tratamento de engenharia (mais sistemático, controlado e de qualidade mensurável) ao desenvolvimento de sistemas de "software" complexos. Um sistema de "software" complexo se caracteriza por um conjunto de componentes abstratos de "software" (estruturas de dados e algoritmos) encapsulados na forma de algoritmos, funções, módulos, objetos ou agentes interconectados entre si, compondo a arquitetura do software, que deverão ser executados em sistemas computacionais.
Os fundamentos científicos envolvem o uso de modelos abstratos e precisos que permitem ao engenheiro especificar, projetar, implementar e manter sistemas de "software", avaliando e garantindo sua qualidade. Além disto, deve oferecer mecanismos para se planejar e gerenciar o processo de desenvolvimento. Empresas desenvolvedoras de "software" passaram a empregar esses conceitos sobretudo para orientar suas áreas de desenvolvimento, muitas delas organizadas sob a forma de Fábrica de Software.
A engenharia de sistemas é uma área ampla por tratar de aspectos de sistemas baseados em computadores, incluindo "hardware" e engenharia de processos para construção de "software".
A Universidade Federal de Goiás foi pioneira no Brasil quando criou o curso de graduação em Engenharia de Software, hoje o curso ganha popularidade e já é adotado por outras universidades como PUC-Campinas, PUC-RS, Universidade de Brasilia, Universidade Federal do Ceará, Universidade Federal do Pampa, Universidade Estadual de Ponta Grossa, Universidade Federal do Amazonas, Universidade do Estado de Santa Catarina entre demais.
Os princípios da Engenharia de Software, constituem a base dos métodos, tecnologias, metodologias e ferramentas adotadas na prática e que norteiam a pratica de desenvolvimento de soluções de software. Os princípios se aplicam ao processo e ao produto de software se tornando em prática de desenvolvimento de software através da adoção de métodos e técnicas. Geralmente, métodos e técnicas constituem uma metodologia, as quais, são apoiadas pela utilização de ferramentas.
Os princípios-chave são:
Considerando o Rigor e Formalidade, deve-se considerar que a engenharia de software é uma atividade criativa, mas que deve ser realizada de maneira sistemática, o Rigor é um complemento necessário a criatividade que visa aumentar a confiança dos desenvolvimentos de software. A Formalidade é o Rigor no seu nível mais elevado. Exemplos: Analise matemática (formal) da corretude do Programa, Analises sistemáticas de dados de testes, Documentação rigorosa dos passos de desenvolvimento e os passos de gerenciamento bem como a avaliação dos prazos de entrega.
A Separação de Interesses envolve dominar a complexidade, separando os problemas principais e concentrando-se em um de cada vez ( dividir e conquistar ) suporte a paralelização de atividades e separação das responsabilidades. Exemplo: Desenvolvimento por fases de maneira incremental ( como no processo Ágil ) fazendo a separação dos interesses por atividades e respeitando o tempo. Outro exemplo relacionado a um software relaciona-se a manter os requisitos de funcionalidade, performance e interface e usabilidade de usuário em separado.
A Modularidade considera que um sistema complexo pode ser divido em peças mais simples, chamadas de módulos. Um sistema composto pode módulos é chamado de modular. Se faz fundamental que o suporte a separação de interesses seja suportada, quando lidamos com um modulo em específico deve ser possível ignorar os detalhes dos outros módulos da solução. Cada modulo deve ter alto nível de coesão, sendo entendido como uma unidade significativa, os componentes de um modulo são fortemente relacionados entre si. O baixo acoplamento remete a baixa interação de um modulo com outros do sistema possibilitando que eles sejam compreendidos como unidades em separado.
A Abstração é um conceito que visa a identificação de aspectos importantes de um fenômeno, ignorando os seus detalhes. O tipo de abstração a ser aplicado depende do propósito. Por exemplo: Os botões de um relógio são a sua interface com o usuário, eles podem ser usados como uma abstração para o propósito interno de ajustar o horário, equações que descrevem um circuito (por exemplo, um amplificador) permitem a um designer pensar sobre amplificação de sinal. Uma abstração deve tornar possível pensar sobre um sistema através do raciocínio sobre os modelos. A abstração pode ser útil para realizar uma estimativa de custos de um projeto de software através de analise de similaridade com projetos passados.
A Antecipação a Mudanças é diretamente relacionada ao suporte a evolução de um software considerando na arquitetura do software aspectos relacionados ao processo de evolução e compatibilidade com mudanças futuras relacionadas ao domínio de aplicação do software.
A Generalidade é um principio que visa durante a resolução de um problema, descobrir se ele é uma instância de um problema mais geral, no qual a solução pode ser reutilizada em outros casos. O desafio da generalidade está no balanço entre custo e performance.
A Incrementação é relacionada a evolução de um software através de incrementos estruturados. Pode ser realizado através da entrega de subconjuntos de um sistema desde cedo, visando coletar o feedback dos usuários e adicionar funcionalidades de forma incremental. O processo incremental deve focar inicialmente na funcionalidade, para então, pensarmos na performance da solução, naturalmente o protótipo amadurecerá e se tornará um produto.
Segundo o SWEBOK (Corpo de Conhecimento da Engenharia de Software), versão 2004, as áreas de conhecimento da Engenharia de Software são:
Conforme Pressman, a Engenharia de Software (ES) é uma tecnologia em camadas. E a base de todas essas camadas é o foco na qualidade do software desenvolvido. Portanto, inclusive do ponto de vista didático, é interessante estudarmos a ES em suas camadas de Processo, Métodos e Ferramentas.
Processo de "software", ou processo de engenharia de software, é uma sequência coerente de práticas que objetiva o desenvolvimento ou evolução de sistemas de "software". Estas práticas englobam as atividades de especificação, projeto, implementação, testes e caracterizam-se pela interação de ferramentas, pessoas e métodos.
SEE e PSEE são os ambientes voltados ao desenvolvimento e manutenção de processos. O projeto ExPSEE é uma continuação dos estudos de processos, principalmente do ambiente PSEE.
Devido ao uso da palavra projeto em muitos contextos, por questões de clareza, há vezes em que se prefira usar o original em inglês design.
Um modelo de processo de desenvolvimento de software, ou simplesmente modelo de processo, pode ser visto como uma representação, ou abstração dos objetos e atividades envolvidas no processo de software. Além disso, oferece uma forma mais abrangente e fácil de representar o gerenciamento de processo de software e consequentemente o progresso do projeto.
Exemplos de alguns modelos de processo de software;
Os modelos de maturidade são um metamodelo de processo. Eles surgiram para avaliar a qualidade dos processos de "software" aplicados em uma organização (empresa ou instituição). O mais conhecido é o "Capability Maturity Model Integration" (CMMi), do Software Engineering Institute - SEI.
O CMMI pode ser organizado através de duas formas: Contínua e estagiada.
Pelo modelo estagiado, mais tradicional e mantendo compatibilidade com o CMM, uma organização pode ter sua maturidade medida em 5 níveis:
O (MPS.BR), ou Melhoria de Processos do Software Brasileiro, é simultaneamente um movimento para a melhoria e um modelo de qualidade de processo voltada para a realidade do mercado de pequenas e médias empresas de desenvolvimento de software no Brasil. O MPS.BR contempla 7 níveis de maturidade, de A a G, sendo a primeira o mais maduro. Até agosto/2012, no Brasil, há somente 2 empresas neste nível.
O termo metodologia é bastante controverso nas ciências em geral e na Engenharia de Software em particular. Muitos autores parecem tratar metodologia e método como sinônimos, porém seria mais adequado dizer que uma metodologia envolve princípios filosóficos que guiam uma gama de métodos que utilizam ferramentas e práticas diferenciadas para realizar algo.
Assim teríamos, por exemplo, a Metodologia Estruturada, na qual existem vários métodos, como Análise Estruturada e Projeto Estruturado (muitas vezes denominados SA/SD, e Análise Essencial).
Dessa forma, tanto a Análise Estruturada quanto a Análise Essencial utilizam a ferramenta Diagrama de Fluxos de Dados para modelar o funcionamento do sistema.
Segue abaixo as principais Metodologias e Métodos correspondentes no desenvolvimento de software:
A abstração do sistema de "software" através de modelos que o descrevem é um poderoso instrumento para o entendimento e comunicação do produto final que será desenvolvido.
A maior dificuldade nesta atividade está no equilíbrio ("tradeoff") entre simplicidade (favorecendo a comunicação) e a complexidade (favorecendo a precisão) do modelo.
Para a modelagem podemos citar 3 métodos:
A engenharia de software aborda uma série de práticas e tecnologias, principalmente estudadas pela ciência da computação, enfocando seu impacto na produtividade e qualidade de "software".
Destacam-se o estudo de linguagem de programação, banco de dados e paradigmas de programação, como:
Outro ponto importante é o uso de ferramentas CASE (do inglês "Computer-Aided Software Engineering"). Essa classificação abrange toda ferramenta baseada em computadores que auxiliam atividades de engenharia de "software", desde a análise de requisitos e modelagem até programação e testes.
Os ambientes de desenvolvimento integrado (IDEs) têm maior destaque e suportam, entre outras coisas:
A gerência de projetos se preocupa em entregar o sistema de "software" no prazo e de acordo com os requisitos estabelecidos, levando em conta sempre as limitações de orçamento e tempo.
A gerência de projetos de software se caracteriza por tratar sobre um produto intangível, muito flexível e com processo de desenvolvimento com baixa padronização.
O planejamento de um projeto de desenvolvimento de "software" inclui:
Essas atividades sofrem com dificuldades típicas de desenvolvimento de "software". A produtividade não é linear em relação ao tamanho da equipe e o aumento de produtividade não é imediato devido aos custos de aprendizado de novos membros. A diminuição de qualidade para acelerar o desenvolvimento constantemente prejudica futuramente a produtividade.
A estimativa de dificuldades e custos de desenvolvimentos são muito difíceis, além do surgimento de problemas técnicos. Esses fatores requerem uma análise de riscos cuidadosa.
Além da própria identificação dos riscos, há que ter em conta a sua gestão. Seja evitando, seja resolvendo, os riscos necessitam ser identificados (estimando o seu impacto) e devem ser criados planos para resolução de problemas.
As atividades de análise concentram-se na identificação, especificação e descrição dos requisitos do sistema de "software". De acordo com a ISO/IEC/IEEE 24765 requisito é:
(1) condição ou capacidade necessária por um usuário para resolver um problema ou alcançar um objetivo;
(2) condição ou capacidade que deve ser atingida ou possuída por um sistema ou componente de um sistema para satisfazer um contrato, padrão, especificação ou outro documento formalmente imposto;
(3) representação documentada de uma condição ou capacidade como em (1) ou (2);
(4) condição ou capacidade que deve ser alcançada ou possuída por um sistema, produto, serviço, resultado ou componente para satisfazer um contrato, padrão, especificação ou outro documento formalmente imposto. Requisitos incluem as necessidades quantificadas e documentadas, desejos e expectativas do patrocinador, clientes e outras partes
interessadas.
Há várias classificações sobre requisitos, o PMBOK e o BABOK utilizam a seguinte classificação hierárquica:
É comum que o cliente não saiba o que ele realmente deseja, que haja problemas na comunicação e ainda que haja mudança constante de requisitos. Todos esses fatores são recrudescidos pela intangibilidade sobre características de sistemas de "software", principalmente sobre o custo de cada requisito.
A Engenharia de requisitos é um processo que envolve todas as atividades exigidas para criar e manter o documento de requisitos de sistema (SOMMERVILLE). Segundo RUMBAUGH, alguns analistas consideram a engenharia de Requisitos como um processo de aplicação de um método estrutura como a análise orientada a objetos. No entanto, a Engenharia de requisitos possui muito mais aspectos do que os que estão abordados por esses métodos.
Abaixo um pequeno Processo de Engenharia de Requisitos (SOMMERVILLE).
Estudo da viabilidade → "Relatório de Viabilidade"
Obtenção e Análise de Requisitos → "Modelos de Sistema"
Especificação de Requisitos → "Requisitos de Usuário e de Sistema"
Validação de Requisitos → "Documento de Requisitos"
O primeiro processo a ser realizado num Sistema novo é o Estudo de Viabilidade. Os resultados deste processo devem ser um relatório com as recomendações da viabilidade técnica ou não da continuidade no desenvolvimento do Sistema proposto. Basicamente um estudo de viabilidade, embora seja normalmente rápido, deverá abordar fundamentalmente as seguintes questões:
Existem cinco tipo de gestões: pessoal, produto, processo, projeto e material.
A Engenharia de Software (ES) surgiu em meados dos anos 1970 numa tentativa de contornar a crise do software e dar um tratamento de engenharia (mais sistemático e controlado) ao desenvolvimento de sistemas de software complexos. Um sistema de software complexo se caracteriza por um conjunto de componentes abstratos de software (estruturas de dados e algoritmos) encapsulados na forma de procedimentos, funções, módulos, objetos ou agentes interconectados entre si, compondo a arquitetura do software, que deverão ser executados em sistemas computacionais.
Atualmente existe um destaque todo especial para a Engenharia de Software na Web. Também utilizado por Presmann a sigla WebE, é o processo usado para criar WebApps (aplicações baseadas na Web) de alta qualidade. Embora os princípios básicos da WebE sejam muito próximos da Engenharia de Software clássica, existem peculiaridades específicas e próprias.
Com o advento do B2B (e-business) e do B2C (e-commerce), e ainda mais com aplicações para a Web 2.0, maior importância ficou sendo esse tipo de engenharia. Normalmente adotam no desenvolvimento a arquitetura MVC (Model-View-Controller).
Outra área de tendência em Engenharia de Software trata da aplicação de técnicas otimização matemática para a resolução de diversos problemas da área. A área, denominada Search-based software engineering, ou Otimização em engenharia de software em Português, apresenta vários resultados interessantes. Para mais detalhes em Português, ver texto com aplicações da otimização em engenharia de software.
O Brasil atualmente conta com diversos cursos de nível superior em Engenharia de Software nas seguintes instituições reconhecidas pelo MEC: UnB, UFRN, Universidade do Estado de Santa Catarina, Universidade Federal do Ceará, Universidade Federal de Goiás, Universidade de Rio Verde, Unipampa, UniCesumar, UTFPR e PUCRS
Eventos acadêmicos também mostram tópicos interessantes sobre futuras tendências de engenharia de software. O Brasil em 2013 sedia grandes eventos de engenharia como a Conferência Internacional de Engenharia de Requisitos e a Escola Latino Americana de Engenharia de Software.

A engenharia civil é o ramo da engenharia que engloba a concepção, o projeto, construção e manutenção de todos os tipos de infraestrutura necessários ao bem estar e ao desenvolvimento da sociedade, além da preservação do ambiente natural. Desta forma, esta área dedica-se à criação de edifícios, pontes, túneis, usinas geradoras de energia, indústrias e inúmeros outros tipos de estrutura.
Desde o início da história, os humanos passaram a construir seus próprios abrigos utilizando os elementos naturais ao seu redor. Posteriormente, as estruturas adquiriram características cada vez mais complexas, reflexo do desenvolvimento das técnicas. Passou-se então, a utilizar conhecimentos científicos nesta área, de forma que as dimensões, a resistência e outros atributos de uma determinada obra podiam ser estimados. Novos materiais passaram a ser utilizados, sobretudo ferro e cimento, que possibilitaram o surgimento das grandes estruturas que hoje compõem o cenário do mundo moderno.
Desta forma, a formação de um engenheiro civil é fortemente ligada às ciências exatas. Contudo, um bom profissional deve conter muitos outros atributos, principalmente habilidades em comunicação e de análise racional dos fatos, além de seguir um código de ética, visto que suas obras influenciam significativamente em todos os segmentos da sociedade. Dada a vasta abrangência, a engenharia civil divide-se em vários campos específicos, desde geotecnia, mapeamento, até transportes, construção e estrutural, dentre muitas outras.
A designação "engenharia civil" foi inicialmente utilizada por oposição à de "engenharia militar". Designava assim, toda a engenharia não militar. Com o passar do tempo e na maioria dos países, o termo passou a ser utilizado num âmbito mais restrito, referindo-se apenas ao ramo da construção, com os outros ramos da engenharia a receberem designações distintas (ex., industrial, agrícola, posteriormente outras). Contudo, em alguns países como a Bélgica, a Dinamarca, a França, a Noruega e a Suécia, os engenheiros não militares são ainda genericamente referidos como "engenheiros civis", independentemente da sua especialidade ser a construção ou outra (mecânica, química, eletricidade, etc.).
Desde o início da existência humana, conhecimentos e habilidades de engenharia tem sido necessários para evolução do padrão de vida. A partir do momento em que tribos deixaram de ser nômades, surgiram assentamentos que necessitavam de estrutura necessária para abrigo e proteção que, ao longo do tempo, cresceram em complexidade. Ao decorrer dos séculos, a grande demanda por estruturas cada vez maiores e mais eficientes impulsionava o surgimento de novas técnicas e a formação de profissionais habilitados para assumir tal responsabilidade. Entretanto, a profissão de engenheiro civil só foi reconhecida oficialmente a partir da Revolução Industrial.
São diversas as obras remanescentes que atestam o desenvolvimento da engenharia civil ao longo de milênios. Os registros escritos destas construções, contudo, se perderam no tempo. Grandes obras de engenharia surgiram há mais de cinco mil anos na Mesopotâmia, embora haja poucos edifícios remanescentes. Os sumérios que habitavam a região construíram muros e templos e criaram canais para irrigação. Ainda na mesma região surgiu a pavimentação, feita com pedras achatadas colocadas nos trajetos mais movimentados das cidades. Ainda na Mesopotâmia há registro da primeira ponte feita de pedra, que se estendia sobre o rio Eufrates. Até então, as pontes eram feitas somente com madeira.
Os pérsios, ao longo do tempo e de seus vastos domínios, foram responsáveis por criar novas e eficientes técnicas de irrigação, além de inovarem nas técnicas construtivas de pontes, especialmente para fins militares. No Antigo Egito, dentre as mais notáveis obras de engenharia destacam-se as Pirâmides de Gizé, feitas há mais de quatro mil anos, e a cidade de Alexandria (durante a era de Alexandre, o Grande), na qual foi concebido um grande farol, não mais existente. Contudo, na Grécia Antiga, houve, pela primeira vez, a conexão entre a engenharia e a ciência pura, sendo um dos primeiros trabalhos considerando aplicações práticas de princípios físicos e matemáticos atribuído à Arquimedes, que criou um sistema capaz de transportar água para diferentes elevações.
Durante a expansão do Império Romano, houve o surgimento de novas técnicas construtivas, especialmente a partir da grande oferta de matérias-primas e trabalho escravo. Embora não tenha grande ligação com a ciência, a engenharia praticada pelos romanos estava fortemente ligada ao pragmatismo. As grandes estruturas eram voltadas sobretudo para bens públicos, como aquedutos, portos, mercados, pontes, barragens e estradas. Vitrúvio foi o autor de um dos manuscritos mais antigos sobre engenharia, no qual descreve as técnicas e habilidades que um profissional deve dominar, como conhecimentos científicos, filosóficos e éticos, dentre outros. Os romanos também foram os primeiros a utilizar concreto em suas obras, quando descobriu-se que uma mistura formada principalmente por cinzas vulcânicas solidificava-se e dava origem a um material tão duro quanto as rochas.
Na Índia a maior parte das construções eram feitas com madeira. Contudo, a partir do surgimento do budismo, novos e grandes templos e monastérios foram construídos no topo e nas bordas das montanhas, o que exigiu novas técnicas que faziam o uso de pedras e rochas. De forma similar, o hinduísmo motivou o surgimento de grandes templos construídos com pedras. As técnicas de engenharia na China, por outro lado, desenvolveram-se de forma quase independente àquelas do mundo ocidental. Os chineses utilizavam-se da grande variedade de matérias primas existentes em seu território para construção das fundações de pedra e casas de tijolos e telhados de argila. Destaca-se, ainda o surgimento de pontes suspensas antes feitas com fibras de bambu e posteriormente com correntes de ferro, além dos pagodes, templos em forma de torres. Contudo, a mais notável obra ainda remanescente é a Muralha da China, que se estende por milhares de quilômetros e cuja construção iniciou-se em 220 a.C.
No continente africano ao sul do deserto do Saara, as obras com estilos mais simples utilizavam-se dos materiais existentes e dependiam da cultura das milhares de etnias diferentes do continente. Destaca-se, contudo, um local de cunho religioso, o Grande Zimbabwe, cuja origem remonta ao século XI. Na América, por fim, as grandes civilizações inovaram em técnicas que os permitiram criar grandes templos, especialmente de cunho religioso. Durante a civilização Maia, muitas grandes obras foram realizadas, das quais destaca-se a cidade de Teotihuacan. Os Incas, séculos depois, estenderam seus domínios na cordilheira dos Andes e criaram elementos de infraestrutura como pontes, estradas e complexos urbanos, centralizados na então capital, Cusco. Dentre os principais feitos dos Astecas, contemporâneos dos Incas, destaca-se a cidade de Tenochtitlán, capital do império dotada de complexos componentes urbanos, localizada numa região pantanosa no centro de um lago.
O Império Romano, devido à sua grande extensão e falta de governo central, não conseguiu se manter unido e chegou ao fim no ano de 476. Muitas das obras de infraestrutura, inclusive estradas, aquedutos e portos então existentes, foram demolidas para construção de fortificações. Durante todo o período medieval, quase não houve avanços científicos, o que afetou também o desenvolvimento de técnicas de engenharia, que passaram a se restringir a conceitos práticos pouco estruturados. Os árabes, sobretudo durante o período da expansão islâmica, incorporaram técnicas romanas sobretudo utilizadas em fortificações, embora já possuíssem conhecimentos na construção de grandes mesquitas.
Não havia método científico nas construções, pelo que eram baseadas no sistema de tentativa e erro, sendo numerosos os exemplos de colapso de estruturas. Neste período nota-se, ainda, a criação de grandes fortificações em castelos, para prevenir invasões. Houve um avanço na utilização de rodas de água para transportar água e mover moinhos. Ocorreram também avanços na construção de canais navegáveis.
A partir da Renascença, o profissional engenheiro passou a ganhar importância e reconhecimento, ao contrário do período medieval em que projetos eram criados por artesãos. Um dos pioneiros do período foi Filippo Brunelleschi, que projetou o domo da catedral de Santa Maria del Fiore em Florença. Ainda com o surgimento da impressão de livros, começaram a surgir os primeiros manuais com técnicas de projeto e construção.
Posteriormente, a Revolução Industrial começava a mudar radicalmente o perfil da Inglaterra, o que posteriormente viria a acontecer no restante da Europa. A população começou a migrar da zona rural para as cidades para trabalharem nas indústrias. As obras estruturais necessárias para o desenvolvimento industrial era geralmente conduzida por engenheiros militares. No entanto, em 1768, o inglês John Smeaton se autodenominou 'engenheiro civil' para diferenciar-se dos profissionais militares, criando assim uma nova e distinta profissão. Poucos anos depois criou a Sociedade dos Engenheiros Civis, com a finalidade de reunir profissionais para conceber e executar grandes projetos.
A Revolução Industrial trouxe consigo novas técnicas e materiais pertinentes à engenharia. A Ponte de Ferro, no Reino Unido, foi a primeira ponte de arco construída somente com ferro fundido, o que é considerado um marco na história. Conforme ocorria o crescimento econômico, era cada vez maior a necessidade de se acelerar os transportes. Por isso, houve grande ampliação do sistema de canais e posteriormente surgiu a primeira ferrovia. A utilização do ferro como elemento estrutural causou grandes mudanças, especialmente por conta de sua resistência, capacidade de pré-fabricação e facilidade de montagem. Os engenheiros civis, a partir de então, puderam inovar no formato dos prédios, além de agilizar sua construção. Houve ainda inovação no que se refere à construção de túneis, a partir do primeiro construído sob o rio Tâmisa em Londres para a criação do sistema metroviário londrino.
A partir do século XX, a engenharia como um todo passou a se desenvolver e se especializar sobretudo por conta dos avanços científicos e fundamentações teóricas do comportamento dos materiais. A partir de então surgiram grandes estruturas antes inimagináveis, como o Viaduto de Millau, na França, a mais alta ponte para veículos do mundo, e o Burj Khalifa, o mais alto edifício do mundo, com mais de oitocentos metros de altura. A Sociedade Americana de Engenheiros Civis compilou uma lista com as sete maravilhas do mundo moderno, das quais destacam-se o Eurotúnel, sob o estreito de Dover entre o Reino Unido e a França, o canal do Panamá, que liga o oceano Pacífico ao Atlântico e a Usina Hidrelétrica de Itaipu entre o Brasil e o Paraguai.
A demanda de profissionais especializados logo demandou o surgimento de centros de ensino voltados para a engenharia. O primeiro deles foi a École Polytechnique em Paris, criada no ano de 1794. Várias décadas depois academias surgiram pela Europa e Estados Unidos, onde, em 1835, formaram-se os primeiros engenheiros civis pela Instituto Politécnico Rensselaer.
É necessária para a formação de um engenheiro civil uma forte base na área de ciências exatas, especialmente matemática e física, além da análise de dados, concepção, planejamento e execução de sistemas, identificação e solução de problemas e uso prático de técnicas e habilidades. Desta forma, o curso geralmente apresenta uma combinação de várias especialidades científicas, como mecânica, hidráulica, geotécnica, ciências dos materiais e análises estatísticas. Estes conhecimentos passam a ser aplicados para o desenvolvimento de projetos, especialmente com o uso de ferramentas de desenho assistido por computador (CAD). O período de formação em engenharia civil leva entre três anos para o grau de licenciatura ou cinco anos para o grau de mestrado. São grandes ainda as opções de especialização, dada a vasta gama de temas que um curso de engenharia civil abrange. Deve haver ainda uma preocupação durante a formação no que se refere a conceitos de legislação, economia e ética, uma vez que as atividades de um engenheiro civil afetam grande parte dos segmentos da sociedade.
Um engenheiro civil é um profissional capacitado para conceber, projetar e construir os mais diversos componentes da infraestrutura necessários para o bem-estar e desenvolvimento da sociedade. O local de trabalho de um engenheiro varia conforme a especialidade escolhida, embora a maioria trabalhe em firmas de consultoria, que criam projetos e soluções para construção de determinada estrutura. Existem ainda muitas possibilidades no setor público, desde o âmbito municipal até federal, além da possibilidade de atuar em carreira militar ou no setor industrial. Tipicamente o engenheiro precisa visitar os locais de obra e trabalhar com diferentes equipes técnicas especializadas. A Associação Americana de Engenheiros Civis define engenharia civil como sendo:
Em geral, um engenheiro civil deve ser um profissional devidamente preparado com base em aspectos teóricos que lhe conferem uma habilidade de análise racional das situações. Desta forma, é necessária uma sólida formação em ciências exatas, especialmente matemática e física. Além disso, o profissional deve seguir um código de ética, dada a importância de sua função na sociedade, que inclui realizar seu trabalho de forma responsável, buscando sempre contribuir ao máximo para o bem estar da sociedade. Um atributo indispensável de um engenheiro civil é a sua capacidade de comunicação e liderança, visto que frequentemente é necessária a coordenação entre diversos tipos de profissionais para uma determinada finalidade.
Existem na maioria dos países associações de engenheiros civis que buscam a troca de conhecimento e a divulgação e aperfeiçoamento de técnicas. As pioneiras e atualmente mais importantes são o Instituto Britânico de Engenheiros Civis e a Sociedade Americana de Engenheiros Civis. Para exercer a profissão, o engenheiro civil precisa obter certificação e licença formal, tipicamente fornecida por estas associações. No Brasil, a certificação é fornecida pelo Conselho Federal de Engenharia e Agronomia, através de seus conselhos regionais. Em Portugal, a validação do diploma é feita pela Agência de Avaliação e Acreditação do Ensino Superior.
As tendências atribuídas para a engenharia civil estão diretamente relacionadas às transformações naturais, sociais e econômicas que o mundo tem experimentado nas últimas décadas. Com a migração da população para as cidades será necessário a utilização racional dos recursos naturais, utilizando meios sustentáveis de desenvolvimento. Será necessário o aumento, melhoria e manutenção da infraestrutura urbana, além da maior preocupação no fornecimento de água, energia aliados à correta disposição dos resíduos gerados. Desta forma, o engenheiro tem papel fundamental na determinação dos rumos do desenvolvimento, tendo em vista os benefícios à sociedade e a proteção do ambiente.
A engenharia civil, por sua própria natureza, é uma área na qual erros causam grandes consequências. Desta forma, o profissional deve desenvolver com o máximo de atenção para evitar erros atribuídos a omissões, falta de planejamento, erros durante o processo de construção e relacionados à qualidade dos componentes. Há a necessidade de avaliação cuidadosa do ambiente na qual determinada estrutura será instalada, a fim de garantir sua durabilidade a longo prazo. Um engenheiro precisa, ainda, ser capaz de aprender com erros anteriores relatados em outras obras, de forma que haja minimização dos riscos. Dentre os exemplos notáveis de falhas estão o desabamento do teto do terminal 2 do Aeroporto de Paris-Charles de Gaulle em 2004 e a Ponte Tacoma Narrows que, em 1940, entrou em colapso por ação do vento.
 concreto protendido, estruturas de madeira, fundações).
No grande geral as universidades oferecem aos acadêmicos cursos com dez períodos semestrais (cinco anos) quando estes são lecionados em dois períodos diários (Ex. matutino e vespertino), também é possível encontrar cursos apenas noturnos, que são ofertados para que os acadêmicos possam trabalhar, mas estes duram em média sete a oito anos.
Um engenheiro civil tipicamente interage com a interface dos projetos e seu ambiente de implantação. Em geral é capaz de aplicar os princípios básicos de construção, estruturais, geotécnicos, hidráulicos e de transporte para a construção de edifícios residenciais, industriais ou outras obras públicas de diferentes tipos e finalidades. Contudo, há a necessidade de se interagir em diversas ocasiões com profissionais especializados em uma determinada área, dada a abrangência desta profissão.
Dentre as áreas de atuação de um engenheiro civil, está a de Recursos Energéticos. Esse profissional pode se relacionar com fontes de energia relacionadas com Engenharia ambiental, como as tradicionais, alternativas e renováveis, com sistemas e métodos de conversão e conservação de energia, com impactos energéticos ambientais e com a eficientização ambiental de sistemas energéticos vinculados ao campo de atuação da engenharia ambiental.
Como é característica da área de engenharia civil, há diversas funções que podem ser desempenhadas por esse engenheiro que envolve recursos energéticos. O mercado de trabalho é constituído por Empresas Públicas, Privadas ou de Economia Mista, Órgãos Governamentais nas três esferas de governo, além de organizações sociais de interesse público e Organizações não Governamentais.
As atividades desenvolvidas são várias, dentre elas o diagnóstico do melhor tipo e melhores condições de uso de energia, planejar e coordenar o processo de implantação de usinas e analisar os impactos (sociais, econômicos e ambientais) no local de instalação, desenvolver tecnologia para a geração, uso e transformação de energia e a otimização do consumo de energia nas indústrias, com o objetivo de reduzir gastos.
Os locais de atuação podem ser em escritórios ou em campo, fixo ou variável, dependendo da atividade desenvolvida pelo profissional. Por exemplo, para analisar impactos de instalação de usinas, o trabalho envolve pesquisa em campo e em escritório.
Este ramo lida com a execução e gerenciamento de obras, levando em conta custos, eficiência e segurança. Dentre as atividades desenvolvidas, destacam-se a criação de fundações, concretagem, acabamento, construção de pontes e túneis, dentre muitos outros exemplos. O profissional especializado nesta área deve possuir domínio sobre as técnicas e equipamentos modernos disponíveis. Dentre as funções de gerenciamento busca-se a economia e a utilização racional dos recursos disponíveis com o objetivo principal de aumentar a eficiência. O profissional é responsável ainda pela utilização dos materiais de qualidade que visem a segurança e a durabilidade da obra a longo prazo, além de organizar toda a logística necessária para o transporte e a utilização dos materiais, funcionários e equipamentos. Este segmento lida ainda com os aspectos legais de uma obra, como a criação e revisão de contratos e concordância com a legislação vigente.
Esta subdisciplina tem como fundamento o estudo das infraestruturas relacionadas direta ou indiretamente com sistemas de transportes e seu possível desenvolvimento e manutenção. O princípio básico desta área é o transporte de pessoas e mercadorias de forma rápida, econômica e segura. Desta forma, esta especialidade lida com o planejamento e manutenção de rodovias, ferrovias, sistema hidroviários e aeroviário e sua interação, de forma a criar uma rede eficiente. Desta forma, o engenheiro de transporte pode atuar desde a concepção de uma via de trasporte e sua construção até o planejamento e gerenciamento do tráfego.
Focada no projeto de estruturas em edificações, a engenharia estrutural busca a concepção de elementos seguros e econômicos para fornecer rigidez e resistência a um edifício. Portanto, são necessários o uso de princípios físicos, conhecimento das características dos materiais e ferramentas computacionais para realizar o dimensionamento correto de vigas, colunas e outros elementos, inclusive a fundação. O engenheiro estrutural pode escolher dentre os diversos materiais disponíveis no mercado, de acordo com a necessidade de cada projeto. Pode atuar nos mais diversos segmentos de obras, desde prédios, pontes e túneis até plataformas de petróleo e gás em alto mar.
O campo dos recursos hídricos incluem uma série de métodos e conhecimentos relacionados a processos hidrológicos e hidráulicos utilizados como base para o planejamento e dimensionamento de estruturas para realizar o fornecimento de água, prevenção de enchentes, criação de redes de irrigação e geração de energia, dentre muitas outras aplicações. Em geral, este ramo engloba todos os campos do conhecimento que, de alguma forma, relacionam-se com a água, desde o subsolo, rios, lagos e oceanos até o gerenciamento de água da chuva. Além de sistemas de distribuição de água, um engenheiro hidráulico atua na construção de canais, usinas hidroelétricas, sistemas de proteção costeiros, dentre inúmeros outros exemplos. Um engenheiro hídrico também deve preocupar-se com os impactos ambientais de suas obras, especialmente sobre a vida aquática, além de aspectos dos arredores como estética e utilização pública.
A engenharia geotécnica é o ramo que se preocupa com os componentes que se encontram na superfície terrestre, como o solo e as rochas, e sua principal aplicação refere-se ao comportamento e a capacidade destas estruturas ao receberem sobre si a fundação das demais obras de infraestrutura, especialmente suas fundações. Dentre os atributos analisados na mecânica dos solos e das rochas, incluem sua origem, distribuição granulométrica, capacidade de drenagem, resistência à compressão e capacidade de cargas, dentre outros.
A análise destas variáveis é necessária para que se obtenha segurança e firmeza duradouras, uma vez que todo o peso de uma determinada estrutura é transferido para o solo, e este deve ser capaz de suportar tal estrutura. Um dos exemplos mais notáveis de erros relacionados ao mal planejamento geotécnico é a Torre de Pisa, inclinada porque o solo sob sua base não suportou o peso e afundou, de forma que a torre perdesse seu alinhamento. Reforços na estrutura são responsáveis por mantê-la ainda de pé.
Lida com a interação entre os elementos abióticos e a biosfera, especialmente no que se refere à proteção ambiental, manejo de recursos e minimização dos impactos ambientais. Destaca-se nesta área de atuação a distribuição de água e criação de infraestruturas para o saneamento básico. Com a crescente urbanização, tornou-se cada vez maior a demanda de componentes hidrossanitários e, consequentemente, manutenção da saúde pública. Os resíduos gerados também precisam ser tratados para que não haja poluição dos rios ou de qualquer outro local de despejo. Muitos locais, contudo, ainda enfrentam problemas severos com a poluição, especialmente provocada por detritos industriais, além do despejo incorreto de lixo, dentre outros. Desta forma, a engenharia ambiental procura entender todos os impactos provocados no ambiente e suas consequências, inclusive, para a população, além de propor possíveis soluções para que as atividades humanas causem o menor prejuízo possível para os ecossistemas.
Para que haja a criação de uma nova infraestrutura é imprescindível que haja um levantamento detalhado da área a ser ocupada, o que é feito por meio de mapeamentos conforme o futuro da construção. O profissional especializado é responsável pela coleta de dados em campo e confecção de mapas que servirão de base para o planejamento. Desta forma, são efetuadas medidas em determinados pontos, cujos dados são reunidos de forma a criar um modelo do terreno. Estes dados podem ser coletados com uma vasta gama de equipamentos existentes, desde instrumentos rústicos como teodolitos e fitas métricas para a determinação de ângulos e distâncias, até estações totais e o Sistema de Posicionamento Global (GPS), cada um de acordo com as circunstâncias. Existe ainda a possibilidade de atuação em áreas como planejamento urbano, gerenciamento de situações de desastre e manejo ambiental, utilizando técnicas modernas como os sistemas de informações geográficas, sensoriamento remoto e fotografias aéreas, dentre outras.


Теорія алгоритмів () — окремий розділ математики, що вивчає загальні властивості алгоритмів. Виникла в 30-х роках 20 століття.
Алгоритми, проте, простежуються в математиці протягом всього часу її існування. Необхідність точного математичного уточнення інтуїтивного поняття алгоритму стала неминучою після усвідомлення неможливості існування алгоритмів розв'язку багатьох масових проблем, в першу чергу пов'язаних з арифметикою та математичною логікою (проблеми істинності арифметичних формул та формул першопорядкового числення предикатів, 10-та проблема Гільберта про розв'язність діофантових рівнянь та ін.). Для доведення неіснування алгоритму треба мати його точне математичне визначення, тому після сформування поняття алгоритму як нової та окремої сутності першочерговою стала проблема знаходження адекватних формальних моделей алгоритму та дослідження їх властивостей. При цьому формальні моделі були запропоновані як для первісного поняття алгоритму, так і для похідного поняття алгоритмічно обчислюваної функції.
Вперше поняття алгоритму з'явилося в працях Е. Бореля (1912) та Г. Вейля (1921).
Першими формальними моделями алгоритмічно обчислюваних функцій були "λ-означувані функції" (Алонзо Черч, 1932) та "загальнорекурсивні функції" (Курт Гедель, 1934). Вказані класи визначались як функції, графіки яких породжуються відповідно численням λ-конверсій та численням Ербрана-Геделя. В 1936 році Стівен Коул Кліні поширив поняття загальнорекурсивної функції на випадок часткових функцій, ввівши поняття частково рекурсивної функції, та описав клас таких функцій в чисто функціональних термінах. В 1943 році Еміль Пост запропонував модель обчислюваних функцій на основі введеного ним числення спеціального вигляду ("канонічних систем").
Для формалізації самого поняття алгоритму були запропоновані точні математичні описи алгоритмічної машини та обчислюваності на ній. Першою формальною моделлю алгоритмічної машини була машина Тюрінга (Алан Тюрінг, Еміль Пост, 1936). Із пізніших моделей відзначимо нормальні алгоритми (А. Марков, І952) та регістрові машини (Д. Шепердсон, Г. Стерджіс, 1963).
В 1936 р.А. Черч та С. Кліні довели збіг класів загально-рекурсивних та λ-означуваних функцій. На основі цього факту та аналізу ідей, які привели до вказаних понять, А. Черч висунув тезу про збіг класу АОФ з класом загальнорекурсивних функцій. С. Кліні узагальнив цю тезу для випадку часткових функцій. Доведений А. Тьюрінгом в 1937 р. збіг класів частково рекурсивних функцій та функцій, обчислюваних на машинах Тюрінга, стало ще одним підтвердженням тези Черча. Пізніше такі збіги були встановлені для всіх відомих формальних моделей АОФ. Тому є всі підстави вважати, що кожна із названих вище формальних моделей адекватно уточнює інтуїтивне поняття АОФ.
Теорія алгоритмів виникла як розділ математичної логіки, поняття алгоритму тісно пов'язане з поняттям числення. Перші та найчисельніші застосування теорія алгоритмів має саме в математичній логіці. Теорія алгоритмів є теоретичним фундаментом програмування, вона має застосування всюди, де зустрічаються алгоритмічні проблеми (основи математики, теорія інформації, теорія керування, конструктивний аналіз, обчислювальна математика, теорія ймовірності, лінгвістика, економіка та ін.).
Областю застосовності алгоритму називається сукупність тих об'єктів, до яких його можна застосувати, тобто в застосуванні до яких він дає результат. Про алгоритм "U" кажуть, що він: 1) «"обчислює функцію" "f"», коли його область застосування збігається з областю визначення "f", і "U" перетворює будь-який "х" зі своєї області застосування в "f(х)"; 2) «"розв'язує множину A відносно множини X"», коли він застосовується до будь-якого "х" з "X", і перетворює будь-який "х" з" X∩A" на слово «так», а будь-який "х" з "Х\А" — на слово «ні»; 3) «"перераховує множину B"», коли його область застосування є натуральний ряд, а сукупність результатів є "B". Функція наз. обчислюваною, якщо існує алгоритм, що її обчислює. Множина називається "розв'язною" відносно "X", якщо існує алгоритм, що розв'язує її відносно "X". Множина наз. перераховуваною, якщо або вона порожня, або існує перераховуючий її алгоритм.
Детальний аналіз поняття «алгоритм» виявляє, що (I) область можливих вихідних даних і область застосовності будь-якого алгоритму є перераховуваними множинами. Своєю чергою, (II) для будь-якої пари вкладених одна в другу перераховуваних множин можна підібрати алгоритм, у якого більша множина слугує областю можливих вихідних даних, а менша — областю застосовності. Мають місце такі основні теореми: (III) функція "f" обчислювана тоді і тільки тоді, коли перераховуваний її графік, тобто множина всіх пар вигляду "<х, f(x)>". (IV) Підмножина "А" перераховуваної множини "X" тоді і тільки тоді розв'язна відносно" X", коли "А" і "X\A" перераховувані. (V) Якщо "А" і "В" перераховувані, то "A об'єднати B" і "A∩B" також перераховувані. (VI) В кожній нескінченній перераховуваній множині "X" існує перераховувана підмножина з неперераховуваним доповненням (в силу (IV) ця перераховувана підмножина буде нерозв'язною відносно "X"). (VII) Для кожної нескінченної перераховуваної множини" X" існує обчислювана функція, визначена на підмножині цієї множини і яка не продовжувана до обчислюваної функції, визначеної на всій "X". Твердження (VI) і (II) в сукупності дають приклад алгоритму з нерозв'язною областю застосовуваності.
Розв'язні і перераховувані множини складають найпростіші (і найважливіші) приклади множин, структура яких задається за допомогою тих чи тих алгоритмічних процедур. Систематичне вивчення множин конструктивних об'єктів з точки зору таких властивостей цих множин, які зв'язані з наявністю тих чи тих алгоритмів, утворює так звану алгоритмічну теорію множин.
Теорію алгоритмів можна розділити на "дескриптивну" (якісну) і "метричну" (кількісну). Перша досліджує алгоритми з точки зору встановлюваної ними відповідності між вихідними даними і результатами; до неї належать, зокрема, проблеми побудови алгоритму, що йому властиві ті чи ті властивості,— алгоритмічні проблеми. Друга досліджує алгоритми з точки зору складності як самих алгоритмів, так і обчислень, що ними задаються, тобто процесів послідовного перетворення конструктивних об'ектів (див. Складність алгоритму). Важливо підкреслити, що як складність алгоритмів, так і складність обчислень можуть визначатися різними способами. Розробка методів оцінки складності алгоритмів і обчислень має важливе теоретичне і практичне значення.
Серед інших поширених математичних моделей алгоритмів можна назвати:
Алан Тьюринг висловив припущення (відоме як Теза Черча - Тьюринга), що будь-який алгоритм в інтуїтивному сенсі цього слова може бути представлений еквівалентною машиною Тьюринга. Уточнення уявлення про обчислюваності на основі поняття машини Тьюринга (і інших аналогічних їй понять) відкрило можливості для суворого доказу алгоритмічної нерозв'язності різних масових проблем (тобто проблем про знаходження єдиного методу рішення деякого класу задач, умови яких можуть змінюватися в певних межах). Найпростішим прикладом алгоритмічно нерозв'язної масової проблеми є так звана проблема застосовності алгоритму (звана також проблемою зупинки). Вона полягає в наступному: потрібно знайти спільний метод, який дозволяв би для довільної машини Тьюринга (заданої за допомогою своєї програми) і довільного початкового стану стрічки цієї машини визначити, чи завершиться робота машини за кінцеве число кроків, або ж буде тривати необмежено довго.
Протягом першого десятиліття історії теорії алгоритмів нерозв'язні масові проблеми були виявлені лише всередині самої цієї теорії (сюди відноситься описана вище проблема застосовності), а також всередині математичної логіки (проблема виводу в класичному численні предикатів). Тому вважалося, що теорія алгоритмів є узбіччя математики, що не має значення для таких її класичних розділів, як абстрактна алгебра або математичний аналіз. Положення змінилося після того, як А. А. Марков і Е. Л. Пост в 1947 році встановили алгоритмічну нерозв'язність відомої в алгебрі проблеми рівності для кінцево-створених і кінцево-визначених напівгруп (т. Н. Проблеми ТУЕ). Згодом було встановлено алгоритмічна нерозв'язність і багатьох інших «чисто математичних» масових проблем. Одним з найбільш відомих результатів в цій області є доведена Ю. В. Матіясевіч алгоритмічна нерозв'язність десятої проблеми Гільберта.
У всіх областях математики, в яких зустрічаються алгоритмічні проблеми. Такі проблеми виникають практично в усіх розділах математики. В математичній логіці для кожної теорії формулюється проблема розв'язування множини всіх істинних або довідних тверджень цієї теорії відносно множини всіх її пропозиції (теорії поділяються на розв'язні і нерозв'язні в залежності від розв'язності або нерозв'язності вказаної проблеми); у 1936 р. А. Черч встановив нерозв'язність проблеми розв'язності для множини всіх істинних пропозицій логіки предикатів, подальші важливі результати в цьому напрямі належать А. Тарському, А. І. Мальцеву та інші. Нерозв'язні алгоритмічні проблеми зустрічаються в алгебрі (проблема тотожності для напівгруп і, зокрема, для груп; перші приклади напівгруп з нерозв'язною проблемою тотожності були винайдені в 1947 р. незалежно А. А. Марковим і Е. Постом, а приклад групи з нерозв'язною проблемою тотожності — в 1952 р. П. С. Новіковим); в топології (проблема гомеоморфії, нерозв'язність якої для важливого класу випадків була доведена в 1958 р. А. А. Марковим); в теорії чисел (проблема розв'язності діофантових рівнянь, нерозв'язність якої була встановлена в 1970 р. Ю. В. Матіясевичем) та в інших розділах математики.
Теорія алгоритмів тісно зв'язана:
В даний час теорія алгоритмів розвивається, головним чином, за трьома напрямками.
Метою аналізу трудомісткості алгоритмів є знаходження оптимального алгоритму для вирішення даного завдання. Як критерій оптимальності алгоритму вибирається трудомісткість алгоритму, що розуміється як кількість елементарних операцій, які необхідно виконати для вирішення задачі за допомогою даного алгоритму. Функцією трудомісткості називається відношення, що зв'язують вхідні дані алгоритму з кількістю елементарних операцій.
Трудомісткість алгоритмів по-різному залежить від вхідних даних. Для деяких алгоритмів трудомісткість залежить тільки від обсягу даних, для інших алгоритмів - від значень даних, в деяких випадках порядок надходження даних може впливати на трудомісткість. Трудомісткість багатьох алгоритмів може в тій чи іншій мірі залежати від всіх перерахованих вище факторів.
Одним з спрощених видів аналізу, що використовуються на практиці, є асимптотичний аналіз алгоритмів. Метою асимптотичного аналізу є порівняння витрат часу та інших ресурсів різними алгоритмами, призначеними для вирішення однієї і тієї ж задачі, при великих обсягах вхідних даних. Використовувана в асимптотичному аналізі оцінка функції трудомісткості, звана складністю алгоритму, дозволяє визначити, як швидко зростає трудомісткість алгоритму зі збільшенням обсягу даних. У асимптотичному аналізі алгоритмів використовуються позначення, прийняті в математичному асимптотичному аналізі. Нижче перераховані основні оцінки складності.
Основною оцінкою функції складності алгоритму f(n) є оцінка formula_1. Тут n - величина обсягу даних або довжина входу. Ми говоримо, що оцінка складності алгоритму
formula_2
якщо при g > 0 при n > 0 існують додатні с, с, n, такі, що:
formula_3
при n > n, інакше кажучи, можна знайти такі с і c, що при достатньо великих n f(n) буде знаходитьсь між
formula_4 і formula_5.
У такому випадку говорять ще, що функція g(n) є асимптотично точною оцінкою функції f(n), так як за визначенням функція f(n) не відрізняється від функції g(n) з точністю до постійного множника. Наприклад, для методу сортування heapsort оцінка трудомісткості становить
formula_6 то є formula_7
Із formula_2 випливає, що formula_9.
Важливо розуміти, що formula_10 представляє собою не функцію, а безліч функцій, що описують зростання formula_11 з точністю до постійного множника.
formula_12 дає одночасно верхню і нижню оцінки зростання функції. Часто буває необхідно розглядати ці оцінки окремо. Оцінка formula_13 представляє собою верхню асимптотичну оцінку трудомісткості алгоритму.
Ми говоримо, що formula_14 якщо
formula_15
Інакше кажучи, запис formula_16 означає, що f(n) належить класу функцій, що ростуть не швидше, ніж функція g(n) з точністю до постійного множника.
Оцінка formula_17 задає нижню асимптотичну оцінку зростання функції f(n) і визначає клас функцій, які ростуть не повільніше, ніж g(n) з точністю до постійного множника. formula_18 якщо
formula_19
Наприклад, запис formula_20 позначає клас функцій, які ростуть не повільніше, ніж formula_21, в цей клас потрапляють всі поліноми зі ступенем більшої одиниці, так само як і всі статичні функції з повним правом великої одиниці.
Рівність formula_22 виконується тоді і тільки тоді, коли formula_14 і formula_24.
Асимптотичний аналіз алгоритмів має не тільки практичне, але і теоретичне значення. Наприклад, доведено, що всі алгоритми сортування, засновані на попарному порівнянні елементів, відсортують n елементів за час, не менше formula_25.
Важливу роль у розвитку асимптотичного аналізу алгоритмів зіграли A. Ахо, Дж. Ульман, Дж. Хопкрофта.
В рамках класичної теорії здійснюється класифікація завдань за класами складності (P-складні, NP-складні, експоненціально складні і ін.). До класу P відносяться завдання, які можуть бути вирішені за час, залежне від обсягу вихідних даних, за допомогою детермінованої обчислювальної машини (наприклад, машини Тьюринга), а до класу NP - завдання, які можуть бути вирішені за виражений час за допомогою недетермінованої обчислювальної машини, тобто машини, наступний стан якої не завжди однозначно визначається попередніми. Роботу такої машини можна уявити як розгалужується на кожній неоднозначності процесу: завдання вважається вирішеним, якщо хоча б одна гілка процесу прийшла до відповіді. Інше визначення класу NP: до класу NP відносяться завдання, вирішення яких за допомогою додаткової інформації довжини, даної нам згори, ми можемо перевірити за поліноміальний час. Зокрема, до класу NP відносяться всі завдання, вирішення яких можна "перевірити" за поліноміального часу. Клас P міститься в класі NP. Класичним прикладом NP-задачі є задача про комівояжера.
Оскільки клас P міститься в класі NP, приналежність того чи іншого завдання до класу NP часто відображає наше поточне уявлення про способи вирішення даного завдання і носить неостаточний характер. У загальному випадку немає підстав вважати, що для того чи іншого NP-завдання не може бути знайдено P-рішення. Питання про можливість еквівалентності класів P і NP (тобто про можливість знаходження P-рішення для будь-якої NP-задачі) вважається одним з основних питань сучасної теорії складності алгоритмів. Відповідь на це питання не знайдена досі. Сама постановка питання про еквівалентність класів P і NP можлива завдяки введенню поняття NP-повних задач. NP-повні задачі складають підмножина NP-задач і відрізняються тією властивістю, що все NP-завдання можуть бути тим чи іншим способом зведені до них. З цього випливає, що якщо для NP-повної задачі буде знайдено P-рішення, то P-рішення буде знайдено для всіх завдань класу NP. Прикладом NP-повної задачі є задача про кон'юнктивні форми.
Дослідження складності алгоритмів дозволили по-новому поглянути на вирішення багатьох класичних математичних задач і знайти для ряду таких завдань (множення многочленів і матриць, рішення лінійних систем рівнянь і ін.) Рішення, які вимагають менше ресурсів, ніж традиційні.

